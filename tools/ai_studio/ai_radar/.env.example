# AI Radar â€” Translation & LLM settings

# Enable/disable translation enrichment (title/excerpt i18n)
RADAR_DO_TRANSLATE=1

# Translate scope:
#   - Set to 'all' (recommended) to translate every item in the window
#   - Or set a number (e.g., 20) to limit by hotness
RADAR_TRANSLATE_TOP=all

# Alternative explicit switch. If set to 1, overrides TOP to all
RADAR_TRANSLATE_ALL=1

# Token and timeout caps for the translator
RADAR_TRANSLATE_MAX_TOKENS=900   # per call max tokens for responses
RADAR_TRANSLATE_TIMEOUT=480       # seconds (if your provider supports per-call timeout)
RADAR_TRANSLATE_EXCERPTS=1       # 1=also translate excerpts; 0=translate titles only

# Enable a local fake-translation mode for testing without API calls
# When 1, translations will be stubbed with markers to verify UI and pipeline
RADAR_FAKE_TRANSLATE=0

# Provider selection (ai_llm.py)
PREFERRED_PROVIDER=deepseek

# DeepSeek (OpenAI-compatible) endpoint
DEEPSEEK_API_KEY=sk-xxxx
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# Optional general OpenAI-compatible fallbacks
# OPENAI_API_KEY=
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_BASE_URL=https://api.openai.com/v1

# Note: copy this file to project root as .env and fill keys locally.