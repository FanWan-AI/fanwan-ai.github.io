{
  "generated_at": "2025-09-08T04:00:00+00:00",
  "items": [
    {
      "headline": "伦理指南：评估大型语言模型在建筑项目管理中的决策支持",
      "one_liner": "本研究评估了大型语言模型在建筑项目管理中的决策支持能力，探讨其伦理影响。",
      "task": "NLP",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "数据增强"
      ],
      "limitations": [
        "评测偏差"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04505",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04505.pdf"
      },
      "tags": [
        "NLP",
        "决策支持",
        "伦理"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究探讨了大型语言模型在建筑项目管理中的应用，评估其作为决策支持工具的伦理影响。",
      "who_should_try": "建筑项目管理者、AI伦理研究者",
      "title_i18n": {
        "zh": "伦理指南：评估大型语言模型在建筑项目管理中的决策支持",
        "en": "The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management"
      },
      "summary_i18n": {
        "zh": "人工智能的引入正在改变建筑项目管理的决策支持方式。研究指出，大型语言模型（LLMs）作为一种可访问的决策支持工具，正在加速这一进程。这些模型能够处理复杂的信息并提供实时的建议，从而提高项目管理的效率和准确性。",
        "en": "arXiv:2509.04505v1 Announce Type: new \nAbstract: The integration of Artificial Intelligence (AI) into construction project management (CPM) is accelerating, with Large Language Models (LLMs) emerging as accessible decision-support tools. This study aims to critically evaluate the"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "Maestro：可靠AI代理的联合图与配置优化",
      "one_liner": "该研究提出了一种优化方法，旨在提高大型语言模型代理的可靠性。",
      "task": "Agent",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "模型配置"
      ],
      "limitations": [
        "算力门槛"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04642",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04642.pdf"
      },
      "tags": [
        "Agent",
        "优化",
        "可靠性"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究提出了一种新的优化框架，旨在提升大型语言模型代理的决策能力和可靠性。",
      "who_should_try": "AI代理开发者",
      "title_i18n": {
        "zh": "Maestro：可靠AI代理的联合图与配置优化",
        "en": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents"
      },
      "summary_i18n": {
        "zh": "为了构建可靠的AI代理，必须在图结构和每个节点的配置上进行优化。研究表明，现有的优化器主要集中在调整配置参数，而忽视了图的整体结构，这可能会影响代理的性能和可靠性。",
        "en": "arXiv:2509.04642v1 Announce Type: new \nAbstract: Building reliable LLM agents requires decisions at two levels: the graph (which modules exist and how information flows) and the configuration of each node (models, prompts, tools, control knobs). Most existing optimizers tune conf"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "个性化健康模拟的解释框架：以利益相关者为中心的总结方法",
      "one_liner": "本研究提出了一种混合方法框架，以支持健康领域的个性化决策。",
      "task": "NLP",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "数据增强"
      ],
      "limitations": [
        "评测偏差"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04646",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04646.pdf"
      },
      "tags": [
        "NLP",
        "健康",
        "个性化"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究提出了一种新的框架，旨在通过个性化的方式支持健康决策过程。",
      "who_should_try": "健康决策者、研究人员",
      "title_i18n": {
        "zh": "个性化健康模拟的解释框架：以利益相关者为中心的总结方法",
        "en": "Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization"
      },
      "summary_i18n": {
        "zh": "在健康模拟领域，个性化的解释对于利益相关者的决策至关重要。研究提出了一种混合方法框架，旨在为不同的利益相关者提供定制化的总结和解释，从而支持更有效的决策过程。",
        "en": "arXiv:2509.04646v1 Announce Type: new \nAbstract: Modeling & Simulation (M&S) approaches such as agent-based models hold significant potential to support decision-making activities in health, with recent examples including the adoption of vaccines, and a vast literature on hea"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "基于人类标准的AI模型评估方法",
      "one_liner": "本研究提出了一种新方法，将人类标准应用于AI模型的评估。",
      "task": "Theory",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "评估标准"
      ],
      "limitations": [
        "评测偏差"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04676",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04676.pdf"
      },
      "tags": [
        "评估",
        "AI",
        "标准"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究探讨了如何将人类标准融入AI模型的评估，以更好地捕捉模型的能力。",
      "who_should_try": "AI研究人员、评估专家",
      "title_i18n": {
        "zh": "基于人类标准的AI模型评估方法",
        "en": "An Approach to Grounding AI Model Evaluations in Human-derived Criteria"
      },
      "summary_i18n": {
        "zh": "本研究探讨了如何将人类标准融入AI模型的评估，以更好地捕捉模型的能力。",
        "en": "arXiv:2509.04676v1 Announce Type: new \nAbstract: In the rapidly evolving field of artificial intelligence (AI), traditional benchmarks can fall short in attempting to capture the nuanced capabilities of AI models. We focus on the case of physical world modeling and propose a nove"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "语言驱动的层次任务结构作为多智能体学习的显式世界模型",
      "one_liner": "本研究探讨了语言模型与多智能体学习的结合，提出了一种新的世界模型。",
      "task": "Agent",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "任务结构设计"
      ],
      "limitations": [
        "算力门槛"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04731",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04731.pdf"
      },
      "tags": [
        "Agent",
        "学习",
        "模型"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究提出了一种新的层次任务结构，旨在提升多智能体学习的效率和效果。",
      "who_should_try": "多智能体系统研究者",
      "title_i18n": {
        "zh": "语言驱动的层次任务结构作为多智能体学习的显式世界模型",
        "en": "Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning"
      },
      "summary_i18n": {
        "zh": "本研究提出了一种新的层次任务结构，旨在提升多智能体学习的效率和效果。",
        "en": "arXiv:2509.04731v1 Announce Type: new \nAbstract: The convergence of Language models, Agent models, and World models represents a critical frontier for artificial intelligence. While recent progress has focused on scaling Language and Agent models, the development of sophisticated"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "大型语言模型的假设分析：使用前瞻性思维探索游戏世界",
      "one_liner": "本研究探讨了大型语言模型在假设分析中的应用，提升其探索能力。",
      "task": "NLP",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "假设分析"
      ],
      "limitations": [
        "评测偏差"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04791",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04791.pdf"
      },
      "tags": [
        "NLP",
        "假设分析",
        "探索"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究提出了一种方法，利用大型语言模型进行假设分析，探索游戏世界中的可能性。",
      "who_should_try": "游戏开发者、AI研究人员",
      "title_i18n": {
        "zh": "大型语言模型的假设分析：使用前瞻性思维探索游戏世界",
        "en": "What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking"
      },
      "summary_i18n": {
        "zh": "本研究提出了一种方法，利用大型语言模型进行假设分析，探索游戏世界中的可能性。",
        "en": "arXiv:2509.04791v1 Announce Type: new \nAbstract: Large language models (LLMs) excel at processing information reactively but lack the ability to systemically explore hypothetical futures. They cannot ask, \"what if we take this action? how will it affect the final outcome\" and for"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "TalkToAgent：以人为本的强化学习代理解释",
      "one_liner": "本研究提出了一种新的方法，旨在提高强化学习代理的可解释性。",
      "task": "Agent",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "可解释性方法"
      ],
      "limitations": [
        "评测偏差"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04809",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04809.pdf"
      },
      "tags": [
        "Agent",
        "可解释性",
        "强化学习"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究探讨了如何通过大型语言模型提高强化学习代理的可解释性，缩小专家与模型之间的差距。",
      "who_should_try": "强化学习研究者、AI伦理专家",
      "title_i18n": {
        "zh": "TalkToAgent：以人为本的强化学习代理解释",
        "en": "TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models"
      },
      "summary_i18n": {
        "zh": "本研究探讨了如何通过大型语言模型提高强化学习代理的可解释性，缩小专家与模型之间的差距。",
        "en": "arXiv:2509.04809v1 Announce Type: new \nAbstract: Explainable Reinforcement Learning (XRL) has emerged as a promising approach in improving the transparency of Reinforcement Learning (RL) agents. However, there remains a gap between complex RL policies and domain experts, due to t"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "人类与语言模型之间的合作与冲突：博弈论视角",
      "one_liner": "本研究探讨了人类与语言模型在多方环境中的互动行为。",
      "task": "NLP",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "博弈论应用"
      ],
      "limitations": [
        "评测偏差"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04847",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04847.pdf"
      },
      "tags": [
        "NLP",
        "博弈论",
        "互动"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究通过博弈论分析人类与语言模型之间的合作与冲突，揭示其在多方环境中的行为模式。",
      "who_should_try": "AI研究人员、社会科学家",
      "title_i18n": {
        "zh": "人类与语言模型之间的合作与冲突：博弈论视角",
        "en": "Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory"
      },
      "summary_i18n": {
        "zh": "人类与语言模型之间的互动日益频繁，这引发了对其合作与竞争行为的研究。通过博弈论的视角，研究者们分析了这种互动的动态，揭示了在多方环境中可能出现的合作与冲突。",
        "en": "arXiv:2509.04847v1 Announce Type: new \nAbstract: Language models are increasingly deployed in interactive online environments, from personal chat assistants to domain-specific agents, raising questions about their cooperative and competitive behavior in multi-party settings. Whil"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    }
  ],
  "refs": [],
  "stats": {
    "by_task": {
      "LLM": 0
    },
    "with_code": 0,
    "new_benchmarks": 0
  },
  "must_reads": [
    0,
    1,
    2,
    3,
    4
  ],
  "nice_to_read": [
    5,
    6,
    7,
    8
  ],
  "deep_dive": {
    "title": "N/A",
    "summary": "N/A",
    "refs": []
  }
}