{
  "generated_at": "2025-09-08T04:00:00+00:00",
  "items": [
    {
      "headline": "伦理指南针：评估大型语言模型在建设项目管理中的决策支持",
      "one_liner": "本研究旨在评估大型语言模型在建设项目管理中的决策支持能力，探讨其伦理影响。",
      "task": "NLP",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "数据增强"
      ],
      "limitations": [
        "评测偏差"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04505",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04505.pdf"
      },
      "tags": [
        "NLP",
        "决策支持",
        "伦理"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究探讨了大型语言模型在建设项目管理中的应用，评估其作为决策支持工具的伦理影响。",
      "who_should_try": "项目管理者、AI伦理研究者",
      "title_i18n": {
        "zh": "伦理指南针：评估大型语言模型在建设项目管理中的决策支持",
        "en": "The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management"
      },
      "summary_i18n": {
        "zh": "在建筑项目管理中，大型语言模型（LLMs）被视为重要的决策支持工具。研究表明，这些模型能够加速信息处理和决策制定，提升项目管理的效率和准确性。通过整合AI技术，建筑行业能够更好地应对复杂的项目需求和挑战，从而优化资源配置和时间管理。",
        "en": "arXiv:2509.04505v1 Announce Type: new \nAbstract: The integration of Artificial Intelligence (AI) into construction project management (CPM) is accelerating, with Large Language Models (LLMs) emerging as accessible decision-support tools. This study aims to critically evaluate the"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "Maestro：可靠AI代理的联合图与配置优化",
      "one_liner": "本研究提出了一种优化框架，通过图和配置的联合优化来构建可靠的AI代理。",
      "task": "Agent",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "模型配置"
      ],
      "limitations": [
        "算力门槛"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04642",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04642.pdf"
      },
      "tags": [
        "Agent",
        "优化",
        "AI"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究提出了一种新的优化方法，旨在通过联合图和配置优化来提升AI代理的可靠性。",
      "who_should_try": "AI研究人员、系统设计师",
      "title_i18n": {
        "zh": "Maestro：可靠AI代理的联合图与配置优化",
        "en": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents"
      },
      "summary_i18n": {
        "zh": "在健康模拟领域，个性化解释框架的建立采用了混合方法，旨在增强利益相关者的理解能力。通过结合定量和定性数据，该框架能够提供更具针对性的解释，帮助用户更好地理解模拟结果及其影响，从而支持更有效的决策过程。",
        "en": "arXiv:2509.04642v1 Announce Type: new \nAbstract: Building reliable LLM agents requires decisions at two levels: the graph (which modules exist and how information flows) and the configuration of each node (models, prompts, tools, control knobs). Most existing optimizers tune conf"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "个性化健康模拟的解释框架：以利益相关者为中心的总结方法",
      "one_liner": "本研究提出了一种混合方法框架，以支持健康领域的个性化决策。",
      "task": "NLP",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "数据增强"
      ],
      "limitations": [
        "评测偏差"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04646",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04646.pdf"
      },
      "tags": [
        "NLP",
        "健康",
        "模拟"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究提出了一种以利益相关者为中心的框架，旨在为健康模拟提供个性化的解释和总结。",
      "who_should_try": "健康研究人员、政策制定者",
      "title_i18n": {
        "zh": "个性化健康模拟的解释框架：以利益相关者为中心的总结方法",
        "en": "Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization"
      },
      "summary_i18n": {
        "zh": "传统的AI模型评估方法往往无法全面捕捉模型的复杂能力。因此，研究者提出了一种基于人类标准的新评估方法，旨在更准确地反映模型在实际应用中的表现。这一新方法有助于提高AI模型的透明度和可解释性，从而增强用户的信任。",
        "en": "arXiv:2509.04646v1 Announce Type: new \nAbstract: Modeling & Simulation (M&S) approaches such as agent-based models hold significant potential to support decision-making activities in health, with recent examples including the adoption of vaccines, and a vast literature on hea"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "基于人类标准的AI模型评估方法",
      "one_liner": "本研究提出了一种新的评估方法，以人类标准为基础来评估AI模型的能力。",
      "task": "Theory",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "评估标准"
      ],
      "limitations": [
        "评测偏差"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04676",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04676.pdf"
      },
      "tags": [
        "AI",
        "评估",
        "标准"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究聚焦于AI模型的评估，提出了一种基于人类标准的评估方法，以更好地捕捉模型的能力。",
      "who_should_try": "AI研究人员、评估专家",
      "title_i18n": {
        "zh": "基于人类标准的AI模型评估方法",
        "en": "An Approach to Grounding AI Model Evaluations in Human-derived Criteria"
      },
      "summary_i18n": {
        "zh": "语言驱动的任务结构为多代理学习提供了明确的世界模型。这种结构不仅促进了代理之间的协作，还提高了任务执行的效率。通过建立清晰的任务层次，代理能够更好地理解其角色和目标，从而实现更高效的学习和决策。",
        "en": "arXiv:2509.04676v1 Announce Type: new \nAbstract: In the rapidly evolving field of artificial intelligence (AI), traditional benchmarks can fall short in attempting to capture the nuanced capabilities of AI models. We focus on the case of physical world modeling and propose a nove"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "语言驱动的层次任务结构作为多智能体学习的显式世界模型",
      "one_liner": "本研究探讨了语言模型、智能体模型和世界模型的结合，推动多智能体学习的发展。",
      "task": "Agent",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "模型集成"
      ],
      "limitations": [
        "算力门槛"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04731",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04731.pdf"
      },
      "tags": [
        "Agent",
        "学习",
        "模型"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究提出了一种新的方法，通过语言驱动的层次任务结构来提升多智能体学习的能力。",
      "who_should_try": "AI研究人员、学习算法开发者",
      "title_i18n": {
        "zh": "语言驱动的层次任务结构作为多智能体学习的显式世界模型",
        "en": "Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning"
      },
      "summary_i18n": {
        "zh": "本研究提出了一种新的方法，通过语言驱动的层次任务结构来提升多智能体学习的能力。",
        "en": "arXiv:2509.04731v1 Announce Type: new \nAbstract: The convergence of Language models, Agent models, and World models represents a critical frontier for artificial intelligence. While recent progress has focused on scaling Language and Agent models, the development of sophisticated"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "大型语言模型的假设分析：使用主动思维探索游戏世界",
      "one_liner": "本研究分析了大型语言模型在处理假设性问题时的局限性，并提出改进方法。",
      "task": "NLP",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "模型优化"
      ],
      "limitations": [
        "评测偏差"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04791",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04791.pdf"
      },
      "tags": [
        "NLP",
        "假设分析",
        "模型"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究探讨了大型语言模型在假设分析中的局限性，提出了改进的思路以提升其探索能力。",
      "who_should_try": "NLP研究人员、游戏设计者",
      "title_i18n": {
        "zh": "大型语言模型的假设分析：使用主动思维探索游戏世界",
        "en": "What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking"
      },
      "summary_i18n": {
        "zh": "本研究探讨了大型语言模型在假设分析中的局限性，提出了改进的思路以提升其探索能力。",
        "en": "arXiv:2509.04791v1 Announce Type: new \nAbstract: Large language models (LLMs) excel at processing information reactively but lack the ability to systemically explore hypothetical futures. They cannot ask, \"what if we take this action? how will it affect the final outcome\" and for"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "TalkToAgent：基于大型语言模型的强化学习代理的人本解释",
      "one_liner": "本研究提出了一种人本解释方法，以提升强化学习代理的透明度和可理解性。",
      "task": "Agent",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "解释方法"
      ],
      "limitations": [
        "复杂性"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04809",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04809.pdf"
      },
      "tags": [
        "Agent",
        "解释",
        "强化学习"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究提出了一种新的方法，通过人本解释来提升强化学习代理的透明度，缩小与领域专家的差距。",
      "who_should_try": "强化学习研究人员、AI伦理专家",
      "title_i18n": {
        "zh": "TalkToAgent：基于大型语言模型的强化学习代理的人本解释",
        "en": "TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models"
      },
      "summary_i18n": {
        "zh": "本研究提出了一种新的方法，通过人本解释来提升强化学习代理的透明度，缩小与领域专家的差距。",
        "en": "arXiv:2509.04809v1 Announce Type: new \nAbstract: Explainable Reinforcement Learning (XRL) has emerged as a promising approach in improving the transparency of Reinforcement Learning (RL) agents. However, there remains a gap between complex RL policies and domain experts, due to t"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    },
    {
      "headline": "人类与语言模型之间的合作与冲突：博弈论视角",
      "one_liner": "本研究探讨了语言模型在多方互动环境中的合作与竞争行为。",
      "task": "NLP",
      "type": "paper",
      "novelty": "method",
      "key_numbers": [
        {
          "dataset": "N/A",
          "metric": "N/A",
          "ours": "N/A",
          "baseline": "N/A",
          "impr_abs": "N/A",
          "impr_rel": "N/A"
        }
      ],
      "reusability": [
        "博弈论应用"
      ],
      "limitations": [
        "评测偏差"
      ],
      "links": {
        "paper": "https://arxiv.org/abs/2509.04847",
        "code": "N/A",
        "project": "N/A",
        "pdf": "https://arxiv.org/pdf/2509.04847.pdf"
      },
      "tags": [
        "NLP",
        "博弈论",
        "合作"
      ],
      "impact_score": 0,
      "reproducibility_score": 0,
      "quick_read": "本研究通过博弈论分析语言模型在多方互动中的行为，揭示其合作与竞争的动态。",
      "who_should_try": "博弈论研究者、NLP专家",
      "title_i18n": {
        "zh": "人类与语言模型之间的合作与冲突：博弈论视角",
        "en": "Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory"
      },
      "summary_i18n": {
        "zh": "本研究通过博弈论分析语言模型在多方互动中的行为，揭示其合作与竞争的动态。",
        "en": "arXiv:2509.04847v1 Announce Type: new \nAbstract: Language models are increasingly deployed in interactive online environments, from personal chat assistants to domain-specific agents, raising questions about their cooperative and competitive behavior in multi-party settings. Whil"
      },
      "host": "arxiv.org",
      "ts": "2025-09-08T04:00:00+00:00",
      "has_code": false,
      "key_numbers_compact": []
    }
  ],
  "refs": [],
  "stats": {
    "by_task": {
      "LLM": 0
    },
    "with_code": 0,
    "new_benchmarks": 0
  },
  "must_reads": [
    0,
    1,
    2,
    3,
    4
  ],
  "nice_to_read": [
    5,
    6,
    7,
    8
  ]
}