尽管大型语言模型（LLM）代理在快速发展中取得了进展，但在复杂任务中生成有意义的反思仍面临挑战，主要由于错误分析不足和对稀有成功轨迹的依赖。为此，本文提出了SAMULE框架，通过多层次反思合成提升自学习代理的能力，采用单轨迹学习、任务内学习和任务间学习三种互补层次进行高质量反思的合成，并通过微调语言模型生成反思。关键创新在于引入了基于前瞻的反思机制，使代理在用户交互中能够主动反思和适应。实验结果表明，该方法在多个基准测试中显著优于现有的反思基线，强调了反思合成和以失败为中心的学习在构建自我改进LLM代理中的重要性。这一研究为自学习系统的设计提供了新的思路，具有广泛的应用潜力。