随着生成模型在基准数据上的评估日益普遍，公众和科学界对AI能力的期望受到影响，但对评估结果可靠性的质疑也在增加。现有的评估往往将基准分数视为能力的简单测量，缺乏对能力本质的深入理解。为此，本文提出了一种基于能力理论的评估框架，强调将评估视为推断过程，并引入了考虑不确定性和样本有限性的能力推断方法，包括一种显著降低样本复杂度的自适应算法。该框架的创新之处在于明确了能力评估的理论基础，并提供了更可靠的能力估计方法，具有潜在的广泛应用价值，能够提升AI评估的可信度和科学性。