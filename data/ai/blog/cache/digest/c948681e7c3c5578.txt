本研究旨在解决大语言模型（LLMs）在重复提示时响应一致性的问题，填补了现有方法在计算预算下的自一致性评估缺口。通过分析在固定计算预算条件下的自一致性估计器，提出了在任务分布中采样提示数量与每个提示重复调用次数的最佳分配策略，即$m,n\propto\sqrt{B}$。关键创新在于提供了自一致性评估的新方法，并揭示了计算预算对模型性能的影响。研究结果表明，该方法在提高响应可靠性方面优于主流基线，具有较高的实用价值。此研究为优化大语言模型的使用提供了新的思路，可能对相关领域的模型设计和应用产生深远影响。