在自然语言描述优化或满足问题的翻译过程中，现有方法往往缺乏有效的逻辑推理和约束编程能力，导致难以生成正确的MiniZinc模型。为此，研究者提出了一种基于多智能体的框架，通过多个专门的大型语言模型（LLM）代理，根据全局约束类型分解建模任务。关键创新在于每个代理专注于特定类型的全局约束生成代码，并由最终的汇总代理整合这些代码片段，显著降低了整体复杂性。实验结果表明，该方法在性能上优于主流的单次提示和思维链提示策略。此研究为未来的优化建模提供了新的思路，具有广泛的应用潜力，尤其在需要复杂逻辑推理的领域。