该论文提出现代人工智能研究应采用抗脆弱的安全观，以应对长期AI安全问题，尤其是处理稀有或分布外事件的能力。现有的静态基准和单次鲁棒性测试未能考虑环境的演变，可能导致模型适应不良。研究的关键创新在于强调利用不确定性来应对未来更不可预测的挑战，并提出抗脆弱解决方案以管理稀有事件。论文指出，现有测试方法存在场景多样性不足、奖励黑客和过度对齐等局限，建议重新校准AI安全的测量和改进方法，以建立一个更具伦理和实用性的抗脆弱AI安全社区。这一研究对推动AI安全领域的长期可靠性具有重要影响，尤其在应对动态环境变化时。