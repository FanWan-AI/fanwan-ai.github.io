在大型语言模型（LLMs）应用于下游任务时，现有的验证模型方法虽然能提高准确性，但通常在测试阶段均匀增加计算量，导致资源利用效率低下。为了解决这一问题，本文提出了一种名为“局部自适应测试时间缩放”（LATTS）的方法，通过在生成步骤中动态调整计算资源分配，基于验证模型的接受标准决定是否重新采样、回溯、重启或停止生成过程。该方法的关键创新在于引入了针对每个生成步骤的“局部难度”评估，从而实现更灵活的计算分配。实证结果表明，LATTS在准确性与计算效率的权衡上显著优于传统的验证模型方法。这一研究为优化大型语言模型的计算资源使用提供了新的思路，具有广泛的应用潜力。