在社会影响优化领域，现有的AI决策系统通常依赖于优化良好的数学目标，但难以直接适应不断变化的人类偏好。为了解决这一问题，本文提出了VORTEX框架，通过大语言模型（LLM）引导的奖励塑造，既保持了优化目标，又灵活地融入人类反馈。关键创新在于将问题形式化为多目标优化，并通过自然语言反馈迭代生成奖励，确保系统在满足人类偏好的同时不牺牲核心效用。实证结果表明，VORTEX在满足人类对覆盖目标的需求方面优于主流基线，同时保持高效能。这一研究为人机协作优化提供了一个实用且理论基础扎实的新范式，具有广泛的应用潜力。