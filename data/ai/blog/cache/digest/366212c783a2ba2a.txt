本研究针对强化学习（RL）代理在实际环境中面临的传感器故障、执行器磨损及环境变化等问题，提出了一种信息论框架，以填补现有RL系统缺乏内在故障检测机制的空白。通过分析机器人控制任务中的状态-动作互信息模式，研究表明成功学习的过程中，互信息在状态熵增加的情况下仍持续增长，反映出代理对任务相关模式的选择性关注。此外，研究发现状态、动作与下一状态的联合互信息呈现倒U型曲线，揭示了从广泛探索到高效利用的转变。该框架还通过控制扰动实验展示了信息度量在故障诊断中的差异化能力，能够在不改变系统架构的前提下实现精确的故障定位。这一方法为自适应强化学习系统的健康监测奠定了基础，具有重要的应用潜力。