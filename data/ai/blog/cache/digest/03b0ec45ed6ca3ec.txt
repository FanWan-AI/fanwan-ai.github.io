本研究提出了一种探索性检索增强规划框架（ExRAP），旨在解决动态非静态环境中具身智能体的持续指令跟随任务。该框架通过有效探索物理环境并建立环境上下文记忆，提升了大型语言模型（LLMs）在具身推理方面的能力，从而使任务规划过程能够更好地适应时间变化的环境。ExRAP的关键创新在于将信息驱动的探索整合到任务规划中，并设计了时间一致性优化方案，以应对记忆中知识的衰减。实验结果表明，该方法在多种具身指令跟随场景中表现出色，优于主流的LLM任务规划方法，显示出其在动态环境下的广泛适用性和潜在影响。此研究为持续学习和智能体自主决策提供了新的思路和实践借鉴。