随着AI系统在评估其他AI输出中的应用日益增加，理解其评估行为变得至关重要，以防止偏见的蔓延。本文通过分析NVIDIA的Describe Anything Model生成的视觉-语言描述，并由三种GPT变体（GPT-4o、GPT-4o-mini、GPT-5）进行评估，揭示了各模型的独特评估特征及其潜在偏见。研究发现，GPT-4o-mini在一致性上表现优异，GPT-4o在错误检测方面突出，而GPT-5则表现出高度保守和变异性。通过使用Gemini 2.5 Pro作为独立问题生成器的实验验证了这些评估特征是模型固有属性，而非外部因素。结果表明，评估能力并不随着模型的普遍能力提升而增强，强调了在AI评估中引入多样化架构视角的重要性，对未来AI系统的设计与评估方法具有重要启示。