{
  "date": "2025-09-26",
  "items": [
    {
      "id": "timm/mobilenetv3_small_100.lamb_in1k",
      "source": "hf",
      "name": "mobilenetv3_small_100.lamb_in1k",
      "url": "https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1905.02244",
        "arxiv:2110.00476",
        "dataset:imagenet-1k",
        "image-classification",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "safetensors",
        "timm",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 130903980,
        "likes_total": 37
      },
      "score": 261826.46,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "MobileNetV3-Small 100是一种专为移动和嵌入式视觉应用优化的轻量级卷积神经网络。它采用倒残差块结构，结合压缩激励模块和硬切换激活函数以提高效率。在ImageNet-1k数据集上使用LAMB优化器训练，能够在参数和计算成本极低的情况下实现高精度。典型应用包括实时图像分类、作为目标检测网络的主干架构，以及部署在计算资源受限的设备上。该模型平衡了性能与效率，适合移动端和边缘计算场景。",
      "updated_at": "2025-09-21T12:06:53.893Z",
      "task_keys": [
        "image_classification"
      ],
      "summary_en": "MobileNetV3-Small 100 is a lightweight convolutional neural network optimized for mobile and embedded vision applications. It uses inverted residual blocks with squeeze-and-excite modules and hard-swish activations for efficiency. Trained on ImageNet-1k with LAMB optimizer, it achieves strong accuracy with minimal parameters and computational cost. Typical uses include real-time image classification, object detection backbones, and deployment on resource-constrained devices.",
      "summary_zh": "MobileNetV3-Small 100是一种专为移动和嵌入式视觉应用优化的轻量级卷积神经网络。它采用倒残差块结构，结合压缩激励模块和硬切换激活函数以提高效率。在ImageNet-1k数据集上使用LAMB优化器训练，能够在参数和计算成本极低的情况下实现高精度。典型应用包括实时图像分类、作为目标检测网络的主干架构，以及部署在计算资源受限的设备上。该模型平衡了性能与效率，适合移动端和边缘计算场景。",
      "summary_es": "MobileNetV3-Small 100 es una red neuronal convolucional ligera optimizada para aplicaciones de visión en dispositivos móviles y embebidos. Utiliza bloques residuales invertidos con módulos de compresión-excitación y activaciones hard-swish para eficiencia. Entrenado en ImageNet-1k con optimizador LAMB, logra alta precisión con parámetros y coste computacional mínimos. Usos típicos incluyen clasificación de imágenes en tiempo real, backbones para detección de objetos y despliegue en dispositivos con recursos limitados."
    },
    {
      "id": "Falconsai/nsfw_image_detection",
      "source": "hf",
      "name": "nsfw_image_detection",
      "url": "https://huggingface.co/Falconsai/nsfw_image_detection",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2010.11929",
        "autotrain_compatible",
        "endpoints_compatible",
        "image-classification",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "safetensors",
        "transformers",
        "vit"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 96871313,
        "likes_total": 822
      },
      "score": 194153.62600000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "该项目是一个基于视觉变换器（ViT）架构的图像分类模型，专门用于检测图像中的NSFW（不适宜工作场所）内容。核心功能包括识别不适当的视觉材料，支持PyTorch和Transformers库，采用SafeTensors格式，并遵循Apache 2.0许可证。优势在于高效的内容审核能力，适用于社交媒体平台的内容过滤、网络应用的安全审查以及自动化审核系统，帮助维护安全的数字环境。典型用例涵盖在线内容管理和用户生成内容的实时监控。",
      "updated_at": "2025-09-21T12:06:53.893Z",
      "summary_en": "This project is an image classification model designed to detect NSFW (Not Safe For Work) content in images. It utilizes Vision Transformer (ViT) architecture to identify inappropriate visual material. The model is compatible with PyTorch and Transformers libraries, supports SafeTensors format, and is licensed under Apache 2.0. Typical use cases include content moderation for social platforms, web filtering applications, and automated content review systems to maintain safe digital environments.",
      "summary_zh": "该项目是一个基于视觉变换器（ViT）架构的图像分类模型，专门用于检测图像中的NSFW（不适宜工作场所）内容。核心功能包括识别不适当的视觉材料，支持PyTorch和Transformers库，采用SafeTensors格式，并遵循Apache 2.0许可证。优势在于高效的内容审核能力，适用于社交媒体平台的内容过滤、网络应用的安全审查以及自动化审核系统，帮助维护安全的数字环境。典型用例涵盖在线内容管理和用户生成内容的实时监控。",
      "summary_es": "Este proyecto es un modelo de clasificación de imágenes diseñado para detectar contenido NSFW (No Seguro para el Trabajo) en imágenes. Utiliza la arquitectura Vision Transformer (ViT) para identificar material visual inapropiado. Es compatible con las bibliotecas PyTorch y Transformers, soporta el formato SafeTensors y tiene licencia Apache 2.0. Los casos de uso típicos incluyen moderación de contenido para plataformas sociales, filtrado web y sistemas de revisión automatizada para mantener entornos digitales seguros."
    },
    {
      "id": "sentence-transformers/all-MiniLM-L6-v2",
      "source": "hf",
      "name": "all-MiniLM-L6-v2",
      "url": "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1704.05179",
        "arxiv:1810.09305",
        "arxiv:1904.06472",
        "arxiv:2102.07033",
        "arxiv:2104.08727",
        "autotrain_compatible",
        "bert",
        "dataset:code_search_net",
        "dataset:eli5",
        "dataset:embedding-data/PAQ_pairs",
        "dataset:embedding-data/QQP",
        "dataset:embedding-data/SPECTER",
        "dataset:embedding-data/WikiAnswers",
        "dataset:embedding-data/altlex",
        "dataset:embedding-data/flickr30k-captions",
        "dataset:embedding-data/sentence-compression",
        "dataset:embedding-data/simple-wiki",
        "dataset:flax-sentence-embeddings/stackexchange_xml",
        "dataset:gooaq",
        "dataset:ms_marco",
        "dataset:multi_nli",
        "dataset:natural_questions",
        "dataset:s2orc",
        "dataset:search_qa",
        "dataset:snli",
        "dataset:trivia_qa",
        "dataset:wikihow",
        "dataset:yahoo_answers_topics",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "license:apache-2.0",
        "onnx",
        "openvino",
        "pytorch",
        "region:us",
        "rust",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "text-embeddings-inference",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 87829966,
        "likes_total": 3907
      },
      "score": 177613.432,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "all-MiniLM-L6-v2 是一个紧凑型句子转换模型，专为高效生成文本嵌入而设计。它将输入文本转换为高维向量表示，支持语义相似性比较和检索任务。该模型的核心优势包括体积小、推理速度快以及在多样化领域中的稳健性能。典型应用场景涵盖语义搜索、文本聚类、重复检测和推荐系统，特别适合资源受限环境下需要精确文本理解的应用。",
      "updated_at": "2025-09-21T12:06:53.893Z",
      "task_keys": [
        "inference_acceleration"
      ],
      "summary_en": "The all-MiniLM-L6-v2 model is a compact sentence transformer designed for efficient text embedding generation. It converts input text into high-dimensional vector representations, enabling semantic similarity comparisons and retrieval tasks. Its key strengths include small size, fast inference, and robust performance across diverse domains. Typical use cases encompass semantic search, clustering, duplicate detection, and recommendation systems, making it suitable for resource-constrained environments requiring accurate text understanding.",
      "summary_zh": "all-MiniLM-L6-v2 是一个紧凑型句子转换模型，专为高效生成文本嵌入而设计。它将输入文本转换为高维向量表示，支持语义相似性比较和检索任务。该模型的核心优势包括体积小、推理速度快以及在多样化领域中的稳健性能。典型应用场景涵盖语义搜索、文本聚类、重复检测和推荐系统，特别适合资源受限环境下需要精确文本理解的应用。",
      "summary_es": "El modelo all-MiniLM-L6-v2 es un transformador de oraciones compacto diseñado para generar incrustaciones de texto de manera eficiente. Convierte texto de entrada en representaciones vectoriales de alta dimensión, permitiendo comparaciones de similitud semántica y tareas de recuperación. Sus principales fortalezas incluyen tamaño reducido, inferencia rápida y rendimiento robusto en diversos dominios. Los casos de uso típicos abarcan búsqueda semántica, agrupación, detección de duplicados y sistemas de recomendación, ideal para entornos con recursos limitados."
    },
    {
      "id": "dima806/fairface_age_image_detection",
      "source": "hf",
      "name": "fairface_age_image_detection",
      "url": "https://huggingface.co/dima806/fairface_age_image_detection",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "autotrain_compatible",
        "base_model:finetune:google/vit-base-patch16-224-in21k",
        "base_model:google/vit-base-patch16-224-in21k",
        "dataset:nateraw/fairface",
        "endpoints_compatible",
        "image-classification",
        "license:apache-2.0",
        "region:us",
        "safetensors",
        "transformers",
        "vit"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 58904599,
        "likes_total": 41
      },
      "score": 117829.698,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "该项目基于Google的ViT-Base模型，在FairFace数据集上微调，用于从面部图像进行年龄分类。它能准确将年龄划分为0-2岁、3-9岁、10-19岁、20-29岁、30-39岁、40-49岁、50-59岁、60-69岁和70岁以上等组别。优势包括高精度、多样化人口统计代表性以及与Transformers库的兼容性。典型应用包括人口统计分析、年龄验证和视觉数据中年龄相关模式的研究。",
      "updated_at": "2025-09-21T12:06:53.893Z",
      "summary_en": "This project fine-tunes Google's ViT-Base model on the FairFace dataset for age classification from facial images. It accurately categorizes ages into groups like 0-2, 3-9, 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, and 70+. Strengths include high precision with diverse demographic representation and compatibility with Transformers. Typical use cases are demographic analysis, age verification, and research on age-related patterns in visual data.",
      "summary_zh": "该项目基于Google的ViT-Base模型，在FairFace数据集上微调，用于从面部图像进行年龄分类。它能准确将年龄划分为0-2岁、3-9岁、10-19岁、20-29岁、30-39岁、40-49岁、50-59岁、60-69岁和70岁以上等组别。优势包括高精度、多样化人口统计代表性以及与Transformers库的兼容性。典型应用包括人口统计分析、年龄验证和视觉数据中年龄相关模式的研究。",
      "summary_es": "Este proyecto ajusta el modelo ViT-Base de Google en el conjunto de datos FairFace para clasificación de edad a partir de imágenes faciales. Clasifica con precisión edades en grupos como 0-2, 3-9, 10-19, 20-29, 30-39, 40-49, 50-59, 60-69 y 70+. Sus fortalezas incluyen alta precisión con representación demográfica diversa y compatibilidad con Transformers. Los casos de uso típicos son análisis demográfico, verificación de edad e investigación de patrones relacionados con la edad en datos visuales."
    },
    {
      "id": "google-bert/bert-base-uncased",
      "source": "hf",
      "name": "bert-base-uncased",
      "url": "https://huggingface.co/google-bert/bert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1810.04805",
        "autotrain_compatible",
        "bert",
        "coreml",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "en",
        "endpoints_compatible",
        "exbert",
        "fill-mask",
        "jax",
        "license:apache-2.0",
        "onnx",
        "pytorch",
        "region:us",
        "rust",
        "safetensors",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 55932506,
        "likes_total": 2414
      },
      "score": 113072.012,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BERT-base-uncased是谷歌开发的一种基于Transformer架构的语言理解模型，采用双向上下文编码技术，能够同时利用左右上下文信息来理解词汇含义。该模型在英文维基百科和图书语料库上进行预训练，支持文本分类、命名实体识别、问答系统等多种自然语言处理任务。其不区分大小写的特性使其在处理不同格式的文本时更加灵活，广泛应用于学术研究和工业场景中的语言分析工作。",
      "updated_at": "2025-09-21T12:06:53.893Z",
      "summary_en": "BERT-base-uncased is a transformer-based language model developed by Google for natural language understanding. It uses bidirectional context to capture word meanings from both directions, enabling strong performance on tasks like text classification, named entity recognition, and question answering. The model is pre-trained on English text from Wikipedia and BookCorpus, making it effective for various NLP applications without case sensitivity.",
      "summary_zh": "BERT-base-uncased是谷歌开发的一种基于Transformer架构的语言理解模型，采用双向上下文编码技术，能够同时利用左右上下文信息来理解词汇含义。该模型在英文维基百科和图书语料库上进行预训练，支持文本分类、命名实体识别、问答系统等多种自然语言处理任务。其不区分大小写的特性使其在处理不同格式的文本时更加灵活，广泛应用于学术研究和工业场景中的语言分析工作。",
      "summary_es": "BERT-base-uncased es un modelo de lenguaje basado en transformadores desarrollado por Google para comprensión del lenguaje natural. Utiliza contexto bidireccional para capturar significados de palabras desde ambas direcciones, permitiendo un rendimiento sólido en tareas como clasificación de texto, reconocimiento de entidades nombradas y respuesta a preguntas. El modelo está preentrenado en texto inglés de Wikipedia y BookCorpus, siendo efectivo para diversas aplicaciones de PLN sin sensibilidad a mayúsculas."
    },
    {
      "id": "tech4humans/yolov8s-signature-detector",
      "source": "hf",
      "name": "yolov8s-signature-detector",
      "url": "https://huggingface.co/tech4humans/yolov8s-signature-detector",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "base_model:Ultralytics/YOLOv8",
        "base_model:quantized:Ultralytics/YOLOv8",
        "dataset:tech4humans/signature-detection",
        "endpoints_compatible",
        "license:agpl-3.0",
        "model-index",
        "object-detection",
        "onnx",
        "pytorch",
        "region:us",
        "signature-detection",
        "tensorboard",
        "ultralytics",
        "yolo",
        "yolov8"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 43141280,
        "likes_total": 39
      },
      "score": 86302.06,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "yolov8s-signature-detector是基于YOLOv8架构的目标检测模型，专门针对签名检测任务进行了微调。它采用Ultralytics YOLOv8基础模型，并在tech4humans/signature-detection数据集上训练。该模型提供ONNX和PyTorch格式，支持量化以提高效率，并与推理端点兼容。其主要优势在于精确的文档签名定位，典型应用场景包括文档处理、认证系统和自动化表单分析。该模型采用AGPL-3.0许可证，具有高精度和部署灵活性。",
      "updated_at": "2025-09-21T12:06:53.893Z",
      "task_keys": [
        "object_detection"
      ],
      "summary_en": "The yolov8s-signature-detector is an object detection model based on YOLOv8 architecture, specifically fine-tuned for signature detection tasks. It utilizes the Ultralytics YOLOv8 base model and was trained on the tech4humans/signature-detection dataset. The model is available in ONNX and PyTorch formats, supports quantization for efficiency, and is compatible with inference endpoints. Its primary strength lies in accurate signature localization within documents, with typical use cases including document processing, authentication systems, and automated form analysis.",
      "summary_zh": "yolov8s-signature-detector是基于YOLOv8架构的目标检测模型，专门针对签名检测任务进行了微调。它采用Ultralytics YOLOv8基础模型，并在tech4humans/signature-detection数据集上训练。该模型提供ONNX和PyTorch格式，支持量化以提高效率，并与推理端点兼容。其主要优势在于精确的文档签名定位，典型应用场景包括文档处理、认证系统和自动化表单分析。该模型采用AGPL-3.0许可证，具有高精度和部署灵活性。",
      "summary_es": "El yolov8s-signature-detector es un modelo de detección de objetos basado en la arquitectura YOLOv8, específicamente ajustado para tareas de detección de firmas. Utiliza el modelo base Ultralytics YOLOv8 y fue entrenado en el conjunto de datos tech4humans/signature-detection. Está disponible en formatos ONNX y PyTorch, admite cuantificación para eficiencia y es compatible con endpoints de inferencia. Su principal fortaleza es la localización precisa de firmas en documentos, con casos de uso típicos que incluyen procesamiento de documentos, sistemas de autenticación y análisis automatizado de formularios."
    },
    {
      "id": "pyannote/segmentation-3.0",
      "source": "hf",
      "name": "segmentation-3.0",
      "url": "https://huggingface.co/pyannote/segmentation-3.0",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "audio",
        "license:mit",
        "overlapped-speech-detection",
        "pyannote",
        "pyannote-audio",
        "pyannote-audio-model",
        "pytorch",
        "region:us",
        "resegmentation",
        "speaker",
        "speaker-change-detection",
        "speaker-diarization",
        "speaker-segmentation",
        "speech",
        "voice",
        "voice-activity-detection"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 18789102,
        "likes_total": 591
      },
      "score": 37873.704,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Pyannote segmentation-3.0 是一个用于说话人日志和分割的音频处理模型。它能够检测音频录音中的说话人变化、语音活动以及重叠语音。核心功能包括精确的边界检测和说话人识别。优势在于处理多说话人复杂音频环境时的高准确性。典型应用场景包括会议转录、播客分析和需要详细说话人分离的呼叫中心监控应用。该模型基于PyTorch框架开发，采用MIT许可证。",
      "updated_at": "2025-09-21T12:06:53.893Z",
      "summary_en": "Pyannote segmentation-3.0 is an audio processing model for speaker diarization and segmentation. It detects speaker changes, voice activity, and overlapped speech in audio recordings. Core capabilities include precise boundary detection and speaker identification. Strengths include high accuracy in complex audio environments with multiple speakers. Typical use cases include meeting transcription, podcast analysis, and call center monitoring applications requiring detailed speaker separation.",
      "summary_zh": "Pyannote segmentation-3.0 是一个用于说话人日志和分割的音频处理模型。它能够检测音频录音中的说话人变化、语音活动以及重叠语音。核心功能包括精确的边界检测和说话人识别。优势在于处理多说话人复杂音频环境时的高准确性。典型应用场景包括会议转录、播客分析和需要详细说话人分离的呼叫中心监控应用。该模型基于PyTorch框架开发，采用MIT许可证。",
      "summary_es": "Pyannote segmentation-3.0 es un modelo de procesamiento de audio para diarización y segmentación de hablantes. Detecta cambios de hablante, actividad vocal y habla superpuesta en grabaciones de audio. Capacidades principales incluyen detección precisa de límites e identificación de hablantes. Fortalezas incluyen alta precisión en entornos de audio complejos con múltiples hablantes. Casos de uso típicos incluyen transcripción de reuniones, análisis de podcasts y monitoreo de centros de llamadas que requieren separación detallada de hablantes."
    },
    {
      "id": "pyannote/wespeaker-voxceleb-resnet34-LM",
      "source": "hf",
      "name": "wespeaker-voxceleb-resnet34-LM",
      "url": "https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "audio",
        "dataset:voxceleb",
        "license:cc-by-4.0",
        "pyannote",
        "pyannote-audio",
        "pyannote-audio-model",
        "pytorch",
        "region:us",
        "speaker",
        "speaker-embedding",
        "speaker-identification",
        "speaker-recognition",
        "speaker-verification",
        "speech",
        "voice",
        "wespeaker"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 18459011,
        "likes_total": 74
      },
      "score": 36955.022,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "该模型是基于ResNet-34架构的说话人识别系统，使用VoxCeleb数据集训练。核心功能是提取说话人嵌入向量，用于身份识别和验证任务。主要优势包括在不同语音条件下的稳定性能表现和高效处理能力。典型应用场景包括说话人日志记录、语音认证系统以及需要精确说话人辨别的司法语音分析领域。模型专注于技术实现，不涉及商业推广内容。",
      "updated_at": "2025-09-21T12:06:53.893Z",
      "summary_en": "This model is a speaker recognition system based on ResNet-34 architecture, trained on VoxCeleb datasets. Its core purpose is to extract speaker embeddings for identification and verification tasks. Key strengths include robust performance across diverse speech conditions and efficient processing. Typical use cases involve speaker diarization, voice authentication systems, and forensic voice analysis applications requiring accurate speaker discrimination.",
      "summary_zh": "该模型是基于ResNet-34架构的说话人识别系统，使用VoxCeleb数据集训练。核心功能是提取说话人嵌入向量，用于身份识别和验证任务。主要优势包括在不同语音条件下的稳定性能表现和高效处理能力。典型应用场景包括说话人日志记录、语音认证系统以及需要精确说话人辨别的司法语音分析领域。模型专注于技术实现，不涉及商业推广内容。",
      "summary_es": "Este modelo es un sistema de reconocimiento de hablantes basado en arquitectura ResNet-34, entrenado con conjuntos de datos VoxCeleb. Su propósito principal es extraer embeddings de voz para identificación y verificación de locutores. Fortalezas clave incluyen rendimiento robusto en diversas condiciones de habla y procesamiento eficiente. Casos de uso típicos abarcan diarización de hablantes, sistemas de autenticación vocal y análisis forense de voz que requieren discriminación precisa de locutores."
    },
    {
      "id": "pyannote/speaker-diarization-3.1",
      "source": "hf",
      "name": "speaker-diarization-3.1",
      "url": "https://huggingface.co/pyannote/speaker-diarization-3.1",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2012.01477",
        "arxiv:2111.14448",
        "audio",
        "automatic-speech-recognition",
        "endpoints_compatible",
        "license:mit",
        "overlapped-speech-detection",
        "pyannote",
        "pyannote-audio",
        "pyannote-audio-pipeline",
        "region:us",
        "speaker",
        "speaker-change-detection",
        "speaker-diarization",
        "speech",
        "voice",
        "voice-activity-detection"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 16895629,
        "likes_total": 1137
      },
      "score": 34359.758,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Pyannote speaker-diarization-3.1 是一个音频处理流程，用于在录音中按不同说话人分割和标记语音。它使用神经网络检测说话人变化、语音活动和重叠语音。核心能力包括高精度的多说话人场景处理和多种音频格式兼容性。主要优势在于复杂对话环境中的准确性和鲁棒性。典型应用场景包括会议转录、播客分析和呼叫中心监控，需要说话人分离的场合。",
      "updated_at": "2025-09-21T12:06:53.893Z",
      "summary_en": "Pyannote speaker-diarization-3.1 is an audio processing pipeline that segments and labels speech by different speakers in recordings. It detects speaker changes, voice activity, and overlapping speech using neural networks. Key strengths include high accuracy in multi-speaker scenarios and compatibility with various audio formats. Typical use cases include meeting transcription, podcast analysis, and call center monitoring where speaker separation is required.",
      "summary_zh": "Pyannote speaker-diarization-3.1 是一个音频处理流程，用于在录音中按不同说话人分割和标记语音。它使用神经网络检测说话人变化、语音活动和重叠语音。核心能力包括高精度的多说话人场景处理和多种音频格式兼容性。主要优势在于复杂对话环境中的准确性和鲁棒性。典型应用场景包括会议转录、播客分析和呼叫中心监控，需要说话人分离的场合。",
      "summary_es": "Pyannote speaker-diarization-3.1 es una pipeline de procesamiento de audio que segmenta y etiqueta el habla por diferentes locutores en grabaciones. Detecta cambios de locutor, actividad vocal y habla superpuesta mediante redes neuronales. Sus principales fortalezas incluyen alta precisión en escenarios multi-locutor y compatibilidad con varios formatos de audio. Casos de uso típicos incluyen transcripción de reuniones, análisis de podcasts y monitoreo de centros de llamadas donde se requiere separación de locutores."
    },
    {
      "id": "sentence-transformers/all-mpnet-base-v2",
      "source": "hf",
      "name": "all-mpnet-base-v2",
      "url": "https://huggingface.co/sentence-transformers/all-mpnet-base-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1704.05179",
        "arxiv:1810.09305",
        "arxiv:1904.06472",
        "arxiv:2102.07033",
        "arxiv:2104.08727",
        "autotrain_compatible",
        "dataset:code_search_net",
        "dataset:eli5",
        "dataset:embedding-data/PAQ_pairs",
        "dataset:embedding-data/QQP",
        "dataset:embedding-data/SPECTER",
        "dataset:embedding-data/WikiAnswers",
        "dataset:embedding-data/altlex",
        "dataset:embedding-data/flickr30k-captions",
        "dataset:embedding-data/sentence-compression",
        "dataset:embedding-data/simple-wiki",
        "dataset:flax-sentence-embeddings/stackexchange_xml",
        "dataset:gooaq",
        "dataset:ms_marco",
        "dataset:multi_nli",
        "dataset:natural_questions",
        "dataset:s2orc",
        "dataset:search_qa",
        "dataset:snli",
        "dataset:trivia_qa",
        "dataset:wikihow",
        "dataset:yahoo_answers_topics",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "fill-mask",
        "license:apache-2.0",
        "mpnet",
        "onnx",
        "openvino",
        "pytorch",
        "region:us",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "text-embeddings-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 16696575,
        "likes_total": 1156
      },
      "score": 33971.15,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "all-mpnet-base-v2模型是一种句子转换器，旨在为文本生成密集向量嵌入。它在语义相似性任务、聚类和检索应用中表现出色，基于MPNet架构，并在MS MARCO和NLI等多种数据集上训练，确保稳健性能。优势包括高精度的句子比较能力和高效处理大规模文本语料。典型用例涵盖搜索引擎、推荐系统以及自然语言理解任务，适用于需要精确文本表示的场景。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "inference_acceleration"
      ],
      "summary_en": "The all-mpnet-base-v2 model is a sentence transformer designed to generate dense vector embeddings for text. It excels in semantic similarity tasks, clustering, and retrieval applications. Trained on diverse datasets including MS MARCO and NLI, it leverages MPNet architecture for robust performance. Its strengths include high accuracy in sentence comparisons and efficient processing of large text corpora. Typical use cases encompass search engines, recommendation systems, and natural language understanding tasks.",
      "summary_zh": "all-mpnet-base-v2模型是一种句子转换器，旨在为文本生成密集向量嵌入。它在语义相似性任务、聚类和检索应用中表现出色，基于MPNet架构，并在MS MARCO和NLI等多种数据集上训练，确保稳健性能。优势包括高精度的句子比较能力和高效处理大规模文本语料。典型用例涵盖搜索引擎、推荐系统以及自然语言理解任务，适用于需要精确文本表示的场景。",
      "summary_es": "El modelo all-mpnet-base-v2 es un transformador de oraciones diseñado para generar incrustaciones vectoriales densas para texto. Sobresale en tareas de similitud semántica, agrupación y aplicaciones de recuperación. Entrenado en conjuntos de datos diversos como MS MARCO y NLI, utiliza arquitectura MPNet para un rendimiento robusto. Sus fortalezas incluyen alta precisión en comparaciones de oraciones y procesamiento eficiente de grandes corpus de texto. Los casos de uso típicos abarcan motores de búsqueda, sistemas de recomendación y tareas de comprensión del lenguaje natural."
    },
    {
      "id": "Bingsu/adetailer",
      "source": "hf",
      "name": "adetailer",
      "url": "https://huggingface.co/Bingsu/adetailer",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "dataset:skytnt/anime-segmentation",
        "dataset:wider_face",
        "doi:10.57967/hf/3633",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "ultralytics"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 15383187,
        "likes_total": 616
      },
      "score": 31074.374,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ADetailer 是一款自动面部检测和修复工具，旨在增强图像中的面部细节。它利用先进的分割模型识别面部区域，并应用精确的修复技术来提高清晰度和分辨率。该工具擅长处理低质量或被遮挡的面部，适用于图像恢复、照片编辑和内容创作。典型用例包括修复模糊肖像、去除伪影以及在数字媒体中提升面部特征。其核心能力基于深度学习和计算机视觉，支持高效批量处理，广泛应用于摄影、设计和人像优化领域。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "ADetailer is an automatic face detection and inpainting tool designed to enhance facial details in images. It uses advanced segmentation models to identify facial regions and applies precise inpainting techniques to improve clarity and resolution. The tool excels at handling low-quality or obscured faces, making it valuable for image restoration, photo editing, and content creation. Typical use cases include fixing blurry portraits, removing artifacts, and upscaling facial features in digital media.",
      "summary_zh": "ADetailer 是一款自动面部检测和修复工具，旨在增强图像中的面部细节。它利用先进的分割模型识别面部区域，并应用精确的修复技术来提高清晰度和分辨率。该工具擅长处理低质量或被遮挡的面部，适用于图像恢复、照片编辑和内容创作。典型用例包括修复模糊肖像、去除伪影以及在数字媒体中提升面部特征。其核心能力基于深度学习和计算机视觉，支持高效批量处理，广泛应用于摄影、设计和人像优化领域。",
      "summary_es": "ADetailer es una herramienta automática de detección facial e inpainting diseñada para mejorar los detalles faciales en imágenes. Utiliza modelos de segmentación avanzados para identificar regiones faciales y aplica técnicas precisas de inpainting para aumentar la claridad y resolución. La herramienta destaca en el manejo de rostros de baja calidad u ocultos, siendo valiosa para restauración de imágenes, edición fotográfica y creación de contenido. Los casos de uso típicos incluyen arreglar retratos borrosos, eliminar artefactos y mejorar características faciales en medios digitales."
    },
    {
      "id": "openai/clip-vit-base-patch32",
      "source": "hf",
      "name": "clip-vit-base-patch32",
      "url": "https://huggingface.co/openai/clip-vit-base-patch32",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1908.04913",
        "arxiv:2103.00020",
        "clip",
        "endpoints_compatible",
        "jax",
        "pytorch",
        "region:us",
        "tf",
        "transformers",
        "vision",
        "zero-shot-image-classification"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 15096939,
        "likes_total": 767
      },
      "score": 30577.378,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "CLIP-ViT-Base-Patch32是OpenAI开发的一种视觉语言模型，通过自然语言监督学习视觉概念。该模型采用Vision Transformer（ViT）架构，补丁大小为32，将图像和文本编码到共享嵌入空间中。它擅长零样本图像分类、图像检索和跨模态理解，无需任务特定训练。其优势包括在不同数据集上的强大泛化能力和对分布变化的鲁棒性。典型应用场景包括内容审核、视觉搜索和多模态人工智能应用。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "CLIP-ViT-Base-Patch32 is a vision-language model developed by OpenAI that learns visual concepts from natural language supervision. It uses a Vision Transformer (ViT) architecture with patch size 32 to encode images and text into a shared embedding space. The model excels at zero-shot image classification, image retrieval, and cross-modal understanding without task-specific training. Its strengths include strong generalization across diverse datasets and robustness to distribution shifts. Typical use cases include content moderation, visual search, and multimodal AI applications.",
      "summary_zh": "CLIP-ViT-Base-Patch32是OpenAI开发的一种视觉语言模型，通过自然语言监督学习视觉概念。该模型采用Vision Transformer（ViT）架构，补丁大小为32，将图像和文本编码到共享嵌入空间中。它擅长零样本图像分类、图像检索和跨模态理解，无需任务特定训练。其优势包括在不同数据集上的强大泛化能力和对分布变化的鲁棒性。典型应用场景包括内容审核、视觉搜索和多模态人工智能应用。",
      "summary_es": "CLIP-ViT-Base-Patch32 es un modelo de visión y lenguaje desarrollado por OpenAI que aprende conceptos visuales a partir de supervisión de lenguaje natural. Utiliza una arquitectura Vision Transformer (ViT) con tamaño de parche 32 para codificar imágenes y texto en un espacio de incrustación compartido. El modelo sobresale en clasificación de imágenes de cero disparos, recuperación de imágenes y comprensión multimodal sin entrenamiento específico. Sus fortalezas incluyen una fuerte generalización en diversos conjuntos de datos y robustez ante cambios de distribución. Los casos de uso típicos incluyen moderación de contenido, búsqueda visual y aplicaciones de IA multimodal."
    },
    {
      "id": "openai-community/gpt2",
      "source": "hf",
      "name": "gpt2",
      "url": "https://huggingface.co/openai-community/gpt2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "autotrain_compatible",
        "doi:10.57967/hf/0039",
        "en",
        "endpoints_compatible",
        "exbert",
        "gpt2",
        "jax",
        "license:mit",
        "onnx",
        "pytorch",
        "region:us",
        "rust",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "tf",
        "tflite",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 12339920,
        "likes_total": 2951
      },
      "score": 26155.34,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "GPT-2是由OpenAI开发的基于Transformer架构的语言模型，专用于文本生成。其核心能力包括根据输入提示生成连贯且上下文相关的文本。优势在于能产生类人文本、支持多种语言以及应用的多样性。典型用例涵盖内容创作、聊天机器人、语言翻译和自动化写作辅助，利用其预测性文本生成功能而无需额外训练。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "GPT-2 is a transformer-based language model developed by OpenAI for text generation. Its core capabilities include generating coherent and contextually relevant text based on input prompts. Strengths include its ability to produce human-like text, support for various languages, and versatility in applications. Typical use cases encompass content creation, chatbots, language translation, and automated writing assistance, leveraging its predictive text generation without additional training.",
      "summary_zh": "GPT-2是由OpenAI开发的基于Transformer架构的语言模型，专用于文本生成。其核心能力包括根据输入提示生成连贯且上下文相关的文本。优势在于能产生类人文本、支持多种语言以及应用的多样性。典型用例涵盖内容创作、聊天机器人、语言翻译和自动化写作辅助，利用其预测性文本生成功能而无需额外训练。",
      "summary_es": "GPT-2 es un modelo de lenguaje basado en transformadores desarrollado por OpenAI para la generación de texto. Sus capacidades principales incluyen generar texto coherente y contextualmente relevante a partir de entradas. Sus fortalezas son la producción de texto similar al humano, soporte para múltiples idiomas y versatilidad en aplicaciones. Los casos de uso típicos abarcan creación de contenido, chatbots, traducción automática y asistencia en escritura automatizada, aprovechando su generación predictiva sin entrenamiento adicional."
    },
    {
      "id": "FacebookAI/roberta-large",
      "source": "hf",
      "name": "roberta-large",
      "url": "https://huggingface.co/FacebookAI/roberta-large",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1806.02847",
        "arxiv:1907.11692",
        "autotrain_compatible",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "en",
        "endpoints_compatible",
        "exbert",
        "fill-mask",
        "jax",
        "license:mit",
        "onnx",
        "pytorch",
        "region:us",
        "roberta",
        "safetensors",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 12229272,
        "likes_total": 246
      },
      "score": 24581.544,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "RoBERTa-large是由Facebook AI开发的基于Transformer架构的大规模语言模型，专为掩码语言建模优化。它在BERT基础上改进了训练方法，去除了下一句预测任务并使用更大规模数据集。核心能力包括文本理解、分类和信息抽取，优势在于在各种自然语言处理任务中表现稳健且微调高效。典型应用场景包括情感分析、问答系统和文本分类，适用于需要深度语言理解的场景。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "RoBERTa-large is a transformer-based language model optimized for masked language modeling, developed by Facebook AI. It builds on BERT's architecture with improved training procedures, removing next sentence prediction and using larger datasets. Core capabilities include text understanding, classification, and information extraction. Strengths are robust performance across NLP tasks and efficient fine-tuning. Typical use cases are sentiment analysis, question answering, and text classification.",
      "summary_zh": "RoBERTa-large是由Facebook AI开发的基于Transformer架构的大规模语言模型，专为掩码语言建模优化。它在BERT基础上改进了训练方法，去除了下一句预测任务并使用更大规模数据集。核心能力包括文本理解、分类和信息抽取，优势在于在各种自然语言处理任务中表现稳健且微调高效。典型应用场景包括情感分析、问答系统和文本分类，适用于需要深度语言理解的场景。",
      "summary_es": "RoBERTa-large es un modelo de lenguaje basado en transformers optimizado para modelado de lenguaje enmascarado, desarrollado por Facebook AI. Mejora la arquitectura de BERT con procedimientos de entrenamiento mejorados, eliminando la predicción de oraciones siguientes y usando conjuntos de datos más grandes. Capacidades principales incluyen comprensión de texto, clasificación y extracción de información. Fortalezas son rendimiento robusto en tareas de PLN y ajuste fino eficiente. Casos de uso típicos son análisis de sentimientos, respuesta a preguntas y clasificación de texto."
    },
    {
      "id": "distilbert/distilbert-base-uncased",
      "source": "hf",
      "name": "distilbert-base-uncased",
      "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1910.01108",
        "autotrain_compatible",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "distilbert",
        "en",
        "endpoints_compatible",
        "exbert",
        "fill-mask",
        "jax",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "rust",
        "safetensors",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 11913020,
        "likes_total": 758
      },
      "score": 24205.04,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "DistilBERT是BERT的轻量化版本，在保持97%性能的同时减少了40%的参数，实现了更快的推理速度和更低的计算需求。该模型基于英语BookCorpus和Wikipedia数据预训练，专精于掩码语言建模任务。核心能力包括文本分类、问答系统和命名实体识别，支持PyTorch、TensorFlow和JAX等多种框架，适用于资源受限环境下的高效自然语言处理应用。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "DistilBERT is a smaller, faster version of BERT that retains 97% of its performance while using 40% fewer parameters. It is designed for efficient natural language processing tasks like text classification, question answering, and named entity recognition. The model is pre-trained on English text from BookCorpus and Wikipedia, optimized for masked language modeling, and supports multiple frameworks including PyTorch, TensorFlow, and JAX.",
      "summary_zh": "DistilBERT是BERT的轻量化版本，在保持97%性能的同时减少了40%的参数，实现了更快的推理速度和更低的计算需求。该模型基于英语BookCorpus和Wikipedia数据预训练，专精于掩码语言建模任务。核心能力包括文本分类、问答系统和命名实体识别，支持PyTorch、TensorFlow和JAX等多种框架，适用于资源受限环境下的高效自然语言处理应用。",
      "summary_es": "DistilBERT es una versión más pequeña y rápida de BERT que mantiene el 97% de su rendimiento con un 40% menos de parámetros. Está diseñado para procesamiento eficiente de lenguaje natural, incluyendo clasificación de texto, respuesta a preguntas y reconocimiento de entidades nombradas. Preentrenado con texto inglés de BookCorpus y Wikipedia, optimizado para modelado de lenguaje enmascarado y compatible con frameworks como PyTorch, TensorFlow y JAX."
    },
    {
      "id": "FacebookAI/roberta-base",
      "source": "hf",
      "name": "roberta-base",
      "url": "https://huggingface.co/FacebookAI/roberta-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1806.02847",
        "arxiv:1907.11692",
        "autotrain_compatible",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "en",
        "endpoints_compatible",
        "exbert",
        "fill-mask",
        "jax",
        "license:mit",
        "pytorch",
        "region:us",
        "roberta",
        "rust",
        "safetensors",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 11214297,
        "likes_total": 528
      },
      "score": 22692.594,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，专为掩码语言建模优化。它在BERT架构基础上改进，移除了下一句预测任务并采用动态掩码训练。核心能力包括文本理解、分类和序列标注，优势在于在各种自然语言处理任务中表现稳健且预训练效率高。典型应用场景涵盖情感分析、问答系统和命名实体识别，充分利用其双向上下文编码能力，适用于英语文本处理。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "RoBERTa-base is a transformer-based language model optimized for masked language modeling, developed by Facebook AI. It builds on BERT's architecture but removes next-sentence prediction and uses dynamic masking during training. Core capabilities include text understanding, classification, and sequence labeling. Strengths are robust performance on various NLP tasks and efficient pre-training. Typical use cases span sentiment analysis, question answering, and named entity recognition, leveraging its bidirectional context encoding.",
      "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，专为掩码语言建模优化。它在BERT架构基础上改进，移除了下一句预测任务并采用动态掩码训练。核心能力包括文本理解、分类和序列标注，优势在于在各种自然语言处理任务中表现稳健且预训练效率高。典型应用场景涵盖情感分析、问答系统和命名实体识别，充分利用其双向上下文编码能力，适用于英语文本处理。",
      "summary_es": "RoBERTa-base es un modelo de lenguaje basado en transformers optimizado para modelado de lenguaje enmascarado, desarrollado por Facebook AI. Mejora la arquitectura de BERT al eliminar la predicción de oraciones siguientes y usar enmascaramiento dinámico durante el entrenamiento. Capacidades principales incluyen comprensión de texto, clasificación y etiquetado de secuencias. Fortalezas son rendimiento robusto en diversas tareas de PLN y preentrenamiento eficiente. Casos de uso típicos abarcan análisis de sentimientos, respuesta a preguntas y reconocimiento de entidades nombradas."
    },
    {
      "id": "google/electra-base-discriminator",
      "source": "hf",
      "name": "electra-base-discriminator",
      "url": "https://huggingface.co/google/electra-base-discriminator",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1406.2661",
        "electra",
        "en",
        "endpoints_compatible",
        "jax",
        "license:apache-2.0",
        "pretraining",
        "pytorch",
        "region:us",
        "rust",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 11129059,
        "likes_total": 65
      },
      "score": 22290.618000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ELECTRA-base-discriminator是谷歌开发的一种预训练Transformer模型，专为高效语言理解设计。它采用判别式预训练方法，学习区分真实标记与替换标记，相比生成式方法更具样本效率。核心能力包括文本分类、问答和标记分类。优势在于训练速度更快，且用较少数据在下游任务中表现更佳。典型应用场景涵盖情感分析、命名实体识别和自然语言推理任务。该模型基于Apache 2.0许可，支持多种框架如PyTorch和TensorFlow。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "ELECTRA-base-discriminator is a pre-trained transformer model from Google, designed for efficient language understanding. It uses a discriminative pre-training approach where it learns to distinguish real tokens from replaced ones, making it more sample-efficient than generative methods. Core capabilities include text classification, question answering, and token classification. Strengths include faster training and better performance on downstream tasks with less data. Typical use cases span sentiment analysis, named entity recognition, and natural language inference tasks.",
      "summary_zh": "ELECTRA-base-discriminator是谷歌开发的一种预训练Transformer模型，专为高效语言理解设计。它采用判别式预训练方法，学习区分真实标记与替换标记，相比生成式方法更具样本效率。核心能力包括文本分类、问答和标记分类。优势在于训练速度更快，且用较少数据在下游任务中表现更佳。典型应用场景涵盖情感分析、命名实体识别和自然语言推理任务。该模型基于Apache 2.0许可，支持多种框架如PyTorch和TensorFlow。",
      "summary_es": "ELECTRA-base-discriminator es un modelo transformer preentrenado de Google, diseñado para una comprensión eficiente del lenguaje. Utiliza un enfoque de preentrenamiento discriminativo donde aprende a distinguir tokens reales de reemplazados, haciéndolo más eficiente en muestras que los métodos generativos. Capacidades principales incluyen clasificación de texto, respuesta a preguntas y clasificación de tokens. Fortalezas son entrenamiento más rápido y mejor rendimiento en tareas posteriores con menos datos. Casos de uso típicos abarcan análisis de sentimientos, reconocimiento de entidades nombradas y tareas de inferencia de lenguaje natural."
    },
    {
      "id": "facebook/opt-125m",
      "source": "hf",
      "name": "opt-125m",
      "url": "https://huggingface.co/facebook/opt-125m",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2005.14165",
        "arxiv:2205.01068",
        "autotrain_compatible",
        "en",
        "jax",
        "license:other",
        "opt",
        "pytorch",
        "region:us",
        "text-generation",
        "text-generation-inference",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 9875029,
        "likes_total": 217
      },
      "score": 19858.558,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "OPT-125M是Meta AI开发的1.25亿参数仅解码器Transformer模型，属于开放预训练Transformer系列。该模型基于公开文本数据训练，专门用于因果语言建模任务，如内容生成、对话系统和文本补全。支持PyTorch、TensorFlow和JAX框架，适用于研究和需要高效文本生成能力的轻量级应用场景。模型设计注重可访问性和研究用途，提供基础的文本生成功能。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "OPT-125M is a 125 million parameter decoder-only transformer model developed by Meta AI for text generation. It is part of the Open Pre-trained Transformer series, trained on publicly available text data. The model supports causal language modeling tasks like content creation, dialogue systems, and text completion. It is compatible with PyTorch, TensorFlow, and JAX frameworks, making it accessible for research and lightweight applications requiring efficient text generation capabilities.",
      "summary_zh": "OPT-125M是Meta AI开发的1.25亿参数仅解码器Transformer模型，属于开放预训练Transformer系列。该模型基于公开文本数据训练，专门用于因果语言建模任务，如内容生成、对话系统和文本补全。支持PyTorch、TensorFlow和JAX框架，适用于研究和需要高效文本生成能力的轻量级应用场景。模型设计注重可访问性和研究用途，提供基础的文本生成功能。",
      "summary_es": "OPT-125M es un modelo transformer de solo decodificador con 125 millones de parámetros desarrollado por Meta AI para generación de texto. Es parte de la serie Open Pre-trained Transformer, entrenado con datos de texto públicamente disponibles. El modelo admite tareas de modelado de lenguaje causal como creación de contenido, sistemas de diálogo y completado de texto. Es compatible con frameworks PyTorch, TensorFlow y JAX, siendo accesible para investigación y aplicaciones ligeras que requieren capacidades eficientes de generación de texto."
    },
    {
      "id": "prajjwal1/bert-tiny",
      "source": "hf",
      "name": "bert-tiny",
      "url": "https://huggingface.co/prajjwal1/bert-tiny",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "BERT",
        "MNLI",
        "NLI",
        "arxiv:1908.08962",
        "arxiv:2110.01518",
        "en",
        "endpoints_compatible",
        "license:mit",
        "pre-training",
        "pytorch",
        "region:us",
        "transformer",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 9595121,
        "likes_total": 129
      },
      "score": 19254.742000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bert-tiny 是一个紧凑型 BERT 模型，专为高效自然语言推理任务设计。它在保持 BERT 核心架构的同时大幅减少参数，以实现更快推理。主要优势包括轻量级部署、与标准 transformers 兼容以及 MIT 许可。典型用例涵盖移动应用、边缘计算和需要低延迟 NLI 处理而无需大量计算资源的场景。该模型基于预训练，支持英语，适用于多种下游任务。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "bert-tiny is a compact BERT model designed for efficient natural language inference tasks. It maintains core BERT architecture while significantly reducing parameters for faster inference. Key strengths include lightweight deployment, compatibility with standard transformers, and MIT licensing. Typical use cases include mobile applications, edge computing, and scenarios requiring low-latency NLI processing without extensive computational resources.",
      "summary_zh": "bert-tiny 是一个紧凑型 BERT 模型，专为高效自然语言推理任务设计。它在保持 BERT 核心架构的同时大幅减少参数，以实现更快推理。主要优势包括轻量级部署、与标准 transformers 兼容以及 MIT 许可。典型用例涵盖移动应用、边缘计算和需要低延迟 NLI 处理而无需大量计算资源的场景。该模型基于预训练，支持英语，适用于多种下游任务。",
      "summary_es": "bert-tiny es un modelo BERT compacto diseñado para tareas eficientes de inferencia en lenguaje natural. Mantiene la arquitectura central de BERT mientras reduce significativamente los parámetros para una inferencia más rápida. Sus fortalezas clave incluyen implementación ligera, compatibilidad con transformers estándar y licencia MIT. Los casos de uso típicos abarcan aplicaciones móviles, computación perimetral y escenarios que requieren procesamiento de NLI de baja latencia sin recursos computacionales extensos."
    },
    {
      "id": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
      "source": "hf",
      "name": "paraphrase-multilingual-MiniLM-L12-v2",
      "url": "https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "ar",
        "arxiv:1908.10084",
        "autotrain_compatible",
        "bert",
        "bg",
        "ca",
        "cs",
        "da",
        "de",
        "el",
        "en",
        "endpoints_compatible",
        "es",
        "et",
        "fa",
        "feature-extraction",
        "fi",
        "fr",
        "gl",
        "gu",
        "he",
        "hi",
        "hr",
        "hu",
        "hy",
        "id",
        "it",
        "ja",
        "ka",
        "ko",
        "ku",
        "license:apache-2.0",
        "lt",
        "lv",
        "mk",
        "mn",
        "mr",
        "ms",
        "multilingual",
        "my",
        "nb",
        "nl",
        "onnx",
        "openvino",
        "pl",
        "pt",
        "pytorch",
        "region:us",
        "ro",
        "ru",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "sk",
        "sl",
        "sq",
        "sr",
        "sv",
        "text-embeddings-inference",
        "tf",
        "th",
        "tr",
        "transformers",
        "uk",
        "ur",
        "vi"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 9573294,
        "likes_total": 1014
      },
      "score": 19653.588,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "paraphrase-multilingual-MiniLM-L12-v2 是一个紧凑的多语言句子转换模型，专为生成语义嵌入而设计。它支持超过 50 种语言，并采用 12 层 MiniLM 架构进行高效计算。核心功能包括语义相似性计算、文本聚类和跨语言检索。优势在于多语言支持、在复述识别方面的高性能以及高效的推理能力。典型应用场景包括语义搜索、重复内容检测和多语言内容推荐系统。该模型基于 BERT 架构优化，适用于资源受限环境，同时保持较高的准确性。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "inference_acceleration"
      ],
      "summary_en": "The paraphrase-multilingual-MiniLM-L12-v2 model is a compact multilingual sentence transformer designed for generating semantic embeddings. It supports over 50 languages and is optimized for efficient computation with a 12-layer MiniLM architecture. Its core capabilities include semantic similarity, text clustering, and cross-lingual retrieval. Strengths include multilingual support, high performance in paraphrase identification, and efficient inference. Typical use cases include semantic search, duplicate detection, and multilingual content recommendation systems.",
      "summary_zh": "paraphrase-multilingual-MiniLM-L12-v2 是一个紧凑的多语言句子转换模型，专为生成语义嵌入而设计。它支持超过 50 种语言，并采用 12 层 MiniLM 架构进行高效计算。核心功能包括语义相似性计算、文本聚类和跨语言检索。优势在于多语言支持、在复述识别方面的高性能以及高效的推理能力。典型应用场景包括语义搜索、重复内容检测和多语言内容推荐系统。该模型基于 BERT 架构优化，适用于资源受限环境，同时保持较高的准确性。",
      "summary_es": "El modelo paraphrase-multilingual-MiniLM-L12-v2 es un transformador de oraciones multilingüe compacto diseñado para generar incrustaciones semánticas. Soporta más de 50 idiomas y está optimizado para cómputo eficiente con una arquitectura MiniLM de 12 capas. Sus capacidades principales incluyen similitud semántica, agrupación de texto y recuperación cross-lingual. Fortalezas: soporte multilingüe, alto rendimiento en identificación de paráfrasis e inferencia eficiente. Casos de uso típicos: búsqueda semántica, detección de duplicados y sistemas de recomendación de contenido multilingüe."
    },
    {
      "id": "context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16",
      "source": "hf",
      "name": "meta-llama-Llama-3.2-3B-Instruct-FP16",
      "url": "https://huggingface.co/context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2204.05149",
        "arxiv:2405.16406",
        "autotrain_compatible",
        "conversational",
        "de",
        "en",
        "endpoints_compatible",
        "es",
        "facebook",
        "fr",
        "hi",
        "it",
        "license:llama3.2",
        "llama",
        "llama-3",
        "meta",
        "pt",
        "pytorch",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "th",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 9025392,
        "likes_total": 7
      },
      "score": 18054.284,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Meta Llama 3.2 3B Instruct FP16 是一个拥有 30 亿参数的指令微调语言模型，专为对话式人工智能优化。它支持多种语言，包括英语、西班牙语、德语、法语、印地语、意大利语和葡萄牙语。该模型擅长遵循指令、回答问题并进行对话，同时保持事实准确性。典型用例包括聊天机器人、虚拟助手和多语言客户支持应用。它采用 FP16 精度以实现高效推理，基于 Llama 3.2 架构，适用于需要轻量级但高性能 AI 助手的场景。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Meta Llama 3.2 3B Instruct FP16 is a 3-billion parameter instruction-tuned language model optimized for conversational AI. It supports multiple languages including English, Spanish, German, French, Hindi, Italian, and Portuguese. The model excels at following instructions, answering questions, and engaging in dialogue while maintaining factual accuracy. Typical use cases include chatbots, virtual assistants, and multilingual customer support applications. It uses FP16 precision for efficient inference.",
      "summary_zh": "Meta Llama 3.2 3B Instruct FP16 是一个拥有 30 亿参数的指令微调语言模型，专为对话式人工智能优化。它支持多种语言，包括英语、西班牙语、德语、法语、印地语、意大利语和葡萄牙语。该模型擅长遵循指令、回答问题并进行对话，同时保持事实准确性。典型用例包括聊天机器人、虚拟助手和多语言客户支持应用。它采用 FP16 精度以实现高效推理，基于 Llama 3.2 架构，适用于需要轻量级但高性能 AI 助手的场景。",
      "summary_es": "Meta Llama 3.2 3B Instruct FP16 es un modelo de lenguaje de 3 mil millones de parámetros ajustado para instrucciones, optimizado para IA conversacional. Soporta múltiples idiomas, incluidos inglés, español, alemán, francés, hindi, italiano y portugués. Destaca en seguir instrucciones, responder preguntas y mantener diálogos con precisión factual. Los casos de uso típicos incluyen chatbots, asistentes virtuales y aplicaciones de soporte al cliente multilingüe. Utiliza precisión FP16 para una inferencia eficiente."
    },
    {
      "id": "omni-research/Tarsier2-Recap-7b",
      "source": "hf",
      "name": "Tarsier2-Recap-7b",
      "url": "https://huggingface.co/omni-research/Tarsier2-Recap-7b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2501.07888",
        "license:apache-2.0",
        "region:us",
        "safetensors",
        "video LLM"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8924832,
        "likes_total": 18
      },
      "score": 17858.664,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Tarsier2-Recap-7b 是一个拥有 70 亿参数的多模态视频语言模型，专为视频内容理解和摘要生成而设计。该模型能够处理视频中的视觉和时序信息，提取关键事件并生成简洁的摘要。其核心能力包括高效分析长视频、准确识别重要场景以及生成连贯的叙述。典型应用场景包括教育内容总结、视频索引自动化以及媒体内容分析。该模型基于 Apache 2.0 许可证发布，支持安全张量格式。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Tarsier2-Recap-7b is a 7-billion parameter video language model designed for video understanding and summarization. It processes video content to generate concise recaps, leveraging multimodal capabilities to analyze visual and temporal information. The model excels at extracting key events and narratives from videos, making it suitable for content analysis, educational summaries, and automated video indexing. Its strengths include efficient processing of long videos and accurate event detection.",
      "summary_zh": "Tarsier2-Recap-7b 是一个拥有 70 亿参数的多模态视频语言模型，专为视频内容理解和摘要生成而设计。该模型能够处理视频中的视觉和时序信息，提取关键事件并生成简洁的摘要。其核心能力包括高效分析长视频、准确识别重要场景以及生成连贯的叙述。典型应用场景包括教育内容总结、视频索引自动化以及媒体内容分析。该模型基于 Apache 2.0 许可证发布，支持安全张量格式。",
      "summary_es": "Tarsier2-Recap-7b es un modelo de lenguaje de video con 7 mil millones de parámetros diseñado para la comprensión y resumen de contenido visual. Procesa videos para generar recapitulaciones concisas, utilizando capacidades multimodales para analizar información visual y temporal. Sus fortalezas incluyen la extracción precisa de eventos clave y el procesamiento eficiente de videos largos. Es ideal para análisis de contenido, resúmenes educativos e indexación automatizada de videos."
    },
    {
      "id": "openai/clip-vit-large-patch14",
      "source": "hf",
      "name": "clip-vit-large-patch14",
      "url": "https://huggingface.co/openai/clip-vit-large-patch14",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1908.04913",
        "arxiv:2103.00020",
        "clip",
        "endpoints_compatible",
        "jax",
        "pytorch",
        "region:us",
        "safetensors",
        "tf",
        "transformers",
        "vision",
        "zero-shot-image-classification"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8287393,
        "likes_total": 1864
      },
      "score": 17506.786,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "CLIP-ViT-Large-Patch14是OpenAI开发的多模态人工智能模型，连接视觉与语言处理。它采用Vision Transformer架构和大尺寸图像块处理图像与文本。该模型擅长零样本图像分类，无需特定任务训练即可将图像与自然语言描述匹配。核心能力包括跨模态理解、图像文本检索和视觉问答。典型应用涵盖内容审核、视觉搜索和自动图像标注等多个领域，具有强大的泛化性能和灵活的部署能力。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "CLIP-ViT-Large-Patch14 is a multimodal AI model developed by OpenAI that connects vision and language. It uses a Vision Transformer architecture with large patch size to process images and text simultaneously. The model excels at zero-shot image classification by matching images with natural language descriptions without task-specific training. Its core capabilities include cross-modal understanding, image-text retrieval, and visual question answering. Typical use cases span content moderation, visual search, and automated image captioning across various domains.",
      "summary_zh": "CLIP-ViT-Large-Patch14是OpenAI开发的多模态人工智能模型，连接视觉与语言处理。它采用Vision Transformer架构和大尺寸图像块处理图像与文本。该模型擅长零样本图像分类，无需特定任务训练即可将图像与自然语言描述匹配。核心能力包括跨模态理解、图像文本检索和视觉问答。典型应用涵盖内容审核、视觉搜索和自动图像标注等多个领域，具有强大的泛化性能和灵活的部署能力。",
      "summary_es": "CLIP-ViT-Large-Patch14 es un modelo multimodal de IA desarrollado por OpenAI que conecta visión y lenguaje. Utiliza una arquitectura Vision Transformer con parches grandes para procesar imágenes y texto simultáneamente. El modelo sobresale en clasificación de imágenes zero-shot al emparejar imágenes con descripciones en lenguaje natural sin entrenamiento específico. Sus capacidades principales incluyen comprensión cross-modal, recuperación imagen-texto y respuesta a preguntas visuales. Los casos de uso típicos abarcan moderación de contenido, búsqueda visual y subtitulado automático de imágenes."
    },
    {
      "id": "trpakov/vit-face-expression",
      "source": "hf",
      "name": "vit-face-expression",
      "url": "https://huggingface.co/trpakov/vit-face-expression",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "autotrain_compatible",
        "doi:10.57967/hf/2289",
        "endpoints_compatible",
        "image-classification",
        "license:apache-2.0",
        "onnx",
        "pytorch",
        "region:us",
        "safetensors",
        "transformers",
        "vit"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8254929,
        "likes_total": 80
      },
      "score": 16549.858,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "vit-face-expression模型是一种基于Vision Transformer（ViT）的面部表情分类工具，专门用于从输入图像中识别和分类人类面部表情。其核心能力包括利用Transformer架构精确检测面部特征中的情绪，具备高分类准确性和处理效率。优势在于模型性能稳定、兼容主流框架如PyTorch和ONNX，并支持安全张量格式。典型应用场景包括心理学中的情绪分析、用户体验研究以及需要实时表情识别的交互式应用，如人机交互和情感计算领域。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "The vit-face-expression model is a Vision Transformer (ViT) designed for facial expression classification. It analyzes input images to categorize human facial expressions into predefined classes. Core capabilities include accurate emotion detection from facial features, leveraging transformer architecture for robust performance. Strengths are high classification accuracy, efficient processing, and compatibility with standard frameworks. Typical use cases include emotion analysis in psychology, user experience research, and interactive applications requiring real-time expression recognition.",
      "summary_zh": "vit-face-expression模型是一种基于Vision Transformer（ViT）的面部表情分类工具，专门用于从输入图像中识别和分类人类面部表情。其核心能力包括利用Transformer架构精确检测面部特征中的情绪，具备高分类准确性和处理效率。优势在于模型性能稳定、兼容主流框架如PyTorch和ONNX，并支持安全张量格式。典型应用场景包括心理学中的情绪分析、用户体验研究以及需要实时表情识别的交互式应用，如人机交互和情感计算领域。",
      "summary_es": "El modelo vit-face-expression es un Vision Transformer (ViT) diseñado para la clasificación de expresiones faciales. Analiza imágenes de entrada para categorizar expresiones humanas en clases predefinidas. Sus capacidades principales incluyen la detección precisa de emociones a partir de características faciales, aprovechando la arquitectura transformer para un rendimiento robusto. Fortalezas son alta precisión de clasificación, procesamiento eficiente y compatibilidad con frameworks estándar. Casos de uso típicos incluyen análisis de emociones en psicología, investigación de experiencia de usuario y aplicaciones interactivas que requieren reconocimiento de expresiones en tiempo real."
    },
    {
      "id": "google/vit-base-patch16-224-in21k",
      "source": "hf",
      "name": "vit-base-patch16-224-in21k",
      "url": "https://huggingface.co/google/vit-base-patch16-224-in21k",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2006.03677",
        "arxiv:2010.11929",
        "dataset:imagenet-21k",
        "image-feature-extraction",
        "jax",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "safetensors",
        "tf",
        "transformers",
        "vision",
        "vit"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8138717,
        "likes_total": 372
      },
      "score": 16463.434,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "该Vision Transformer（ViT）基础模型将224x224像素图像分割为16x16补丁进行处理。在ImageNet-21k数据集上预训练，擅长图像分类和特征提取。其优势包括强大的跨视觉任务泛化能力，以及支持PyTorch、TensorFlow和JAX等框架。典型应用场景包括针对特定图像识别任务的微调，或作为计算机视觉流程中的特征提取器。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "image_classification"
      ],
      "summary_en": "The Vision Transformer (ViT) base model processes 224x224 pixel images by splitting them into 16x16 patches. Pre-trained on ImageNet-21k, it excels at image classification and feature extraction. Its strengths include strong generalization across vision tasks and compatibility with frameworks like PyTorch, TensorFlow, and JAX. Typical use cases involve fine-tuning for specific image recognition applications or as a feature extractor in computer vision pipelines.",
      "summary_zh": "该Vision Transformer（ViT）基础模型将224x224像素图像分割为16x16补丁进行处理。在ImageNet-21k数据集上预训练，擅长图像分类和特征提取。其优势包括强大的跨视觉任务泛化能力，以及支持PyTorch、TensorFlow和JAX等框架。典型应用场景包括针对特定图像识别任务的微调，或作为计算机视觉流程中的特征提取器。",
      "summary_es": "El modelo base Vision Transformer (ViT) procesa imágenes de 224x224 píxeles dividiéndolas en parches de 16x16. Preentrenado en ImageNet-21k, sobresale en clasificación de imágenes y extracción de características. Sus fortalezas incluyen una fuerte generalización en tareas visuales y compatibilidad con frameworks como PyTorch, TensorFlow y JAX. Los casos de uso típicos implican ajuste fino para aplicaciones específicas de reconocimiento de imágenes o como extractor de características en pipelines de visión por computadora."
    },
    {
      "id": "facebook/contriever",
      "source": "hf",
      "name": "contriever",
      "url": "https://huggingface.co/facebook/contriever",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2112.09118",
        "bert",
        "endpoints_compatible",
        "pytorch",
        "region:us",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8071747,
        "likes_total": 64
      },
      "score": 16175.494,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Contriever是Facebook开发的对比学习模型，用于密集文本检索。它将文档和查询编码为紧凑的向量表示，支持高效的相似性搜索。核心能力包括无需精确关键词匹配的语义搜索。优势在于无监督训练方法和与标准BERT架构的兼容性。典型应用场景包括信息检索、文档搜索和问答系统，特别适用于需要精确语义理解的场景。模型基于对比学习原理，能够有效捕捉文本的深层语义关系。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Contriever is a contrastive learning model for dense text retrieval, developed by Facebook. It encodes documents and queries into compact vector representations, enabling efficient similarity search. Core capabilities include semantic matching without exact keyword overlap. Strengths are its unsupervised training approach and compatibility with standard BERT architectures. Typical use cases include information retrieval, document search, and question answering systems where precise semantic understanding is required.",
      "summary_zh": "Contriever是Facebook开发的对比学习模型，用于密集文本检索。它将文档和查询编码为紧凑的向量表示，支持高效的相似性搜索。核心能力包括无需精确关键词匹配的语义搜索。优势在于无监督训练方法和与标准BERT架构的兼容性。典型应用场景包括信息检索、文档搜索和问答系统，特别适用于需要精确语义理解的场景。模型基于对比学习原理，能够有效捕捉文本的深层语义关系。",
      "summary_es": "Contriever es un modelo de aprendizaje contrastivo para recuperación densa de texto, desarrollado por Facebook. Codifica documentos y consultas en representaciones vectoriales compactas, permitiendo búsquedas de similitud eficientes. Sus capacidades principales incluyen coincidencia semántica sin superposición exacta de palabras clave. Fortalezas son su enfoque de entrenamiento no supervisado y compatibilidad con arquitecturas BERT estándar. Casos de uso típicos incluyen recuperación de información, búsqueda de documentos y sistemas de respuesta a preguntas que requieren comprensión semántica precisa."
    },
    {
      "id": "FacebookAI/xlm-roberta-base",
      "source": "hf",
      "name": "xlm-roberta-base",
      "url": "https://huggingface.co/FacebookAI/xlm-roberta-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "af",
        "am",
        "ar",
        "arxiv:1911.02116",
        "as",
        "autotrain_compatible",
        "az",
        "be",
        "bg",
        "bn",
        "br",
        "bs",
        "ca",
        "cs",
        "cy",
        "da",
        "de",
        "el",
        "en",
        "endpoints_compatible",
        "eo",
        "es",
        "et",
        "eu",
        "exbert",
        "fa",
        "fi",
        "fill-mask",
        "fr",
        "fy",
        "ga",
        "gd",
        "gl",
        "gu",
        "ha",
        "he",
        "hi",
        "hr",
        "hu",
        "hy",
        "id",
        "is",
        "it",
        "ja",
        "jax",
        "jv",
        "ka",
        "kk",
        "km",
        "kn",
        "ko",
        "ku",
        "ky",
        "la",
        "license:mit",
        "lo",
        "lt",
        "lv",
        "mg",
        "mk",
        "ml",
        "mn",
        "mr",
        "ms",
        "multilingual",
        "my",
        "ne",
        "nl",
        "no",
        "om",
        "onnx",
        "or",
        "pa",
        "pl",
        "ps",
        "pt",
        "pytorch",
        "region:us",
        "ro",
        "ru",
        "sa",
        "safetensors",
        "sd",
        "si",
        "sk",
        "sl",
        "so",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "tf",
        "th",
        "tl",
        "tr",
        "transformers",
        "ug",
        "uk",
        "ur",
        "uz",
        "vi",
        "xh",
        "xlm-roberta",
        "yi",
        "zh"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7971501,
        "likes_total": 730
      },
      "score": 16308.002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "xlm-roberta-base是Facebook AI开发的多语言语言模型，基于RoBERTa架构。支持100种语言，通过大规模多语言文本预训练。核心功能包括文本分类、命名实体识别和问答任务。优势在于跨语言理解能力和高效微调性能。典型应用场景涵盖多语言自然语言处理任务，如情感分析和信息抽取，适用于处理不同语言的文本数据。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "xlm-roberta-base is a multilingual language model developed by Facebook AI, based on the RoBERTa architecture. It supports 100 languages and is pretrained on large-scale multilingual text. Core capabilities include text classification, named entity recognition, and question answering. Strengths are cross-lingual understanding and efficient fine-tuning. Typical use cases involve multilingual NLP tasks like sentiment analysis and information extraction across diverse languages.",
      "summary_zh": "xlm-roberta-base是Facebook AI开发的多语言语言模型，基于RoBERTa架构。支持100种语言，通过大规模多语言文本预训练。核心功能包括文本分类、命名实体识别和问答任务。优势在于跨语言理解能力和高效微调性能。典型应用场景涵盖多语言自然语言处理任务，如情感分析和信息抽取，适用于处理不同语言的文本数据。",
      "summary_es": "xlm-roberta-base es un modelo de lenguaje multilingüe desarrollado por Facebook AI, basado en la arquitectura RoBERTa. Soporta 100 idiomas y está preentrenado con texto multilingüe a gran escala. Capacidades principales incluyen clasificación de texto, reconocimiento de entidades nombradas y respuesta a preguntas. Fortalezas son la comprensión cross-lingual y el ajuste fino eficiente. Casos de uso típicos involucran tareas NLP multilingües como análisis de sentimientos y extracción de información en diversos idiomas."
    },
    {
      "id": "amazon/chronos-t5-small",
      "source": "hf",
      "name": "chronos-t5-small",
      "url": "https://huggingface.co/amazon/chronos-t5-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1910.10683",
        "arxiv:2403.07815",
        "endpoints_compatible",
        "forecasting",
        "foundation models",
        "license:apache-2.0",
        "pretrained models",
        "region:us",
        "safetensors",
        "t5",
        "text-generation-inference",
        "text2text-generation",
        "time series",
        "time series foundation models",
        "time-series",
        "time-series-forecasting",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7826603,
        "likes_total": 132
      },
      "score": 15719.206,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Chronos-T5-small是亚马逊开发的时间序列预测模型，基于T5架构。它将时间序列数据转换为文本标记进行预测，支持零样本预测而无需重新训练。核心能力包括处理各种时间序列模式并提供概率性预测。其优势在于高效性、可扩展性以及与transformers的兼容性。典型应用场景涵盖零售需求预测、金融市场分析和能源消耗预测，适用于多种行业的时间序列分析任务。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "time_series_forecasting"
      ],
      "summary_en": "Chronos-T5-small is a time series forecasting model developed by Amazon, based on the T5 architecture. It transforms time series data into text tokens for prediction, enabling zero-shot forecasting without retraining. Core capabilities include handling various time series patterns and providing probabilistic forecasts. Its strengths are efficiency, scalability, and compatibility with transformers. Typical use cases span retail demand prediction, financial market analysis, and energy consumption forecasting.",
      "summary_zh": "Chronos-T5-small是亚马逊开发的时间序列预测模型，基于T5架构。它将时间序列数据转换为文本标记进行预测，支持零样本预测而无需重新训练。核心能力包括处理各种时间序列模式并提供概率性预测。其优势在于高效性、可扩展性以及与transformers的兼容性。典型应用场景涵盖零售需求预测、金融市场分析和能源消耗预测，适用于多种行业的时间序列分析任务。",
      "summary_es": "Chronos-T5-small es un modelo de pronóstico de series temporales desarrollado por Amazon, basado en la arquitectura T5. Transforma datos de series temporales en tokens de texto para predicción, permitiendo pronósticos zero-shot sin reentrenamiento. Sus capacidades principales incluyen manejar diversos patrones de series temporales y proporcionar pronósticos probabilísticos. Sus fortalezas son eficiencia, escalabilidad y compatibilidad con transformers. Los casos de uso típicos abarcan predicción de demanda minorista, análisis de mercados financieros y pronóstico de consumo energético."
    },
    {
      "id": "pyannote/segmentation",
      "source": "hf",
      "name": "segmentation",
      "url": "https://huggingface.co/pyannote/segmentation",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2104.04045",
        "audio",
        "license:mit",
        "overlapped-speech-detection",
        "pyannote",
        "pyannote-audio",
        "pyannote-audio-model",
        "pytorch",
        "region:us",
        "resegmentation",
        "speaker",
        "speaker-segmentation",
        "speech",
        "voice",
        "voice-activity-detection"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7771470,
        "likes_total": 638
      },
      "score": 15861.94,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "PyAnnote Segmentation 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志化和音频分割。该模型能够检测音频录音中的说话人变化、语音活动以及重叠语音。其核心能力包括精确的时间边界检测和多说话人场景处理，在语音处理流程中表现出色。典型应用场景包括会议转录、播客分析和语音处理系统。该模型采用 MIT 许可证，因其准确性和鲁棒性而被广泛应用于研究和生产环境。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "PyAnnote Segmentation is a PyTorch-based neural network model for speaker diarization and audio segmentation. It detects speaker changes, voice activity, and overlapping speech in audio recordings. The model excels at precise temporal boundary detection and handles multi-speaker scenarios effectively. Typical applications include meeting transcription, podcast analysis, and speech processing pipelines. It is MIT-licensed and widely used in research and production environments for its accuracy and robustness.",
      "summary_zh": "PyAnnote Segmentation 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志化和音频分割。该模型能够检测音频录音中的说话人变化、语音活动以及重叠语音。其核心能力包括精确的时间边界检测和多说话人场景处理，在语音处理流程中表现出色。典型应用场景包括会议转录、播客分析和语音处理系统。该模型采用 MIT 许可证，因其准确性和鲁棒性而被广泛应用于研究和生产环境。",
      "summary_es": "PyAnnote Segmentation es un modelo de red neuronal basado en PyTorch para diarización de hablantes y segmentación de audio. Detecta cambios de hablante, actividad vocal y habla superpuesta en grabaciones de audio. El modelo destaca en la detección precisa de límites temporales y maneja eficazmente escenarios con múltiples hablantes. Las aplicaciones típicas incluyen transcripción de reuniones, análisis de podcasts y pipelines de procesamiento de voz. Tiene licencia MIT y es ampliamente utilizado en entornos de investigación y producción por su precisión y robustez."
    },
    {
      "id": "facebook/bart-base",
      "source": "hf",
      "name": "bart-base",
      "url": "https://huggingface.co/facebook/bart-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1910.13461",
        "bart",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "jax",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "safetensors",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7662269,
        "likes_total": 198
      },
      "score": 15423.538,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BART-base是一种基于Transformer的自然语言处理模型，专为序列到序列任务设计。其核心能力包括文本生成、摘要和翻译。优势在于去噪预训练方法，提升了在各种下游应用中的性能。典型用例涉及文档摘要、问答和文本校正，利用其双向编码器和自回归解码器架构，适用于多语言环境并支持多种框架集成。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "BART-base is a transformer-based model for natural language processing, designed for sequence-to-sequence tasks. Its core capabilities include text generation, summarization, and translation. Strengths lie in its denoising pre-training approach, which enhances performance on various downstream applications. Typical use cases involve document summarization, question answering, and text correction, leveraging its bidirectional encoder and autoregressive decoder architecture.",
      "summary_zh": "BART-base是一种基于Transformer的自然语言处理模型，专为序列到序列任务设计。其核心能力包括文本生成、摘要和翻译。优势在于去噪预训练方法，提升了在各种下游应用中的性能。典型用例涉及文档摘要、问答和文本校正，利用其双向编码器和自回归解码器架构，适用于多语言环境并支持多种框架集成。",
      "summary_es": "BART-base es un modelo basado en transformadores para procesamiento de lenguaje natural, diseñado para tareas de secuencia a secuencia. Sus capacidades principales incluyen generación de texto, resumen y traducción. Sus fortalezas radican en su enfoque de preentrenamiento con desruido, que mejora el rendimiento en diversas aplicaciones. Los casos de uso típicos implican resumen de documentos, respuesta a preguntas y corrección de texto."
    },
    {
      "id": "meta-llama/Llama-3.2-1B-Instruct",
      "source": "hf",
      "name": "Llama-3.2-1B-Instruct",
      "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2204.05149",
        "arxiv:2405.16406",
        "autotrain_compatible",
        "conversational",
        "de",
        "en",
        "endpoints_compatible",
        "es",
        "facebook",
        "fr",
        "hi",
        "it",
        "license:llama3.2",
        "llama",
        "llama-3",
        "meta",
        "pt",
        "pytorch",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "th",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7557620,
        "likes_total": 1071
      },
      "score": 15650.74,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Llama-3.2-1B-Instruct是Meta开发的10亿参数语言模型，专为指令遵循和对话任务优化。支持英语、德语、西班牙语、法语、印地语、意大利语和葡萄牙语等多语言。核心能力包括文本生成、问答和对话处理。优势在于模型紧凑、高效且支持多语言。典型应用场景包括聊天机器人、虚拟助手和教育工具，适用于资源受限的环境。基于Llama 3.2架构，注重实用性和可访问性。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Llama-3.2-1B-Instruct is a 1-billion parameter language model by Meta, optimized for instruction following and conversational tasks. It supports multiple languages including English, German, Spanish, French, Hindi, Italian, and Portuguese. Core capabilities include text generation, question answering, and dialogue. Strengths are its compact size, efficiency, and multilingual support. Typical use cases are chatbots, virtual assistants, and educational tools where resource constraints exist.",
      "summary_zh": "Llama-3.2-1B-Instruct是Meta开发的10亿参数语言模型，专为指令遵循和对话任务优化。支持英语、德语、西班牙语、法语、印地语、意大利语和葡萄牙语等多语言。核心能力包括文本生成、问答和对话处理。优势在于模型紧凑、高效且支持多语言。典型应用场景包括聊天机器人、虚拟助手和教育工具，适用于资源受限的环境。基于Llama 3.2架构，注重实用性和可访问性。",
      "summary_es": "Llama-3.2-1B-Instruct es un modelo de lenguaje de 1 billón de parámetros de Meta, optimizado para seguir instrucciones y tareas conversacionales. Soporta múltiples idiomas como inglés, alemán, español, francés, hindi, italiano y portugués. Capacidades principales incluyen generación de texto, respuesta a preguntas y diálogo. Fortalezas son su tamaño compacto, eficiencia y soporte multilingüe. Casos de uso típicos son chatbots, asistentes virtuales y herramientas educativas en entornos con limitaciones de recursos."
    },
    {
      "id": "openai/gpt-oss-20b",
      "source": "hf",
      "name": "gpt-oss-20b",
      "url": "https://huggingface.co/openai/gpt-oss-20b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "8-bit",
        "arxiv:2508.10925",
        "autotrain_compatible",
        "conversational",
        "endpoints_compatible",
        "gpt_oss",
        "license:apache-2.0",
        "mxfp4",
        "region:us",
        "safetensors",
        "text-generation",
        "transformers",
        "vllm"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7503160,
        "likes_total": 3557
      },
      "score": 16784.82,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "GPT-OSS-20B是由OpenAI开发的200亿参数开源语言模型，基于GPT架构。它专长于文本生成和对话任务，支持8位量化以实现高效部署。核心能力包括自然语言理解、内容创作和对话系统。优势在于其大规模参数、Apache 2.0许可证的广泛使用许可，以及与transformers和vllm框架的兼容性。典型应用场景涉及研究、人工智能开发、聊天机器人和自动化内容生成。该模型通过安全张量格式提供，适用于多种计算环境。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "inference_acceleration"
      ],
      "summary_en": "GPT-OSS-20B is a 20-billion-parameter open-source language model developed by OpenAI, based on the GPT architecture. It specializes in text generation and conversational tasks, supporting 8-bit quantization for efficient deployment. Core capabilities include natural language understanding, content creation, and dialogue systems. Strengths include its large scale, Apache 2.0 license for broad use, and compatibility with transformers and vllm frameworks. Typical use cases involve research, AI development, chatbots, and automated content generation.",
      "summary_zh": "GPT-OSS-20B是由OpenAI开发的200亿参数开源语言模型，基于GPT架构。它专长于文本生成和对话任务，支持8位量化以实现高效部署。核心能力包括自然语言理解、内容创作和对话系统。优势在于其大规模参数、Apache 2.0许可证的广泛使用许可，以及与transformers和vllm框架的兼容性。典型应用场景涉及研究、人工智能开发、聊天机器人和自动化内容生成。该模型通过安全张量格式提供，适用于多种计算环境。",
      "summary_es": "GPT-OSS-20B es un modelo de lenguaje de código abierto de 20 mil millones de parámetros desarrollado por OpenAI, basado en la arquitectura GPT. Se especializa en generación de texto y tareas conversacionales, admitiendo cuantización de 8 bits para un despliegue eficiente. Capacidades principales incluyen comprensión del lenguaje natural, creación de contenido y sistemas de diálogo. Fortalezas son su escala grande, licencia Apache 2.0 para uso amplio y compatibilidad con frameworks transformers y vllm. Casos de uso típicos involucran investigación, desarrollo de IA, chatbots y generación automatizada de contenido."
    },
    {
      "id": "BAAI/bge-base-en-v1.5",
      "source": "hf",
      "name": "bge-base-en-v1.5",
      "url": "https://huggingface.co/BAAI/bge-base-en-v1.5",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2309.07597",
        "arxiv:2310.07554",
        "arxiv:2311.13534",
        "arxiv:2312.15503",
        "arxiv:2401.03462",
        "autotrain_compatible",
        "bert",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "license:mit",
        "model-index",
        "mteb",
        "onnx",
        "pytorch",
        "region:us",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "text-embeddings-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7468962,
        "likes_total": 347
      },
      "score": 15111.424,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bge-base-en-v1.5是由BAAI开发的英文文本嵌入模型，旨在将文本转换为数值向量以处理语义相似性任务。其核心能力包括生成高质量句子嵌入、支持特征提取和实现高效文本比较。优势体现在MTEB基准测试中的优异表现、与多种框架（PyTorch、ONNX）的兼容性以及MIT许可。典型应用场景包括语义搜索、文本聚类、检索增强生成和英文语境下的相似性分析，适用于需要精确语义表示的自然语言处理项目。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "bge-base-en-v1.5 is an English text embedding model developed by BAAI, designed to convert text into numerical vectors for semantic similarity tasks. Its core capabilities include generating high-quality sentence embeddings, supporting feature extraction, and enabling efficient text comparison. Strengths include strong performance on MTEB benchmarks, compatibility with various frameworks (PyTorch, ONNX), and MIT licensing. Typical use cases encompass semantic search, clustering, retrieval-augmented generation, and similarity analysis in English-language applications.",
      "summary_zh": "bge-base-en-v1.5是由BAAI开发的英文文本嵌入模型，旨在将文本转换为数值向量以处理语义相似性任务。其核心能力包括生成高质量句子嵌入、支持特征提取和实现高效文本比较。优势体现在MTEB基准测试中的优异表现、与多种框架（PyTorch、ONNX）的兼容性以及MIT许可。典型应用场景包括语义搜索、文本聚类、检索增强生成和英文语境下的相似性分析，适用于需要精确语义表示的自然语言处理项目。",
      "summary_es": "bge-base-en-v1.5 es un modelo de incrustación de texto en inglés desarrollado por BAAI, diseñado para convertir texto en vectores numéricos para tareas de similitud semántica. Sus capacidades principales incluyen generar incrustaciones de oraciones de alta calidad, soportar extracción de características y permitir comparación eficiente de texto. Fortalezas: rendimiento sólido en benchmarks MTEB, compatibilidad con varios frameworks (PyTorch, ONNX) y licencia MIT. Casos de uso típicos: búsqueda semántica, agrupamiento, generación aumentada por recuperación y análisis de similitud en aplicaciones en inglés."
    },
    {
      "id": "Qwen/Qwen2.5-3B-Instruct",
      "source": "hf",
      "name": "Qwen2.5-3B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2407.10671",
        "autotrain_compatible",
        "base_model:Qwen/Qwen2.5-3B",
        "base_model:finetune:Qwen/Qwen2.5-3B",
        "chat",
        "conversational",
        "en",
        "endpoints_compatible",
        "license:other",
        "qwen2",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7220665,
        "likes_total": 311
      },
      "score": 14596.83,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2.5-3B-Instruct 是基于 Qwen2.5-3B 的 30 亿参数指令微调语言模型，专为对话式人工智能和文本生成任务设计。该模型擅长理解和遵循用户指令，生成连贯的响应，并处理多语言内容。主要优势包括高效的参数利用、与 transformers 和推理端点的兼容性，以及在对话系统中的出色表现。典型应用场景包括聊天机器人、虚拟助手和自动化内容创作。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Qwen2.5-3B-Instruct is a 3-billion parameter instruction-tuned language model based on Qwen2.5-3B, designed for conversational AI and text generation tasks. It excels in understanding and following user instructions, generating coherent responses, and handling multilingual content. Key strengths include efficient parameter usage, compatibility with transformers and inference endpoints, and strong performance in dialogue systems. Typical use cases include chatbots, virtual assistants, and automated content creation.",
      "summary_zh": "Qwen2.5-3B-Instruct 是基于 Qwen2.5-3B 的 30 亿参数指令微调语言模型，专为对话式人工智能和文本生成任务设计。该模型擅长理解和遵循用户指令，生成连贯的响应，并处理多语言内容。主要优势包括高效的参数利用、与 transformers 和推理端点的兼容性，以及在对话系统中的出色表现。典型应用场景包括聊天机器人、虚拟助手和自动化内容创作。",
      "summary_es": "Qwen2.5-3B-Instruct es un modelo de lenguaje de 3 mil millones de parámetros ajustado por instrucciones, basado en Qwen2.5-3B, diseñado para IA conversacional y generación de texto. Destaca en comprender y seguir instrucciones del usuario, generar respuestas coherentes y manejar contenido multilingüe. Sus fortanzas clave incluyen uso eficiente de parámetros, compatibilidad con transformers y endpoints de inferencia, y buen rendimiento en sistemas de diálogo. Casos de uso típicos son chatbots, asistentes virtuales y creación automatizada de contenido."
    },
    {
      "id": "meta-llama/Llama-3.1-8B-Instruct",
      "source": "hf",
      "name": "Llama-3.1-8B-Instruct",
      "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2204.05149",
        "autotrain_compatible",
        "base_model:finetune:meta-llama/Llama-3.1-8B",
        "base_model:meta-llama/Llama-3.1-8B",
        "conversational",
        "de",
        "en",
        "endpoints_compatible",
        "es",
        "facebook",
        "fr",
        "hi",
        "it",
        "license:llama3.1",
        "llama",
        "llama-3",
        "meta",
        "pt",
        "pytorch",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "th",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 6846729,
        "likes_total": 4641
      },
      "score": 16013.958,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Llama-3.1-8B-Instruct是Meta开发的80亿参数语言模型，专为指令跟随而微调。它擅长对话任务，支持英语、西班牙语、德语等多种语言，并针对对话和用户查询进行了优化。典型用例包括聊天机器人、虚拟助手和需要精确、上下文感知响应的文本应用。其优势在于对话能力、多语言支持和高效的性能表现，适用于各种交互式场景。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Llama-3.1-8B-Instruct is an 8-billion parameter language model from Meta, fine-tuned for instruction following. It excels in conversational tasks, supports multiple languages including English, Spanish, and German, and is optimized for dialogue and user queries. Typical use cases include chatbots, virtual assistants, and text-based applications requiring precise, context-aware responses. Its strengths lie in its conversational capabilities, multilingual support, and efficient performance for its size.",
      "summary_zh": "Llama-3.1-8B-Instruct是Meta开发的80亿参数语言模型，专为指令跟随而微调。它擅长对话任务，支持英语、西班牙语、德语等多种语言，并针对对话和用户查询进行了优化。典型用例包括聊天机器人、虚拟助手和需要精确、上下文感知响应的文本应用。其优势在于对话能力、多语言支持和高效的性能表现，适用于各种交互式场景。",
      "summary_es": "Llama-3.1-8B-Instruct es un modelo de lenguaje de 8 mil millones de parámetros de Meta, ajustado para seguir instrucciones. Destaca en tareas conversacionales, admite múltiples idiomas como inglés, español y alemán, y está optimizado para diálogos y consultas de usuarios. Los casos de uso típicos incluyen chatbots, asistentes virtuales y aplicaciones basadas en texto que requieren respuestas precisas y contextuales. Sus fortalezas son sus capacidades conversacionales, soporte multilingüe y rendimiento eficiente."
    },
    {
      "id": "Qwen/Qwen2.5-7B-Instruct",
      "source": "hf",
      "name": "Qwen2.5-7B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2309.00071",
        "arxiv:2407.10671",
        "autotrain_compatible",
        "base_model:Qwen/Qwen2.5-7B",
        "base_model:finetune:Qwen/Qwen2.5-7B",
        "chat",
        "conversational",
        "en",
        "endpoints_compatible",
        "license:apache-2.0",
        "qwen2",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 6795171,
        "likes_total": 797
      },
      "score": 13988.842,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2.5-7B-Instruct 是基于 Qwen2.5-7B 的 70 亿参数指令微调语言模型，专为对话 AI 和文本生成任务设计。它擅长理解和遵循复杂指令，生成连贯且上下文相关的响应。核心能力包括多语言支持、代码生成和逻辑推理。典型用例涵盖聊天机器人、虚拟助手、内容创作和编程辅助。该模型采用 Apache 2.0 许可证，兼容 Transformers 等流行框架，强调实用性和可访问性。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Qwen2.5-7B-Instruct is a 7-billion parameter instruction-tuned language model based on Qwen2.5-7B, designed for conversational AI and text generation tasks. It excels in understanding and following complex instructions, generating coherent and contextually appropriate responses. Core capabilities include multilingual support, code generation, and reasoning. Typical use cases include chatbots, virtual assistants, content creation, and programming assistance. The model is Apache 2.0 licensed and compatible with popular frameworks like Transformers.",
      "summary_zh": "Qwen2.5-7B-Instruct 是基于 Qwen2.5-7B 的 70 亿参数指令微调语言模型，专为对话 AI 和文本生成任务设计。它擅长理解和遵循复杂指令，生成连贯且上下文相关的响应。核心能力包括多语言支持、代码生成和逻辑推理。典型用例涵盖聊天机器人、虚拟助手、内容创作和编程辅助。该模型采用 Apache 2.0 许可证，兼容 Transformers 等流行框架，强调实用性和可访问性。",
      "summary_es": "Qwen2.5-7B-Instruct es un modelo de lenguaje de 7 mil millones de parámetros ajustado para instrucciones, basado en Qwen2.5-7B, diseñado para IA conversacional y generación de texto. Destaca en comprender y seguir instrucciones complejas, generando respuestas coherentes y contextuales. Sus capacidades incluyen soporte multilingüe, generación de código y razonamiento. Los casos de uso típicos son chatbots, asistentes virtuales, creación de contenido y asistencia en programación. Tiene licencia Apache 2.0 y es compatible con frameworks como Transformers."
    },
    {
      "id": "pyannote/voice-activity-detection",
      "source": "hf",
      "name": "voice-activity-detection",
      "url": "https://huggingface.co/pyannote/voice-activity-detection",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "audio",
        "automatic-speech-recognition",
        "dataset:ami",
        "dataset:dihard",
        "dataset:voxconverse",
        "license:mit",
        "pyannote",
        "pyannote-audio",
        "pyannote-audio-pipeline",
        "region:us",
        "speaker",
        "speech",
        "voice",
        "voice-activity-detection"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 6201537,
        "likes_total": 210
      },
      "score": 12508.074,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Pyannote语音活动检测是一种音频处理工具，用于识别录音中的语音片段。它采用深度学习技术，能够高精度地区分语音和非语音区域。主要优势包括在各种声学条件下的稳定性能以及与pyannote-audio管道的无缝集成。典型应用场景包括语音识别系统的预处理、说话人日志生成和音频转录工作流程，特别适用于会议记录和媒体内容分析。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Pyannote voice-activity-detection is an audio processing tool that identifies speech segments in audio recordings. It uses deep learning to distinguish between speech and non-speech regions with high accuracy. Key strengths include robust performance across various acoustic conditions and integration with pyannote-audio pipelines. Typical use cases include preprocessing for speech recognition systems, speaker diarization, and audio transcription workflows.",
      "summary_zh": "Pyannote语音活动检测是一种音频处理工具，用于识别录音中的语音片段。它采用深度学习技术，能够高精度地区分语音和非语音区域。主要优势包括在各种声学条件下的稳定性能以及与pyannote-audio管道的无缝集成。典型应用场景包括语音识别系统的预处理、说话人日志生成和音频转录工作流程，特别适用于会议记录和媒体内容分析。",
      "summary_es": "Pyannote voice-activity-detection es una herramienta de procesamiento de audio que identifica segmentos de voz en grabaciones. Utiliza aprendizaje profundo para distinguir entre regiones de voz y no voz con alta precisión. Sus principales fortalezas incluyen rendimiento robusto en diversas condiciones acústicas e integración con pipelines de pyannote-audio. Los casos de uso típicos incluyen preprocesamiento para sistemas de reconocimiento de voz, diarización de hablantes y flujos de trabajo de transcripción de audio."
    },
    {
      "id": "colbert-ir/colbertv2.0",
      "source": "hf",
      "name": "colbertv2.0",
      "url": "https://huggingface.co/colbert-ir/colbertv2.0",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "ColBERT",
        "arxiv:2004.12832",
        "arxiv:2007.00814",
        "arxiv:2101.00436",
        "arxiv:2112.01488",
        "arxiv:2205.09707",
        "bert",
        "en",
        "endpoints_compatible",
        "license:mit",
        "onnx",
        "pytorch",
        "region:us",
        "safetensors",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 6056741,
        "likes_total": 285
      },
      "score": 12255.982,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ColBERTv2.0是一种神经搜索模型，通过结合BERT的上下文理解能力与高效的延迟交互机制来改进信息检索。它将查询和文档分别编码为细粒度嵌入向量，支持快速的近似最近邻搜索。主要优势包括高准确性、可扩展至大规模文档集，以及与现有基础设施的兼容性。典型应用场景涵盖网络搜索、企业文档检索和问答系统，适用于需要精确高效匹配的任务。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "ColBERTv2.0 is a neural search model that enhances information retrieval by combining BERT's contextual understanding with efficient late interaction. It encodes queries and documents separately into fine-grained embeddings, enabling fast approximate nearest neighbor search. Key strengths include high accuracy, scalability to large collections, and compatibility with existing infrastructure. Typical use cases include web search, enterprise document retrieval, and question-answering systems where precise, efficient matching is required.",
      "summary_zh": "ColBERTv2.0是一种神经搜索模型，通过结合BERT的上下文理解能力与高效的延迟交互机制来改进信息检索。它将查询和文档分别编码为细粒度嵌入向量，支持快速的近似最近邻搜索。主要优势包括高准确性、可扩展至大规模文档集，以及与现有基础设施的兼容性。典型应用场景涵盖网络搜索、企业文档检索和问答系统，适用于需要精确高效匹配的任务。",
      "summary_es": "ColBERTv2.0 es un modelo de búsqueda neuronal que mejora la recuperación de información al combinar la comprensión contextual de BERT con una interacción tardía eficiente. Codifica consultas y documentos por separado en incrustaciones de grano fino, permitiendo búsquedas rápidas de vecinos aproximados. Sus fortalezas clave incluyen alta precisión, escalabilidad a grandes colecciones y compatibilidad con infraestructura existente. Los casos de uso típicos son búsqueda web, recuperación de documentos empresariales y sistemas de pregunta-respuesta que requieren coincidencias precisas y eficientes."
    },
    {
      "id": "Qwen/Qwen3-0.6B",
      "source": "hf",
      "name": "Qwen3-0.6B",
      "url": "https://huggingface.co/Qwen/Qwen3-0.6B",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2505.09388",
        "autotrain_compatible",
        "base_model:Qwen/Qwen3-0.6B-Base",
        "base_model:finetune:Qwen/Qwen3-0.6B-Base",
        "conversational",
        "endpoints_compatible",
        "license:apache-2.0",
        "qwen3",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5871880,
        "likes_total": 637
      },
      "score": 12062.26,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen3-0.6B是阿里巴巴Qwen系列中的一款紧凑型0.6亿参数语言模型，专为高效文本生成而设计。它支持多语言处理和对话应用，针对受限硬件部署进行了优化。核心能力包括自然语言理解、文本补全和对话系统。优势在于其小尺寸、Apache 2.0许可证以及与transformers和推理工具的兼容性。典型用例涉及聊天机器人、内容生成和计算资源有限的轻量级AI应用，适用于需要快速响应和低功耗的场景。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Qwen3-0.6B is a compact 0.6 billion parameter language model from Alibaba's Qwen series, designed for efficient text generation. It supports multilingual processing and conversational applications, optimized for deployment on constrained hardware. Core capabilities include natural language understanding, text completion, and dialogue systems. Strengths include its small size, Apache 2.0 license, and compatibility with transformers and inference tools. Typical use cases involve chatbots, content generation, and lightweight AI applications where computational resources are limited.",
      "summary_zh": "Qwen3-0.6B是阿里巴巴Qwen系列中的一款紧凑型0.6亿参数语言模型，专为高效文本生成而设计。它支持多语言处理和对话应用，针对受限硬件部署进行了优化。核心能力包括自然语言理解、文本补全和对话系统。优势在于其小尺寸、Apache 2.0许可证以及与transformers和推理工具的兼容性。典型用例涉及聊天机器人、内容生成和计算资源有限的轻量级AI应用，适用于需要快速响应和低功耗的场景。",
      "summary_es": "Qwen3-0.6B es un modelo de lenguaje compacto de 0.6 mil millones de parámetros de la serie Qwen de Alibaba, diseñado para generación de texto eficiente. Soporta procesamiento multilingüe y aplicaciones conversacionales, optimizado para implementación en hardware limitado. Capacidades principales incluyen comprensión de lenguaje natural, completado de texto y sistemas de diálogo. Fortalezas son su tamaño reducido, licencia Apache 2.0 y compatibilidad con transformers y herramientas de inferencia. Casos de uso típicos incluyen chatbots, generación de contenido y aplicaciones ligeras de IA donde los recursos computacionales son limitados."
    },
    {
      "id": "BAAI/bge-m3",
      "source": "hf",
      "name": "bge-m3",
      "url": "https://huggingface.co/BAAI/bge-m3",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2004.04906",
        "arxiv:2004.12832",
        "arxiv:2106.14807",
        "arxiv:2107.05720",
        "arxiv:2402.03216",
        "autotrain_compatible",
        "endpoints_compatible",
        "feature-extraction",
        "license:mit",
        "onnx",
        "pytorch",
        "region:us",
        "sentence-similarity",
        "sentence-transformers",
        "text-embeddings-inference",
        "xlm-roberta"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5808603,
        "likes_total": 2367
      },
      "score": 12800.706,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BGE-M3是由北京智源人工智能研究院开发的多语言文本嵌入模型，支持超过100种语言的密集向量表示生成。其核心能力包括语义相似度计算、跨语言检索和文本聚类，采用先进的训练技术确保多语言场景下的高性能表现。该模型适用于多语言搜索引擎、文档匹配、内容推荐系统等需要语言无关理解的典型应用场景，具有强大的泛化能力和准确性。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "BGE-M3 is a multilingual text embedding model developed by BAAI, designed to generate dense vector representations of text in over 100 languages. It excels in semantic similarity, retrieval, and clustering tasks, leveraging advanced training techniques for robust cross-lingual performance. Typical use cases include multilingual search engines, document matching, and content recommendation systems where language-agnostic understanding is required.",
      "summary_zh": "BGE-M3是由北京智源人工智能研究院开发的多语言文本嵌入模型，支持超过100种语言的密集向量表示生成。其核心能力包括语义相似度计算、跨语言检索和文本聚类，采用先进的训练技术确保多语言场景下的高性能表现。该模型适用于多语言搜索引擎、文档匹配、内容推荐系统等需要语言无关理解的典型应用场景，具有强大的泛化能力和准确性。",
      "summary_es": "BGE-M3 es un modelo de incrustación de texto multilingüe desarrollado por BAAI, diseñado para generar representaciones vectoriales densas de texto en más de 100 idiomas. Destaca en tareas de similitud semántica, recuperación y agrupación, utilizando técnicas de entrenamiento avanzadas para un rendimiento robusto cross-lingual. Los casos de uso típicos incluyen motores de búsqueda multilingües, emparejamiento de documentos y sistemas de recomendación de contenido que requieren comprensión independiente del idioma."
    },
    {
      "id": "Datadog/Toto-Open-Base-1.0",
      "source": "hf",
      "name": "Toto-Open-Base-1.0",
      "url": "https://huggingface.co/Datadog/Toto-Open-Base-1.0",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2505.14766",
        "dataset:Salesforce/GiftEvalPretrain",
        "dataset:autogluon/chronos_datasets",
        "endpoints_compatible",
        "forecasting",
        "foundation models",
        "license:apache-2.0",
        "observability",
        "pretrained models",
        "region:us",
        "safetensors",
        "time series",
        "time series foundation models",
        "time-series",
        "time-series-forecasting",
        "timeseries",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5681266,
        "likes_total": 109
      },
      "score": 11417.032000000001,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Toto-Open-Base-1.0是由Datadog开发的时间序列基础模型，专为预测应用设计。该模型在Salesforce/GiftEvalPretrain和AutoGluon/chronos_datasets等数据集上进行了预训练，能够准确预测多种时间模式。核心功能包括处理多样化时间序列数据、支持Transformer架构以及提供可靠的预测输出。典型应用场景涵盖可观测性监控、资源规划和运维环境中的异常检测，适用于需要高精度时间预测的各类业务场景。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Toto-Open-Base-1.0 is a time series foundation model developed by Datadog for forecasting applications. It is pretrained on datasets including Salesforce/GiftEvalPretrain and AutoGluon/chronos_datasets, enabling accurate predictions across various temporal patterns. Core capabilities include handling diverse time series data, supporting transformers architecture, and providing reliable forecasting outputs. Typical use cases span observability monitoring, resource planning, and anomaly detection in operational environments.",
      "summary_zh": "Toto-Open-Base-1.0是由Datadog开发的时间序列基础模型，专为预测应用设计。该模型在Salesforce/GiftEvalPretrain和AutoGluon/chronos_datasets等数据集上进行了预训练，能够准确预测多种时间模式。核心功能包括处理多样化时间序列数据、支持Transformer架构以及提供可靠的预测输出。典型应用场景涵盖可观测性监控、资源规划和运维环境中的异常检测，适用于需要高精度时间预测的各类业务场景。",
      "summary_es": "Toto-Open-Base-1.0 es un modelo fundacional de series temporales desarrollado por Datadog para aplicaciones de pronóstico. Está preentrenado en conjuntos de datos como Salesforce/GiftEvalPretrain y AutoGluon/chronos_datasets, permitiendo predicciones precisas en diversos patrones temporales. Sus capacidades principales incluyen el manejo de datos de series temporales variadas, soporte para arquitectura transformers y generación de pronósticos confiables. Los casos de uso típicos abarcan monitoreo de observabilidad, planificación de recursos y detección de anomalías en entornos operativos."
    },
    {
      "id": "nlpaueb/legal-bert-base-uncased",
      "source": "hf",
      "name": "legal-bert-base-uncased",
      "url": "https://huggingface.co/nlpaueb/legal-bert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "bert",
        "en",
        "endpoints_compatible",
        "fill-mask",
        "jax",
        "legal",
        "license:cc-by-sa-4.0",
        "pretraining",
        "pytorch",
        "region:us",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5596750,
        "likes_total": 271
      },
      "score": 11329,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Legal-BERT-base-uncased 是一个专门针对法律文本预训练的 BERT 模型，基于大量法律语料库开发。该模型擅长理解和处理法律语言，包括复杂术语和文档结构。核心能力包括文本分类、命名实体识别和法律文档信息提取。其优势在于领域特定的预训练，使其在法律自然语言处理任务中表现卓越。典型应用场景包括合同分析、法律研究自动化和合规文档处理，能够有效提升法律工作的效率和准确性。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Legal-BERT-base-uncased is a specialized BERT model pretrained on extensive legal text corpora. It excels in understanding and processing legal language, including complex terminology and document structures. Core capabilities include text classification, named entity recognition, and information extraction from legal documents. Its strengths lie in domain-specific pretraining, making it highly effective for legal NLP tasks. Typical use cases include contract analysis, legal research automation, and compliance document processing.",
      "summary_zh": "Legal-BERT-base-uncased 是一个专门针对法律文本预训练的 BERT 模型，基于大量法律语料库开发。该模型擅长理解和处理法律语言，包括复杂术语和文档结构。核心能力包括文本分类、命名实体识别和法律文档信息提取。其优势在于领域特定的预训练，使其在法律自然语言处理任务中表现卓越。典型应用场景包括合同分析、法律研究自动化和合规文档处理，能够有效提升法律工作的效率和准确性。",
      "summary_es": "Legal-BERT-base-uncased es un modelo BERT especializado preentrenado en extensos corpus de texto legal. Destaca en la comprensión y procesamiento del lenguaje jurídico, incluyendo terminología compleja y estructuras documentales. Sus capacidades principales incluyen clasificación de texto, reconocimiento de entidades nombradas y extracción de información de documentos legales. Sus fortalezas radican en el preentrenamiento específico del dominio, haciéndolo muy efectivo para tareas de PLN legal. Los casos de uso típicos incluyen análisis de contratos, automatización de investigación legal y procesamiento de documentos de cumplimiento."
    },
    {
      "id": "thuml/sundial-base-128m",
      "source": "hf",
      "name": "sundial-base-128m",
      "url": "https://huggingface.co/thuml/sundial-base-128m",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2403.07815",
        "arxiv:2502.00816",
        "custom_code",
        "dataset:Salesforce/lotsa_data",
        "dataset:autogluon/chronos_datasets",
        "dataset:thuml/UTSD",
        "forecasting",
        "foundation models",
        "generative models",
        "license:apache-2.0",
        "pretrained models",
        "region:us",
        "safetensors",
        "sundial",
        "time series",
        "time series foundation models",
        "time-series",
        "time-series-forecasting"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5380391,
        "likes_total": 45
      },
      "score": 10783.282000000001,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Sundial-base-128m是由THUML开发的1.28亿参数时间序列基础模型，专门用于时间序列预测和生成任务。该模型基于Salesforce/lotsa_data、AutoGluon/chronos_datasets等多个数据集训练，具备强大的时序模式处理能力。核心优势包括高效的预测精度、灵活的生成能力以及广泛的应用适应性。典型用例涵盖金融预测、气象预报、工业监控等领域，采用Apache 2.0开源许可和Safetensors格式确保安全部署。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Sundial-base-128m is a 128 million parameter time series foundation model developed by THUML. It specializes in time series forecasting and generation, trained on multiple datasets including Salesforce/lotsa_data and AutoGluon/chronos_datasets. The model demonstrates strong capabilities in handling various temporal patterns and is designed for applications in financial forecasting, weather prediction, and industrial monitoring. It uses Apache 2.0 license and Safetensors format for secure deployment.",
      "summary_zh": "Sundial-base-128m是由THUML开发的1.28亿参数时间序列基础模型，专门用于时间序列预测和生成任务。该模型基于Salesforce/lotsa_data、AutoGluon/chronos_datasets等多个数据集训练，具备强大的时序模式处理能力。核心优势包括高效的预测精度、灵活的生成能力以及广泛的应用适应性。典型用例涵盖金融预测、气象预报、工业监控等领域，采用Apache 2.0开源许可和Safetensors格式确保安全部署。",
      "summary_es": "Sundial-base-128m es un modelo fundacional de series temporales de 128 millones de parámetros desarrollado por THUML. Se especializa en predicción y generación de series temporales, entrenado con múltiples conjuntos de datos incluyendo Salesforce/lotsa_data y AutoGluon/chronos_datasets. El modelo demuestra fuertes capacidades para manejar diversos patrones temporales y está diseñado para aplicaciones en pronóstico financiero, predicción meteorológica y monitoreo industrial. Utiliza licencia Apache 2.0 y formato Safetensors para despliegue seguro."
    },
    {
      "id": "autogluon/chronos-bolt-base",
      "source": "hf",
      "name": "chronos-bolt-base",
      "url": "https://huggingface.co/autogluon/chronos-bolt-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1910.10683",
        "arxiv:2403.07815",
        "forecasting",
        "foundation models",
        "license:apache-2.0",
        "pretrained models",
        "region:us",
        "safetensors",
        "t5",
        "time series",
        "time series foundation models",
        "time-series",
        "time-series-forecasting"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5256572,
        "likes_total": 26
      },
      "score": 10526.144,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Chronos-Bolt-Base是基于T5架构的时间序列预测基础模型，经过大规模数据集预训练，用于单变量时间序列的未来值预测。核心能力包括零样本预测、针对特定领域的微调以及处理各种时间序列模式。其优势在于跨领域的泛化能力、高效的预训练过程和Apache 2.0开源许可。典型应用场景涵盖零售需求预测、金融市场预测和工业传感器监控，无需领域特定的训练数据即可部署。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "time_series_forecasting"
      ],
      "summary_en": "Chronos-Bolt-Base is a time series forecasting foundation model based on T5 architecture. It is pretrained on large-scale datasets to predict future values in univariate time series. Core capabilities include zero-shot forecasting, fine-tuning for specific domains, and handling various time series patterns. Strengths are its generalization across domains, efficient pretraining, and Apache 2.0 license. Typical use cases span retail demand forecasting, financial market prediction, and industrial sensor monitoring without requiring domain-specific training data.",
      "summary_zh": "Chronos-Bolt-Base是基于T5架构的时间序列预测基础模型，经过大规模数据集预训练，用于单变量时间序列的未来值预测。核心能力包括零样本预测、针对特定领域的微调以及处理各种时间序列模式。其优势在于跨领域的泛化能力、高效的预训练过程和Apache 2.0开源许可。典型应用场景涵盖零售需求预测、金融市场预测和工业传感器监控，无需领域特定的训练数据即可部署。",
      "summary_es": "Chronos-Bolt-Base es un modelo fundacional de pronóstico de series temporales basado en la arquitectura T5. Está preentrenado en conjuntos de datos a gran escala para predecir valores futuros en series temporales univariantes. Sus capacidades principales incluyen pronóstico zero-shot, ajuste fino para dominios específicos y manejo de diversos patrones de series temporales. Sus fortalezas son la generalización entre dominios, el preentrenamiento eficiente y la licencia Apache 2.0. Los casos de uso típicos abarcan pronóstico de demanda minorista, predicción de mercados financieros y monitoreo de sensores industriales sin necesidad de datos de entrenamiento específicos del dominio."
    },
    {
      "id": "facebook/esmfold_v1",
      "source": "hf",
      "name": "esmfold_v1",
      "url": "https://huggingface.co/facebook/esmfold_v1",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "endpoints_compatible",
        "esm",
        "license:mit",
        "pytorch",
        "region:us",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5169161,
        "likes_total": 42
      },
      "score": 10359.322,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ESMFold v1是Meta AI开发的蛋白质结构预测模型。它利用进化尺度建模直接从氨基酸序列预测蛋白质的三维结构。该模型擅长快速准确地预测结构，无需多重序列比对。特别适用于预测新型蛋白质的结构，在计算生物学和药物发现领域有广泛应用。该模型与Transformers兼容，采用MIT许可证发布，支持端点部署。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "ESMFold v1 is a protein structure prediction model developed by Meta AI. It uses evolutionary scale modeling to predict 3D protein structures directly from amino acid sequences. The model excels at rapid and accurate structure prediction without requiring multiple sequence alignments. It is particularly useful for predicting structures of novel proteins and has applications in computational biology and drug discovery. The model is compatible with Transformers and available under MIT license.",
      "summary_zh": "ESMFold v1是Meta AI开发的蛋白质结构预测模型。它利用进化尺度建模直接从氨基酸序列预测蛋白质的三维结构。该模型擅长快速准确地预测结构，无需多重序列比对。特别适用于预测新型蛋白质的结构，在计算生物学和药物发现领域有广泛应用。该模型与Transformers兼容，采用MIT许可证发布，支持端点部署。",
      "summary_es": "ESMFold v1 es un modelo de predicción de estructura proteica desarrollado por Meta AI. Utiliza modelado a escala evolutiva para predecir estructuras 3D de proteínas directamente a partir de secuencias de aminoácidos. El modelo destaca por su predicción rápida y precisa sin necesidad de alineamientos de secuencias múltiples. Es especialmente útil para predecir estructuras de proteínas novedosas y tiene aplicaciones en biología computacional y descubrimiento de fármacos. Es compatible con Transformers y disponible bajo licencia MIT."
    },
    {
      "id": "Comfy-Org/Wan_2.2_ComfyUI_Repackaged",
      "source": "hf",
      "name": "Wan_2.2_ComfyUI_Repackaged",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "comfyui",
        "diffusion-single-file",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5076158,
        "likes_total": 326
      },
      "score": 10315.316,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Wan_2.2_ComfyUI_Repackaged 是一个专为 ComfyUI 优化的单文件扩散模型，旨在实现稳定高效的图像生成。其核心功能包括高质量的文本到图像合成，并确保输出可靠。优势在于易于集成、资源使用减少以及与 ComfyUI 工作流程的兼容性。典型用例涉及创意艺术生成、视觉概念原型设计以及各种应用的自动化内容创建，适合需要快速且一致图像输出的场景。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "text_to_image"
      ],
      "summary_en": "Wan_2.2_ComfyUI_Repackaged is a single-file diffusion model optimized for ComfyUI, designed for stable and efficient image generation. Its core capabilities include high-quality text-to-image synthesis with reliable outputs. Strengths encompass ease of integration, reduced resource usage, and compatibility with ComfyUI workflows. Typical use cases involve creative art generation, prototyping visual concepts, and automated content creation for various applications.",
      "summary_zh": "Wan_2.2_ComfyUI_Repackaged 是一个专为 ComfyUI 优化的单文件扩散模型，旨在实现稳定高效的图像生成。其核心功能包括高质量的文本到图像合成，并确保输出可靠。优势在于易于集成、资源使用减少以及与 ComfyUI 工作流程的兼容性。典型用例涉及创意艺术生成、视觉概念原型设计以及各种应用的自动化内容创建，适合需要快速且一致图像输出的场景。",
      "summary_es": "Wan_2.2_ComfyUI_Repackaged es un modelo de difusión de archivo único optimizado para ComfyUI, diseñado para la generación de imágenes estable y eficiente. Sus capacidades principales incluyen síntesis de texto a imagen de alta calidad con salidas confiables. Sus fortalezas abarcan facilidad de integración, uso reducido de recursos y compatibilidad con flujos de trabajo de ComfyUI. Los casos de uso típicos involucran generación de arte creativo, prototipado de conceptos visuales y creación automatizada de contenido para diversas aplicaciones."
    },
    {
      "id": "coqui/XTTS-v2",
      "source": "hf",
      "name": "XTTS-v2",
      "url": "https://huggingface.co/coqui/XTTS-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "coqui",
        "license:other",
        "region:us",
        "text-to-speech"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5051839,
        "likes_total": 3043
      },
      "score": 11625.178,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "XTTS-v2 是一个多语言文本转语音模型，能够从文本输入生成自然语音。它支持仅用几秒钟音频进行语音克隆，并以多种语言输出高质量结果。核心能力包括跨语言语音转换和高效推理。主要优势在于语音自然度和多语言支持。典型应用场景包括有声读物旁白、配音工作以及为言语障碍用户提供辅助工具，提升数字内容的可访问性。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "tts"
      ],
      "summary_en": "XTTS-v2 is a multilingual text-to-speech model that generates natural speech from text input. It supports voice cloning with just a few seconds of audio, producing high-quality output in multiple languages. Key strengths include cross-lingual voice transfer and efficient inference. Typical use cases are audiobook narration, voiceovers, and accessibility tools for speech-impaired users.",
      "summary_zh": "XTTS-v2 是一个多语言文本转语音模型，能够从文本输入生成自然语音。它支持仅用几秒钟音频进行语音克隆，并以多种语言输出高质量结果。核心能力包括跨语言语音转换和高效推理。主要优势在于语音自然度和多语言支持。典型应用场景包括有声读物旁白、配音工作以及为言语障碍用户提供辅助工具，提升数字内容的可访问性。",
      "summary_es": "XTTS-v2 es un modelo de texto a voz multilingüe que genera habla natural a partir de texto. Permite clonar voces con solo unos segundos de audio, produciendo salida de alta calidad en múltiples idiomas. Sus fortalezas incluyen transferencia de voz entre idiomas e inferencia eficiente. Casos de uso típicos son narración de audiolibros, doblaje y herramientas de accesibilidad para usuarios con dificultades del habla."
    },
    {
      "id": "Qwen/Qwen2.5-1.5B-Instruct",
      "source": "hf",
      "name": "Qwen2.5-1.5B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2407.10671",
        "autotrain_compatible",
        "base_model:Qwen/Qwen2.5-1.5B",
        "base_model:finetune:Qwen/Qwen2.5-1.5B",
        "chat",
        "conversational",
        "en",
        "endpoints_compatible",
        "license:apache-2.0",
        "qwen2",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5025112,
        "likes_total": 513
      },
      "score": 10306.724,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2.5-1.5B-Instruct是基于Qwen2.5架构的15亿参数指令微调语言模型，专门用于对话式人工智能和文本生成任务。该模型优化了遵循用户指令和进行对话的能力，主要支持英语但具备多语言处理功能。典型应用包括聊天机器人、内容创作和自动化辅助系统。采用Apache 2.0许可证，与标准推理框架兼容，下载量超过500万次，在Hugging Face平台获得广泛使用。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Qwen2.5-1.5B-Instruct is a 1.5 billion parameter instruction-tuned language model based on Qwen2.5 architecture. It specializes in conversational AI and text generation tasks, optimized for following user instructions and engaging in dialogue. The model supports English primarily but handles multilingual content. Typical applications include chatbots, content creation, and automated assistance systems. It is Apache 2.0 licensed and compatible with standard inference frameworks.",
      "summary_zh": "Qwen2.5-1.5B-Instruct是基于Qwen2.5架构的15亿参数指令微调语言模型，专门用于对话式人工智能和文本生成任务。该模型优化了遵循用户指令和进行对话的能力，主要支持英语但具备多语言处理功能。典型应用包括聊天机器人、内容创作和自动化辅助系统。采用Apache 2.0许可证，与标准推理框架兼容，下载量超过500万次，在Hugging Face平台获得广泛使用。",
      "summary_es": "Qwen2.5-1.5B-Instruct es un modelo de lenguaje de 1.5 mil millones de parámetros ajustado por instrucciones, basado en la arquitectura Qwen2.5. Se especializa en IA conversacional y generación de texto, optimizado para seguir instrucciones de usuario y mantener diálogos. Soporta principalmente inglés pero maneja contenido multilingüe. Aplicaciones típicas incluyen chatbots, creación de contenido y sistemas de asistencia automatizada. Tiene licencia Apache 2.0 y es compatible con frameworks de inferencia estándar."
    },
    {
      "id": "BAAI/bge-small-en-v1.5",
      "source": "hf",
      "name": "bge-small-en-v1.5",
      "url": "https://huggingface.co/BAAI/bge-small-en-v1.5",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2309.07597",
        "arxiv:2310.07554",
        "arxiv:2311.13534",
        "arxiv:2312.15503",
        "arxiv:2401.03462",
        "autotrain_compatible",
        "bert",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "license:mit",
        "model-index",
        "mteb",
        "onnx",
        "pytorch",
        "region:us",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "text-embeddings-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4976585,
        "likes_total": 372
      },
      "score": 10139.17,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bge-small-en-v1.5是由BAAI开发的紧凑型英文文本嵌入模型，专为高效的句子相似度和特征提取而设计。它生成文本的密集向量表示，用于语义搜索、聚类和检索任务。该模型体积小巧，推理速度快，同时在基准评估中保持竞争力。典型应用场景包括文档匹配、推荐系统和信息检索，特别适用于需要计算效率优先的场景。基于BERT架构，支持多种部署方式。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "bge-small-en-v1.5 is a compact English text embedding model developed by BAAI, designed for efficient sentence similarity and feature extraction. It generates dense vector representations of text for semantic search, clustering, and retrieval tasks. With its small size, it offers fast inference while maintaining competitive performance on benchmark evaluations. Typical use cases include document matching, recommendation systems, and information retrieval applications where computational efficiency is prioritized.",
      "summary_zh": "bge-small-en-v1.5是由BAAI开发的紧凑型英文文本嵌入模型，专为高效的句子相似度和特征提取而设计。它生成文本的密集向量表示，用于语义搜索、聚类和检索任务。该模型体积小巧，推理速度快，同时在基准评估中保持竞争力。典型应用场景包括文档匹配、推荐系统和信息检索，特别适用于需要计算效率优先的场景。基于BERT架构，支持多种部署方式。",
      "summary_es": "bge-small-en-v1.5 es un modelo compacto de incrustación de texto en inglés desarrollado por BAAI, diseñado para similitud de oraciones y extracción de características eficientes. Genera representaciones vectoriales densas de texto para búsqueda semántica, agrupación y tareas de recuperación. Con su tamaño reducido, ofrece inferencia rápida manteniendo un rendimiento competitivo en evaluaciones de referencia. Los casos de uso típicos incluyen coincidencia de documentos, sistemas de recomendación y aplicaciones de recuperación de información donde se prioriza la eficiencia computacional."
    },
    {
      "id": "Salesforce/moirai-2.0-R-small",
      "source": "hf",
      "name": "moirai-2.0-R-small",
      "url": "https://huggingface.co/Salesforce/moirai-2.0-R-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2402.02592",
        "arxiv:2403.07815",
        "forecasting",
        "foundation models",
        "license:cc-by-nc-4.0",
        "pretrained models",
        "region:us",
        "safetensors",
        "time series",
        "time series foundation models",
        "time-series",
        "time-series-forecasting"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4759058,
        "likes_total": 20
      },
      "score": 9528.116,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Moirai-2.0-R-small是Salesforce开发的小型时间序列预测基础模型。该模型专门使用Transformer架构预测多样化时间序列数据的未来值，核心能力包括处理多频率数据、支持零样本预测和最小化训练数据需求。主要优势体现在零售需求预测、金融市场分析、能源负荷预测和经济指标预测等典型应用场景中。该模型采用CC-BY-NC-4.0许可证，适用于非商业研究用途。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "time_series_forecasting"
      ],
      "summary_en": "Moirai-2.0-R-small is a compact time series forecasting foundation model developed by Salesforce. It specializes in predicting future values across diverse time series data using transformer architecture. Key strengths include handling multiple frequencies, supporting zero-shot forecasting, and requiring minimal training data. Typical applications span retail demand prediction, financial market analysis, energy load forecasting, and economic indicator projection. The model is licensed under CC-BY-NC-4.0 for non-commercial research use.",
      "summary_zh": "Moirai-2.0-R-small是Salesforce开发的小型时间序列预测基础模型。该模型专门使用Transformer架构预测多样化时间序列数据的未来值，核心能力包括处理多频率数据、支持零样本预测和最小化训练数据需求。主要优势体现在零售需求预测、金融市场分析、能源负荷预测和经济指标预测等典型应用场景中。该模型采用CC-BY-NC-4.0许可证，适用于非商业研究用途。",
      "summary_es": "Moirai-2.0-R-small es un modelo fundacional compacto de pronóstico de series temporales desarrollado por Salesforce. Especializado en predecir valores futuros en datos de series temporales diversas utilizando arquitectura transformer. Sus principales fortalezas incluyen manejo de múltiples frecuencias, soporte para pronóstico zero-shot y requerimientos mínimos de datos de entrenamiento. Aplicaciones típicas abarcan predicción de demanda minorista, análisis de mercados financieros, pronóstico de carga energética y proyección de indicadores económicos. Licenciado bajo CC-BY-NC-4.0 para uso investigativo no comercial."
    },
    {
      "id": "dphn/dolphin-2.9.1-yi-1.5-34b",
      "source": "hf",
      "name": "dolphin-2.9.1-yi-1.5-34b",
      "url": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "autotrain_compatible",
        "axolotl",
        "base_model:01-ai/Yi-1.5-34B",
        "base_model:finetune:01-ai/Yi-1.5-34B",
        "conversational",
        "dataset:Locutusque/function-calling-chatml",
        "dataset:cognitivecomputations/Dolphin-2.9",
        "dataset:cognitivecomputations/dolphin-coder",
        "dataset:cognitivecomputations/samantha-data",
        "dataset:internlm/Agent-FLAN",
        "dataset:m-a-p/CodeFeedback-Filtered-Instruction",
        "dataset:microsoft/orca-math-word-problems-200k",
        "dataset:teknium/OpenHermes-2.5",
        "endpoints_compatible",
        "generated_from_trainer",
        "license:apache-2.0",
        "llama",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4705950,
        "likes_total": 39
      },
      "score": 9431.4,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Dolphin-2.9.1-yi-1.5-34b是基于Yi-1.5-34B微调的语言模型，专为对话AI和文本生成设计。核心能力包括自然语言理解、代码辅助和函数调用，优势在于处理多样化数据集如OpenHermes和Orca-Math。典型用例涉及聊天机器人、编程支持以及解决复杂文字问题，利用其从多个高质量来源的稳健训练实现高效性能。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "code_generation"
      ],
      "summary_en": "Dolphin-2.9.1-yi-1.5-34b is a fine-tuned language model based on Yi-1.5-34B, designed for conversational AI and text generation. Its core capabilities include natural language understanding, code assistance, and function calling, with strengths in handling diverse datasets like OpenHermes and Orca-Math. Typical use cases involve chatbots, coding support, and solving complex word problems, leveraging its robust training from multiple high-quality sources.",
      "summary_zh": "Dolphin-2.9.1-yi-1.5-34b是基于Yi-1.5-34B微调的语言模型，专为对话AI和文本生成设计。核心能力包括自然语言理解、代码辅助和函数调用，优势在于处理多样化数据集如OpenHermes和Orca-Math。典型用例涉及聊天机器人、编程支持以及解决复杂文字问题，利用其从多个高质量来源的稳健训练实现高效性能。",
      "summary_es": "Dolphin-2.9.1-yi-1.5-34b es un modelo de lenguaje ajustado basado en Yi-1.5-34B, diseñado para IA conversacional y generación de texto. Sus capacidades principales incluyen comprensión del lenguaje natural, asistencia de código y llamadas a funciones, con fortalezas en manejar conjuntos de datos diversos como OpenHermes y Orca-Math. Los casos de uso típicos involucran chatbots, soporte de programación y resolución de problemas de palabras complejos, aprovechando su entrenamiento robusto de múltiples fuentes de alta calidad."
    },
    {
      "id": "sentence-transformers/gtr-t5-base",
      "source": "hf",
      "name": "gtr-t5-base",
      "url": "https://huggingface.co/sentence-transformers/gtr-t5-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2112.07899",
        "autotrain_compatible",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "t5"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4568501,
        "likes_total": 25
      },
      "score": 9149.502,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "gtr-t5-base 是基于 T5 架构的文本嵌入模型，专为生成句子的密集向量表示而设计。其核心能力是计算文本之间的语义相似度，支持语义搜索、聚类和检索等应用。优势包括高效处理英文文本以及与 sentence-transformers 框架的集成。典型用例包括文档匹配、重复检测和基于文本内容相似度的推荐系统。该模型适用于需要理解文本语义而非表面特征的任务。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "gtr-t5-base is a text embedding model based on T5 architecture, designed for generating dense vector representations of sentences. Its core capability is computing semantic similarity between texts, enabling applications like semantic search, clustering, and retrieval. Strengths include efficient processing of English text and integration with the sentence-transformers framework. Typical use cases include document matching, duplicate detection, and recommendation systems based on textual content similarity.",
      "summary_zh": "gtr-t5-base 是基于 T5 架构的文本嵌入模型，专为生成句子的密集向量表示而设计。其核心能力是计算文本之间的语义相似度，支持语义搜索、聚类和检索等应用。优势包括高效处理英文文本以及与 sentence-transformers 框架的集成。典型用例包括文档匹配、重复检测和基于文本内容相似度的推荐系统。该模型适用于需要理解文本语义而非表面特征的任务。",
      "summary_es": "gtr-t5-base es un modelo de incrustación de texto basado en la arquitectura T5, diseñado para generar representaciones vectoriales densas de oraciones. Su capacidad principal es calcular la similitud semántica entre textos, permitiendo aplicaciones como búsqueda semántica, agrupación y recuperación. Sus fortalezas incluyen el procesamiento eficiente de texto en inglés y la integración con el framework sentence-transformers. Los casos de uso típicos incluyen coincidencia de documentos, detección de duplicados y sistemas de recomendación basados en similitud de contenido textual."
    },
    {
      "id": "google-bert/bert-base-multilingual-cased",
      "source": "hf",
      "name": "bert-base-multilingual-cased",
      "url": "https://huggingface.co/google-bert/bert-base-multilingual-cased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "af",
        "an",
        "ar",
        "arxiv:1810.04805",
        "ast",
        "autotrain_compatible",
        "az",
        "aze",
        "ba",
        "bar",
        "be",
        "bert",
        "bg",
        "bn",
        "br",
        "bs",
        "ca",
        "ce",
        "ceb",
        "cs",
        "cv",
        "cy",
        "da",
        "dataset:wikipedia",
        "de",
        "el",
        "en",
        "endpoints_compatible",
        "es",
        "et",
        "eu",
        "fa",
        "fi",
        "fill-mask",
        "fr",
        "fry",
        "ga",
        "gl",
        "gu",
        "he",
        "hi",
        "hr",
        "ht",
        "hu",
        "hy",
        "id",
        "inc",
        "io",
        "is",
        "it",
        "ja",
        "jax",
        "jv",
        "ka",
        "kk",
        "kn",
        "ko",
        "ky",
        "la",
        "license:apache-2.0",
        "lm",
        "lt",
        "lv",
        "mg",
        "min",
        "mk",
        "ml",
        "mn",
        "mr",
        "ms",
        "multilingual",
        "my",
        "nb",
        "nds",
        "ne",
        "new",
        "nl",
        "nn",
        "oc",
        "pa",
        "pl",
        "pms",
        "pnb",
        "pt",
        "pytorch",
        "region:us",
        "ro",
        "roa",
        "ru",
        "safetensors",
        "scn",
        "sco",
        "sk",
        "sl",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "tf",
        "tg",
        "th",
        "tl",
        "tr",
        "transformers",
        "tt",
        "ud",
        "uk",
        "uz",
        "vi",
        "vo",
        "war",
        "yo",
        "zh"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4551506,
        "likes_total": 530
      },
      "score": 9368.012,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BERT-base-multilingual-cased 是一个基于 Transformer 的多语言预训练语言模型，支持 104 种语言，基于维基百科文本训练。核心能力包括掩码语言建模和下一句预测任务，优势在于跨语言迁移学习和在多语言环境中保持稳定性能。典型应用场景涵盖文本分类、命名实体识别和多语言问答系统，利用其双向上下文理解能力处理跨语言自然语言处理任务。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "BERT-base-multilingual-cased is a transformer-based language model pre-trained on Wikipedia text across 104 languages. It handles masked language modeling and next sentence prediction tasks. Key strengths include cross-lingual transfer learning and consistent performance across diverse languages. Typical use cases are text classification, named entity recognition, and question answering in multilingual contexts, leveraging its bidirectional context understanding.",
      "summary_zh": "BERT-base-multilingual-cased 是一个基于 Transformer 的多语言预训练语言模型，支持 104 种语言，基于维基百科文本训练。核心能力包括掩码语言建模和下一句预测任务，优势在于跨语言迁移学习和在多语言环境中保持稳定性能。典型应用场景涵盖文本分类、命名实体识别和多语言问答系统，利用其双向上下文理解能力处理跨语言自然语言处理任务。",
      "summary_es": "BERT-base-multilingual-cased es un modelo de lenguaje preentrenado basado en Transformer para 104 idiomas, entrenado con texto de Wikipedia. Sus capacidades incluyen modelado de lenguaje enmascarado y predicción de oraciones siguientes. Fortalezas clave son el aprendizaje por transferencia cross-lingüe y rendimiento consistente en diversos idiomas. Casos de uso típicos son clasificación de texto, reconocimiento de entidades nombradas y respuesta a preguntas en contextos multilingües."
    },
    {
      "id": "google-t5/t5-small",
      "source": "hf",
      "name": "t5-small",
      "url": "https://huggingface.co/google-t5/t5-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1606.05250",
        "arxiv:1704.05426",
        "arxiv:1708.00055",
        "arxiv:1805.12471",
        "arxiv:1808.09121",
        "arxiv:1810.12885",
        "arxiv:1905.10044",
        "arxiv:1910.09700",
        "dataset:c4",
        "de",
        "en",
        "endpoints_compatible",
        "fr",
        "jax",
        "license:apache-2.0",
        "multilingual",
        "onnx",
        "pytorch",
        "region:us",
        "ro",
        "rust",
        "safetensors",
        "summarization",
        "t5",
        "text-generation-inference",
        "text2text-generation",
        "tf",
        "transformers",
        "translation"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4517967,
        "likes_total": 489
      },
      "score": 9280.434,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "T5-small是谷歌开发的小型文本到文本转换Transformer模型，采用统一文本生成框架处理多种自然语言处理任务。核心能力包括翻译、摘要和问答，支持多语言输入输出。优势在于模型紧凑、效率高、适用性广，适用于研究、教育或资源受限环境中的文本处理、语言理解和内容生成等典型场景。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "T5-small is a compact text-to-text transformer model from Google, designed for diverse NLP tasks through unified text generation. It handles tasks like translation, summarization, and question answering with a consistent input-output format. Strengths include multilingual support, efficient performance, and versatility across applications. Typical use cases involve text processing, language understanding, and content generation in research or lightweight deployments.",
      "summary_zh": "T5-small是谷歌开发的小型文本到文本转换Transformer模型，采用统一文本生成框架处理多种自然语言处理任务。核心能力包括翻译、摘要和问答，支持多语言输入输出。优势在于模型紧凑、效率高、适用性广，适用于研究、教育或资源受限环境中的文本处理、语言理解和内容生成等典型场景。",
      "summary_es": "T5-small es un modelo transformer compacto de texto a texto de Google, diseñado para diversas tareas de PLN mediante generación unificada de texto. Maneja traducción, resumen y respuesta a preguntas con un formato consistente. Fortalezas incluyen soporte multilingüe, rendimiento eficiente y versatilidad. Casos de uso típicos son procesamiento de texto, comprensión lingüística y generación de contenido en investigaciones o implementaciones ligeras."
    },
    {
      "id": "openai/whisper-large-v3",
      "source": "hf",
      "name": "whisper-large-v3",
      "url": "https://huggingface.co/openai/whisper-large-v3",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "af",
        "am",
        "ar",
        "arxiv:2212.04356",
        "as",
        "audio",
        "automatic-speech-recognition",
        "az",
        "ba",
        "be",
        "bg",
        "bn",
        "bo",
        "br",
        "bs",
        "ca",
        "cs",
        "cy",
        "da",
        "de",
        "el",
        "en",
        "endpoints_compatible",
        "es",
        "et",
        "eu",
        "fa",
        "fi",
        "fo",
        "fr",
        "gl",
        "gu",
        "ha",
        "haw",
        "he",
        "hf-asr-leaderboard",
        "hi",
        "hr",
        "ht",
        "hu",
        "hy",
        "id",
        "is",
        "it",
        "ja",
        "jax",
        "jw",
        "ka",
        "kk",
        "km",
        "kn",
        "ko",
        "la",
        "lb",
        "license:apache-2.0",
        "ln",
        "lo",
        "lt",
        "lv",
        "mg",
        "mi",
        "mk",
        "ml",
        "mn",
        "mr",
        "ms",
        "mt",
        "my",
        "ne",
        "nl",
        "nn",
        "no",
        "oc",
        "pa",
        "pl",
        "ps",
        "pt",
        "pytorch",
        "region:us",
        "ro",
        "ru",
        "sa",
        "safetensors",
        "sd",
        "si",
        "sk",
        "sl",
        "sn",
        "so",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "tg",
        "th",
        "tk",
        "tl",
        "tr",
        "transformers",
        "tt",
        "uk",
        "ur",
        "uz",
        "vi",
        "whisper",
        "yi",
        "yo",
        "zh"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4515271,
        "likes_total": 4926
      },
      "score": 11493.542,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Whisper-large-v3是OpenAI开发的开源自动语音识别模型，支持多种语言的语音转文本。核心功能包括多语言转录、翻译和语言识别。其优势在于广泛的语言支持、对不同口音的鲁棒性能以及开源可访问性。典型应用场景包括转录服务、无障碍工具和多语言内容处理，适用于全球范围内的语音数据处理需求。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "asr"
      ],
      "summary_en": "Whisper-large-v3 is an open-source automatic speech recognition model developed by OpenAI. It transcribes speech to text across multiple languages with high accuracy. Core capabilities include multilingual transcription, translation, and language identification. Strengths are its broad language support, robust performance on diverse accents, and open accessibility. Typical use cases include transcription services, accessibility tools, and multilingual content processing.",
      "summary_zh": "Whisper-large-v3是OpenAI开发的开源自动语音识别模型，支持多种语言的语音转文本。核心功能包括多语言转录、翻译和语言识别。其优势在于广泛的语言支持、对不同口音的鲁棒性能以及开源可访问性。典型应用场景包括转录服务、无障碍工具和多语言内容处理，适用于全球范围内的语音数据处理需求。",
      "summary_es": "Whisper-large-v3 es un modelo de reconocimiento automático de voz de código abierto desarrollado por OpenAI. Transcribe voz a texto en múltiples idiomas con alta precisión. Sus capacidades principales incluyen transcripción multilingüe, traducción e identificación de idiomas. Fortalezas son su amplio soporte lingüístico, rendimiento robusto en acentos diversos y accesibilidad abierta. Casos de uso típicos incluyen servicios de transcripción, herramientas de accesibilidad y procesamiento de contenido multilingüe."
    },
    {
      "id": "Qwen/Qwen2-VL-2B-Instruct",
      "source": "hf",
      "name": "Qwen2-VL-2B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2308.12966",
        "arxiv:2409.12191",
        "base_model:Qwen/Qwen2-VL-2B",
        "base_model:finetune:Qwen/Qwen2-VL-2B",
        "conversational",
        "en",
        "endpoints_compatible",
        "image-text-to-text",
        "image-to-text",
        "license:apache-2.0",
        "multimodal",
        "qwen2_vl",
        "region:us",
        "safetensors",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4461990,
        "likes_total": 450
      },
      "score": 9148.98,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2-VL-2B-Instruct 是一个拥有 20 亿参数的多模态人工智能模型，专为视觉语言任务设计。它能够同时处理图像和文本输入，生成上下文相关的响应，支持对话式交互和图像到文本的转换应用。主要优势包括高效的参数利用、与推理端点的兼容性以及 Apache 2.0 开源许可。典型应用场景涵盖视觉问答、图像描述生成和多模态对话系统，适用于需要结合视觉和语言理解的实际任务。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Qwen2-VL-2B-Instruct is a 2-billion parameter multimodal AI model designed for visual-language tasks. It processes both images and text to generate contextual responses, supporting conversational interactions and image-to-text applications. Key strengths include efficient parameter usage, compatibility with inference endpoints, and Apache 2.0 licensing. Typical use cases involve visual question answering, image captioning, and multimodal dialogue systems.",
      "summary_zh": "Qwen2-VL-2B-Instruct 是一个拥有 20 亿参数的多模态人工智能模型，专为视觉语言任务设计。它能够同时处理图像和文本输入，生成上下文相关的响应，支持对话式交互和图像到文本的转换应用。主要优势包括高效的参数利用、与推理端点的兼容性以及 Apache 2.0 开源许可。典型应用场景涵盖视觉问答、图像描述生成和多模态对话系统，适用于需要结合视觉和语言理解的实际任务。",
      "summary_es": "Qwen2-VL-2B-Instruct es un modelo multimodal de IA con 2 mil millones de parámetros diseñado para tareas de lenguaje visual. Procesa imágenes y texto para generar respuestas contextuales, admitiendo interacciones conversacionales y aplicaciones de imagen a texto. Sus principales fortalezas incluyen uso eficiente de parámetros, compatibilidad con endpoints de inferencia y licencia Apache 2.0. Los casos de uso típicos involucran respuesta visual a preguntas, generación de descripciones de imágenes y sistemas de diálogo multimodal."
    },
    {
      "id": "google/t5gemma-b-b-prefixlm",
      "source": "hf",
      "name": "t5gemma-b-b-prefixlm",
      "url": "https://huggingface.co/google/t5gemma-b-b-prefixlm",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1705.03551",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1907.10641",
        "arxiv:1911.01547",
        "arxiv:1911.11641",
        "arxiv:2009.03300",
        "arxiv:2103.03874",
        "arxiv:2107.03374",
        "arxiv:2108.07732",
        "arxiv:2110.14168",
        "arxiv:2206.04615",
        "arxiv:2304.06364",
        "arxiv:2504.06225",
        "base_model:finetune:google/t5gemma-b-b-prefixlm",
        "base_model:google/t5gemma-b-b-prefixlm",
        "endpoints_compatible",
        "license:gemma",
        "region:us",
        "safetensors",
        "t5gemma",
        "text2text-generation",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4427257,
        "likes_total": 9
      },
      "score": 8859.014000000001,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "t5gemma-b-b-prefixlm 是一个结合 T5 编码器-解码器架构与 Gemma 高效训练方法的混合模型。它通过前缀语言建模擅长文本生成、摘要和翻译任务。优势包括在多语言数据上的稳健性能以及微调适应性。典型应用场景涉及内容创作、数据预处理和跨语言应用，充分利用其结构化输出能力。该模型基于开源许可，支持安全部署。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "t5gemma-b-b-prefixlm is a hybrid model combining T5's encoder-decoder architecture with Gemma's efficient training. It excels at text generation, summarization, and translation tasks through prefix language modeling. Strengths include robust performance on multilingual data and fine-tuning adaptability. Typical use cases involve content creation, data preprocessing, and cross-lingual applications, leveraging its structured output capabilities.",
      "summary_zh": "t5gemma-b-b-prefixlm 是一个结合 T5 编码器-解码器架构与 Gemma 高效训练方法的混合模型。它通过前缀语言建模擅长文本生成、摘要和翻译任务。优势包括在多语言数据上的稳健性能以及微调适应性。典型应用场景涉及内容创作、数据预处理和跨语言应用，充分利用其结构化输出能力。该模型基于开源许可，支持安全部署。",
      "summary_es": "t5gemma-b-b-prefixlm es un modelo híbrido que combina la arquitectura codificador-decodificador de T5 con el entrenamiento eficiente de Gemma. Destaca en generación de texto, resumen y traducción mediante modelado de lenguaje por prefijos. Sus fortalezas incluyen rendimiento robusto en datos multilingües y adaptabilidad para ajuste fino. Los casos de uso típicos abarcan creación de contenido, preprocesamiento de datos y aplicaciones cross-linguales, aprovechando sus capacidades de salida estructurada."
    },
    {
      "id": "jinaai/jina-embeddings-v3",
      "source": "hf",
      "name": "jina-embeddings-v3",
      "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "af",
        "am",
        "ar",
        "arxiv:2409.10173",
        "as",
        "az",
        "be",
        "bg",
        "bn",
        "br",
        "bs",
        "ca",
        "cs",
        "custom_code",
        "cy",
        "da",
        "de",
        "el",
        "en",
        "eo",
        "es",
        "et",
        "eu",
        "fa",
        "feature-extraction",
        "fi",
        "fr",
        "fy",
        "ga",
        "gd",
        "gl",
        "gu",
        "ha",
        "he",
        "hi",
        "hr",
        "hu",
        "hy",
        "id",
        "is",
        "it",
        "ja",
        "jv",
        "ka",
        "kk",
        "km",
        "kn",
        "ko",
        "ku",
        "ky",
        "la",
        "license:cc-by-nc-4.0",
        "lo",
        "lt",
        "lv",
        "mg",
        "mk",
        "ml",
        "mn",
        "model-index",
        "mr",
        "ms",
        "mteb",
        "multilingual",
        "my",
        "ne",
        "nl",
        "no",
        "om",
        "onnx",
        "or",
        "pa",
        "pl",
        "ps",
        "pt",
        "pytorch",
        "region:eu",
        "ro",
        "ru",
        "sa",
        "safetensors",
        "sd",
        "sentence-similarity",
        "sentence-transformers",
        "si",
        "sk",
        "sl",
        "so",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "th",
        "tl",
        "tr",
        "transformers",
        "ug",
        "uk",
        "ur",
        "uz",
        "vi",
        "xh",
        "yi",
        "zh"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4305369,
        "likes_total": 1068
      },
      "score": 9144.738,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Jina Embeddings V3 是一个支持 100 多种语言的多语言文本嵌入模型，能够生成 1024 维向量用于语义相似性任务。其核心优势包括卓越的跨语言性能、高效的计算能力和广泛的语言覆盖。典型应用场景涵盖多语言搜索、文档检索、文本聚类和推荐系统，可在不同语言环境下实现统一处理，无需依赖特定语言的模型，提升了多语言应用的效率和准确性。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "summary_en": "Jina Embeddings V3 is a multilingual text embedding model supporting 100+ languages. It generates 1024-dimensional vectors for semantic similarity tasks. Key strengths include strong cross-lingual performance, efficient computation, and broad language coverage. Typical use cases include multilingual search, document retrieval, clustering, and recommendation systems across diverse linguistic contexts without requiring language-specific models.",
      "summary_zh": "Jina Embeddings V3 是一个支持 100 多种语言的多语言文本嵌入模型，能够生成 1024 维向量用于语义相似性任务。其核心优势包括卓越的跨语言性能、高效的计算能力和广泛的语言覆盖。典型应用场景涵盖多语言搜索、文档检索、文本聚类和推荐系统，可在不同语言环境下实现统一处理，无需依赖特定语言的模型，提升了多语言应用的效率和准确性。",
      "summary_es": "Jina Embeddings V3 es un modelo de incrustación de texto multilingüe que admite más de 100 idiomas. Genera vectores de 1024 dimensiones para tareas de similitud semántica. Sus principales fortalezas incluyen rendimiento cruzado lingüístico sólido, computación eficiente y amplia cobertura de idiomas. Los casos de uso típicos son búsqueda multilingüe, recuperación de documentos, agrupación y sistemas de recomendación en diversos contextos lingüísticos."
    },
    {
      "id": "Qwen/Qwen2.5-VL-7B-Instruct",
      "source": "hf",
      "name": "Qwen2.5-VL-7B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2308.12966",
        "arxiv:2309.00071",
        "arxiv:2409.12191",
        "conversational",
        "en",
        "endpoints_compatible",
        "image-text-to-text",
        "image-to-text",
        "license:apache-2.0",
        "multimodal",
        "qwen2_5_vl",
        "region:us",
        "safetensors",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4278243,
        "likes_total": 1249
      },
      "score": 9180.986,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2.5-VL-7B-Instruct 是一个拥有70亿参数的多模态人工智能模型，能够同时处理图像和文本以生成响应。它在视觉问答、图像描述和涉及视觉内容的对话任务中表现出色。该模型针对指令跟随进行了优化，支持多种语言，适用于教育、内容分析和交互式AI助手等应用场景。采用Apache 2.0许可证，并与主流推理框架兼容，具有高效的计算性能和广泛的应用潜力。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "image_text_alignment",
        "multimodal_understanding_generation",
        "vqa",
        "visual_grounding",
        "lightweight_visual_model",
        "multilingual_processing",
        "dialogue_system_optimization"
      ],
      "summary_en": "Qwen2.5-VL-7B-Instruct is a 7-billion parameter multimodal AI model that processes both images and text to generate responses. It excels in visual question answering, image captioning, and conversational tasks involving visual content. The model is optimized for instruction following and supports multiple languages, making it suitable for applications in education, content analysis, and interactive AI assistants. It is Apache 2.0 licensed and compatible with popular inference frameworks.",
      "summary_zh": "Qwen2.5-VL-7B-Instruct 是一个拥有70亿参数的多模态人工智能模型，能够同时处理图像和文本以生成响应。它在视觉问答、图像描述和涉及视觉内容的对话任务中表现出色。该模型针对指令跟随进行了优化，支持多种语言，适用于教育、内容分析和交互式AI助手等应用场景。采用Apache 2.0许可证，并与主流推理框架兼容，具有高效的计算性能和广泛的应用潜力。",
      "summary_es": "Qwen2.5-VL-7B-Instruct es un modelo multimodal de IA con 7 mil millones de parámetros que procesa imágenes y texto para generar respuestas. Destaca en respuesta a preguntas visuales, descripción de imágenes y tareas conversacionales que involucran contenido visual. Optimizado para seguir instrucciones y compatible con múltiples idiomas, es adecuado para aplicaciones en educación, análisis de contenido y asistentes de IA interactivos. Tiene licencia Apache 2.0 y es compatible con frameworks de inferencia populares."
    },
    {
      "id": "Comfy-Org/Wan_2.1_ComfyUI_repackaged",
      "source": "hf",
      "name": "Wan_2.1_ComfyUI_repackaged",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "comfyui",
        "diffusion-single-file",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4251525,
        "likes_total": 747
      },
      "score": 8876.55,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Wan_2.1_ComfyUI_repackaged 是一个专为 ComfyUI（基于节点的 AI 工作流界面）重新打包的单文件扩散模型。它通过简化且用户友好的界面提供稳定的图像生成能力。该模型擅长高效处理并生成高质量的视觉输出，适用于创意艺术作品制作、视觉概念原型设计以及 AI 图像合成的教育演示等典型场景。",
      "updated_at": "2025-09-21T12:06:53.894Z",
      "task_keys": [
        "text_to_image"
      ],
      "summary_en": "Wan_2.1_ComfyUI_repackaged is a single-file diffusion model repackaged for ComfyUI, a node-based AI workflow interface. It provides stable diffusion capabilities for image generation through a streamlined, user-friendly interface. The model excels in producing high-quality visual outputs with efficient processing. Typical use cases include creative artwork generation, prototyping visual concepts, and educational demonstrations of AI image synthesis.",
      "summary_zh": "Wan_2.1_ComfyUI_repackaged 是一个专为 ComfyUI（基于节点的 AI 工作流界面）重新打包的单文件扩散模型。它通过简化且用户友好的界面提供稳定的图像生成能力。该模型擅长高效处理并生成高质量的视觉输出，适用于创意艺术作品制作、视觉概念原型设计以及 AI 图像合成的教育演示等典型场景。",
      "summary_es": "Wan_2.1_ComfyUI_repackaged es un modelo de difusión empaquetado en un solo archivo para ComfyUI, una interfaz de flujo de trabajo de IA basada en nodos. Proporciona capacidades de generación de imágenes mediante una interfaz simplificada y fácil de usar. El modelo destaca en la producción de salidas visuales de alta calidad con procesamiento eficiente. Los casos de uso típicos incluyen generación de obras de arte creativas, prototipado de conceptos visuales y demostraciones educativas de síntesis de imágenes con IA."
    }
  ]
}