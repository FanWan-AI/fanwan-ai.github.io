{
  "date": "2025-09-21",
  "items": [
    {
      "id": "timm/mobilenetv3_small_100.lamb_in1k",
      "source": "hf",
      "name": "mobilenetv3_small_100.lamb_in1k",
      "url": "https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1905.02244",
        "arxiv:2110.00476",
        "dataset:imagenet-1k",
        "image-classification",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "safetensors",
        "timm",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 129663114,
        "likes_total": 37
      },
      "score": 259344.728,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "MobileNetV3-Small 100 是一种轻量级卷积神经网络，专为移动和嵌入式视觉应用优化。它采用 LAMB 优化器并在 ImageNet-1K 上训练，实现了高效的图像分类，同时显著降低计算需求。核心能力包括高精度和低参数量，适用于资源受限设备的实时推理。典型用例涵盖移动应用、物联网设备和边缘计算场景，其中能效至关重要。该模型基于 PyTorch 和 Transformers 框架，支持安全张量格式，具有广泛的实际部署价值。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "image_classification"
      ],
      "summary_en": "MobileNetV3-Small 100 is a lightweight convolutional neural network optimized for mobile and embedded vision applications. It uses the LAMB optimizer and was trained on ImageNet-1K, achieving efficient image classification with reduced computational requirements. Core capabilities include high accuracy with minimal parameters, making it suitable for real-time inference on resource-constrained devices. Typical use cases span mobile apps, IoT devices, and edge computing scenarios where power efficiency is critical.",
      "summary_zh": "MobileNetV3-Small 100 是一种轻量级卷积神经网络，专为移动和嵌入式视觉应用优化。它采用 LAMB 优化器并在 ImageNet-1K 上训练，实现了高效的图像分类，同时显著降低计算需求。核心能力包括高精度和低参数量，适用于资源受限设备的实时推理。典型用例涵盖移动应用、物联网设备和边缘计算场景，其中能效至关重要。该模型基于 PyTorch 和 Transformers 框架，支持安全张量格式，具有广泛的实际部署价值。",
      "summary_es": "MobileNetV3-Small 100 es una red neuronal convolucional ligera optimizada para aplicaciones de visión en dispositivos móviles y embebidos. Utiliza el optimizador LAMB y fue entrenada en ImageNet-1K, logrando clasificación de imágenes eficiente con requisitos computacionales reducidos. Sus capacidades principales incluyen alta precisión con parámetros mínimos, siendo ideal para inferencia en tiempo real en dispositivos con recursos limitados. Los casos de uso típicos abarcan aplicaciones móviles, dispositivos IoT y computación perimetral donde la eficiencia energética es crucial."
    },
    {
      "id": "Falconsai/nsfw_image_detection",
      "source": "hf",
      "name": "nsfw_image_detection",
      "url": "https://huggingface.co/Falconsai/nsfw_image_detection",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2010.11929",
        "autotrain_compatible",
        "endpoints_compatible",
        "image-classification",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "safetensors",
        "transformers",
        "vit"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 96473337,
        "likes_total": 821
      },
      "score": 193357.174,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "该项目是一个基于视觉变换器（ViT）架构的图像分类模型，专门用于检测图像中的NSFW（不适宜工作场所）内容。核心功能包括识别不适当的视觉材料，支持PyTorch和Transformers库，采用SafeTensors格式，并遵循Apache 2.0许可证。优势在于高效的内容审核能力，适用于社交媒体平台的内容过滤、网络应用的安全审查以及自动化审核系统，以维护安全的数字环境。典型用例涵盖在线内容管理和用户生成内容的实时监控。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "This project is an image classification model designed to detect NSFW (Not Safe For Work) content in images. It utilizes Vision Transformer (ViT) architecture to identify inappropriate visual material. The model is compatible with PyTorch and Transformers libraries, supports SafeTensors format, and is licensed under Apache 2.0. Typical use cases include content moderation for social media platforms, web filtering applications, and automated content review systems to maintain safe digital environments.",
      "summary_zh": "该项目是一个基于视觉变换器（ViT）架构的图像分类模型，专门用于检测图像中的NSFW（不适宜工作场所）内容。核心功能包括识别不适当的视觉材料，支持PyTorch和Transformers库，采用SafeTensors格式，并遵循Apache 2.0许可证。优势在于高效的内容审核能力，适用于社交媒体平台的内容过滤、网络应用的安全审查以及自动化审核系统，以维护安全的数字环境。典型用例涵盖在线内容管理和用户生成内容的实时监控。",
      "summary_es": "Este proyecto es un modelo de clasificación de imágenes diseñado para detectar contenido NSFW (No Seguro para el Trabajo) en imágenes. Utiliza la arquitectura Vision Transformer (ViT) para identificar material visual inapropiado. Es compatible con las bibliotecas PyTorch y Transformers, soporta el formato SafeTensors y tiene licencia Apache 2.0. Los casos de uso típicos incluyen moderación de contenido para plataformas de redes sociales, aplicaciones de filtrado web y sistemas automatizados de revisión para mantener entornos digitales seguros."
    },
    {
      "id": "sentence-transformers/all-MiniLM-L6-v2",
      "source": "hf",
      "name": "all-MiniLM-L6-v2",
      "url": "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1704.05179",
        "arxiv:1810.09305",
        "arxiv:1904.06472",
        "arxiv:2102.07033",
        "arxiv:2104.08727",
        "autotrain_compatible",
        "bert",
        "dataset:code_search_net",
        "dataset:eli5",
        "dataset:embedding-data/PAQ_pairs",
        "dataset:embedding-data/QQP",
        "dataset:embedding-data/SPECTER",
        "dataset:embedding-data/WikiAnswers",
        "dataset:embedding-data/altlex",
        "dataset:embedding-data/flickr30k-captions",
        "dataset:embedding-data/sentence-compression",
        "dataset:embedding-data/simple-wiki",
        "dataset:flax-sentence-embeddings/stackexchange_xml",
        "dataset:gooaq",
        "dataset:ms_marco",
        "dataset:multi_nli",
        "dataset:natural_questions",
        "dataset:s2orc",
        "dataset:search_qa",
        "dataset:snli",
        "dataset:trivia_qa",
        "dataset:wikihow",
        "dataset:yahoo_answers_topics",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "license:apache-2.0",
        "onnx",
        "openvino",
        "pytorch",
        "region:us",
        "rust",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "text-embeddings-inference",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 88466968,
        "likes_total": 3906
      },
      "score": 178886.93600000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "all-MiniLM-L6-v2 是一个紧凑型句子转换模型，专为高效生成文本嵌入而设计。它将输入文本转换为高维向量表示，支持语义相似性比较和各种下游自然语言处理任务。该模型的核心优势包括体积小、推理速度快以及在多个领域中的稳定性能。典型应用场景涵盖语义搜索、文本聚类、检索增强生成和文本分类，特别适合资源受限的环境。其训练基于多种数据集，确保了广泛的适用性和实用性。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "inference_acceleration"
      ],
      "summary_en": "all-MiniLM-L6-v2 is a compact sentence transformer model designed for efficient text embedding generation. It converts input text into high-dimensional vector representations, enabling semantic similarity comparisons and downstream NLP tasks. Key strengths include its small size, fast inference speed, and robust performance across diverse domains. Typical use cases encompass semantic search, clustering, retrieval-augmented generation, and text classification, making it suitable for resource-constrained environments.",
      "summary_zh": "all-MiniLM-L6-v2 是一个紧凑型句子转换模型，专为高效生成文本嵌入而设计。它将输入文本转换为高维向量表示，支持语义相似性比较和各种下游自然语言处理任务。该模型的核心优势包括体积小、推理速度快以及在多个领域中的稳定性能。典型应用场景涵盖语义搜索、文本聚类、检索增强生成和文本分类，特别适合资源受限的环境。其训练基于多种数据集，确保了广泛的适用性和实用性。",
      "summary_es": "all-MiniLM-L6-v2 es un modelo compacto de transformación de oraciones diseñado para generar incrustaciones de texto de manera eficiente. Convierte el texto de entrada en representaciones vectoriales de alta dimensión, permitiendo comparaciones de similitud semántica y tareas posteriores de PLN. Sus principales fortalezas incluyen su pequeño tamaño, velocidad de inferencia rápida y rendimiento robusto en diversos dominios. Los casos de uso típicos abarcan búsqueda semántica, agrupación, generación aumentada por recuperación y clasificación de texto, ideal para entornos con recursos limitados."
    },
    {
      "id": "dima806/fairface_age_image_detection",
      "source": "hf",
      "name": "fairface_age_image_detection",
      "url": "https://huggingface.co/dima806/fairface_age_image_detection",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "autotrain_compatible",
        "base_model:finetune:google/vit-base-patch16-224-in21k",
        "base_model:google/vit-base-patch16-224-in21k",
        "dataset:nateraw/fairface",
        "endpoints_compatible",
        "image-classification",
        "license:apache-2.0",
        "region:us",
        "safetensors",
        "transformers",
        "vit"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 58431546,
        "likes_total": 41
      },
      "score": 116883.592,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "该项目是一个基于谷歌ViT-base-patch16-224架构微调的视觉Transformer模型，专门用于从面部图像进行年龄分类。它在FairFace数据集上训练，旨在预测图像中的年龄组别，侧重于准确和公平的人口统计分析。核心能力包括具有特定年龄范围输出的图像分类。其优势在于强大的Transformer架构和伦理数据集基础。典型应用场景涉及人口学研究、年龄验证系统以及需要年龄组识别的社会科学应用。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "This project is a fine-tuned Vision Transformer model for age classification from facial images, based on Google's ViT-base-patch16-224 architecture. It was trained on the FairFace dataset to predict age groups in images, focusing on accurate and fair demographic analysis. Core capabilities include image classification with specific age range outputs. Its strengths lie in the robust transformer architecture and ethical dataset foundation. Typical use cases involve demographic research, age verification systems, and social science applications requiring age group identification.",
      "summary_zh": "该项目是一个基于谷歌ViT-base-patch16-224架构微调的视觉Transformer模型，专门用于从面部图像进行年龄分类。它在FairFace数据集上训练，旨在预测图像中的年龄组别，侧重于准确和公平的人口统计分析。核心能力包括具有特定年龄范围输出的图像分类。其优势在于强大的Transformer架构和伦理数据集基础。典型应用场景涉及人口学研究、年龄验证系统以及需要年龄组识别的社会科学应用。",
      "summary_es": "Este proyecto es un modelo Vision Transformer ajustado para clasificación de edad a partir de imágenes faciales, basado en la arquitectura ViT-base-patch16-224 de Google. Fue entrenado en el conjunto de datos FairFace para predecir grupos de edad en imágenes, centrándose en análisis demográfico preciso y equitativo. Sus capacidades principales incluyen clasificación de imágenes con salidas de rangos de edad específicos. Sus fortalezas radican en la robusta arquitectura transformer y base de datos ética. Los casos de uso típicos involucran investigación demográfica, sistemas de verificación de edad y aplicaciones de ciencias sociales que requieren identificación de grupos etarios."
    },
    {
      "id": "google-bert/bert-base-uncased",
      "source": "hf",
      "name": "bert-base-uncased",
      "url": "https://huggingface.co/google-bert/bert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1810.04805",
        "autotrain_compatible",
        "bert",
        "coreml",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "en",
        "endpoints_compatible",
        "exbert",
        "fill-mask",
        "jax",
        "license:apache-2.0",
        "onnx",
        "pytorch",
        "region:us",
        "rust",
        "safetensors",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 57283719,
        "likes_total": 2412
      },
      "score": 115773.43800000001,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BERT-base-uncased是谷歌开发的一种基于Transformer架构的语言理解模型，采用双向上下文编码技术，能够同时利用词汇左右两侧的语境信息。该模型在英文维基百科和图书语料库上进行预训练，具备强大的文本分类、命名实体识别和问答能力。其核心优势在于无需针对特定任务修改网络结构，即可通过微调适应多种自然语言处理应用场景，包括情感分析、信息抽取和语义相似度计算等任务。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "BERT-base-uncased is a transformer-based language model developed by Google for natural language understanding. It uses bidirectional context to capture word meanings from both directions, enabling strong performance on tasks like text classification, named entity recognition, and question answering. The model is pre-trained on English text from Wikipedia and BookCorpus, making it effective for various NLP applications without task-specific architecture changes.",
      "summary_zh": "BERT-base-uncased是谷歌开发的一种基于Transformer架构的语言理解模型，采用双向上下文编码技术，能够同时利用词汇左右两侧的语境信息。该模型在英文维基百科和图书语料库上进行预训练，具备强大的文本分类、命名实体识别和问答能力。其核心优势在于无需针对特定任务修改网络结构，即可通过微调适应多种自然语言处理应用场景，包括情感分析、信息抽取和语义相似度计算等任务。",
      "summary_es": "BERT-base-uncased es un modelo de lenguaje basado en transformers desarrollado por Google para comprensión del lenguaje natural. Utiliza contexto bidireccional para capturar significados de palabras desde ambas direcciones, permitiendo alto rendimiento en tareas como clasificación de texto, reconocimiento de entidades nombradas y respuesta a preguntas. El modelo está preentrenado en texto inglés de Wikipedia y BookCorpus, siendo efectivo para diversas aplicaciones de PLN sin cambios arquitectónicos específicos por tarea."
    },
    {
      "id": "tech4humans/yolov8s-signature-detector",
      "source": "hf",
      "name": "yolov8s-signature-detector",
      "url": "https://huggingface.co/tech4humans/yolov8s-signature-detector",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "base_model:Ultralytics/YOLOv8",
        "base_model:quantized:Ultralytics/YOLOv8",
        "dataset:tech4humans/signature-detection",
        "endpoints_compatible",
        "license:agpl-3.0",
        "model-index",
        "object-detection",
        "onnx",
        "pytorch",
        "region:us",
        "signature-detection",
        "tensorboard",
        "ultralytics",
        "yolo",
        "yolov8"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 43482337,
        "likes_total": 39
      },
      "score": 86984.174,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "yolov8s-signature-detector是基于YOLOv8架构的目标检测模型，专门针对签名检测任务进行了微调。该模型采用Ultralytics YOLOv8基础模型，并在tech4humans/signature-detection数据集上训练。支持ONNX和PyTorch等多种格式，具备端点兼容性优化部署。主要优势在于能够精确识别文档中的签名位置，适用于文档处理、身份验证系统和自动化表单处理等应用场景。模型经过量化处理，在保持精度的同时提升了推理效率。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "object_detection"
      ],
      "summary_en": "The yolov8s-signature-detector is an object detection model based on YOLOv8 architecture, specifically fine-tuned for signature detection tasks. It utilizes the Ultralytics YOLOv8 base model and is trained on the tech4humans/signature-detection dataset. The model supports multiple formats including ONNX and PyTorch, and is optimized for deployment with endpoints compatibility. Its primary strength lies in accurate signature localization within documents, making it suitable for document processing, authentication systems, and automated form handling applications.",
      "summary_zh": "yolov8s-signature-detector是基于YOLOv8架构的目标检测模型，专门针对签名检测任务进行了微调。该模型采用Ultralytics YOLOv8基础模型，并在tech4humans/signature-detection数据集上训练。支持ONNX和PyTorch等多种格式，具备端点兼容性优化部署。主要优势在于能够精确识别文档中的签名位置，适用于文档处理、身份验证系统和自动化表单处理等应用场景。模型经过量化处理，在保持精度的同时提升了推理效率。",
      "summary_es": "El yolov8s-signature-detector es un modelo de detección de objetos basado en la arquitectura YOLOv8, específicamente ajustado para tareas de detección de firmas. Utiliza el modelo base Ultralytics YOLOv8 y está entrenado en el conjunto de datos tech4humans/signature-detection. Soporta múltiples formatos incluyendo ONNX y PyTorch, y está optimizado para implementación con compatibilidad de endpoints. Su principal fortaleza radica en la localización precisa de firmas dentro de documentos, siendo adecuado para procesamiento documental, sistemas de autenticación y manejo automatizado de formularios."
    },
    {
      "id": "pyannote/segmentation-3.0",
      "source": "hf",
      "name": "segmentation-3.0",
      "url": "https://huggingface.co/pyannote/segmentation-3.0",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "audio",
        "license:mit",
        "overlapped-speech-detection",
        "pyannote",
        "pyannote-audio",
        "pyannote-audio-model",
        "pytorch",
        "region:us",
        "resegmentation",
        "speaker",
        "speaker-change-detection",
        "speaker-diarization",
        "speaker-segmentation",
        "speech",
        "voice",
        "voice-activity-detection"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 19036867,
        "likes_total": 589
      },
      "score": 38368.234000000004,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Pyannote segmentation-3.0 是一个用于说话人日志和分割的音频处理模型。它能够检测音频录音中的说话人变化、语音活动以及重叠语音。核心功能包括识别说话人边界和多人同时说话的区域。优势在于复杂音频环境中的高准确性以及与 Pyannote 音频工具包的集成。典型应用场景包括会议转录、播客分析和呼叫中心监控等需要说话人分离的场合。该模型基于 PyTorch 框架，采用 MIT 许可证开源。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Pyannote segmentation-3.0 is an audio processing model for speaker diarization and segmentation. It detects speaker changes, voice activity, and overlapped speech in audio recordings. Core capabilities include identifying speaker boundaries and regions with multiple speakers. Strengths include high accuracy in complex audio environments and integration with Pyannote audio toolkit. Typical use cases are meeting transcription, podcast analysis, and call center monitoring where speaker separation is required.",
      "summary_zh": "Pyannote segmentation-3.0 是一个用于说话人日志和分割的音频处理模型。它能够检测音频录音中的说话人变化、语音活动以及重叠语音。核心功能包括识别说话人边界和多人同时说话的区域。优势在于复杂音频环境中的高准确性以及与 Pyannote 音频工具包的集成。典型应用场景包括会议转录、播客分析和呼叫中心监控等需要说话人分离的场合。该模型基于 PyTorch 框架，采用 MIT 许可证开源。",
      "summary_es": "Pyannote segmentation-3.0 es un modelo de procesamiento de audio para diarización y segmentación de hablantes. Detecta cambios de locutor, actividad vocal y habla superpuesta en grabaciones de audio. Capacidades principales incluyen identificar límites entre hablantes y regiones con múltiples voces. Fortalezas son alta precisión en entornos auditivos complejos e integración con el toolkit Pyannote audio. Casos de uso típicos son transcripción de reuniones, análisis de podcasts y monitoreo de centros de llamadas donde se requiere separación de hablantes."
    },
    {
      "id": "pyannote/wespeaker-voxceleb-resnet34-LM",
      "source": "hf",
      "name": "wespeaker-voxceleb-resnet34-LM",
      "url": "https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "audio",
        "dataset:voxceleb",
        "license:cc-by-4.0",
        "pyannote",
        "pyannote-audio",
        "pyannote-audio-model",
        "pytorch",
        "region:us",
        "speaker",
        "speaker-embedding",
        "speaker-identification",
        "speaker-recognition",
        "speaker-verification",
        "speech",
        "voice",
        "wespeaker"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 18694320,
        "likes_total": 74
      },
      "score": 37425.64,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "该模型是基于ResNet-34架构的说话人识别系统，使用VoxCeleb数据集训练。核心目的是提取说话人嵌入向量，用于身份识别和验证任务。主要能力包括生成区分性说话人表征，支持文本无关和文本相关场景。优势在于在不同声学条件下表现稳健且推理高效。典型应用场景包括说话人日志记录、认证系统以及安全和电信领域的语音生物识别应用。模型采用CC-BY-4.0许可证，由PyAnnote团队开发。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "This model is a speaker recognition system based on ResNet-34 architecture, trained on the VoxCeleb dataset. Its core purpose is to extract speaker embeddings for identification and verification tasks. Key capabilities include generating discriminative speaker representations, supporting both text-independent and text-dependent scenarios. Strengths include robust performance across varying acoustic conditions and efficient inference. Typical use cases involve speaker diarization, authentication systems, and voice biometric applications in security and telecommunications.",
      "summary_zh": "该模型是基于ResNet-34架构的说话人识别系统，使用VoxCeleb数据集训练。核心目的是提取说话人嵌入向量，用于身份识别和验证任务。主要能力包括生成区分性说话人表征，支持文本无关和文本相关场景。优势在于在不同声学条件下表现稳健且推理高效。典型应用场景包括说话人日志记录、认证系统以及安全和电信领域的语音生物识别应用。模型采用CC-BY-4.0许可证，由PyAnnote团队开发。",
      "summary_es": "Este modelo es un sistema de reconocimiento de hablantes basado en arquitectura ResNet-34, entrenado con el conjunto de datos VoxCeleb. Su propósito principal es extraer embeddings de hablantes para tareas de identificación y verificación. Capacidades clave incluyen generar representaciones discriminativas de hablantes, soportando escenarios tanto independientes como dependientes del texto. Fortalezas incluyen rendimiento robusto en diversas condiciones acústicas e inferencia eficiente. Casos de uso típicos involucran diarización de hablantes, sistemas de autenticación y aplicaciones biométricas de voz en seguridad y telecomunicaciones."
    },
    {
      "id": "pyannote/speaker-diarization-3.1",
      "source": "hf",
      "name": "speaker-diarization-3.1",
      "url": "https://huggingface.co/pyannote/speaker-diarization-3.1",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2012.01477",
        "arxiv:2111.14448",
        "audio",
        "automatic-speech-recognition",
        "endpoints_compatible",
        "license:mit",
        "overlapped-speech-detection",
        "pyannote",
        "pyannote-audio",
        "pyannote-audio-pipeline",
        "region:us",
        "speaker",
        "speaker-change-detection",
        "speaker-diarization",
        "speech",
        "voice",
        "voice-activity-detection"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 16980708,
        "likes_total": 1136
      },
      "score": 34529.416,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "PyAnnote Speaker Diarization 3.1 是一个开源音频处理管道，专门用于识别和分割录音中的不同说话者。该系统执行说话人变更检测、语音活动检测和重叠语音检测。其核心能力包括准确区分多个说话者，即使在对话场景中也能有效工作。典型应用场景包括会议转录、播客分析和广播监控，需要识别不同发言者的场合。该系统基于MIT许可证发布，具有较强的实用性和可靠性。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "PyAnnote Speaker Diarization 3.1 is an open-source audio processing pipeline that identifies and segments different speakers in audio recordings. It performs speaker change detection, voice activity detection, and overlapped speech detection. The system is particularly effective at handling conversational audio with multiple participants. Typical use cases include meeting transcription, podcast analysis, and broadcast monitoring where speaker identification is required.",
      "summary_zh": "PyAnnote Speaker Diarization 3.1 是一个开源音频处理管道，专门用于识别和分割录音中的不同说话者。该系统执行说话人变更检测、语音活动检测和重叠语音检测。其核心能力包括准确区分多个说话者，即使在对话场景中也能有效工作。典型应用场景包括会议转录、播客分析和广播监控，需要识别不同发言者的场合。该系统基于MIT许可证发布，具有较强的实用性和可靠性。",
      "summary_es": "PyAnnote Speaker Diarization 3.1 es una pipeline de procesamiento de audio de código abierto que identifica y segmenta diferentes hablantes en grabaciones de audio. Realiza detección de cambios de hablante, detección de actividad vocal y detección de habla superpuesta. El sistema es particularmente efectivo para manejar audio conversacional con múltiples participantes. Los casos de uso típicos incluyen transcripción de reuniones, análisis de podcasts y monitoreo de transmisiones donde se requiere identificación de hablantes."
    },
    {
      "id": "sentence-transformers/all-mpnet-base-v2",
      "source": "hf",
      "name": "all-mpnet-base-v2",
      "url": "https://huggingface.co/sentence-transformers/all-mpnet-base-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1704.05179",
        "arxiv:1810.09305",
        "arxiv:1904.06472",
        "arxiv:2102.07033",
        "arxiv:2104.08727",
        "autotrain_compatible",
        "dataset:code_search_net",
        "dataset:eli5",
        "dataset:embedding-data/PAQ_pairs",
        "dataset:embedding-data/QQP",
        "dataset:embedding-data/SPECTER",
        "dataset:embedding-data/WikiAnswers",
        "dataset:embedding-data/altlex",
        "dataset:embedding-data/flickr30k-captions",
        "dataset:embedding-data/sentence-compression",
        "dataset:embedding-data/simple-wiki",
        "dataset:flax-sentence-embeddings/stackexchange_xml",
        "dataset:gooaq",
        "dataset:ms_marco",
        "dataset:multi_nli",
        "dataset:natural_questions",
        "dataset:s2orc",
        "dataset:search_qa",
        "dataset:snli",
        "dataset:trivia_qa",
        "dataset:wikihow",
        "dataset:yahoo_answers_topics",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "fill-mask",
        "license:apache-2.0",
        "mpnet",
        "onnx",
        "openvino",
        "pytorch",
        "region:us",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "text-embeddings-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 16780526,
        "likes_total": 1155
      },
      "score": 34138.552,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "all-mpnet-base-v2模型是一种句子转换器，专为生成文本的密集向量表示而设计。它在语义相似性任务、聚类和检索应用中表现出色。该模型基于MPNet架构，在QQP、WikiAnswers和MS MARCO等多种数据集上训练，具有强大的性能。其优势包括句子嵌入的高准确性，以及无需微调即可适用于各种下游自然语言处理任务，如信息检索和文本分类。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "inference_acceleration"
      ],
      "summary_en": "The all-mpnet-base-v2 model is a sentence transformer designed for generating dense vector representations of text. It excels in semantic similarity tasks, clustering, and retrieval applications. Trained on diverse datasets including QQP, WikiAnswers, and MS MARCO, it leverages MPNet architecture for robust performance. Its strengths include high accuracy in sentence embeddings and compatibility with various downstream NLP tasks without fine-tuning.",
      "summary_zh": "all-mpnet-base-v2模型是一种句子转换器，专为生成文本的密集向量表示而设计。它在语义相似性任务、聚类和检索应用中表现出色。该模型基于MPNet架构，在QQP、WikiAnswers和MS MARCO等多种数据集上训练，具有强大的性能。其优势包括句子嵌入的高准确性，以及无需微调即可适用于各种下游自然语言处理任务，如信息检索和文本分类。",
      "summary_es": "El modelo all-mpnet-base-v2 es un transformador de oraciones diseñado para generar representaciones vectoriales densas de texto. Sobresale en tareas de similitud semántica, agrupación y aplicaciones de recuperación. Entrenado en conjuntos de datos diversos como QQP, WikiAnswers y MS MARCO, utiliza arquitectura MPNet para un rendimiento robusto. Sus fortalezas incluyen alta precisión en incrustaciones de oraciones y compatibilidad con diversas tareas de NLP sin ajuste fino."
    },
    {
      "id": "Bingsu/adetailer",
      "source": "hf",
      "name": "adetailer",
      "url": "https://huggingface.co/Bingsu/adetailer",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "dataset:skytnt/anime-segmentation",
        "dataset:wider_face",
        "doi:10.57967/hf/3633",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "ultralytics"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 15400855,
        "likes_total": 616
      },
      "score": 31109.71,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ADetailer是一款自动面部检测和修复工具，专门用于增强图像中的面部细节。它利用先进的分割模型识别面部区域，并应用复杂的修复技术来提高清晰度和细节表现。该工具擅长处理各种面部表情和光照条件，特别适用于照片修复、数字艺术增强以及需要精确面部细节改进的自动化图像编辑工作流程。其核心能力包括高精度面部定位、智能细节重建和批量处理功能。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "ADetailer is an automatic face detection and inpainting tool designed to enhance facial details in images. It utilizes advanced segmentation models to identify facial regions and applies sophisticated inpainting techniques to improve clarity and detail. The tool excels at handling various facial expressions and lighting conditions, making it particularly useful for photo restoration, digital art enhancement, and automated image editing workflows where precise facial detail improvement is required.",
      "summary_zh": "ADetailer是一款自动面部检测和修复工具，专门用于增强图像中的面部细节。它利用先进的分割模型识别面部区域，并应用复杂的修复技术来提高清晰度和细节表现。该工具擅长处理各种面部表情和光照条件，特别适用于照片修复、数字艺术增强以及需要精确面部细节改进的自动化图像编辑工作流程。其核心能力包括高精度面部定位、智能细节重建和批量处理功能。",
      "summary_es": "ADetailer es una herramienta automática de detección facial e inpainting diseñada para mejorar los detalles faciales en imágenes. Utiliza modelos de segmentación avanzados para identificar regiones faciales y aplica técnicas sofisticadas de inpainting para mejorar la claridad y el detalle. La herramienta destaca en el manejo de diversas expresiones faciales y condiciones de iluminación, siendo particularmente útil para restauración fotográfica, mejora de arte digital y flujos de trabajo de edición de imágenes automatizados donde se requiere mejora precisa de detalles faciales."
    },
    {
      "id": "openai/clip-vit-base-patch32",
      "source": "hf",
      "name": "clip-vit-base-patch32",
      "url": "https://huggingface.co/openai/clip-vit-base-patch32",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1908.04913",
        "arxiv:2103.00020",
        "clip",
        "endpoints_compatible",
        "jax",
        "pytorch",
        "region:us",
        "tf",
        "transformers",
        "vision",
        "zero-shot-image-classification"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 15157995,
        "likes_total": 767
      },
      "score": 30699.49,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "CLIP-ViT-Base-Patch32是OpenAI开发的一种视觉语言模型，通过对比学习连接图像和文本。它采用Vision Transformer（ViT）架构，使用32x32图像块处理视觉输入，并结合文本编码器理解语言。核心能力是零样本图像分类，无需针对特定任务训练即可根据文本描述对图像进行分类。优势包括强大的跨模态理解和泛化性能。典型应用场景涵盖图像检索、内容审核以及需要对齐视觉与文本数据的多模态人工智能任务。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "CLIP-ViT-Base-Patch32 is a vision-language model developed by OpenAI that connects images and text through contrastive learning. It uses a Vision Transformer (ViT) architecture with 32x32 patches to process images and a text encoder for language understanding. Its core strength is zero-shot image classification, allowing it to categorize images based on textual descriptions without task-specific training. Typical use cases include image retrieval, content moderation, and multimodal AI applications where visual and textual data need alignment.",
      "summary_zh": "CLIP-ViT-Base-Patch32是OpenAI开发的一种视觉语言模型，通过对比学习连接图像和文本。它采用Vision Transformer（ViT）架构，使用32x32图像块处理视觉输入，并结合文本编码器理解语言。核心能力是零样本图像分类，无需针对特定任务训练即可根据文本描述对图像进行分类。优势包括强大的跨模态理解和泛化性能。典型应用场景涵盖图像检索、内容审核以及需要对齐视觉与文本数据的多模态人工智能任务。",
      "summary_es": "CLIP-ViT-Base-Patch32 es un modelo de visión y lenguaje desarrollado por OpenAI que conecta imágenes y texto mediante aprendizaje contrastivo. Utiliza una arquitectura Vision Transformer (ViT) con parches de 32x32 para procesar imágenes y un codificador de texto para comprensión lingüística. Su principal fortaleza es la clasificación de imágenes zero-shot, permitiendo categorizar imágenes basándose en descripciones textuales sin entrenamiento específico. Los casos de uso típicos incluyen recuperación de imágenes, moderación de contenido y aplicaciones de IA multimodal que requieren alineación de datos visuales y textuales."
    },
    {
      "id": "openai-community/gpt2",
      "source": "hf",
      "name": "gpt2",
      "url": "https://huggingface.co/openai-community/gpt2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "autotrain_compatible",
        "doi:10.57967/hf/0039",
        "en",
        "endpoints_compatible",
        "exbert",
        "gpt2",
        "jax",
        "license:mit",
        "onnx",
        "pytorch",
        "region:us",
        "rust",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "tf",
        "tflite",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 12372571,
        "likes_total": 2951
      },
      "score": 26220.642,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "GPT-2是由OpenAI开发的基于Transformer架构的语言模型，专用于文本生成。其核心能力包括预测序列中的下一个词，从而产生连贯且上下文相关的文本。优势在于生成类人文本、处理多样化提示以及支持针对特定任务的微调。典型应用场景涵盖创意写作、聊天机器人、内容摘要和代码生成，充分利用其强大的自然语言处理能力，避免营销宣传，注重实用性和事实性。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "GPT-2 is a transformer-based language model developed by OpenAI for text generation. Its core capabilities include predicting the next word in a sequence, enabling coherent and context-aware text production. Strengths include its ability to generate human-like text, handle various prompts, and support fine-tuning for specific tasks. Typical use cases encompass creative writing, chatbots, content summarization, and code generation, leveraging its robust natural language processing without marketing hype.",
      "summary_zh": "GPT-2是由OpenAI开发的基于Transformer架构的语言模型，专用于文本生成。其核心能力包括预测序列中的下一个词，从而产生连贯且上下文相关的文本。优势在于生成类人文本、处理多样化提示以及支持针对特定任务的微调。典型应用场景涵盖创意写作、聊天机器人、内容摘要和代码生成，充分利用其强大的自然语言处理能力，避免营销宣传，注重实用性和事实性。",
      "summary_es": "GPT-2 es un modelo de lenguaje basado en transformadores desarrollado por OpenAI para la generación de texto. Sus capacidades principales incluyen predecir la siguiente palabra en una secuencia, permitiendo la producción de texto coherente y consciente del contexto. Fortalezas abarcan su habilidad para generar texto similar al humano, manejar diversos prompts y admitir ajustes para tareas específicas. Casos de uso típicos incluyen escritura creativa, chatbots, resumen de contenido y generación de código, aprovechando su sólido procesamiento de lenguaje natural sin marketing."
    },
    {
      "id": "FacebookAI/roberta-large",
      "source": "hf",
      "name": "roberta-large",
      "url": "https://huggingface.co/FacebookAI/roberta-large",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1806.02847",
        "arxiv:1907.11692",
        "autotrain_compatible",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "en",
        "endpoints_compatible",
        "exbert",
        "fill-mask",
        "jax",
        "license:mit",
        "onnx",
        "pytorch",
        "region:us",
        "roberta",
        "safetensors",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 12252879,
        "likes_total": 246
      },
      "score": 24628.758,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "RoBERTa-large是一个拥有3.55亿参数的优化版BERT预训练Transformer模型。它移除了下一句预测任务，采用动态掩码训练策略。核心能力包括掩码语言建模、文本分类和问答任务。优势在于在GLUE和SQuAD等基准测试中性能优于原始BERT。典型应用场景包括自然语言理解、情感分析和信息抽取等NLP任务。该模型基于大规模文本语料训练，支持多种下游应用。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach transformer model with 355M parameters. It removes next sentence prediction and uses dynamic masking during training. Core capabilities include masked language modeling, text classification, and question answering. Strengths are improved performance over BERT on GLUE and SQuAD benchmarks. Typical use cases are natural language understanding tasks, sentiment analysis, and information extraction.",
      "summary_zh": "RoBERTa-large是一个拥有3.55亿参数的优化版BERT预训练Transformer模型。它移除了下一句预测任务，采用动态掩码训练策略。核心能力包括掩码语言建模、文本分类和问答任务。优势在于在GLUE和SQuAD等基准测试中性能优于原始BERT。典型应用场景包括自然语言理解、情感分析和信息抽取等NLP任务。该模型基于大规模文本语料训练，支持多种下游应用。",
      "summary_es": "RoBERTa-large es un modelo transformer optimizado de preentrenamiento BERT con 355 millones de parámetros. Elimina la predicción de oración siguiente y utiliza enmascaramiento dinámico durante el entrenamiento. Capacidades principales incluyen modelado de lenguaje enmascarado, clasificación de texto y respuesta a preguntas. Fortalezas son mejor rendimiento que BERT en benchmarks GLUE y SQuAD. Casos de uso típicos son comprensión del lenguaje natural, análisis de sentimientos y extracción de información."
    },
    {
      "id": "distilbert/distilbert-base-uncased",
      "source": "hf",
      "name": "distilbert-base-uncased",
      "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1910.01108",
        "autotrain_compatible",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "distilbert",
        "en",
        "endpoints_compatible",
        "exbert",
        "fill-mask",
        "jax",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "rust",
        "safetensors",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 12020430,
        "likes_total": 757
      },
      "score": 24419.36,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模、文本分类和问答任务。优势在于计算效率高和适用性广泛。典型用例涉及文本分析、情感检测和信息提取，特别适用于资源受限的环境。该模型基于BookCorpus和Wikipedia数据训练，支持多种框架如PyTorch和TensorFlow。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "DistilBERT-base-uncased is a distilled version of BERT, designed for efficient natural language processing. It retains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling, text classification, and question answering. Strengths are computational efficiency and broad applicability. Typical use cases involve text analysis, sentiment detection, and information extraction where resource constraints exist.",
      "summary_zh": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模、文本分类和问答任务。优势在于计算效率高和适用性广泛。典型用例涉及文本分析、情感检测和信息提取，特别适用于资源受限的环境。该模型基于BookCorpus和Wikipedia数据训练，支持多种框架如PyTorch和TensorFlow。",
      "summary_es": "DistilBERT-base-uncased es una versión destilada de BERT, diseñada para procesamiento eficiente de lenguaje natural. Mantiene el 97% del rendimiento de BERT mientras es un 40% más pequeño y un 60% más rápido. Capacidades principales incluyen modelado de lenguaje enmascarado, clasificación de texto y respuesta a preguntas. Fortalezas son la eficiencia computacional y amplia aplicabilidad. Casos de uso típicos involucran análisis de texto, detección de sentimientos y extracción de información donde existen limitaciones de recursos."
    },
    {
      "id": "google/electra-base-discriminator",
      "source": "hf",
      "name": "electra-base-discriminator",
      "url": "https://huggingface.co/google/electra-base-discriminator",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1406.2661",
        "electra",
        "en",
        "endpoints_compatible",
        "jax",
        "license:apache-2.0",
        "pretraining",
        "pytorch",
        "region:us",
        "rust",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 11398853,
        "likes_total": 65
      },
      "score": 22830.206000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ELECTRA-base-discriminator是谷歌开发的一种预训练Transformer模型，采用判别式预训练方法而非掩码语言建模。它区分真实与生成标记，提高效率与下游任务效果。核心能力包括文本分类、问答和自然语言推理。优势在于样本效率更高，在多种基准测试中表现优异。典型用例涉及针对特定NLP应用（如情感分析或信息抽取）进行微调，适用于需要高效文本理解的场景。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "ELECTRA-base-discriminator is a pre-trained transformer model from Google that uses a discriminative pre-training approach instead of masked language modeling. It distinguishes between real and generated tokens, making it more efficient and effective for downstream tasks. Core capabilities include text classification, question answering, and natural language inference. Strengths are higher sample efficiency and better performance on various benchmarks. Typical use cases involve fine-tuning for specific NLP applications like sentiment analysis or information extraction.",
      "summary_zh": "ELECTRA-base-discriminator是谷歌开发的一种预训练Transformer模型，采用判别式预训练方法而非掩码语言建模。它区分真实与生成标记，提高效率与下游任务效果。核心能力包括文本分类、问答和自然语言推理。优势在于样本效率更高，在多种基准测试中表现优异。典型用例涉及针对特定NLP应用（如情感分析或信息抽取）进行微调，适用于需要高效文本理解的场景。",
      "summary_es": "ELECTRA-base-discriminator es un modelo transformer preentrenado de Google que utiliza un enfoque de preentrenamiento discriminativo en lugar de modelado de lenguaje enmascarado. Distingue entre tokens reales y generados, haciéndolo más eficiente y efectivo para tareas posteriores. Capacidades principales incluyen clasificación de texto, respuesta a preguntas e inferencia de lenguaje natural. Fortalezas son mayor eficiencia de muestras y mejor rendimiento en varios benchmarks. Casos de uso típicos implican ajuste fino para aplicaciones NLP específicas como análisis de sentimientos o extracción de información."
    },
    {
      "id": "FacebookAI/roberta-base",
      "source": "hf",
      "name": "roberta-base",
      "url": "https://huggingface.co/FacebookAI/roberta-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1806.02847",
        "arxiv:1907.11692",
        "autotrain_compatible",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "en",
        "endpoints_compatible",
        "exbert",
        "fill-mask",
        "jax",
        "license:mit",
        "pytorch",
        "region:us",
        "roberta",
        "rust",
        "safetensors",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 11256563,
        "likes_total": 528
      },
      "score": 22777.126,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，专为掩码语言建模优化。它在BERT基础上改进了训练技术，包括更长的训练时间和更大的批次大小，从而提升了上下文和语义理解能力。核心功能包括文本分类、情感分析和问答任务。其优势在于对各种自然语言处理任务的鲁棒性和高效性。典型应用场景涉及学术研究、内容审核和自动化文本处理。该模型基于BookCorpus和Wikipedia数据集训练，支持多种框架如PyTorch和TensorFlow。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "RoBERTa-base is a transformer-based language model optimized for masked language modeling, developed by Facebook AI. It builds upon BERT with improved training techniques, including longer training times and larger batch sizes, enhancing its understanding of context and semantics. Core capabilities include text classification, sentiment analysis, and question answering. Strengths lie in its robustness and efficiency for various NLP tasks. Typical use cases involve academic research, content moderation, and automated text processing applications.",
      "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，专为掩码语言建模优化。它在BERT基础上改进了训练技术，包括更长的训练时间和更大的批次大小，从而提升了上下文和语义理解能力。核心功能包括文本分类、情感分析和问答任务。其优势在于对各种自然语言处理任务的鲁棒性和高效性。典型应用场景涉及学术研究、内容审核和自动化文本处理。该模型基于BookCorpus和Wikipedia数据集训练，支持多种框架如PyTorch和TensorFlow。",
      "summary_es": "RoBERTa-base es un modelo de lenguaje basado en transformers optimizado para el modelado de lenguaje enmascarado, desarrollado por Facebook AI. Se basa en BERT con técnicas de entrenamiento mejoradas, incluyendo tiempos de entrenamiento más largos y tamaños de lote más grandes, mejorando su comprensión del contexto y la semántica. Las capacidades principales incluyen clasificación de texto, análisis de sentimientos y respuesta a preguntas. Sus fortalezas radican en su robustez y eficiencia para diversas tareas de PLN. Los casos de uso típicos involucran investigación académica, moderación de contenido y aplicaciones de procesamiento de texto automatizado."
    },
    {
      "id": "facebook/opt-125m",
      "source": "hf",
      "name": "opt-125m",
      "url": "https://huggingface.co/facebook/opt-125m",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2005.14165",
        "arxiv:2205.01068",
        "autotrain_compatible",
        "en",
        "jax",
        "license:other",
        "opt",
        "pytorch",
        "region:us",
        "text-generation",
        "text-generation-inference",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 10208417,
        "likes_total": 217
      },
      "score": 20525.334,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "OPT-125M是Meta AI开发的1.25亿参数仅解码器Transformer模型，专用于文本生成任务。作为开放预训练Transformer系列的一部分，它采用公开训练数据复现GPT-3架构。核心能力包括自然语言理解、文本补全和对话响应生成。优势在于开源可访问性、高效推理能力以及与其规模相匹配的强劲性能。典型应用场景涵盖研究原型开发、教育工具实现和轻量级人工智能助手部署，适用于计算资源有限的环境。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "OPT-125M is a 125 million parameter decoder-only transformer model developed by Meta AI for text generation. It is part of the Open Pre-trained Transformer series, designed to replicate GPT-3 architecture with publicly available training data. Core capabilities include natural language understanding, text completion, and conversational response generation. Strengths include open accessibility, efficient inference, and strong performance for its size. Typical use cases involve research prototyping, educational applications, and lightweight AI assistants.",
      "summary_zh": "OPT-125M是Meta AI开发的1.25亿参数仅解码器Transformer模型，专用于文本生成任务。作为开放预训练Transformer系列的一部分，它采用公开训练数据复现GPT-3架构。核心能力包括自然语言理解、文本补全和对话响应生成。优势在于开源可访问性、高效推理能力以及与其规模相匹配的强劲性能。典型应用场景涵盖研究原型开发、教育工具实现和轻量级人工智能助手部署，适用于计算资源有限的环境。",
      "summary_es": "OPT-125M es un modelo transformer de solo decodificador con 125 millones de parámetros desarrollado por Meta AI para generación de texto. Forma parte de la serie Open Pre-trained Transformer, diseñada para replicar la arquitectura GPT-3 con datos de entrenamiento públicamente disponibles. Capacidades principales incluyen comprensión de lenguaje natural, completación de texto y generación de respuestas conversacionales. Fortalezas son accesibilidad abierta, inferencia eficiente y buen rendimiento para su tamaño. Casos de uso típicos incluyen prototipos de investigación, aplicaciones educativas y asistentes de IA ligeros."
    },
    {
      "id": "prajjwal1/bert-tiny",
      "source": "hf",
      "name": "bert-tiny",
      "url": "https://huggingface.co/prajjwal1/bert-tiny",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "BERT",
        "MNLI",
        "NLI",
        "arxiv:1908.08962",
        "arxiv:2110.01518",
        "en",
        "endpoints_compatible",
        "license:mit",
        "pre-training",
        "pytorch",
        "region:us",
        "transformer",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 9748754,
        "likes_total": 129
      },
      "score": 19562.008,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BERT-tiny是谷歌BERT模型的紧凑版本，专为高效自然语言理解而设计。该模型仅包含440万个参数，保持了BERT在自然语言推理等任务中的核心能力，同时显著减小了模型尺寸并提高了运行速度。它在资源受限环境、移动应用和快速原型开发中表现出色。该模型基于英文文本进行预训练，并针对MNLI任务进行了微调，适用于分类、情感分析和轻量级NLP部署场景，特别注重计算效率。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "BERT-tiny is a compact version of Google's BERT model designed for efficient natural language understanding. With only 4.4 million parameters, it maintains core BERT capabilities for tasks like natural language inference while being significantly smaller and faster. It excels in resource-constrained environments, mobile applications, and rapid prototyping. The model is pre-trained on English text and fine-tuned for MNLI, making it suitable for classification, sentiment analysis, and lightweight NLP deployments where computational efficiency is prioritized.",
      "summary_zh": "BERT-tiny是谷歌BERT模型的紧凑版本，专为高效自然语言理解而设计。该模型仅包含440万个参数，保持了BERT在自然语言推理等任务中的核心能力，同时显著减小了模型尺寸并提高了运行速度。它在资源受限环境、移动应用和快速原型开发中表现出色。该模型基于英文文本进行预训练，并针对MNLI任务进行了微调，适用于分类、情感分析和轻量级NLP部署场景，特别注重计算效率。",
      "summary_es": "BERT-tiny es una versión compacta del modelo BERT de Google diseñada para una comprensión eficiente del lenguaje natural. Con solo 4.4 millones de parámetros, mantiene las capacidades centrales de BERT para tareas como inferencia de lenguaje natural mientras es significativamente más pequeño y rápido. Sobresale en entornos con recursos limitados, aplicaciones móviles y prototipado rápido. El modelo está preentrenado en texto inglés y ajustado para MNLI, siendo adecuado para clasificación, análisis de sentimientos y implementaciones ligeras de NLP donde se prioriza la eficiencia computacional."
    },
    {
      "id": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
      "source": "hf",
      "name": "paraphrase-multilingual-MiniLM-L12-v2",
      "url": "https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "ar",
        "arxiv:1908.10084",
        "autotrain_compatible",
        "bert",
        "bg",
        "ca",
        "cs",
        "da",
        "de",
        "el",
        "en",
        "endpoints_compatible",
        "es",
        "et",
        "fa",
        "feature-extraction",
        "fi",
        "fr",
        "gl",
        "gu",
        "he",
        "hi",
        "hr",
        "hu",
        "hy",
        "id",
        "it",
        "ja",
        "ka",
        "ko",
        "ku",
        "license:apache-2.0",
        "lt",
        "lv",
        "mk",
        "mn",
        "mr",
        "ms",
        "multilingual",
        "my",
        "nb",
        "nl",
        "onnx",
        "openvino",
        "pl",
        "pt",
        "pytorch",
        "region:us",
        "ro",
        "ru",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "sk",
        "sl",
        "sq",
        "sr",
        "sv",
        "text-embeddings-inference",
        "tf",
        "th",
        "tr",
        "transformers",
        "uk",
        "ur",
        "vi"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 9687012,
        "likes_total": 1013
      },
      "score": 19880.524,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "paraphrase-multilingual-MiniLM-L12-v2 是一个紧凑的多语言句子转换模型，专为语义相似性任务设计。它将50多种语言的文本映射为密集向量表示，支持跨语言比较。核心功能包括释义识别、语义搜索和文本聚类。优势在于采用12层高效架构，无需单独模型即可处理多种语言。典型应用场景涵盖多语言文档检索、重复内容检测和推荐系统，适用于需要统一处理多语言文本的自动化流程。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "inference_acceleration"
      ],
      "summary_en": "The paraphrase-multilingual-MiniLM-L12-v2 model is a compact multilingual sentence transformer designed for semantic similarity tasks. It maps text in 50+ languages to dense vector representations, enabling cross-lingual comparison. Core capabilities include paraphrase identification, semantic search, and clustering. Strengths include efficient performance with 12 layers and support for diverse languages without separate models. Typical use cases involve multilingual document retrieval, duplicate detection, and content recommendation systems.",
      "summary_zh": "paraphrase-multilingual-MiniLM-L12-v2 是一个紧凑的多语言句子转换模型，专为语义相似性任务设计。它将50多种语言的文本映射为密集向量表示，支持跨语言比较。核心功能包括释义识别、语义搜索和文本聚类。优势在于采用12层高效架构，无需单独模型即可处理多种语言。典型应用场景涵盖多语言文档检索、重复内容检测和推荐系统，适用于需要统一处理多语言文本的自动化流程。",
      "summary_es": "El modelo paraphrase-multilingual-MiniLM-L12-v2 es un transformador de oraciones multilingüe compacto diseñado para tareas de similitud semántica. Mapea texto en 50+ idiomas a representaciones vectoriales densas, permitiendo comparación cruzada. Capacidades principales incluyen identificación de paráfrasis, búsqueda semántica y agrupamiento. Fortalezas son rendimiento eficiente con 12 capas y soporte para idiomas diversos sin modelos separados. Casos de uso típicos involucran recuperación de documentos multilingües, detección de duplicados y sistemas de recomendación."
    },
    {
      "id": "amazon/chronos-t5-small",
      "source": "hf",
      "name": "chronos-t5-small",
      "url": "https://huggingface.co/amazon/chronos-t5-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1910.10683",
        "arxiv:2403.07815",
        "endpoints_compatible",
        "forecasting",
        "foundation models",
        "license:apache-2.0",
        "pretrained models",
        "region:us",
        "safetensors",
        "t5",
        "text-generation-inference",
        "text2text-generation",
        "time series",
        "time series foundation models",
        "time-series",
        "time-series-forecasting",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 9254296,
        "likes_total": 132
      },
      "score": 18574.592,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Chronos-T5-small是基于T5架构的时间序列预测模型，它将数值时间序列数据转换为文本标记进行处理，支持无需重新训练的零样本预测。核心功能包括单变量预测、处理多种频率数据和概率性预测。其优势在于采用基础模型方法、可扩展性强且与Transformers库兼容。典型应用场景涵盖零售需求预测、金融市场分析和工业传感器监控等领域。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "time_series_forecasting"
      ],
      "summary_en": "Chronos-T5-small is a time series forecasting model based on T5 architecture. It converts numerical time series data into text tokens for processing, enabling zero-shot forecasting without retraining. Core capabilities include univariate forecasting, handling various frequencies, and probabilistic predictions. Strengths are its foundation model approach, scalability, and compatibility with Transformers. Typical use cases span retail demand forecasting, financial market predictions, and industrial sensor monitoring.",
      "summary_zh": "Chronos-T5-small是基于T5架构的时间序列预测模型，它将数值时间序列数据转换为文本标记进行处理，支持无需重新训练的零样本预测。核心功能包括单变量预测、处理多种频率数据和概率性预测。其优势在于采用基础模型方法、可扩展性强且与Transformers库兼容。典型应用场景涵盖零售需求预测、金融市场分析和工业传感器监控等领域。",
      "summary_es": "Chronos-T5-small es un modelo de pronóstico de series temporales basado en la arquitectura T5. Convierte datos numéricos de series temporales en tokens de texto para su procesamiento, permitiendo pronósticos zero-shot sin reentrenamiento. Capacidades principales incluyen pronóstico univariado, manejo de diversas frecuencias y predicciones probabilísticas. Fortalezas son su enfoque de modelo fundacional, escalabilidad y compatibilidad con Transformers. Casos de uso típicos abarcan pronóstico de demanda retail, predicciones de mercados financieros y monitoreo de sensores industriales."
    },
    {
      "id": "context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16",
      "source": "hf",
      "name": "meta-llama-Llama-3.2-3B-Instruct-FP16",
      "url": "https://huggingface.co/context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2204.05149",
        "arxiv:2405.16406",
        "autotrain_compatible",
        "conversational",
        "de",
        "en",
        "endpoints_compatible",
        "es",
        "facebook",
        "fr",
        "hi",
        "it",
        "license:llama3.2",
        "llama",
        "llama-3",
        "meta",
        "pt",
        "pytorch",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "th",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 9141463,
        "likes_total": 7
      },
      "score": 18286.426,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Meta Llama 3.2 3B Instruct FP16 是一个拥有 30 亿参数的语言模型，专门针对指令跟随任务进行了优化。它支持多种语言，包括英语、西班牙语、德语、法语、印地语、意大利语和葡萄牙语。该模型采用 FP16 精度格式，在保持性能的同时提供高效的推理能力。核心功能包括对话生成、文本创作和多语言问答。典型应用场景涵盖聊天机器人、内容辅助工具和多语言客户服务系统。其优势在于平衡的模型大小与性能，适用于资源受限环境。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Meta Llama 3.2 3B Instruct FP16 is a 3-billion parameter language model optimized for instruction following. It supports multiple languages including English, Spanish, German, French, Hindi, Italian, and Portuguese. The model is designed for conversational AI applications, text generation, and question answering. Its FP16 precision format provides efficient inference while maintaining performance. Typical use cases include chatbots, content creation, and multilingual assistance.",
      "summary_zh": "Meta Llama 3.2 3B Instruct FP16 是一个拥有 30 亿参数的语言模型，专门针对指令跟随任务进行了优化。它支持多种语言，包括英语、西班牙语、德语、法语、印地语、意大利语和葡萄牙语。该模型采用 FP16 精度格式，在保持性能的同时提供高效的推理能力。核心功能包括对话生成、文本创作和多语言问答。典型应用场景涵盖聊天机器人、内容辅助工具和多语言客户服务系统。其优势在于平衡的模型大小与性能，适用于资源受限环境。",
      "summary_es": "Meta Llama 3.2 3B Instruct FP16 es un modelo de lenguaje de 3 mil millones de parámetros optimizado para seguir instrucciones. Soporta múltiples idiomas incluyendo inglés, español, alemán, francés, hindi, italiano y portugués. Está diseñado para aplicaciones de IA conversacional, generación de texto y respuesta de preguntas. El formato de precisión FP16 proporciona inferencia eficiente manteniendo el rendimiento. Los casos de uso típicos incluyen chatbots, creación de contenido y asistencia multilingüe."
    },
    {
      "id": "omni-research/Tarsier2-Recap-7b",
      "source": "hf",
      "name": "Tarsier2-Recap-7b",
      "url": "https://huggingface.co/omni-research/Tarsier2-Recap-7b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2501.07888",
        "license:apache-2.0",
        "region:us",
        "safetensors",
        "video LLM"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8957482,
        "likes_total": 18
      },
      "score": 17923.964,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Tarsier2-Recap-7b 是一个拥有70亿参数的多模态视频语言模型，专门用于视频内容理解和自动摘要生成。该模型通过处理视频帧序列来分析视觉信息，能够准确识别关键事件并生成连贯的文本摘要。其核心优势包括高效的帧处理能力、精确的事件检测技术以及流畅的叙述生成质量。典型应用场景包括内容创作者的视频自动摘要、教育视频分析处理以及需要快速理解视频内容的媒体监控任务，为各类视频处理需求提供可靠的AI解决方案。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Tarsier2-Recap-7b is a 7-billion parameter video language model designed for video understanding and summarization. It processes video frames to generate concise textual recaps, leveraging multimodal capabilities to analyze visual content. Key strengths include efficient frame processing, accurate event detection, and coherent narrative generation. Typical use cases involve automated video summarization for content creators, educational video analysis, and media monitoring applications where quick comprehension of video content is required.",
      "summary_zh": "Tarsier2-Recap-7b 是一个拥有70亿参数的多模态视频语言模型，专门用于视频内容理解和自动摘要生成。该模型通过处理视频帧序列来分析视觉信息，能够准确识别关键事件并生成连贯的文本摘要。其核心优势包括高效的帧处理能力、精确的事件检测技术以及流畅的叙述生成质量。典型应用场景包括内容创作者的视频自动摘要、教育视频分析处理以及需要快速理解视频内容的媒体监控任务，为各类视频处理需求提供可靠的AI解决方案。",
      "summary_es": "Tarsier2-Recap-7b es un modelo de lenguaje multimodal de 7 mil millones de parámetros diseñado para la comprensión y resumen de videos. Procesa secuencias de frames para generar resúmenes textuales concisos, aprovechando capacidades multimodales para analizar contenido visual. Sus principales fortalezas incluyen procesamiento eficiente de frames, detección precisa de eventos y generación coherente de narrativas. Los casos de uso típicos involucran resumen automatizado de videos para creadores de contenido, análisis de videos educativos y aplicaciones de monitoreo mediático que requieren comprensión rápida del contenido visual."
    },
    {
      "id": "openai/clip-vit-large-patch14",
      "source": "hf",
      "name": "clip-vit-large-patch14",
      "url": "https://huggingface.co/openai/clip-vit-large-patch14",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1908.04913",
        "arxiv:2103.00020",
        "clip",
        "endpoints_compatible",
        "jax",
        "pytorch",
        "region:us",
        "safetensors",
        "tf",
        "transformers",
        "vision",
        "zero-shot-image-classification"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8363907,
        "likes_total": 1862
      },
      "score": 17658.814000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "CLIP-ViT-Large-Patch14是OpenAI开发的多模态AI模型，连接视觉与语言处理。它采用Vision Transformer（ViT-L/14）架构，将图像和文本编码到共享嵌入空间，支持无需任务特定训练的零样本图像分类。核心能力包括跨模态理解、强大泛化性及高效处理视觉与文本输入。典型应用涵盖图像检索、内容审核、视觉问答和自动标注，其优势在于通过自然语言提示处理未见类别，适用于多样化数据集和场景。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "CLIP-ViT-Large-Patch14 is a multimodal AI model developed by OpenAI that connects vision and language. It uses a Vision Transformer (ViT-L/14) architecture to encode images and text into a shared embedding space, enabling zero-shot image classification without task-specific training. Its core capabilities include cross-modal understanding, robust generalization across diverse datasets, and efficient processing of visual and textual inputs. Typical use cases span image retrieval, content moderation, visual question answering, and automated captioning, leveraging its strength in handling unseen categories through natural language prompts.",
      "summary_zh": "CLIP-ViT-Large-Patch14是OpenAI开发的多模态AI模型，连接视觉与语言处理。它采用Vision Transformer（ViT-L/14）架构，将图像和文本编码到共享嵌入空间，支持无需任务特定训练的零样本图像分类。核心能力包括跨模态理解、强大泛化性及高效处理视觉与文本输入。典型应用涵盖图像检索、内容审核、视觉问答和自动标注，其优势在于通过自然语言提示处理未见类别，适用于多样化数据集和场景。",
      "summary_es": "CLIP-ViT-Large-Patch14 es un modelo multimodal de IA desarrollado por OpenAI que conecta visión y lenguaje. Utiliza una arquitectura Vision Transformer (ViT-L/14) para codificar imágenes y texto en un espacio de incrustación compartido, permitiendo clasificación de imágenes zero-shot sin entrenamiento específico. Sus capacidades principales incluyen comprensión cross-modal, generalización robusta en diversos conjuntos de datos y procesamiento eficiente de entradas visuales y textuales. Los casos de uso típicos abarcan recuperación de imágenes, moderación de contenido, respuesta visual a preguntas y subtitulado automático, aprovechando su fuerza en el manejo de categorías no vistas mediante prompts de lenguaje natural."
    },
    {
      "id": "trpakov/vit-face-expression",
      "source": "hf",
      "name": "vit-face-expression",
      "url": "https://huggingface.co/trpakov/vit-face-expression",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "autotrain_compatible",
        "doi:10.57967/hf/2289",
        "endpoints_compatible",
        "image-classification",
        "license:apache-2.0",
        "onnx",
        "pytorch",
        "region:us",
        "safetensors",
        "transformers",
        "vit"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8229815,
        "likes_total": 80
      },
      "score": 16499.63,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "vit-face-expression模型是一种基于Vision Transformer（ViT）的面部表情分类工具，用于从输入图像中识别和分类人类情感，如快乐、悲伤、愤怒和惊讶。其核心能力包括高精度的表情识别，利用Transformer架构进行稳健的特征提取。优势在于处理效率高，且兼容多种框架如PyTorch和ONNX。典型应用场景包括心理学研究中的情绪分析、人机交互系统以及媒体中的自动情感检测，适用于需要自动化情感识别的领域。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "The vit-face-expression model is a Vision Transformer (ViT) designed for facial expression classification. It analyzes input images to detect and categorize human emotions such as happiness, sadness, anger, and surprise. Core capabilities include high accuracy in expression recognition, leveraging transformer architecture for robust feature extraction. Strengths are efficient processing and compatibility with various frameworks like PyTorch and ONNX. Typical use cases include emotion analysis in psychology research, human-computer interaction systems, and automated sentiment detection in media.",
      "summary_zh": "vit-face-expression模型是一种基于Vision Transformer（ViT）的面部表情分类工具，用于从输入图像中识别和分类人类情感，如快乐、悲伤、愤怒和惊讶。其核心能力包括高精度的表情识别，利用Transformer架构进行稳健的特征提取。优势在于处理效率高，且兼容多种框架如PyTorch和ONNX。典型应用场景包括心理学研究中的情绪分析、人机交互系统以及媒体中的自动情感检测，适用于需要自动化情感识别的领域。",
      "summary_es": "El modelo vit-face-expression es un Vision Transformer (ViT) diseñado para la clasificación de expresiones faciales. Analiza imágenes de entrada para detectar y categorizar emociones humanas como felicidad, tristeza, enojo y sorpresa. Sus capacidades principales incluyen alta precisión en el reconocimiento de expresiones, aprovechando la arquitectura transformer para una extracción robusta de características. Sus fortalezas son el procesamiento eficiente y la compatibilidad con frameworks como PyTorch y ONNX. Los casos de uso típicos incluyen análisis de emociones en investigación psicológica, sistemas de interacción humano-computadora y detección automática de sentimientos en medios."
    },
    {
      "id": "google/vit-base-patch16-224-in21k",
      "source": "hf",
      "name": "vit-base-patch16-224-in21k",
      "url": "https://huggingface.co/google/vit-base-patch16-224-in21k",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2006.03677",
        "arxiv:2010.11929",
        "dataset:imagenet-21k",
        "image-feature-extraction",
        "jax",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "safetensors",
        "tf",
        "transformers",
        "vision",
        "vit"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8181307,
        "likes_total": 372
      },
      "score": 16548.614,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Vision Transformer (ViT) 基础模型通过将224x224像素图像分割为16x16补丁进行处理。在ImageNet-21k上预训练，擅长图像分类和特征提取。其优势包括在视觉任务中的强大泛化能力，以及与PyTorch、TensorFlow和JAX等框架的兼容性。典型用例包括针对特定分类任务进行微调，或作为计算机视觉流程中的特征提取器。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "image_classification"
      ],
      "summary_en": "The Vision Transformer (ViT) base model processes 224x224 pixel images by splitting them into 16x16 patches. Pre-trained on ImageNet-21k, it excels at image classification and feature extraction. Its strengths include strong generalization across vision tasks and compatibility with frameworks like PyTorch, TensorFlow, and JAX. Typical use cases involve fine-tuning for specific classification tasks or serving as a feature extractor in computer vision pipelines.",
      "summary_zh": "Vision Transformer (ViT) 基础模型通过将224x224像素图像分割为16x16补丁进行处理。在ImageNet-21k上预训练，擅长图像分类和特征提取。其优势包括在视觉任务中的强大泛化能力，以及与PyTorch、TensorFlow和JAX等框架的兼容性。典型用例包括针对特定分类任务进行微调，或作为计算机视觉流程中的特征提取器。",
      "summary_es": "El modelo base Vision Transformer (ViT) procesa imágenes de 224x224 píxeles dividiéndolas en parches de 16x16. Preentrenado en ImageNet-21k, sobresale en clasificación de imágenes y extracción de características. Sus fortalezas incluyen una fuerte generalización en tareas visuales y compatibilidad con frameworks como PyTorch, TensorFlow y JAX. Los casos de uso típicos implican ajuste fino para tareas de clasificación específicas o como extractor de características en pipelines de visión por computadora."
    },
    {
      "id": "FacebookAI/xlm-roberta-base",
      "source": "hf",
      "name": "xlm-roberta-base",
      "url": "https://huggingface.co/FacebookAI/xlm-roberta-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "af",
        "am",
        "ar",
        "arxiv:1911.02116",
        "as",
        "autotrain_compatible",
        "az",
        "be",
        "bg",
        "bn",
        "br",
        "bs",
        "ca",
        "cs",
        "cy",
        "da",
        "de",
        "el",
        "en",
        "endpoints_compatible",
        "eo",
        "es",
        "et",
        "eu",
        "exbert",
        "fa",
        "fi",
        "fill-mask",
        "fr",
        "fy",
        "ga",
        "gd",
        "gl",
        "gu",
        "ha",
        "he",
        "hi",
        "hr",
        "hu",
        "hy",
        "id",
        "is",
        "it",
        "ja",
        "jax",
        "jv",
        "ka",
        "kk",
        "km",
        "kn",
        "ko",
        "ku",
        "ky",
        "la",
        "license:mit",
        "lo",
        "lt",
        "lv",
        "mg",
        "mk",
        "ml",
        "mn",
        "mr",
        "ms",
        "multilingual",
        "my",
        "ne",
        "nl",
        "no",
        "om",
        "onnx",
        "or",
        "pa",
        "pl",
        "ps",
        "pt",
        "pytorch",
        "region:us",
        "ro",
        "ru",
        "sa",
        "safetensors",
        "sd",
        "si",
        "sk",
        "sl",
        "so",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "tf",
        "th",
        "tl",
        "tr",
        "transformers",
        "ug",
        "uk",
        "ur",
        "uz",
        "vi",
        "xh",
        "xlm-roberta",
        "yi",
        "zh"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8080010,
        "likes_total": 730
      },
      "score": 16525.02,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "xlm-roberta-base是基于RoBERTa架构的多语言预训练模型，支持100种语言。它通过掩码语言建模预训练实现卓越的跨语言理解能力。核心优势包括在文本分类、命名实体识别和问答任务上的强大跨语言性能。典型应用涵盖多语言文本分析、内容审核和跨语言信息抽取，无需为每种语言单独训练模型，显著提高了多语言NLP任务的效率和一致性。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "xlm-roberta-base is a multilingual language model based on RoBERTa architecture, supporting 100 languages. It excels at cross-lingual understanding tasks through masked language modeling pretraining. Key strengths include robust performance on text classification, named entity recognition, and question answering across languages. Typical use cases involve multilingual text analysis, content moderation, and cross-lingual information extraction without requiring language-specific models.",
      "summary_zh": "xlm-roberta-base是基于RoBERTa架构的多语言预训练模型，支持100种语言。它通过掩码语言建模预训练实现卓越的跨语言理解能力。核心优势包括在文本分类、命名实体识别和问答任务上的强大跨语言性能。典型应用涵盖多语言文本分析、内容审核和跨语言信息抽取，无需为每种语言单独训练模型，显著提高了多语言NLP任务的效率和一致性。",
      "summary_es": "xlm-roberta-base es un modelo de lenguaje multilingüe basado en la arquitectura RoBERTa que admite 100 idiomas. Destaca en tareas de comprensión cross-lingüe mediante preentrenamiento de lenguaje enmascarado. Sus principales fortalezas incluyen rendimiento robusto en clasificación de texto, reconocimiento de entidades nombradas y respuesta a preguntas en múltiples idiomas. Los casos de uso típicos involucran análisis de texto multilingüe, moderación de contenido y extracción de información cross-lingüe sin requerir modelos específicos por idioma."
    },
    {
      "id": "facebook/contriever",
      "source": "hf",
      "name": "contriever",
      "url": "https://huggingface.co/facebook/contriever",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2112.09118",
        "bert",
        "endpoints_compatible",
        "pytorch",
        "region:us",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 8066749,
        "likes_total": 64
      },
      "score": 16165.498,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Contriever是Facebook开发的密集检索模型，通过无监督学习生成文本表示以进行语义搜索。它采用对比学习技术，无需标注数据即可将相似文本映射到向量空间中的邻近位置。核心能力包括高效文档检索、查询匹配和多语言文本理解。优势在于无监督训练方法、可扩展性以及与Transformer架构的兼容性。典型应用场景包括信息检索系统、文档相似性搜索和构建语义搜索应用，特别适合处理大规模文本数据。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Contriever is a dense retrieval model developed by Facebook that learns unsupervised text representations for semantic search. It uses contrastive learning to map similar texts closer in vector space without requiring labeled data. Core capabilities include efficient document retrieval, query matching, and multilingual text understanding. Strengths are its unsupervised training approach, scalability, and compatibility with transformer architectures. Typical use cases include information retrieval systems, document similarity search, and building semantic search applications.",
      "summary_zh": "Contriever是Facebook开发的密集检索模型，通过无监督学习生成文本表示以进行语义搜索。它采用对比学习技术，无需标注数据即可将相似文本映射到向量空间中的邻近位置。核心能力包括高效文档检索、查询匹配和多语言文本理解。优势在于无监督训练方法、可扩展性以及与Transformer架构的兼容性。典型应用场景包括信息检索系统、文档相似性搜索和构建语义搜索应用，特别适合处理大规模文本数据。",
      "summary_es": "Contriever es un modelo de recuperación densa desarrollado por Facebook que aprende representaciones de texto no supervisadas para búsqueda semántica. Utiliza aprendizaje contrastivo para mapear textos similares en el espacio vectorial sin requerir datos etiquetados. Capacidades principales incluyen recuperación eficiente de documentos, coincidencia de consultas y comprensión multilingüe de texto. Fortalezas son su enfoque de entrenamiento no supervisado, escalabilidad y compatibilidad con arquitecturas transformer. Casos de uso típicos incluyen sistemas de recuperación de información, búsqueda de similitud de documentos y aplicaciones de búsqueda semántica."
    },
    {
      "id": "facebook/bart-base",
      "source": "hf",
      "name": "bart-base",
      "url": "https://huggingface.co/facebook/bart-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1910.13461",
        "bart",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "jax",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "safetensors",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7927928,
        "likes_total": 198
      },
      "score": 15954.856,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BART-base是一种基于Transformer的自然语言处理模型，专为文本生成和理解任务设计。它结合了双向和自回归方法，在摘要、翻译和文本校正方面表现卓越。核心能力包括去噪自编码，使其适用于各种序列到序列应用。典型用例涉及文档摘要、机器翻译和内容生成，利用其在处理嘈杂或不完整文本输入方面的强大性能。该模型支持多框架部署，如PyTorch和TensorFlow，广泛应用于研究和工业场景。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "BART-base is a transformer-based model for natural language processing, specifically designed for text generation and comprehension tasks. It combines bidirectional and autoregressive approaches, excelling in summarization, translation, and text correction. Its core capabilities include denoising autoencoding, making it robust for various sequence-to-sequence applications. Typical use cases involve document summarization, machine translation, and content generation, leveraging its strong performance in handling noisy or incomplete text inputs.",
      "summary_zh": "BART-base是一种基于Transformer的自然语言处理模型，专为文本生成和理解任务设计。它结合了双向和自回归方法，在摘要、翻译和文本校正方面表现卓越。核心能力包括去噪自编码，使其适用于各种序列到序列应用。典型用例涉及文档摘要、机器翻译和内容生成，利用其在处理嘈杂或不完整文本输入方面的强大性能。该模型支持多框架部署，如PyTorch和TensorFlow，广泛应用于研究和工业场景。",
      "summary_es": "BART-base es un modelo basado en transformers para procesamiento de lenguaje natural, diseñado específicamente para generación y comprensión de texto. Combina enfoques bidireccionales y autoregresivos, destacando en resumen, traducción y corrección textual. Sus capacidades principales incluyen auto codificación de desruido, haciéndolo robusto para aplicaciones de secuencia a secuencia. Los casos de uso típicos involucran resumen de documentos, traducción automática y generación de contenido, aprovechando su fuerte rendimiento con entradas de texto ruidosas o incompletas."
    },
    {
      "id": "pyannote/segmentation",
      "source": "hf",
      "name": "segmentation",
      "url": "https://huggingface.co/pyannote/segmentation",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2104.04045",
        "audio",
        "license:mit",
        "overlapped-speech-detection",
        "pyannote",
        "pyannote-audio",
        "pyannote-audio-model",
        "pytorch",
        "region:us",
        "resegmentation",
        "speaker",
        "speaker-segmentation",
        "speech",
        "voice",
        "voice-activity-detection"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7788240,
        "likes_total": 638
      },
      "score": 15895.48,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "PyAnnote分割模型是一个用于音频处理的深度学习工具，专门进行说话人日志化和语音活动检测。它能识别音频中的语音片段并区分不同说话人，核心功能包括重叠语音检测和说话人变化点定位。该模型在处理多人对话环境时表现出高准确性，对各种音频条件具有鲁棒性。典型应用场景包括会议记录转录、播客内容分析和呼叫中心监控，基于PyTorch框架开发，采用MIT许可证。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "PyAnnote segmentation is an audio processing model for speaker diarization and voice activity detection. It identifies speech segments and distinguishes between speakers in audio recordings. Core capabilities include overlapped speech detection and speaker change point identification. Strengths include high accuracy in multi-speaker environments and robust performance across various audio conditions. Typical use cases include meeting transcription, podcast analysis, and call center monitoring.",
      "summary_zh": "PyAnnote分割模型是一个用于音频处理的深度学习工具，专门进行说话人日志化和语音活动检测。它能识别音频中的语音片段并区分不同说话人，核心功能包括重叠语音检测和说话人变化点定位。该模型在处理多人对话环境时表现出高准确性，对各种音频条件具有鲁棒性。典型应用场景包括会议记录转录、播客内容分析和呼叫中心监控，基于PyTorch框架开发，采用MIT许可证。",
      "summary_es": "PyAnnote segmentation es un modelo de procesamiento de audio para diarización de hablantes y detección de actividad vocal. Identifica segmentos de habla y distingue entre hablantes en grabaciones de audio. Capacidades principales incluyen detección de habla superpuesta e identificación de puntos de cambio de hablante. Fortalezas incluyen alta precisión en entornos multi-hablante y rendimiento robusto en diversas condiciones de audio. Casos de uso típicos incluyen transcripción de reuniones, análisis de podcasts y monitoreo de centros de llamadas."
    },
    {
      "id": "openai/gpt-oss-20b",
      "source": "hf",
      "name": "gpt-oss-20b",
      "url": "https://huggingface.co/openai/gpt-oss-20b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "8-bit",
        "arxiv:2508.10925",
        "autotrain_compatible",
        "conversational",
        "endpoints_compatible",
        "gpt_oss",
        "license:apache-2.0",
        "mxfp4",
        "region:us",
        "safetensors",
        "text-generation",
        "transformers",
        "vllm"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7693135,
        "likes_total": 3553
      },
      "score": 17162.77,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "GPT-OSS-20B是OpenAI开发的一个200亿参数开源语言模型，采用Apache 2.0许可证发布。该模型专精于文本生成和对话任务，通过8位量化和Safetensors优化实现高效部署。核心能力包括自然语言理解、内容创作和对话系统处理。其优势在于可访问性高、计算效率优异，且兼容Transformers和vLLM等主流框架。典型应用场景涵盖聊天机器人开发、自动化内容生成以及自然语言处理领域的学术研究，支持广泛的实际部署需求。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "inference_acceleration"
      ],
      "summary_en": "GPT-OSS-20B is a 20-billion-parameter open-source language model developed by OpenAI, released under Apache 2.0 license. It specializes in text generation and conversational tasks, optimized with 8-bit quantization and Safetensors for efficient deployment. Core capabilities include natural language understanding, content creation, and dialogue systems. Strengths include accessibility, computational efficiency, and compatibility with popular frameworks like Transformers and vLLM. Typical use cases encompass chatbots, automated content generation, and research applications in NLP.",
      "summary_zh": "GPT-OSS-20B是OpenAI开发的一个200亿参数开源语言模型，采用Apache 2.0许可证发布。该模型专精于文本生成和对话任务，通过8位量化和Safetensors优化实现高效部署。核心能力包括自然语言理解、内容创作和对话系统处理。其优势在于可访问性高、计算效率优异，且兼容Transformers和vLLM等主流框架。典型应用场景涵盖聊天机器人开发、自动化内容生成以及自然语言处理领域的学术研究，支持广泛的实际部署需求。",
      "summary_es": "GPT-OSS-20B es un modelo de lenguaje de código abierto de 20 mil millones de parámetros desarrollado por OpenAI, publicado bajo licencia Apache 2.0. Se especializa en generación de texto y tareas conversacionales, optimizado con cuantización de 8 bits y Safetensors para implementación eficiente. Capacidades principales incluyen comprensión del lenguaje natural, creación de contenido y sistemas de diálogo. Fortalezas: accesibilidad, eficiencia computacional y compatibilidad con frameworks como Transformers y vLLM. Casos de uso típicos: chatbots, generación automatizada de contenido e investigación en PLN."
    },
    {
      "id": "meta-llama/Llama-3.2-1B-Instruct",
      "source": "hf",
      "name": "Llama-3.2-1B-Instruct",
      "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2204.05149",
        "arxiv:2405.16406",
        "autotrain_compatible",
        "conversational",
        "de",
        "en",
        "endpoints_compatible",
        "es",
        "facebook",
        "fr",
        "hi",
        "it",
        "license:llama3.2",
        "llama",
        "llama-3",
        "meta",
        "pt",
        "pytorch",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "th",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7629316,
        "likes_total": 1071
      },
      "score": 15794.132,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Llama-3.2-1B-Instruct是Meta开发的10亿参数语言模型，专为指令遵循和对话任务优化。支持英语、德语、西班牙语、法语、印地语、意大利语和葡萄牙语等多语言处理。核心能力包括高效推理、与PyTorch和SafeTensors兼容，适合通过端点部署。典型应用场景涵盖聊天机器人、虚拟助手和多语言文本生成。模型基于学术研究，强调实用性和可访问性，适用于资源受限环境。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Llama-3.2-1B-Instruct is a 1-billion parameter language model developed by Meta, optimized for instruction following and conversational tasks. It supports multiple languages including English, German, Spanish, French, Hindi, Italian, and Portuguese. The model is designed for efficient inference, compatible with PyTorch and SafeTensors, and suitable for deployment via endpoints. Typical use cases include chatbots, virtual assistants, and multilingual text generation applications.",
      "summary_zh": "Llama-3.2-1B-Instruct是Meta开发的10亿参数语言模型，专为指令遵循和对话任务优化。支持英语、德语、西班牙语、法语、印地语、意大利语和葡萄牙语等多语言处理。核心能力包括高效推理、与PyTorch和SafeTensors兼容，适合通过端点部署。典型应用场景涵盖聊天机器人、虚拟助手和多语言文本生成。模型基于学术研究，强调实用性和可访问性，适用于资源受限环境。",
      "summary_es": "Llama-3.2-1B-Instruct es un modelo de lenguaje de 1 billón de parámetros desarrollado por Meta, optimizado para seguir instrucciones y tareas conversacionales. Soporta múltiples idiomas, incluidos inglés, alemán, español, francés, hindi, italiano y portugués. Está diseñado para inferencia eficiente, compatible con PyTorch y SafeTensors, y adecuado para implementación mediante endpoints. Los casos de uso típicos incluyen chatbots, asistentes virtuales y aplicaciones de generación de texto multilingüe."
    },
    {
      "id": "BAAI/bge-base-en-v1.5",
      "source": "hf",
      "name": "bge-base-en-v1.5",
      "url": "https://huggingface.co/BAAI/bge-base-en-v1.5",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2309.07597",
        "arxiv:2310.07554",
        "arxiv:2311.13534",
        "arxiv:2312.15503",
        "arxiv:2401.03462",
        "autotrain_compatible",
        "bert",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "license:mit",
        "model-index",
        "mteb",
        "onnx",
        "pytorch",
        "region:us",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "text-embeddings-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7487100,
        "likes_total": 347
      },
      "score": 15147.7,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bge-base-en-v1.5是由BAAI开发的英文文本嵌入模型，旨在将文本转换为数值向量以处理语义相似性任务。其核心能力包括生成高质量的句子嵌入，支持检索、聚类和分类等应用。优势体现在MTEB基准测试中的优异表现、高效的推理速度以及与多种框架的兼容性。典型用例涵盖语义搜索、重复检测和推荐系统。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "bge-base-en-v1.5 is an English text embedding model developed by BAAI, designed to convert text into numerical vectors for semantic similarity tasks. Its core capabilities include generating high-quality sentence embeddings, supporting tasks like retrieval, clustering, and classification. Strengths include strong performance on MTEB benchmarks, efficient inference, and compatibility with various frameworks. Typical use cases encompass semantic search, duplicate detection, and recommendation systems.",
      "summary_zh": "bge-base-en-v1.5是由BAAI开发的英文文本嵌入模型，旨在将文本转换为数值向量以处理语义相似性任务。其核心能力包括生成高质量的句子嵌入，支持检索、聚类和分类等应用。优势体现在MTEB基准测试中的优异表现、高效的推理速度以及与多种框架的兼容性。典型用例涵盖语义搜索、重复检测和推荐系统。",
      "summary_es": "bge-base-en-v1.5 es un modelo de incrustación de texto en inglés desarrollado por BAAI, diseñado para convertir texto en vectores numéricos para tareas de similitud semántica. Sus capacidades principales incluyen generar incrustaciones de oraciones de alta calidad, apoyando tareas como recuperación, agrupación y clasificación. Fortalezas: rendimiento sólido en benchmarks MTEB, inferencia eficiente y compatibilidad con varios frameworks. Casos de uso típicos: búsqueda semántica, detección de duplicados y sistemas de recomendación."
    },
    {
      "id": "Qwen/Qwen2.5-3B-Instruct",
      "source": "hf",
      "name": "Qwen2.5-3B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2407.10671",
        "autotrain_compatible",
        "base_model:Qwen/Qwen2.5-3B",
        "base_model:finetune:Qwen/Qwen2.5-3B",
        "chat",
        "conversational",
        "en",
        "endpoints_compatible",
        "license:other",
        "qwen2",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 7209456,
        "likes_total": 311
      },
      "score": 14574.412,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2.5-3B-Instruct 是一个基于 Qwen2.5-3B 的 30 亿参数指令微调语言模型，专为对话式人工智能和文本生成任务设计。它擅长理解和遵循用户指令，生成连贯的响应，并处理各种基于文本的应用。典型用例包括聊天机器人、虚拟助手、内容创作和自动化客户支持。该模型针对英语交互的效率和性能进行了优化，支持 transformers 框架，适用于部署和集成。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Qwen2.5-3B-Instruct is a 3-billion parameter instruction-tuned language model based on Qwen2.5-3B, designed for conversational AI and text generation tasks. It excels in understanding and following user instructions, generating coherent responses, and handling various text-based applications. Typical use cases include chatbots, virtual assistants, content creation, and automated customer support. The model is optimized for efficiency and performance in English-language interactions.",
      "summary_zh": "Qwen2.5-3B-Instruct 是一个基于 Qwen2.5-3B 的 30 亿参数指令微调语言模型，专为对话式人工智能和文本生成任务设计。它擅长理解和遵循用户指令，生成连贯的响应，并处理各种基于文本的应用。典型用例包括聊天机器人、虚拟助手、内容创作和自动化客户支持。该模型针对英语交互的效率和性能进行了优化，支持 transformers 框架，适用于部署和集成。",
      "summary_es": "Qwen2.5-3B-Instruct es un modelo de lenguaje de instrucción ajustado con 3 mil millones de parámetros, basado en Qwen2.5-3B, diseñado para IA conversacional y generación de texto. Destaca en comprender y seguir instrucciones del usuario, generar respuestas coherentes y manejar diversas aplicaciones basadas en texto. Los casos de uso típicos incluyen chatbots, asistentes virtuales, creación de contenido y soporte al cliente automatizado. El modelo está optimizado para eficiencia y rendimiento en interacciones en inglés."
    },
    {
      "id": "Qwen/Qwen2.5-7B-Instruct",
      "source": "hf",
      "name": "Qwen2.5-7B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2309.00071",
        "arxiv:2407.10671",
        "autotrain_compatible",
        "base_model:Qwen/Qwen2.5-7B",
        "base_model:finetune:Qwen/Qwen2.5-7B",
        "chat",
        "conversational",
        "en",
        "endpoints_compatible",
        "license:apache-2.0",
        "qwen2",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 6920482,
        "likes_total": 797
      },
      "score": 14239.464,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2.5-7B-Instruct 是基于 Qwen2.5-7B 的 70 亿参数指令调优语言模型，专为对话式人工智能和文本生成任务设计。它在自然语言理解、精确遵循指令以及跨多个领域生成连贯响应方面表现出色。典型用例包括聊天机器人、虚拟助手、内容创作和自动化客户支持，充分发挥其在英语和多语言能力上的优势。该模型支持 transformers 框架，采用 Apache 2.0 开源许可。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model based on Qwen2.5-7B, designed for conversational AI and text generation tasks. It excels in natural language understanding, following instructions precisely, and generating coherent responses across various domains. Typical use cases include chatbots, virtual assistants, content creation, and automated customer support, leveraging its strong performance in English and multilingual capabilities.",
      "summary_zh": "Qwen2.5-7B-Instruct 是基于 Qwen2.5-7B 的 70 亿参数指令调优语言模型，专为对话式人工智能和文本生成任务设计。它在自然语言理解、精确遵循指令以及跨多个领域生成连贯响应方面表现出色。典型用例包括聊天机器人、虚拟助手、内容创作和自动化客户支持，充分发挥其在英语和多语言能力上的优势。该模型支持 transformers 框架，采用 Apache 2.0 开源许可。",
      "summary_es": "Qwen2.5-7B-Instruct es un modelo de lenguaje de 7 mil millones de parámetros ajustado por instrucciones, basado en Qwen2.5-7B, diseñado para IA conversacional y generación de texto. Destaca en comprensión del lenguaje natural, seguimiento preciso de instrucciones y generación de respuestas coherentes en diversos dominios. Los casos de uso típicos incluyen chatbots, asistentes virtuales, creación de contenido y soporte al cliente automatizado, aprovechando su sólido rendimiento en inglés y capacidades multilingües."
    },
    {
      "id": "meta-llama/Llama-3.1-8B-Instruct",
      "source": "hf",
      "name": "Llama-3.1-8B-Instruct",
      "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2204.05149",
        "autotrain_compatible",
        "base_model:finetune:meta-llama/Llama-3.1-8B",
        "base_model:meta-llama/Llama-3.1-8B",
        "conversational",
        "de",
        "en",
        "endpoints_compatible",
        "es",
        "facebook",
        "fr",
        "hi",
        "it",
        "license:llama3.1",
        "llama",
        "llama-3",
        "meta",
        "pt",
        "pytorch",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "th",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 6827794,
        "likes_total": 4641
      },
      "score": 15976.088,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Llama-3.1-8B-Instruct 是一个拥有 80 亿参数的语言模型，专门针对指令跟随进行了微调。它在对话任务、多语言支持（包括英语、西班牙语、德语、法语等）和代码生成方面表现出色。优势包括高效的推理能力、强大的逻辑推理以及兼容多种微调工具。典型应用场景涵盖聊天机器人、内容创作、翻译服务和编程辅助。该模型基于 Meta 的 Llama-3.1-8B 基础模型构建，适用于研究和商业用途。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Llama-3.1-8B-Instruct is an 8-billion parameter language model fine-tuned for instruction following. It excels in conversational tasks, multilingual support (English, Spanish, German, French, etc.), and code generation. Strengths include efficient inference, strong reasoning capabilities, and compatibility with fine-tuning tools. Typical use cases include chatbots, content creation, translation, and programming assistance.",
      "summary_zh": "Llama-3.1-8B-Instruct 是一个拥有 80 亿参数的语言模型，专门针对指令跟随进行了微调。它在对话任务、多语言支持（包括英语、西班牙语、德语、法语等）和代码生成方面表现出色。优势包括高效的推理能力、强大的逻辑推理以及兼容多种微调工具。典型应用场景涵盖聊天机器人、内容创作、翻译服务和编程辅助。该模型基于 Meta 的 Llama-3.1-8B 基础模型构建，适用于研究和商业用途。",
      "summary_es": "Llama-3.1-8B-Instruct es un modelo de lenguaje de 8 mil millones de parámetros ajustado para seguir instrucciones. Destaca en tareas conversacionales, soporte multilingüe (inglés, español, alemán, francés, etc.) y generación de código. Sus fortalezas incluyen inferencia eficiente, capacidades de razonamiento sólidas y compatibilidad con herramientas de ajuste fino. Los casos de uso típicos son chatbots, creación de contenido, traducción y asistencia en programación."
    },
    {
      "id": "pyannote/voice-activity-detection",
      "source": "hf",
      "name": "voice-activity-detection",
      "url": "https://huggingface.co/pyannote/voice-activity-detection",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "audio",
        "automatic-speech-recognition",
        "dataset:ami",
        "dataset:dihard",
        "dataset:voxconverse",
        "license:mit",
        "pyannote",
        "pyannote-audio",
        "pyannote-audio-pipeline",
        "region:us",
        "speaker",
        "speech",
        "voice",
        "voice-activity-detection"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 6207440,
        "likes_total": 210
      },
      "score": 12519.880000000001,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Pyannote语音活动检测是一个开源工具，用于识别音频中的语音片段。它能检测语音何时出现，区分语音与静音或噪音。核心功能包括精确的时间分段和在各种声学条件下的稳健性能。优势在于高准确性、MIT许可证以及与Pyannote生态系统的集成。典型用例包括语音识别预处理、说话人日志记录以及会议或通话中的音频分析。该工具基于Pyannote-audio框架，支持多种数据集。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Pyannote voice-activity-detection is an open-source tool for identifying speech segments in audio. It detects when speech occurs, distinguishing it from silence or noise. Core capabilities include precise temporal segmentation and robust performance across various acoustic conditions. Strengths are high accuracy, MIT license, and integration with Pyannote ecosystem. Typical use cases include preprocessing for speech recognition, speaker diarization, and audio analysis in meetings or calls.",
      "summary_zh": "Pyannote语音活动检测是一个开源工具，用于识别音频中的语音片段。它能检测语音何时出现，区分语音与静音或噪音。核心功能包括精确的时间分段和在各种声学条件下的稳健性能。优势在于高准确性、MIT许可证以及与Pyannote生态系统的集成。典型用例包括语音识别预处理、说话人日志记录以及会议或通话中的音频分析。该工具基于Pyannote-audio框架，支持多种数据集。",
      "summary_es": "Pyannote voice-activity-detection es una herramienta de código abierto para identificar segmentos de voz en audio. Detecta cuándo ocurre el habla, distinguiéndola del silencio o ruido. Capacidades principales incluyen segmentación temporal precisa y rendimiento robusto en diversas condiciones acústicas. Fortalezas son alta precisión, licencia MIT e integración con el ecosistema Pyannote. Casos de uso típicos incluyen preprocesamiento para reconocimiento de voz, diarización de hablantes y análisis de audio en reuniones o llamadas."
    },
    {
      "id": "colbert-ir/colbertv2.0",
      "source": "hf",
      "name": "colbertv2.0",
      "url": "https://huggingface.co/colbert-ir/colbertv2.0",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "ColBERT",
        "arxiv:2004.12832",
        "arxiv:2007.00814",
        "arxiv:2101.00436",
        "arxiv:2112.01488",
        "arxiv:2205.09707",
        "bert",
        "en",
        "endpoints_compatible",
        "license:mit",
        "onnx",
        "pytorch",
        "region:us",
        "safetensors",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5861802,
        "likes_total": 285
      },
      "score": 11866.104,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ColBERTv2.0是一种神经检索模型，通过结合BERT的上下文理解能力与高效的后期交互机制来提升信息检索效果。它将查询和文档分别编码为细粒度嵌入表示，支持快速的近似最近邻搜索。核心优势包括高检索精度、可扩展至大规模文档集以及与现有基础设施的良好兼容性。典型应用场景包括需要高精度和高效率的网页搜索、问答系统和文档检索平台。该模型基于多项研究成果开发，采用MIT许可证开源。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "ColBERTv2.0 is a neural retrieval model that enhances information retrieval by combining BERT's contextual understanding with efficient late interaction. It encodes queries and documents separately into fine-grained embeddings, enabling fast approximate nearest neighbor search. Key strengths include high retrieval accuracy, scalability to large collections, and compatibility with existing infrastructure. Typical use cases include web search, question answering, and document retrieval systems where precision and efficiency are critical.",
      "summary_zh": "ColBERTv2.0是一种神经检索模型，通过结合BERT的上下文理解能力与高效的后期交互机制来提升信息检索效果。它将查询和文档分别编码为细粒度嵌入表示，支持快速的近似最近邻搜索。核心优势包括高检索精度、可扩展至大规模文档集以及与现有基础设施的良好兼容性。典型应用场景包括需要高精度和高效率的网页搜索、问答系统和文档检索平台。该模型基于多项研究成果开发，采用MIT许可证开源。",
      "summary_es": "ColBERTv2.0 es un modelo de recuperación neuronal que mejora la búsqueda de información combinando la comprensión contextual de BERT con una interacción tardía eficiente. Codifica consultas y documentos por separado en incrustaciones de grano fino, permitiendo búsquedas aproximadas de vecinos más cercanos rápidas. Sus principales fortalezas incluyen alta precisión de recuperación, escalabilidad a grandes colecciones y compatibilidad con infraestructura existente. Los casos de uso típicos incluyen búsqueda web, sistemas de pregunta-respuesta y recuperación de documentos donde la precisión y eficiencia son críticas."
    },
    {
      "id": "BAAI/bge-m3",
      "source": "hf",
      "name": "bge-m3",
      "url": "https://huggingface.co/BAAI/bge-m3",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2004.04906",
        "arxiv:2004.12832",
        "arxiv:2106.14807",
        "arxiv:2107.05720",
        "arxiv:2402.03216",
        "autotrain_compatible",
        "endpoints_compatible",
        "feature-extraction",
        "license:mit",
        "onnx",
        "pytorch",
        "region:us",
        "sentence-similarity",
        "sentence-transformers",
        "text-embeddings-inference",
        "xlm-roberta"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5822153,
        "likes_total": 2365
      },
      "score": 12826.806,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BGE-M3是由北京智源人工智能研究院开发的多语言文本嵌入模型，旨在为多种语言生成密集的向量表示。其核心功能包括特征提取、句子相似度计算和跨语言语义理解。优势在于跨语言的稳健性能、与PyTorch和ONNX等流行框架的兼容性以及高效的推理能力。典型应用场景包括语义搜索、文档检索、文本聚类以及需要精确文本表示的多语言自然语言处理任务，适用于学术研究和工业应用。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "BGE-M3 is a multilingual text embedding model developed by BAAI, designed to generate dense vector representations of text in multiple languages. Its core capabilities include feature extraction, sentence similarity computation, and cross-lingual semantic understanding. Strengths include robust performance across diverse languages, compatibility with popular frameworks like PyTorch and ONNX, and efficient inference. Typical use cases involve semantic search, document retrieval, clustering, and multilingual NLP applications where accurate text representation is required.",
      "summary_zh": "BGE-M3是由北京智源人工智能研究院开发的多语言文本嵌入模型，旨在为多种语言生成密集的向量表示。其核心功能包括特征提取、句子相似度计算和跨语言语义理解。优势在于跨语言的稳健性能、与PyTorch和ONNX等流行框架的兼容性以及高效的推理能力。典型应用场景包括语义搜索、文档检索、文本聚类以及需要精确文本表示的多语言自然语言处理任务，适用于学术研究和工业应用。",
      "summary_es": "BGE-M3 es un modelo de incrustación de texto multilingüe desarrollado por BAAI, diseñado para generar representaciones vectoriales densas de texto en múltiples idiomas. Sus capacidades principales incluyen extracción de características, cálculo de similitud de oraciones y comprensión semántica cross-lingual. Fortalezas incluyen rendimiento robusto en diversos idiomas, compatibilidad con frameworks populares como PyTorch y ONNX, e inferencia eficiente. Casos de uso típicos involucran búsqueda semántica, recuperación de documentos, agrupación y aplicaciones NLP multilingües que requieren representación textual precisa."
    },
    {
      "id": "Qwen/Qwen3-0.6B",
      "source": "hf",
      "name": "Qwen3-0.6B",
      "url": "https://huggingface.co/Qwen/Qwen3-0.6B",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2505.09388",
        "autotrain_compatible",
        "base_model:Qwen/Qwen3-0.6B-Base",
        "base_model:finetune:Qwen/Qwen3-0.6B-Base",
        "conversational",
        "endpoints_compatible",
        "license:apache-2.0",
        "qwen3",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5780115,
        "likes_total": 635
      },
      "score": 11877.73,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen3-0.6B是Qwen系列中的6亿参数语言模型，专为高效文本生成而设计。它支持对话式AI、内容创作和通用自然语言处理任务。优势包括紧凑的模型大小，便于在有限硬件上部署；采用Apache 2.0开源许可，允许自由使用；兼容transformers和文本生成推理工具。典型应用场景包括聊天机器人、文本摘要以及计算资源受限的轻量级AI应用，适合研究和商业用途。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Qwen3-0.6B is a 0.6 billion parameter language model from the Qwen series, designed for efficient text generation. It supports conversational AI, content creation, and general NLP tasks. Strengths include compact size for deployment on limited hardware, Apache 2.0 licensing for open use, and compatibility with transformers and inference tools. Typical use cases involve chatbots, text summarization, and lightweight AI applications where computational resources are constrained.",
      "summary_zh": "Qwen3-0.6B是Qwen系列中的6亿参数语言模型，专为高效文本生成而设计。它支持对话式AI、内容创作和通用自然语言处理任务。优势包括紧凑的模型大小，便于在有限硬件上部署；采用Apache 2.0开源许可，允许自由使用；兼容transformers和文本生成推理工具。典型应用场景包括聊天机器人、文本摘要以及计算资源受限的轻量级AI应用，适合研究和商业用途。",
      "summary_es": "Qwen3-0.6B es un modelo de lenguaje de 0.6 mil millones de parámetros de la serie Qwen, diseñado para la generación eficiente de texto. Soporta IA conversacional, creación de contenido y tareas generales de PLN. Sus fortalezas incluyen tamaño compacto para implementación en hardware limitado, licencia Apache 2.0 para uso abierto y compatibilidad con transformers y herramientas de inferencia. Los casos de uso típicos involucran chatbots, resumen de texto y aplicaciones ligeras de IA con recursos computacionales restringidos."
    },
    {
      "id": "nlpaueb/legal-bert-base-uncased",
      "source": "hf",
      "name": "legal-bert-base-uncased",
      "url": "https://huggingface.co/nlpaueb/legal-bert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "bert",
        "en",
        "endpoints_compatible",
        "fill-mask",
        "jax",
        "legal",
        "license:cc-by-sa-4.0",
        "pretraining",
        "pytorch",
        "region:us",
        "tf",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5594395,
        "likes_total": 271
      },
      "score": 11324.29,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Legal-BERT-base-uncased 是基于 BERT 架构的专业法律文本处理模型，经过大规模法律语料库预训练。该模型擅长理解法律术语和复杂文档结构，核心功能包括文本分类、命名实体识别和文档分析。优势在于领域特定的预训练和对法律 NLP 任务的强大性能。典型应用场景涉及法律文档处理、合同分析和法规合规自动化，适用于律师事务所、企业法务和司法机构的需求。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Legal-BERT-base-uncased is a specialized BERT model pretrained on extensive legal text corpora. It excels in understanding legal terminology and complex document structures. Core capabilities include text classification, named entity recognition, and document analysis. Strengths include domain-specific pretraining and robust performance on legal NLP tasks. Typical use cases involve legal document processing, contract analysis, and regulatory compliance automation.",
      "summary_zh": "Legal-BERT-base-uncased 是基于 BERT 架构的专业法律文本处理模型，经过大规模法律语料库预训练。该模型擅长理解法律术语和复杂文档结构，核心功能包括文本分类、命名实体识别和文档分析。优势在于领域特定的预训练和对法律 NLP 任务的强大性能。典型应用场景涉及法律文档处理、合同分析和法规合规自动化，适用于律师事务所、企业法务和司法机构的需求。",
      "summary_es": "Legal-BERT-base-uncased es un modelo BERT especializado preentrenado en extensos corpus de texto legal. Destaca en la comprensión de terminología jurídica y estructuras documentales complejas. Capacidades principales incluyen clasificación de texto, reconocimiento de entidades nombradas y análisis documental. Fortalezas son el preentrenamiento específico del dominio y rendimiento robusto en tareas NLP legales. Casos de uso típicos involucran procesamiento de documentos legales, análisis contractual y automatización de cumplimiento normativo."
    },
    {
      "id": "autogluon/chronos-bolt-base",
      "source": "hf",
      "name": "chronos-bolt-base",
      "url": "https://huggingface.co/autogluon/chronos-bolt-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1910.10683",
        "arxiv:2403.07815",
        "forecasting",
        "foundation models",
        "license:apache-2.0",
        "pretrained models",
        "region:us",
        "safetensors",
        "t5",
        "time series",
        "time series foundation models",
        "time-series",
        "time-series-forecasting"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5275394,
        "likes_total": 26
      },
      "score": 10563.788,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Chronos-Bolt-Base是基于T5架构的时间序列预测基础模型，提供预训练能力，可在无需大量训练数据的情况下进行准确预测。核心优势包括处理多样化时间序列模式、零样本预测和高效推理。典型应用涵盖零售需求预测、金融市场预测、能源消耗分析和工业过程监控，以最小配置实现稳健性能。该模型支持多种领域的时间序列分析，适用于需要快速部署和高精度预测的场景。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "time_series_forecasting"
      ],
      "summary_en": "Chronos-Bolt-Base is a time series forecasting foundation model based on T5 architecture. It provides pretrained capabilities for accurate predictions across various domains without requiring extensive training data. Core strengths include handling diverse time series patterns, zero-shot forecasting, and efficient inference. Typical use cases span retail demand forecasting, financial market predictions, energy consumption analysis, and industrial process monitoring, offering robust performance with minimal configuration.",
      "summary_zh": "Chronos-Bolt-Base是基于T5架构的时间序列预测基础模型，提供预训练能力，可在无需大量训练数据的情况下进行准确预测。核心优势包括处理多样化时间序列模式、零样本预测和高效推理。典型应用涵盖零售需求预测、金融市场预测、能源消耗分析和工业过程监控，以最小配置实现稳健性能。该模型支持多种领域的时间序列分析，适用于需要快速部署和高精度预测的场景。",
      "summary_es": "Chronos-Bolt-Base es un modelo fundacional de pronóstico de series temporales basado en arquitectura T5. Proporciona capacidades preentrenadas para predicciones precisas en diversos dominios sin requerir datos extensos de entrenamiento. Sus principales fortalezas incluyen manejo de patrones diversos de series temporales, pronóstico zero-shot e inferencia eficiente. Los casos de uso típicos abarcan pronóstico de demanda minorista, predicciones de mercados financieros, análisis de consumo energético y monitoreo de procesos industriales, ofreciendo rendimiento robusto con configuración mínima."
    },
    {
      "id": "Datadog/Toto-Open-Base-1.0",
      "source": "hf",
      "name": "Toto-Open-Base-1.0",
      "url": "https://huggingface.co/Datadog/Toto-Open-Base-1.0",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2505.14766",
        "dataset:Salesforce/GiftEvalPretrain",
        "dataset:autogluon/chronos_datasets",
        "endpoints_compatible",
        "forecasting",
        "foundation models",
        "license:apache-2.0",
        "observability",
        "pretrained models",
        "region:us",
        "safetensors",
        "time series",
        "time series foundation models",
        "time-series",
        "time-series-forecasting",
        "timeseries",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5156315,
        "likes_total": 109
      },
      "score": 10367.130000000001,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Toto-Open-Base-1.0是由Datadog开发的时间序列基础模型，专为预测应用设计。该模型基于Salesforce/GiftEvalPretrain和AutoGluon/Chronos等数据集进行预训练，具备强大的时序模式识别能力。核心功能包括多步预测、异常检测以及处理多样化时间序列格式。其优势在于可扩展性强、兼容Transformer架构，并采用Apache 2.0开源许可。典型应用场景涵盖可观测性监控、资源分配预测和运营指标分析，适用于多个行业领域。模型支持安全张量格式，下载量已超过500万次，体现了其在实际应用中的广泛采纳。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Toto-Open-Base-1.0 is a time series foundation model developed by Datadog for forecasting applications. It is pretrained on datasets including Salesforce/GiftEvalPretrain and AutoGluon/Chronos, enabling robust pattern recognition in temporal data. Core capabilities include multi-step forecasting, anomaly detection, and handling diverse time series formats. Strengths lie in its scalability, compatibility with transformers architecture, and Apache 2.0 open-source licensing. Typical use cases encompass observability monitoring, resource allocation prediction, and operational metrics analysis across various industries.",
      "summary_zh": "Toto-Open-Base-1.0是由Datadog开发的时间序列基础模型，专为预测应用设计。该模型基于Salesforce/GiftEvalPretrain和AutoGluon/Chronos等数据集进行预训练，具备强大的时序模式识别能力。核心功能包括多步预测、异常检测以及处理多样化时间序列格式。其优势在于可扩展性强、兼容Transformer架构，并采用Apache 2.0开源许可。典型应用场景涵盖可观测性监控、资源分配预测和运营指标分析，适用于多个行业领域。模型支持安全张量格式，下载量已超过500万次，体现了其在实际应用中的广泛采纳。",
      "summary_es": "Toto-Open-Base-1.0 es un modelo fundacional de series temporales desarrollado por Datadog para aplicaciones de pronóstico. Está preentrenado en conjuntos de datos como Salesforce/GiftEvalPretrain y AutoGluon/Chronos, permitiendo un reconocimiento robusto de patrones en datos temporales. Sus capacidades principales incluyen pronóstico multi-paso, detección de anomalías y manejo de diversos formatos de series temporales. Sus fortalezas radican en su escalabilidad, compatibilidad con arquitectura transformers y licencia open-source Apache 2.0. Los casos de uso típicos abarcan monitoreo de observabilidad, predicción de asignación de recursos y análisis de métricas operativas en diversas industrias."
    },
    {
      "id": "Comfy-Org/Wan_2.2_ComfyUI_Repackaged",
      "source": "hf",
      "name": "Wan_2.2_ComfyUI_Repackaged",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "comfyui",
        "diffusion-single-file",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5097262,
        "likes_total": 326
      },
      "score": 10357.524,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Wan_2.2_ComfyUI_Repackaged 是一个专为 ComfyUI 工作流管理器优化的单文件扩散模型。它提供稳定的图像生成能力，支持多种扩散技术，具有高效的资源利用率。该模型在保持与 ComfyUI 节点式界面兼容性的同时，能够生成高质量输出。典型应用场景包括人工智能艺术创作、视觉概念原型设计，以及将扩散模型集成到自动化工作流中，无需复杂配置即可使用。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "text_to_image"
      ],
      "summary_en": "Wan_2.2_ComfyUI_Repackaged is a single-file diffusion model optimized for the ComfyUI workflow manager. It provides stable image generation capabilities with efficient resource usage, supporting various diffusion techniques. The model excels in producing high-quality outputs while maintaining compatibility with ComfyUI's node-based interface. Typical use cases include AI art creation, prototyping visual concepts, and integrating diffusion models into automated workflows without complex setup requirements.",
      "summary_zh": "Wan_2.2_ComfyUI_Repackaged 是一个专为 ComfyUI 工作流管理器优化的单文件扩散模型。它提供稳定的图像生成能力，支持多种扩散技术，具有高效的资源利用率。该模型在保持与 ComfyUI 节点式界面兼容性的同时，能够生成高质量输出。典型应用场景包括人工智能艺术创作、视觉概念原型设计，以及将扩散模型集成到自动化工作流中，无需复杂配置即可使用。",
      "summary_es": "Wan_2.2_ComfyUI_Repackaged es un modelo de difusión de archivo único optimizado para el gestor de flujos de trabajo ComfyUI. Proporciona capacidades estables de generación de imágenes con uso eficiente de recursos, soportando diversas técnicas de difusión. El modelo destaca en producir salidas de alta calidad manteniendo compatibilidad con la interfaz basada en nodos de ComfyUI. Los casos de uso típicos incluyen creación de arte IA, prototipado de conceptos visuales e integración de modelos de difusión en flujos automatizados sin requisitos complejos de configuración."
    },
    {
      "id": "facebook/esmfold_v1",
      "source": "hf",
      "name": "esmfold_v1",
      "url": "https://huggingface.co/facebook/esmfold_v1",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "endpoints_compatible",
        "esm",
        "license:mit",
        "pytorch",
        "region:us",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5091831,
        "likes_total": 42
      },
      "score": 10204.662,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ESMFold v1是由Meta AI开发的蛋白质结构预测模型。它利用进化尺度建模技术，直接从氨基酸序列高精度预测三维蛋白质结构。该模型的核心优势在于无需多重序列比对即可快速生成结构预测，适用于大规模计算任务。典型应用场景包括计算生物学研究、药物发现和蛋白质工程领域。模型基于PyTorch框架构建，采用MIT开源许可证发布，支持端点部署。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "ESMFold v1 is a protein structure prediction model developed by Meta AI. It uses evolutionary scale modeling to predict 3D protein structures from amino acid sequences with high accuracy. The model excels in rapid prediction without requiring multiple sequence alignments, making it efficient for large-scale applications. Typical use cases include computational biology research, drug discovery, and protein engineering. It is compatible with PyTorch and available under an MIT license.",
      "summary_zh": "ESMFold v1是由Meta AI开发的蛋白质结构预测模型。它利用进化尺度建模技术，直接从氨基酸序列高精度预测三维蛋白质结构。该模型的核心优势在于无需多重序列比对即可快速生成结构预测，适用于大规模计算任务。典型应用场景包括计算生物学研究、药物发现和蛋白质工程领域。模型基于PyTorch框架构建，采用MIT开源许可证发布，支持端点部署。",
      "summary_es": "ESMFold v1 es un modelo de predicción de estructura de proteínas desarrollado por Meta AI. Utiliza modelado a escala evolutiva para predecir estructuras 3D de proteínas a partir de secuencias de aminoácidos con alta precisión. El modelo destaca por su predicción rápida sin necesidad de alineamientos de secuencias múltiples, siendo eficiente para aplicaciones a gran escala. Los casos de uso típicos incluyen investigación en biología computacional, descubrimiento de fármacos e ingeniería de proteínas. Es compatible con PyTorch y disponible bajo licencia MIT."
    },
    {
      "id": "Qwen/Qwen2.5-1.5B-Instruct",
      "source": "hf",
      "name": "Qwen2.5-1.5B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2407.10671",
        "autotrain_compatible",
        "base_model:Qwen/Qwen2.5-1.5B",
        "base_model:finetune:Qwen/Qwen2.5-1.5B",
        "chat",
        "conversational",
        "en",
        "endpoints_compatible",
        "license:apache-2.0",
        "qwen2",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5028303,
        "likes_total": 514
      },
      "score": 10313.606,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2.5-1.5B-Instruct是基于Qwen2.5架构的15亿参数指令微调语言模型，专长于对话AI和文本生成任务。该模型优化了遵循用户指令和进行对话的能力，主要支持英语，并与Transformers和文本生成推理框架兼容。典型应用包括聊天机器人、内容创作和自动化辅助系统。采用Apache 2.0许可证，在Hugging Face平台提供。模型具有高效的参数规模和实用的对话功能，适用于资源受限环境下的AI应用部署。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Qwen2.5-1.5B-Instruct is a 1.5 billion parameter instruction-tuned language model based on Qwen2.5 architecture. It specializes in conversational AI and text generation tasks, optimized for following user instructions and engaging in dialogue. The model supports English primarily and is compatible with Transformers and text-generation-inference frameworks. Typical use cases include chatbots, content creation, and automated assistance systems. It is licensed under Apache 2.0 and available on Hugging Face.",
      "summary_zh": "Qwen2.5-1.5B-Instruct是基于Qwen2.5架构的15亿参数指令微调语言模型，专长于对话AI和文本生成任务。该模型优化了遵循用户指令和进行对话的能力，主要支持英语，并与Transformers和文本生成推理框架兼容。典型应用包括聊天机器人、内容创作和自动化辅助系统。采用Apache 2.0许可证，在Hugging Face平台提供。模型具有高效的参数规模和实用的对话功能，适用于资源受限环境下的AI应用部署。",
      "summary_es": "Qwen2.5-1.5B-Instruct es un modelo de lenguaje de 1.5 mil millones de parámetros ajustado para instrucciones, basado en la arquitectura Qwen2.5. Se especializa en IA conversacional y generación de texto, optimizado para seguir instrucciones de usuario y participar en diálogos. Soporta principalmente inglés y es compatible con frameworks como Transformers e inferencia de generación de texto. Los casos de uso típicos incluyen chatbots, creación de contenido y sistemas de asistencia automatizada. Tiene licencia Apache 2.0 y está disponible en Hugging Face."
    },
    {
      "id": "BAAI/bge-small-en-v1.5",
      "source": "hf",
      "name": "bge-small-en-v1.5",
      "url": "https://huggingface.co/BAAI/bge-small-en-v1.5",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2309.07597",
        "arxiv:2310.07554",
        "arxiv:2311.13534",
        "arxiv:2312.15503",
        "arxiv:2401.03462",
        "autotrain_compatible",
        "bert",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "license:mit",
        "model-index",
        "mteb",
        "onnx",
        "pytorch",
        "region:us",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "text-embeddings-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5000832,
        "likes_total": 372
      },
      "score": 10187.664,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bge-small-en-v1.5是由BAAI开发的紧凑型英文文本嵌入模型，专为高效的句子相似度和特征提取而优化。它生成文本的密集向量表示，用于语义搜索、聚类和检索任务。该模型拥有3300万参数，在性能和计算效率之间取得平衡，适用于资源受限的环境。支持通过PyTorch、ONNX和文本嵌入推理进行集成，采用MIT许可证开放使用。典型应用包括文档匹配、推荐系统和自然语言处理流水线中的嵌入生成。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "bge-small-en-v1.5 is a compact English text embedding model developed by BAAI, optimized for efficient sentence similarity and feature extraction. It generates dense vector representations of text for semantic search, clustering, and retrieval tasks. With 33M parameters, it balances performance and computational efficiency, making it suitable for resource-constrained environments. The model supports integration via PyTorch, ONNX, and text-embeddings-inference, licensed under MIT for open use.",
      "summary_zh": "bge-small-en-v1.5是由BAAI开发的紧凑型英文文本嵌入模型，专为高效的句子相似度和特征提取而优化。它生成文本的密集向量表示，用于语义搜索、聚类和检索任务。该模型拥有3300万参数，在性能和计算效率之间取得平衡，适用于资源受限的环境。支持通过PyTorch、ONNX和文本嵌入推理进行集成，采用MIT许可证开放使用。典型应用包括文档匹配、推荐系统和自然语言处理流水线中的嵌入生成。",
      "summary_es": "bge-small-en-v1.5 es un modelo compacto de incrustación de texto en inglés desarrollado por BAAI, optimizado para similitud de oraciones y extracción de características eficientes. Genera representaciones vectoriales densas de texto para búsqueda semántica, agrupación y tareas de recuperación. Con 33M de parámetros, equilibra rendimiento y eficiencia computacional, siendo adecuado para entornos con recursos limitados. Soporta integración mediante PyTorch, ONNX e inferencia de incrustaciones de texto, con licencia MIT para uso abierto."
    },
    {
      "id": "coqui/XTTS-v2",
      "source": "hf",
      "name": "XTTS-v2",
      "url": "https://huggingface.co/coqui/XTTS-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "coqui",
        "license:other",
        "region:us",
        "text-to-speech"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4909924,
        "likes_total": 3043
      },
      "score": 11341.348,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "XTTS-v2 是一个多语言文本转语音模型，能够从文本输入生成自然语音。它支持仅需几秒音频即可进行语音克隆，并以多种语言输出高质量结果。核心功能包括跨语言语音转换和情感语调控制。其优势在于高效性、开源特性以及逼真的语音合成效果。典型应用场景包括有声读物朗读、配音制作、无障碍工具开发以及个性化语音应用。该模型由 Coqui 开发，基于先进技术实现多语言支持。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "tts"
      ],
      "summary_en": "XTTS-v2 is a multilingual text-to-speech model that generates natural speech from text input. It supports voice cloning with just a few seconds of audio, producing high-quality output in multiple languages. Core capabilities include cross-lingual voice transfer and emotional tone control. Strengths are its efficiency, open-source nature, and realistic voice synthesis. Typical use cases include audiobook narration, voiceovers, accessibility tools, and personalized voice applications.",
      "summary_zh": "XTTS-v2 是一个多语言文本转语音模型，能够从文本输入生成自然语音。它支持仅需几秒音频即可进行语音克隆，并以多种语言输出高质量结果。核心功能包括跨语言语音转换和情感语调控制。其优势在于高效性、开源特性以及逼真的语音合成效果。典型应用场景包括有声读物朗读、配音制作、无障碍工具开发以及个性化语音应用。该模型由 Coqui 开发，基于先进技术实现多语言支持。",
      "summary_es": "XTTS-v2 es un modelo de texto a voz multilingüe que genera habla natural a partir de texto. Admite clonación de voz con solo unos segundos de audio, produciendo salida de alta calidad en múltiples idiomas. Capacidades clave incluyen transferencia de voz cross-lingüe y control de tono emocional. Fortalezas son su eficiencia, naturaleza de código abierto y síntesis vocal realista. Casos de uso típicos incluyen narración de audiolibros, doblaje, herramientas de accesibilidad y aplicaciones de voz personalizadas."
    },
    {
      "id": "thuml/sundial-base-128m",
      "source": "hf",
      "name": "sundial-base-128m",
      "url": "https://huggingface.co/thuml/sundial-base-128m",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2403.07815",
        "arxiv:2502.00816",
        "custom_code",
        "dataset:Salesforce/lotsa_data",
        "dataset:autogluon/chronos_datasets",
        "dataset:thuml/UTSD",
        "forecasting",
        "foundation models",
        "generative models",
        "license:apache-2.0",
        "pretrained models",
        "region:us",
        "safetensors",
        "sundial",
        "time series",
        "time series foundation models",
        "time-series",
        "time-series-forecasting"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4856549,
        "likes_total": 44
      },
      "score": 9735.098,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Sundial-base-128m是由THUML开发的1.28亿参数时间序列基础模型。该模型专门用于时间序列预测和生成任务，基于Salesforce/lotsa_data、Chronos数据集和UTSD等多个数据集进行训练。具备强大的时序模式处理能力，能够提供跨不同领域的准确预测。核心优势包括高效的参数利用、稳定的预测性能和广泛的适用性。典型应用场景涵盖需求预测、金融市场分析、工业过程监控等领域。采用Apache 2.0开源协议，支持safetensors格式部署。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Sundial-base-128m is a 128 million parameter time series foundation model developed by THUML. It specializes in time series forecasting and generation tasks, trained on multiple datasets including Salesforce/lotsa_data and Chronos datasets. The model demonstrates strong capabilities in handling various temporal patterns and provides accurate predictions across different domains. Typical use cases include demand forecasting, financial market analysis, and industrial process monitoring. It is released under Apache 2.0 license with safetensors format.",
      "summary_zh": "Sundial-base-128m是由THUML开发的1.28亿参数时间序列基础模型。该模型专门用于时间序列预测和生成任务，基于Salesforce/lotsa_data、Chronos数据集和UTSD等多个数据集进行训练。具备强大的时序模式处理能力，能够提供跨不同领域的准确预测。核心优势包括高效的参数利用、稳定的预测性能和广泛的适用性。典型应用场景涵盖需求预测、金融市场分析、工业过程监控等领域。采用Apache 2.0开源协议，支持safetensors格式部署。",
      "summary_es": "Sundial-base-128m es un modelo fundacional de series temporales de 128 millones de parámetros desarrollado por THUML. Se especializa en tareas de predicción y generación de series temporales, entrenado con múltiples conjuntos de datos incluyendo Salesforce/lotsa_data y datasets Chronos. Demuestra capacidades sólidas para manejar diversos patrones temporales y proporciona predicciones precisas en distintos dominios. Los casos de uso típicos incluyen pronóstico de demanda, análisis de mercados financieros y monitoreo de procesos industriales. Se distribuye bajo licencia Apache 2.0 con formato safetensors."
    },
    {
      "id": "dphn/dolphin-2.9.1-yi-1.5-34b",
      "source": "hf",
      "name": "dolphin-2.9.1-yi-1.5-34b",
      "url": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "autotrain_compatible",
        "axolotl",
        "base_model:01-ai/Yi-1.5-34B",
        "base_model:finetune:01-ai/Yi-1.5-34B",
        "conversational",
        "dataset:Locutusque/function-calling-chatml",
        "dataset:cognitivecomputations/Dolphin-2.9",
        "dataset:cognitivecomputations/dolphin-coder",
        "dataset:cognitivecomputations/samantha-data",
        "dataset:internlm/Agent-FLAN",
        "dataset:m-a-p/CodeFeedback-Filtered-Instruction",
        "dataset:microsoft/orca-math-word-problems-200k",
        "dataset:teknium/OpenHermes-2.5",
        "endpoints_compatible",
        "generated_from_trainer",
        "license:apache-2.0",
        "llama",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4698276,
        "likes_total": 39
      },
      "score": 9416.052,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Dolphin-2.9.1-yi-1.5-34b 是基于 Yi-1.5-34B 微调的大型语言模型，专为对话式人工智能和文本生成而设计。其核心能力包括自然语言理解、代码生成和函数调用，优势在于处理多样化数据集，如 OpenHermes 和 Orca-Math。典型用例涉及聊天机器人、编码辅助和解决复杂文字问题，利用了多个高质量数据集的强大训练基础。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "code_generation"
      ],
      "summary_en": "Dolphin-2.9.1-yi-1.5-34b is a large language model fine-tuned from Yi-1.5-34B, designed for conversational AI and text generation. Its core capabilities include natural language understanding, code generation, and function calling, with strengths in handling diverse datasets like OpenHermes and Orca-Math. Typical use cases involve chatbots, coding assistance, and solving complex word problems, leveraging its robust training on multiple high-quality datasets.",
      "summary_zh": "Dolphin-2.9.1-yi-1.5-34b 是基于 Yi-1.5-34B 微调的大型语言模型，专为对话式人工智能和文本生成而设计。其核心能力包括自然语言理解、代码生成和函数调用，优势在于处理多样化数据集，如 OpenHermes 和 Orca-Math。典型用例涉及聊天机器人、编码辅助和解决复杂文字问题，利用了多个高质量数据集的强大训练基础。",
      "summary_es": "Dolphin-2.9.1-yi-1.5-34b es un modelo de lenguaje grande ajustado a partir de Yi-1.5-34B, diseñado para IA conversacional y generación de texto. Sus capacidades principales incluyen comprensión del lenguaje natural, generación de código y llamadas a funciones, con fortalezas en el manejo de diversos conjuntos de datos como OpenHermes y Orca-Math. Los casos de uso típicos involucran chatbots, asistencia de codificación y resolución de problemas de palabras complejos, aprovechando su entrenamiento robusto en múltiples conjuntos de datos de alta calidad."
    },
    {
      "id": "google-bert/bert-base-multilingual-cased",
      "source": "hf",
      "name": "bert-base-multilingual-cased",
      "url": "https://huggingface.co/google-bert/bert-base-multilingual-cased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "af",
        "an",
        "ar",
        "arxiv:1810.04805",
        "ast",
        "autotrain_compatible",
        "az",
        "aze",
        "ba",
        "bar",
        "be",
        "bert",
        "bg",
        "bn",
        "br",
        "bs",
        "ca",
        "ce",
        "ceb",
        "cs",
        "cv",
        "cy",
        "da",
        "dataset:wikipedia",
        "de",
        "el",
        "en",
        "endpoints_compatible",
        "es",
        "et",
        "eu",
        "fa",
        "fi",
        "fill-mask",
        "fr",
        "fry",
        "ga",
        "gl",
        "gu",
        "he",
        "hi",
        "hr",
        "ht",
        "hu",
        "hy",
        "id",
        "inc",
        "io",
        "is",
        "it",
        "ja",
        "jax",
        "jv",
        "ka",
        "kk",
        "kn",
        "ko",
        "ky",
        "la",
        "license:apache-2.0",
        "lm",
        "lt",
        "lv",
        "mg",
        "min",
        "mk",
        "ml",
        "mn",
        "mr",
        "ms",
        "multilingual",
        "my",
        "nb",
        "nds",
        "ne",
        "new",
        "nl",
        "nn",
        "oc",
        "pa",
        "pl",
        "pms",
        "pnb",
        "pt",
        "pytorch",
        "region:us",
        "ro",
        "roa",
        "ru",
        "safetensors",
        "scn",
        "sco",
        "sk",
        "sl",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "tf",
        "tg",
        "th",
        "tl",
        "tr",
        "transformers",
        "tt",
        "ud",
        "uk",
        "uz",
        "vi",
        "vo",
        "war",
        "yo",
        "zh"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4626601,
        "likes_total": 530
      },
      "score": 9518.202,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BERT-base-multilingual-cased 是一个基于 Transformer 的多语言预训练模型，支持 104 种语言。它保留文本大小写，通过掩码语言建模和下一句预测任务进行训练。核心能力包括生成上下文感知的嵌入表示，适用于跨语言迁移学习。优势在于对多种语言的统一处理和高性能表现。典型应用场景包括文本分类、命名实体识别、问答系统等多语言自然语言处理任务，特别适合需要处理多种语言数据的应用。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "BERT-base-multilingual-cased is a transformer model pre-trained on multilingual text from 104 languages. It processes text with preserved casing and generates contextual embeddings. Core capabilities include masked language modeling and next sentence prediction. Strengths are cross-lingual transfer and robust performance across diverse languages. Typical use cases are text classification, named entity recognition, and question answering in multilingual contexts.",
      "summary_zh": "BERT-base-multilingual-cased 是一个基于 Transformer 的多语言预训练模型，支持 104 种语言。它保留文本大小写，通过掩码语言建模和下一句预测任务进行训练。核心能力包括生成上下文感知的嵌入表示，适用于跨语言迁移学习。优势在于对多种语言的统一处理和高性能表现。典型应用场景包括文本分类、命名实体识别、问答系统等多语言自然语言处理任务，特别适合需要处理多种语言数据的应用。",
      "summary_es": "BERT-base-multilingual-cased es un modelo transformer preentrenado en texto multilingüe de 104 idiomas. Procesa texto conservando las mayúsculas y genera incrustaciones contextuales. Sus capacidades principales incluyen modelado de lenguaje enmascarado y predicción de oraciones siguientes. Sus fortalezas son la transferencia cross-lingüística y el rendimiento robusto en diversos idiomas. Los casos de uso típicos son clasificación de texto, reconocimiento de entidades nombradas y respuesta a preguntas en contextos multilingües."
    },
    {
      "id": "Qwen/Qwen2-VL-2B-Instruct",
      "source": "hf",
      "name": "Qwen2-VL-2B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2308.12966",
        "arxiv:2409.12191",
        "base_model:Qwen/Qwen2-VL-2B",
        "base_model:finetune:Qwen/Qwen2-VL-2B",
        "conversational",
        "en",
        "endpoints_compatible",
        "image-text-to-text",
        "image-to-text",
        "license:apache-2.0",
        "multimodal",
        "qwen2_vl",
        "region:us",
        "safetensors",
        "text-generation-inference",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4601823,
        "likes_total": 450
      },
      "score": 9428.646,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2-VL-2B-Instruct 是一个拥有 20 亿参数的多模态人工智能模型，专为视觉语言任务设计。它能够同时处理图像和文本输入，生成上下文相关的响应，支持对话式交互。核心功能包括图像描述、视觉问答和多模态对话。优势在于高效的参数利用、Apache 2.0 开源许可以及与标准推理端点的兼容性。典型应用涵盖教育工具、内容分析和需要整合视觉与文本理解的辅助应用场景，适用于开发智能助手和自动化分析系统。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Qwen2-VL-2B-Instruct is a 2-billion parameter multimodal AI model designed for visual-language tasks. It processes both images and text to generate contextual responses, supporting conversational interactions. Core capabilities include image captioning, visual question answering, and multimodal dialogue. Strengths include efficient parameter usage, Apache 2.0 licensing, and compatibility with standard inference endpoints. Typical use cases span educational tools, content analysis, and assistive applications requiring integrated visual and textual understanding.",
      "summary_zh": "Qwen2-VL-2B-Instruct 是一个拥有 20 亿参数的多模态人工智能模型，专为视觉语言任务设计。它能够同时处理图像和文本输入，生成上下文相关的响应，支持对话式交互。核心功能包括图像描述、视觉问答和多模态对话。优势在于高效的参数利用、Apache 2.0 开源许可以及与标准推理端点的兼容性。典型应用涵盖教育工具、内容分析和需要整合视觉与文本理解的辅助应用场景，适用于开发智能助手和自动化分析系统。",
      "summary_es": "Qwen2-VL-2B-Instruct es un modelo multimodal de IA con 2 mil millones de parámetros diseñado para tareas de lenguaje visual. Procesa imágenes y texto para generar respuestas contextuales, admitiendo interacciones conversacionales. Sus capacidades principales incluyen descripción de imágenes, respuesta a preguntas visuales y diálogo multimodal. Fortalezas: uso eficiente de parámetros, licencia Apache 2.0 y compatibilidad con endpoints de inferencia estándar. Casos de uso típicos abarcan herramientas educativas, análisis de contenido y aplicaciones asistenciales que requieren comprensión integrada de visión y texto."
    },
    {
      "id": "sentence-transformers/gtr-t5-base",
      "source": "hf",
      "name": "gtr-t5-base",
      "url": "https://huggingface.co/sentence-transformers/gtr-t5-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2112.07899",
        "autotrain_compatible",
        "en",
        "endpoints_compatible",
        "feature-extraction",
        "license:apache-2.0",
        "pytorch",
        "region:us",
        "safetensors",
        "sentence-similarity",
        "sentence-transformers",
        "t5"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4568689,
        "likes_total": 25
      },
      "score": 9149.878,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "gtr-t5-base是基于T5架构的文本嵌入模型，专门用于生成句子的密集向量表示。该模型擅长语义相似性任务，能够准确比较不同文本的含义。核心功能包括句子编码、信息检索和文本聚类。其优势在于基准测试中的高性能表现和高效计算能力。典型应用场景包括语义搜索、重复内容检测以及推荐系统，适用于需要深度理解文本语义的各种自然语言处理任务。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "gtr-t5-base is a text embedding model based on T5 architecture, designed for generating dense vector representations of sentences. It excels at semantic similarity tasks, enabling accurate comparison of text meaning across documents. Core capabilities include sentence encoding, retrieval, and clustering. Strengths include high performance on benchmarks and efficient computation. Typical use cases involve semantic search, duplicate detection, and recommendation systems.",
      "summary_zh": "gtr-t5-base是基于T5架构的文本嵌入模型，专门用于生成句子的密集向量表示。该模型擅长语义相似性任务，能够准确比较不同文本的含义。核心功能包括句子编码、信息检索和文本聚类。其优势在于基准测试中的高性能表现和高效计算能力。典型应用场景包括语义搜索、重复内容检测以及推荐系统，适用于需要深度理解文本语义的各种自然语言处理任务。",
      "summary_es": "gtr-t5-base es un modelo de incrustación de texto basado en la arquitectura T5, diseñado para generar representaciones vectoriales densas de oraciones. Sobresale en tareas de similitud semántica, permitiendo comparaciones precisas del significado textual. Capacidades principales incluyen codificación de oraciones, recuperación de información y agrupación. Fortalezas son alto rendimiento en benchmarks y computación eficiente. Casos de uso típicos incluyen búsqueda semántica, detección de duplicados y sistemas de recomendación."
    },
    {
      "id": "openai/whisper-large-v3",
      "source": "hf",
      "name": "whisper-large-v3",
      "url": "https://huggingface.co/openai/whisper-large-v3",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "af",
        "am",
        "ar",
        "arxiv:2212.04356",
        "as",
        "audio",
        "automatic-speech-recognition",
        "az",
        "ba",
        "be",
        "bg",
        "bn",
        "bo",
        "br",
        "bs",
        "ca",
        "cs",
        "cy",
        "da",
        "de",
        "el",
        "en",
        "endpoints_compatible",
        "es",
        "et",
        "eu",
        "fa",
        "fi",
        "fo",
        "fr",
        "gl",
        "gu",
        "ha",
        "haw",
        "he",
        "hf-asr-leaderboard",
        "hi",
        "hr",
        "ht",
        "hu",
        "hy",
        "id",
        "is",
        "it",
        "ja",
        "jax",
        "jw",
        "ka",
        "kk",
        "km",
        "kn",
        "ko",
        "la",
        "lb",
        "license:apache-2.0",
        "ln",
        "lo",
        "lt",
        "lv",
        "mg",
        "mi",
        "mk",
        "ml",
        "mn",
        "mr",
        "ms",
        "mt",
        "my",
        "ne",
        "nl",
        "nn",
        "no",
        "oc",
        "pa",
        "pl",
        "ps",
        "pt",
        "pytorch",
        "region:us",
        "ro",
        "ru",
        "sa",
        "safetensors",
        "sd",
        "si",
        "sk",
        "sl",
        "sn",
        "so",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "tg",
        "th",
        "tk",
        "tl",
        "tr",
        "transformers",
        "tt",
        "uk",
        "ur",
        "uz",
        "vi",
        "whisper",
        "yi",
        "yo",
        "zh"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4550489,
        "likes_total": 4922
      },
      "score": 11561.978000000001,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Whisper-large-v3是OpenAI开发的高级自动语音识别模型，能够将语音高精度转录为文本，支持多种语言和方言。核心功能包括多语言处理、在嘈杂环境中的稳健性能以及处理不同口音的能力。其优势在于基于多样化音频数据的大规模训练和开源可用性。典型应用场景包括转录服务、无障碍工具和多语言内容处理，适用于全球范围内的语音转文本需求。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "asr"
      ],
      "summary_en": "Whisper-large-v3 is an advanced automatic speech recognition model developed by OpenAI. It transcribes speech to text with high accuracy across multiple languages and dialects. Its core capabilities include multilingual support, robust performance in noisy environments, and handling diverse accents. Strengths are its large-scale training on diverse audio data and open availability. Typical use cases are transcription services, accessibility tools, and multilingual content processing.",
      "summary_zh": "Whisper-large-v3是OpenAI开发的高级自动语音识别模型，能够将语音高精度转录为文本，支持多种语言和方言。核心功能包括多语言处理、在嘈杂环境中的稳健性能以及处理不同口音的能力。其优势在于基于多样化音频数据的大规模训练和开源可用性。典型应用场景包括转录服务、无障碍工具和多语言内容处理，适用于全球范围内的语音转文本需求。",
      "summary_es": "Whisper-large-v3 es un modelo avanzado de reconocimiento automático de voz desarrollado por OpenAI. Transcribe voz a texto con alta precisión en múltiples idiomas y dialectos. Sus capacidades principales incluyen soporte multilingüe, rendimiento robusto en entornos ruidosos y manejo de diversos acentos. Sus fortalezas son el entrenamiento a gran escala con datos diversos y disponibilidad abierta. Casos de uso típicos son servicios de transcripción, herramientas de accesibilidad y procesamiento de contenido multilingüe."
    },
    {
      "id": "google-t5/t5-small",
      "source": "hf",
      "name": "t5-small",
      "url": "https://huggingface.co/google-t5/t5-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1606.05250",
        "arxiv:1704.05426",
        "arxiv:1708.00055",
        "arxiv:1805.12471",
        "arxiv:1808.09121",
        "arxiv:1810.12885",
        "arxiv:1905.10044",
        "arxiv:1910.09700",
        "dataset:c4",
        "de",
        "en",
        "endpoints_compatible",
        "fr",
        "jax",
        "license:apache-2.0",
        "multilingual",
        "onnx",
        "pytorch",
        "region:us",
        "ro",
        "rust",
        "safetensors",
        "summarization",
        "t5",
        "text-generation-inference",
        "text2text-generation",
        "tf",
        "transformers",
        "translation"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4535380,
        "likes_total": 488
      },
      "score": 9314.76,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "T5-small是谷歌开发的小型文本到文本转换Transformer模型，采用统一文本生成框架处理多种自然语言处理任务。核心能力包括翻译、摘要、问答和分类，通过将输入转换为目标文本来实现。优势在于多语言支持（英语、德语、法语、罗马尼亚语）、高效参数化及与PyTorch、JAX和ONNX的兼容性。典型应用场景涵盖学术研究、原型开发和计算资源有限的轻量级部署，适用于快速实验和基础NLP需求。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "T5-small is a compact text-to-text transformer model from Google, designed for diverse NLP tasks through unified text generation. It handles translation, summarization, question answering, and classification by converting inputs to target outputs. Strengths include multilingual support (English, German, French, Romanian), efficient parameterization, and compatibility with PyTorch, JAX, and ONNX. Typical use cases involve research, prototyping, and lightweight applications where computational resources are limited.",
      "summary_zh": "T5-small是谷歌开发的小型文本到文本转换Transformer模型，采用统一文本生成框架处理多种自然语言处理任务。核心能力包括翻译、摘要、问答和分类，通过将输入转换为目标文本来实现。优势在于多语言支持（英语、德语、法语、罗马尼亚语）、高效参数化及与PyTorch、JAX和ONNX的兼容性。典型应用场景涵盖学术研究、原型开发和计算资源有限的轻量级部署，适用于快速实验和基础NLP需求。",
      "summary_es": "T5-small es un modelo transformer compacto de texto a texto de Google, diseñado para diversas tareas de PLN mediante generación unificada de texto. Maneja traducción, resumen, respuesta a preguntas y clasificación convirtiendo entradas en salidas objetivo. Sus fortalezas incluyen soporte multilingüe (inglés, alemán, francés, rumano), parametrización eficiente y compatibilidad con PyTorch, JAX y ONNX. Los casos de uso típicos involucran investigación, prototipado y aplicaciones ligeras con recursos computacionales limitados."
    },
    {
      "id": "google/t5gemma-b-b-prefixlm",
      "source": "hf",
      "name": "t5gemma-b-b-prefixlm",
      "url": "https://huggingface.co/google/t5gemma-b-b-prefixlm",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:1705.03551",
        "arxiv:1905.07830",
        "arxiv:1905.10044",
        "arxiv:1907.10641",
        "arxiv:1911.01547",
        "arxiv:1911.11641",
        "arxiv:2009.03300",
        "arxiv:2103.03874",
        "arxiv:2107.03374",
        "arxiv:2108.07732",
        "arxiv:2110.14168",
        "arxiv:2206.04615",
        "arxiv:2304.06364",
        "arxiv:2504.06225",
        "base_model:finetune:google/t5gemma-b-b-prefixlm",
        "base_model:google/t5gemma-b-b-prefixlm",
        "endpoints_compatible",
        "license:gemma",
        "region:us",
        "safetensors",
        "t5gemma",
        "text2text-generation",
        "transformers"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4427357,
        "likes_total": 9
      },
      "score": 8859.214,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "t5gemma-b-b-prefixlm模型是一种混合架构，结合了T5编码器-解码器结构和Gemma语言建模能力，并通过前缀语言建模进行增强。该模型擅长文本生成、摘要、翻译和问答任务，利用其双向编码和自回归解码能力。典型应用场景包括内容创作、多语言处理和结构化文本转换，在条件生成任务中表现出色，支持高效的序列到序列转换和上下文理解。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "The t5gemma-b-b-prefixlm model is a hybrid architecture combining T5 encoder-decoder structure with Gemma language modeling capabilities, enhanced by prefix language modeling. It excels at text generation, summarization, translation, and question answering through its bidirectional encoding and autoregressive decoding. Typical use cases include content creation, multilingual processing, and structured text transformation tasks, leveraging its strong performance in conditional generation scenarios.",
      "summary_zh": "t5gemma-b-b-prefixlm模型是一种混合架构，结合了T5编码器-解码器结构和Gemma语言建模能力，并通过前缀语言建模进行增强。该模型擅长文本生成、摘要、翻译和问答任务，利用其双向编码和自回归解码能力。典型应用场景包括内容创作、多语言处理和结构化文本转换，在条件生成任务中表现出色，支持高效的序列到序列转换和上下文理解。",
      "summary_es": "El modelo t5gemma-b-b-prefixlm es una arquitectura híbrida que combina la estructura codificador-decodificador de T5 con capacidades de modelado de lenguaje de Gemma, mejorada con modelado de lenguaje de prefijo. Destaca en generación de texto, resumen, traducción y respuesta a preguntas mediante su codificación bidireccional y decodificación autoregresiva. Los casos de uso típicos incluyen creación de contenido, procesamiento multilingüe y transformación de texto estructurado, aprovechando su fuerte rendimiento en escenarios de generación condicional."
    },
    {
      "id": "jinaai/jina-embeddings-v3",
      "source": "hf",
      "name": "jina-embeddings-v3",
      "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "af",
        "am",
        "ar",
        "arxiv:2409.10173",
        "as",
        "az",
        "be",
        "bg",
        "bn",
        "br",
        "bs",
        "ca",
        "cs",
        "custom_code",
        "cy",
        "da",
        "de",
        "el",
        "en",
        "eo",
        "es",
        "et",
        "eu",
        "fa",
        "feature-extraction",
        "fi",
        "fr",
        "fy",
        "ga",
        "gd",
        "gl",
        "gu",
        "ha",
        "he",
        "hi",
        "hr",
        "hu",
        "hy",
        "id",
        "is",
        "it",
        "ja",
        "jv",
        "ka",
        "kk",
        "km",
        "kn",
        "ko",
        "ku",
        "ky",
        "la",
        "license:cc-by-nc-4.0",
        "lo",
        "lt",
        "lv",
        "mg",
        "mk",
        "ml",
        "mn",
        "model-index",
        "mr",
        "ms",
        "mteb",
        "multilingual",
        "my",
        "ne",
        "nl",
        "no",
        "om",
        "onnx",
        "or",
        "pa",
        "pl",
        "ps",
        "pt",
        "pytorch",
        "region:eu",
        "ro",
        "ru",
        "sa",
        "safetensors",
        "sd",
        "sentence-similarity",
        "sentence-transformers",
        "si",
        "sk",
        "sl",
        "so",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "th",
        "tl",
        "tr",
        "transformers",
        "ug",
        "uk",
        "ur",
        "uz",
        "vi",
        "xh",
        "yi",
        "zh"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4325612,
        "likes_total": 1068
      },
      "score": 9185.224,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，支持192种语言和8192个令牌的上下文长度。它生成1024维向量，专为语义相似性任务优化。核心优势包括强大的跨语言检索能力、对称和非对称搜索功能，以及在MTEB等基准测试中的优异表现。典型应用场景涵盖多语言搜索引擎、内容推荐系统和跨语言文档聚类，能够有效处理不同语言的数据集并保持高精度。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "Jina Embeddings V3 is a multilingual text embedding model supporting 8192-token context length across 192 languages. It generates 1024-dimensional vectors optimized for semantic similarity tasks. Key strengths include robust cross-lingual retrieval, symmetric and asymmetric search capabilities, and strong performance on benchmarks like MTEB. Typical use cases include multilingual search engines, content recommendation systems, and document clustering across diverse linguistic datasets.",
      "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，支持192种语言和8192个令牌的上下文长度。它生成1024维向量，专为语义相似性任务优化。核心优势包括强大的跨语言检索能力、对称和非对称搜索功能，以及在MTEB等基准测试中的优异表现。典型应用场景涵盖多语言搜索引擎、内容推荐系统和跨语言文档聚类，能够有效处理不同语言的数据集并保持高精度。",
      "summary_es": "Jina Embeddings V3 es un modelo de incrustación de texto multilingüe que admite 192 idiomas con longitud de contexto de 8192 tokens. Genera vectores de 1024 dimensiones optimizados para tareas de similitud semántica. Sus fortanzas incluyen recuperación cross-lingüe robusta, capacidades de búsqueda simétrica y asimétrica, y alto rendimiento en benchmarks como MTEB. Casos de uso típicos incluyen motores de búsqueda multilingües, sistemas de recomendación de contenido y agrupación de documentos en diversos conjuntos de datos lingüísticos."
    },
    {
      "id": "trl-internal-testing/tiny-Qwen2ForCausalLM-2.5",
      "source": "hf",
      "name": "tiny-Qwen2ForCausalLM-2.5",
      "url": "https://huggingface.co/trl-internal-testing/tiny-Qwen2ForCausalLM-2.5",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "autotrain_compatible",
        "conversational",
        "endpoints_compatible",
        "qwen2",
        "region:us",
        "safetensors",
        "text-generation",
        "text-generation-inference",
        "transformers",
        "trl"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4322548,
        "likes_total": 1
      },
      "score": 8645.596,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "tiny-Qwen2ForCausalLM-2.5 是基于 Qwen2 架构的紧凑型因果语言模型，专为高效文本生成任务设计。核心能力包括对话式人工智能、文本补全和内容创作。优势在于模型体积小、推理速度快，且兼容 Transformers 和文本生成推理框架。典型应用场景包括原型开发、测试以及计算资源受限的轻量级应用，适用于快速迭代和部署验证。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "summary_en": "tiny-Qwen2ForCausalLM-2.5 is a compact causal language model based on Qwen2 architecture, designed for efficient text generation tasks. Its core capabilities include conversational AI, text completion, and content creation. Strengths include small size, fast inference, and compatibility with Transformers and text-generation-inference frameworks. Typical use cases include prototyping, testing, and lightweight applications where computational resources are limited.",
      "summary_zh": "tiny-Qwen2ForCausalLM-2.5 是基于 Qwen2 架构的紧凑型因果语言模型，专为高效文本生成任务设计。核心能力包括对话式人工智能、文本补全和内容创作。优势在于模型体积小、推理速度快，且兼容 Transformers 和文本生成推理框架。典型应用场景包括原型开发、测试以及计算资源受限的轻量级应用，适用于快速迭代和部署验证。",
      "summary_es": "tiny-Qwen2ForCausalLM-2.5 es un modelo de lenguaje causal compacto basado en la arquitectura Qwen2, diseñado para tareas eficientes de generación de texto. Sus capacidades principales incluyen IA conversacional, completación de texto y creación de contenido. Fortalezas: tamaño reducido, inferencia rápida y compatibilidad con frameworks como Transformers e inferencia de generación de texto. Casos de uso típicos: prototipado, pruebas y aplicaciones ligeras con recursos computacionales limitados."
    },
    {
      "id": "Comfy-Org/Wan_2.1_ComfyUI_repackaged",
      "source": "hf",
      "name": "Wan_2.1_ComfyUI_repackaged",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "comfyui",
        "diffusion-single-file",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4303330,
        "likes_total": 747
      },
      "score": 8980.16,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Wan_2.1_ComfyUI_repackaged 是针对 ComfyUI 重新封装的 Wan 2.1 AI 模型版本，专为基于节点的 Stable Diffusion 工作流程优化。它提供单文件扩散模型，用于从文本提示生成高质量图像。主要优势包括与 ComfyUI 模块化系统的轻松集成、高效性能以及多种自定义节点的兼容性。典型应用场景涉及结构化工作流环境中的 AI 艺术创作、概念可视化和实验性图像生成，适合需要精确控制生成过程的用户。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "text_to_image"
      ],
      "summary_en": "Wan_2.1_ComfyUI_repackaged is a repackaged version of the Wan 2.1 AI model optimized for ComfyUI, a node-based interface for Stable Diffusion workflows. It provides a single-file diffusion model for generating high-quality images from text prompts. Key strengths include ease of integration with ComfyUI's modular system, efficient performance, and compatibility with various custom nodes. Typical use cases involve AI art creation, concept visualization, and experimental image generation within structured workflow environments.",
      "summary_zh": "Wan_2.1_ComfyUI_repackaged 是针对 ComfyUI 重新封装的 Wan 2.1 AI 模型版本，专为基于节点的 Stable Diffusion 工作流程优化。它提供单文件扩散模型，用于从文本提示生成高质量图像。主要优势包括与 ComfyUI 模块化系统的轻松集成、高效性能以及多种自定义节点的兼容性。典型应用场景涉及结构化工作流环境中的 AI 艺术创作、概念可视化和实验性图像生成，适合需要精确控制生成过程的用户。",
      "summary_es": "Wan_2.1_ComfyUI_repackaged es una versión reempaquetada del modelo Wan 2.1 optimizada para ComfyUI, una interfaz basada en nodos para flujos de trabajo de Stable Diffusion. Proporciona un modelo de difusión en archivo único para generar imágenes de alta calidad a partir de prompts de texto. Sus principales fortalezas incluyen fácil integración con el sistema modular de ComfyUI, rendimiento eficiente y compatibilidad con varios nodos personalizados. Los casos de uso típicos involucran creación de arte con IA, visualización de conceptos y generación experimental de imágenes en entornos de flujo de trabajo estructurados."
    },
    {
      "id": "Salesforce/moirai-2.0-R-small",
      "source": "hf",
      "name": "moirai-2.0-R-small",
      "url": "https://huggingface.co/Salesforce/moirai-2.0-R-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "arxiv:2402.02592",
        "arxiv:2403.07815",
        "forecasting",
        "foundation models",
        "license:cc-by-nc-4.0",
        "pretrained models",
        "region:us",
        "safetensors",
        "time series",
        "time series foundation models",
        "time-series",
        "time-series-forecasting"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4272176,
        "likes_total": 20
      },
      "score": 8554.352,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Moirai-2.0-R-small是Salesforce开发的一款紧凑型时间序列基础模型，专门用于预测应用。该模型具备强大的泛化能力，能够处理未见过的数据集，支持多种频率和模式的时间序列预测。核心优势包括计算效率高、预测准确性好，适用于商业需求预测、金融市场分析和资源规划等典型场景。基于CC-BY-NC-4.0许可证发布，为研究和商业应用提供可靠的时间序列预测解决方案。",
      "updated_at": "2025-09-20T17:52:25.763Z",
      "task_keys": [
        "time_series_forecasting"
      ],
      "summary_en": "Moirai-2.0-R-small is a compact time series foundation model developed by Salesforce for forecasting applications. It provides core capabilities for predicting future values across diverse time series data with strong generalization to unseen datasets. The model excels in handling various frequencies and patterns while maintaining computational efficiency. Typical use cases include demand forecasting, financial prediction, and resource planning in business and research contexts under CC-BY-NC-4.0 license.",
      "summary_zh": "Moirai-2.0-R-small是Salesforce开发的一款紧凑型时间序列基础模型，专门用于预测应用。该模型具备强大的泛化能力，能够处理未见过的数据集，支持多种频率和模式的时间序列预测。核心优势包括计算效率高、预测准确性好，适用于商业需求预测、金融市场分析和资源规划等典型场景。基于CC-BY-NC-4.0许可证发布，为研究和商业应用提供可靠的时间序列预测解决方案。",
      "summary_es": "Moirai-2.0-R-small es un modelo fundacional de series temporales compacto desarrollado por Salesforce para aplicaciones de pronóstico. Ofrece capacidades centrales para predecir valores futuros en diversos datos de series temporales con fuerte generalización a conjuntos de datos no vistos. El modelo sobresale en manejar múltiples frecuencias y patrones manteniendo eficiencia computacional. Los casos de uso típicos incluyen pronóstico de demanda, predicción financiera y planificación de recursos en contextos comerciales y de investigación bajo licencia CC-BY-NC-4.0."
    }
  ]
}