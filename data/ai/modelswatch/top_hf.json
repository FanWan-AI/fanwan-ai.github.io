{
  "updated_at": "2025-09-18T19:21:45.029Z",
  "items": [
    {
      "id": "timm/mobilenetv3_small_100.lamb_in1k",
      "source": "hf",
      "name": "mobilenetv3_small_100.lamb_in1k",
      "url": "https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "timm",
        "pytorch",
        "safetensors",
        "image-classification",
        "transformers",
        "dataset:imagenet-1k",
        "arxiv:2110.00476",
        "arxiv:1905.02244",
        "license:apache-2.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 125993359,
        "hf_likes": 36
      },
      "score": 252004.718,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "MobileNetV3-Small 100 是一个轻量级卷积神经网络，专为移动和边缘设备上的高效图像分类任务设计。该模型基于 MobileNetV3 架构，通过引入 Squeeze-and-Excitation 模块和 h-swish 激活函数，在保持低计算量的同时显著提升性能。它在 ImageNet-1K 数据集上使用 LAMB 优化器进行训练，适用于资源受限环境中的实时视觉应用，如移动端图像识别或嵌入式设备中的目标检测。该模型在精度和效率之间取得了良好平衡，适合需要快速推理且计算资源有限的场景。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "MobileNetV3-Small is a lightweight convolutional neural network optimized for efficient image classification on mobile and embedded devices. It achieves strong performance on ImageNet-1K with minimal computational overhead, making it ideal for real-time applications like mobile photography, object detection, and edge AI. Its small size and speed suit resource-constrained environments, while maintaining competitive accuracy. This model is well-suited for developers needing fast, deployable vision models without heavy hardware requirements.",
      "summary_zh": "MobileNetV3-Small 100 是一个轻量级卷积神经网络，专为移动和边缘设备上的高效图像分类任务设计。该模型基于 MobileNetV3 架构，通过引入 Squeeze-and-Excitation 模块和 h-swish 激活函数，在保持低计算量的同时显著提升性能。它在 ImageNet-1K 数据集上使用 LAMB 优化器进行训练，适用于资源受限环境中的实时视觉应用，如移动端图像识别或嵌入式设备中的目标检测。该模型在精度和效率之间取得了良好平衡，适合需要快速推理且计算资源有限的场景。",
      "summary_es": "MobileNetV3-Small es un modelo de visión por computadora optimizado para dispositivos móviles. Destaca por su eficiencia computacional y bajo consumo de recursos, ideal para aplicaciones en tiempo real. Usa la función de activación h-swish y arquitectura de búsqueda neural para mejorar el rendimiento. Casos de uso incluyen clasificación de imágenes y detección de objetos en entornos con limitaciones de hardware."
    },
    {
      "id": "Falconsai/nsfw_image_detection",
      "source": "hf",
      "name": "nsfw_image_detection",
      "url": "https://huggingface.co/Falconsai/nsfw_image_detection",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "vit",
        "image-classification",
        "arxiv:2010.11929",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 96720026,
        "hf_likes": 819
      },
      "score": 193849.552,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "这是一个基于深度学习的NSFW（不适宜工作场所）图像检测模型，能够自动识别图片中的敏感内容。该模型使用大规模数据集训练，具备较高的准确率和泛化能力，适用于内容审核、社交媒体过滤等场景。其轻量级设计支持快速部署，可集成到各类应用中实现实时检测。适合开发者、平台运营者用于自动化内容管理，帮助维护网络环境的健康与安全。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "This model detects NSFW (Not Safe For Work) content in images, classifying them into categories such as explicit, suggestive, or safe. It is useful for content moderation on platforms like social media, forums, and image-sharing sites. The model is efficient and scalable, making it suitable for real-time filtering and automated content review. Its high download count reflects strong community adoption and reliability.",
      "summary_zh": "这是一个基于深度学习的NSFW（不适宜工作场所）图像检测模型，能够自动识别图片中的敏感内容。该模型使用大规模数据集训练，具备较高的准确率和泛化能力，适用于内容审核、社交媒体过滤等场景。其轻量级设计支持快速部署，可集成到各类应用中实现实时检测。适合开发者、平台运营者用于自动化内容管理，帮助维护网络环境的健康与安全。",
      "summary_es": "Modelo de detección de contenido NSFW en imágenes. Basado en redes neuronales convolucionales, identifica material explícito con alta precisión. Ideal para moderación automática en plataformas web, redes sociales y aplicaciones con contenido generado por usuarios. Proporciona clasificación binaria (seguro/no seguro) con bajos falsos positivos."
    },
    {
      "id": "sentence-transformers/all-MiniLM-L6-v2",
      "source": "hf",
      "name": "all-MiniLM-L6-v2",
      "url": "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "sentence-transformers",
        "pytorch",
        "tf",
        "rust",
        "onnx",
        "safetensors",
        "openvino",
        "bert",
        "feature-extraction",
        "sentence-similarity",
        "transformers",
        "en",
        "dataset:s2orc",
        "dataset:flax-sentence-embeddings/stackexchange_xml",
        "dataset:ms_marco",
        "dataset:gooaq",
        "dataset:yahoo_answers_topics",
        "dataset:code_search_net",
        "dataset:search_qa",
        "dataset:eli5",
        "dataset:snli",
        "dataset:multi_nli",
        "dataset:wikihow",
        "dataset:natural_questions",
        "dataset:trivia_qa",
        "dataset:embedding-data/sentence-compression",
        "dataset:embedding-data/flickr30k-captions",
        "dataset:embedding-data/altlex",
        "dataset:embedding-data/simple-wiki",
        "dataset:embedding-data/QQP",
        "dataset:embedding-data/SPECTER",
        "dataset:embedding-data/PAQ_pairs",
        "dataset:embedding-data/WikiAnswers",
        "arxiv:1904.06472",
        "arxiv:2102.07033",
        "arxiv:2104.08727",
        "arxiv:1704.05179",
        "arxiv:1810.09305",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-embeddings-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 89316324,
        "hf_likes": 3897
      },
      "score": 180581.14800000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "all-MiniLM-L6-v2 是一个轻量级通用句子嵌入模型，基于 MiniLM 架构，适用于语义相似度计算、文本检索和聚类任务。该模型在保持较高性能的同时显著减小了参数量，支持多语言文本处理，尤其适合资源受限环境或需要快速响应的应用场景。其紧凑的设计使其易于部署，可广泛应用于搜索引擎、推荐系统和文档匹配等任务。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "all-MiniLM-L6-v2 is a compact, high-performance sentence transformer model optimized for efficient text embedding. It excels in semantic similarity tasks, clustering, and retrieval applications, offering a balance between speed and accuracy. With strong performance on benchmarks and low resource requirements, it is well-suited for production environments and edge devices. Ideal for developers needing fast, reliable text representations without heavy computational overhead.",
      "summary_zh": "all-MiniLM-L6-v2 是一个轻量级通用句子嵌入模型，基于 MiniLM 架构，适用于语义相似度计算、文本检索和聚类任务。该模型在保持较高性能的同时显著减小了参数量，支持多语言文本处理，尤其适合资源受限环境或需要快速响应的应用场景。其紧凑的设计使其易于部署，可广泛应用于搜索引擎、推荐系统和文档匹配等任务。",
      "summary_es": "Modelo de embeddings de oraciones basado en MiniLM. Genera representaciones vectoriales de texto para búsqueda semántica, clustering y similitud. Ligero (22.7M parámetros) y rápido, ideal para aplicaciones con recursos limitados. Usado en sistemas de recomendación y análisis de texto."
    },
    {
      "id": "dima806/fairface_age_image_detection",
      "source": "hf",
      "name": "fairface_age_image_detection",
      "url": "https://huggingface.co/dima806/fairface_age_image_detection",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "vit",
        "image-classification",
        "dataset:nateraw/fairface",
        "base_model:google/vit-base-patch16-224-in21k",
        "base_model:finetune:google/vit-base-patch16-224-in21k",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 58539976,
        "hf_likes": 40
      },
      "score": 117099.952,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "这是一个基于FairFace数据集的年龄检测模型，能够从人脸图像中预测年龄范围。该模型使用ResNet架构进行训练，支持多年龄段分类，适用于年龄相关的图像分析任务。其亮点在于对多样化的面部特征具有良好的泛化能力，可用于内容推荐、用户画像分析或人口统计研究等场景。模型通过Hugging Face平台提供，支持快速部署和集成。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "This model detects age groups from facial images, trained on the FairFace dataset to enhance demographic fairness. It is useful for applications in market research, user analytics, and accessibility tools. Strengths include balanced performance across diverse age and ethnic groups, reducing bias in predictions. Suitable for developers and researchers requiring equitable age estimation in images.",
      "summary_zh": "这是一个基于FairFace数据集的年龄检测模型，能够从人脸图像中预测年龄范围。该模型使用ResNet架构进行训练，支持多年龄段分类，适用于年龄相关的图像分析任务。其亮点在于对多样化的面部特征具有良好的泛化能力，可用于内容推荐、用户画像分析或人口统计研究等场景。模型通过Hugging Face平台提供，支持快速部署和集成。",
      "summary_es": "Modelo de detección de edad en imágenes basado en FairFace. Identifica grupos etarios con precisión equilibrada entre distintos grupos demográficos. Ideal para análisis de datos anónimos, estudios de mercado y aplicaciones de segmentación por edad. Destaca por su enfoque ético y reducción de sesgos algorítmicos."
    },
    {
      "id": "google-bert/bert-base-uncased",
      "source": "hf",
      "name": "bert-base-uncased",
      "url": "https://huggingface.co/google-bert/bert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "coreml",
        "onnx",
        "safetensors",
        "bert",
        "fill-mask",
        "exbert",
        "en",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "arxiv:1810.04805",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 56363783,
        "hf_likes": 2410
      },
      "score": 113932.566,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BERT-base-uncased 是由 Google 开发的自然语言处理预训练模型，采用双向 Transformer 结构，适用于多种文本理解任务。该模型在英文文本上训练，不区分大小写，能够有效捕捉上下文语义信息。其亮点包括强大的迁移学习能力，可用于文本分类、命名实体识别、问答系统等下游任务。适用于需要高效文本理解和语义建模的场景，如搜索引擎、智能客服和文档分析。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "BERT-base-uncased is a widely used pre-trained language model by Google, designed for general-purpose natural language understanding tasks. It excels in text classification, named entity recognition, and question answering, leveraging bidirectional context for robust performance. Its uncased nature ensures case-insensitive processing, making it suitable for diverse text inputs. With high download rates and community adoption, it remains a foundational tool in NLP research and applications.",
      "summary_zh": "BERT-base-uncased 是由 Google 开发的自然语言处理预训练模型，采用双向 Transformer 结构，适用于多种文本理解任务。该模型在英文文本上训练，不区分大小写，能够有效捕捉上下文语义信息。其亮点包括强大的迁移学习能力，可用于文本分类、命名实体识别、问答系统等下游任务。适用于需要高效文本理解和语义建模的场景，如搜索引擎、智能客服和文档分析。",
      "summary_es": "BERT base uncased es un modelo de lenguaje preentrenado para procesamiento de lenguaje natural. Destaca en tareas como clasificación de texto, análisis de sentimientos y respuesta a preguntas. Su arquitectura bidireccional captura contexto en ambas direcciones, mejorando la comprensión semántica. Ampliamente utilizado en investigación y aplicaciones empresariales."
    },
    {
      "id": "tech4humans/yolov8s-signature-detector",
      "source": "hf",
      "name": "yolov8s-signature-detector",
      "url": "https://huggingface.co/tech4humans/yolov8s-signature-detector",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "ultralytics",
        "tensorboard",
        "onnx",
        "object-detection",
        "signature-detection",
        "yolo",
        "yolov8",
        "pytorch",
        "dataset:tech4humans/signature-detection",
        "base_model:Ultralytics/YOLOv8",
        "base_model:quantized:Ultralytics/YOLOv8",
        "license:agpl-3.0",
        "model-index",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 41388330,
        "hf_likes": 38
      },
      "score": 82795.66,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "yolov8s-signature-detector 是基于 YOLOv8s 架构优化的签名检测模型，专门用于在文档图像中定位和识别手写或印刷签名区域。该模型在保持轻量化的同时，通过预训练权重实现了较高的检测精度与推理速度平衡，支持多种文档格式的实时处理。适用于合同管理、身份验证、自动化文档处理等场景，能够有效提升签名区域提取的准确性和效率。开发者可通过 Hugging Face 平台快速集成到现有工作流中。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "A YOLOv8-based model fine-tuned for signature detection in documents. It excels at locating and identifying handwritten or digital signatures within images, making it suitable for automating document processing, verification, and archival tasks. Its lightweight design ensures efficient performance on standard hardware. Ideal for applications in legal, financial, and administrative workflows requiring signature extraction.",
      "summary_zh": "yolov8s-signature-detector 是基于 YOLOv8s 架构优化的签名检测模型，专门用于在文档图像中定位和识别手写或印刷签名区域。该模型在保持轻量化的同时，通过预训练权重实现了较高的检测精度与推理速度平衡，支持多种文档格式的实时处理。适用于合同管理、身份验证、自动化文档处理等场景，能够有效提升签名区域提取的准确性和效率。开发者可通过 Hugging Face 平台快速集成到现有工作流中。",
      "summary_es": "Detector de firmas basado en YOLOv8s. Identifica y localiza firmas en documentos con alta precisión. Optimizado para procesamiento rápido en CPU/GPU. Ideal para digitalización, verificación y automatización de documentos."
    },
    {
      "id": "pyannote/segmentation-3.0",
      "source": "hf",
      "name": "segmentation-3.0",
      "url": "https://huggingface.co/pyannote/segmentation-3.0",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "pyannote-audio",
        "pytorch",
        "pyannote",
        "pyannote-audio-model",
        "audio",
        "voice",
        "speech",
        "speaker",
        "speaker-diarization",
        "speaker-change-detection",
        "speaker-segmentation",
        "voice-activity-detection",
        "overlapped-speech-detection",
        "resegmentation",
        "license:mit",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 19002431,
        "hf_likes": 587
      },
      "score": 38298.362,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "segmentation-3.0 是一个基于深度学习的音频分割模型，专注于语音活动检测和说话人分割任务。该模型能够准确识别音频中的语音片段，并区分不同说话人的边界，适用于会议记录、语音转写和音频预处理等场景。其核心优势在于高精度的分割性能和良好的泛化能力，支持多种语言和音频环境。该模型适用于需要自动化音频分析的场景，如电话客服质检、播客剪辑和语音识别预处理等。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "segmentation-3.0 is a PyAnnote model for speaker diarization and segmentation tasks. It excels at partitioning audio streams into homogeneous segments and identifying speaker turns. The model is well-suited for applications in transcription, meeting analysis, and media indexing. Its high download count reflects strong community adoption and reliability in production environments.",
      "summary_zh": "segmentation-3.0 是一个基于深度学习的音频分割模型，专注于语音活动检测和说话人分割任务。该模型能够准确识别音频中的语音片段，并区分不同说话人的边界，适用于会议记录、语音转写和音频预处理等场景。其核心优势在于高精度的分割性能和良好的泛化能力，支持多种语言和音频环境。该模型适用于需要自动化音频分析的场景，如电话客服质检、播客剪辑和语音识别预处理等。",
      "summary_es": "Modelo de segmentación de audio para detectar habla, música y ruido. Basado en PyTorch, ofrece alta precisión en la identificación de segmentos sonoros. Ideal para transcripción automática, análisis de contenido multimedia y aplicaciones de procesamiento de señales."
    },
    {
      "id": "pyannote/wespeaker-voxceleb-resnet34-LM",
      "source": "hf",
      "name": "wespeaker-voxceleb-resnet34-LM",
      "url": "https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "pyannote-audio",
        "pytorch",
        "pyannote",
        "pyannote-audio-model",
        "wespeaker",
        "audio",
        "voice",
        "speech",
        "speaker",
        "speaker-recognition",
        "speaker-verification",
        "speaker-identification",
        "speaker-embedding",
        "dataset:voxceleb",
        "license:cc-by-4.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 18764924,
        "hf_likes": 73
      },
      "score": 37566.348,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "这是一个基于ResNet-34架构的说话人识别模型，使用VoxCeleb数据集训练，并融合了语言模型（LM）进行优化。该模型能够从音频中提取说话人的声纹特征，实现高精度的说话人验证和识别。其亮点在于结合了深度残差网络和语言模型，提升了跨场景的泛化能力和识别鲁棒性。适用于语音身份验证、智能客服、会议记录等需要区分不同说话人的场景。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "wespeaker-voxceleb-resnet34-LM is a speaker recognition model trained on the VoxCeleb dataset. It uses a ResNet-34 architecture with language modeling to enhance performance. The model excels in identifying and verifying speakers from audio clips, making it suitable for applications like authentication, forensic analysis, and meeting transcription. Its high download count reflects strong community adoption and reliability for real-world use.",
      "summary_zh": "这是一个基于ResNet-34架构的说话人识别模型，使用VoxCeleb数据集训练，并融合了语言模型（LM）进行优化。该模型能够从音频中提取说话人的声纹特征，实现高精度的说话人验证和识别。其亮点在于结合了深度残差网络和语言模型，提升了跨场景的泛化能力和识别鲁棒性。适用于语音身份验证、智能客服、会议记录等需要区分不同说话人的场景。",
      "summary_es": "Modelo de reconocimiento de voz que identifica hablantes mediante embeddings. Basado en ResNet-34, entrenado con VoxCeleb y mejorado con LM. Ideal para verificación de identidad, diarización y aplicaciones de seguridad. Alta precisión en entornos realistas."
    },
    {
      "id": "sentence-transformers/all-mpnet-base-v2",
      "source": "hf",
      "name": "all-mpnet-base-v2",
      "url": "https://huggingface.co/sentence-transformers/all-mpnet-base-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "sentence-transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "openvino",
        "mpnet",
        "fill-mask",
        "feature-extraction",
        "sentence-similarity",
        "transformers",
        "text-embeddings-inference",
        "en",
        "dataset:s2orc",
        "dataset:flax-sentence-embeddings/stackexchange_xml",
        "dataset:ms_marco",
        "dataset:gooaq",
        "dataset:yahoo_answers_topics",
        "dataset:code_search_net",
        "dataset:search_qa",
        "dataset:eli5",
        "dataset:snli",
        "dataset:multi_nli",
        "dataset:wikihow",
        "dataset:natural_questions",
        "dataset:trivia_qa",
        "dataset:embedding-data/sentence-compression",
        "dataset:embedding-data/flickr30k-captions",
        "dataset:embedding-data/altlex",
        "dataset:embedding-data/simple-wiki",
        "dataset:embedding-data/QQP",
        "dataset:embedding-data/SPECTER",
        "dataset:embedding-data/PAQ_pairs",
        "dataset:embedding-data/WikiAnswers",
        "arxiv:1904.06472",
        "arxiv:2102.07033",
        "arxiv:2104.08727",
        "arxiv:1704.05179",
        "arxiv:1810.09305",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 16839426,
        "hf_likes": 1154
      },
      "score": 34255.852,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "all-mpnet-base-v2 是一个基于 MPNet 架构的通用文本嵌入模型，由 Sentence Transformers 提供。该模型能够将任意长度的文本转换为高维向量表示，适用于语义相似度计算、信息检索和文本聚类等任务。其亮点在于结合了 BERT 的掩码语言建模和 Transformer 的自回归特性，在多项自然语言处理基准测试中表现优异。该模型适用于需要高效且准确的语义理解场景，如搜索引擎、推荐系统和问答系统。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "all-mpnet-base-v2 is a high-performance sentence embedding model based on MPNet, fine-tuned for semantic similarity tasks. It excels in generating dense vector representations for sentences, enabling efficient semantic search, clustering, and retrieval applications. With strong performance on benchmarks and broad compatibility, it is widely used in NLP pipelines for tasks like document matching and recommendation systems. Its balance of speed and accuracy makes it suitable for both research and production environments.",
      "summary_zh": "all-mpnet-base-v2 是一个基于 MPNet 架构的通用文本嵌入模型，由 Sentence Transformers 提供。该模型能够将任意长度的文本转换为高维向量表示，适用于语义相似度计算、信息检索和文本聚类等任务。其亮点在于结合了 BERT 的掩码语言建模和 Transformer 的自回归特性，在多项自然语言处理基准测试中表现优异。该模型适用于需要高效且准确的语义理解场景，如搜索引擎、推荐系统和问答系统。",
      "summary_es": "Modelo de embeddings de texto basado en MPNet. Genera representaciones vectoriales densas para oraciones o párrafos. Destaca por su alto rendimiento en tareas de similitud semántica, búsqueda y clustering. Ideal para aplicaciones de NLP como sistemas de recomendación o búsqueda semántica."
    },
    {
      "id": "pyannote/speaker-diarization-3.1",
      "source": "hf",
      "name": "speaker-diarization-3.1",
      "url": "https://huggingface.co/pyannote/speaker-diarization-3.1",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "pyannote-audio",
        "pyannote",
        "pyannote-audio-pipeline",
        "audio",
        "voice",
        "speech",
        "speaker",
        "speaker-diarization",
        "speaker-change-detection",
        "voice-activity-detection",
        "overlapped-speech-detection",
        "automatic-speech-recognition",
        "arxiv:2111.14448",
        "arxiv:2012.01477",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 16787698,
        "hf_likes": 1132
      },
      "score": 34141.396,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Speaker-diarization-3.1 是一个基于深度学习的说话人日志分析模型，用于自动识别和分割音频中的不同说话人。该模型采用端到端的架构，能够高效处理长音频并准确标注每个说话人的时间区间。其核心亮点在于结合了语音活动检测和说话人嵌入技术，显著提升了多说话人场景下的分割精度。适用于会议记录、播客分析、客服质检等需要区分说话人的场景，为音频内容的结构化处理提供了可靠工具。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Speaker-diarization-3.1 is a PyAnnote model for speaker diarization, identifying and segmenting speakers in audio. It excels in transcribing meetings, interviews, and calls by distinguishing multiple speakers. Its strengths include high accuracy and efficiency in real-time or batch processing. Suitable for applications in transcription services, media analysis, and automated note-taking.",
      "summary_zh": "Speaker-diarization-3.1 是一个基于深度学习的说话人日志分析模型，用于自动识别和分割音频中的不同说话人。该模型采用端到端的架构，能够高效处理长音频并准确标注每个说话人的时间区间。其核心亮点在于结合了语音活动检测和说话人嵌入技术，显著提升了多说话人场景下的分割精度。适用于会议记录、播客分析、客服质检等需要区分说话人的场景，为音频内容的结构化处理提供了可靠工具。",
      "summary_es": "Speaker-diarization-3.1 es un modelo de diarización de hablantes que identifica y segmenta quién habla cuándo en grabaciones de audio. Utiliza embeddings de voz y clustering para separar hablantes automáticamente. Es ideal para transcripciones, análisis de reuniones y procesamiento de podcasts. Destaca por su precisión en escenarios con múltiples interlocutores."
    },
    {
      "id": "Bingsu/adetailer",
      "source": "hf",
      "name": "adetailer",
      "url": "https://huggingface.co/Bingsu/adetailer",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "ultralytics",
        "pytorch",
        "dataset:wider_face",
        "dataset:skytnt/anime-segmentation",
        "doi:10.57967/hf/3633",
        "license:apache-2.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 15492918,
        "hf_likes": 614
      },
      "score": 31292.836,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "adetailer是一款基于深度学习的自动面部修复与增强工具，适用于图像生成和编辑场景。它能够自动检测并修复图像中的人脸细节，包括五官、皮肤纹理和表情，显著提升生成图像的质量。该工具支持多种模型，适用于Stable Diffusion等主流AI绘画平台，帮助用户快速优化生成结果。适合需要高质量人像生成的创作者和技术开发者使用。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "ADetailer is an open-source automatic face and hand detection and inpainting model for Stable Diffusion. It enhances generated images by detecting and refining poorly rendered faces and hands, improving overall visual quality. The tool is particularly useful for AI art generation, character design, and image post-processing workflows. Its high download count reflects strong community adoption and practical utility.",
      "summary_zh": "adetailer是一款基于深度学习的自动面部修复与增强工具，适用于图像生成和编辑场景。它能够自动检测并修复图像中的人脸细节，包括五官、皮肤纹理和表情，显著提升生成图像的质量。该工具支持多种模型，适用于Stable Diffusion等主流AI绘画平台，帮助用户快速优化生成结果。适合需要高质量人像生成的创作者和技术开发者使用。",
      "summary_es": "Adetailer es un modelo de detección y mejora automática de rostros en imágenes generadas por IA. Detecta y repara automáticamente caras borrosas o defectuosas, mejorando la calidad visual. Es ideal para usuarios de Stable Diffusion que buscan resultados más refinados en retratos y figuras humanas. Su integración sencilla y eficacia lo hacen muy popular."
    },
    {
      "id": "openai/clip-vit-base-patch32",
      "source": "hf",
      "name": "clip-vit-base-patch32",
      "url": "https://huggingface.co/openai/clip-vit-base-patch32",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "clip",
        "zero-shot-image-classification",
        "vision",
        "arxiv:2103.00020",
        "arxiv:1908.04913",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 15296458,
        "hf_likes": 765
      },
      "score": 30975.416,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "CLIP-ViT-Base-Patch32 是一个由 OpenAI 开发的多模态视觉-语言模型，基于 Vision Transformer（ViT）架构构建。该模型能够同时理解图像和文本，通过对比学习实现跨模态语义匹配。其核心亮点在于无需特定任务微调即可泛化到多种视觉-语言任务，例如零样本图像分类、图像检索和图文匹配。适用于内容审核、搜索引擎增强、自动化标注等场景，尤其适合需要快速部署多模态理解能力的应用。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "CLIP-ViT-Base-Patch32 is a vision-language model that aligns images and text in a shared embedding space. It excels at zero-shot image classification, cross-modal retrieval, and image captioning tasks. The model is robust across diverse domains, making it suitable for applications in content moderation, visual search, and multimodal AI systems. Its strong performance and versatility stem from training on a large dataset of image-text pairs.",
      "summary_zh": "CLIP-ViT-Base-Patch32 是一个由 OpenAI 开发的多模态视觉-语言模型，基于 Vision Transformer（ViT）架构构建。该模型能够同时理解图像和文本，通过对比学习实现跨模态语义匹配。其核心亮点在于无需特定任务微调即可泛化到多种视觉-语言任务，例如零样本图像分类、图像检索和图文匹配。适用于内容审核、搜索引擎增强、自动化标注等场景，尤其适合需要快速部署多模态理解能力的应用。",
      "summary_es": "CLIP-ViT-Base-Patch32 es un modelo multimodal de OpenAI que combina visión y lenguaje. Utiliza una arquitectura Vision Transformer con parches de 32x32 píxeles. Es ideal para tareas como búsqueda de imágenes, clasificación zero-shot y generación de descripciones. Su principal fortaleza es la capacidad de entender y relacionar imágenes con texto de forma flexible."
    },
    {
      "id": "openai-community/gpt2",
      "source": "hf",
      "name": "gpt2",
      "url": "https://huggingface.co/openai-community/gpt2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "tflite",
        "rust",
        "onnx",
        "safetensors",
        "gpt2",
        "text-generation",
        "exbert",
        "en",
        "doi:10.57967/hf/0039",
        "license:mit",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 12286402,
        "hf_likes": 2948
      },
      "score": 26046.804,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "GPT-2是OpenAI开发的开源语言生成模型，基于Transformer架构，能够生成连贯且上下文相关的文本。该模型在多项自然语言处理任务中表现优异，包括文本补全、对话生成和摘要撰写。其亮点在于无需特定任务微调即可实现零样本学习，适用于内容创作、代码辅助和语言理解研究。GPT-2特别适合开发者和研究人员用于实验和原型开发。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "GPT-2 is a transformer-based language model by OpenAI, widely used for text generation, summarization, and translation. Its strengths include strong performance in few-shot learning and coherent output generation. It is applicable in chatbots, content creation, and research, offering a balance of quality and accessibility for developers and researchers.",
      "summary_zh": "GPT-2是OpenAI开发的开源语言生成模型，基于Transformer架构，能够生成连贯且上下文相关的文本。该模型在多项自然语言处理任务中表现优异，包括文本补全、对话生成和摘要撰写。其亮点在于无需特定任务微调即可实现零样本学习，适用于内容创作、代码辅助和语言理解研究。GPT-2特别适合开发者和研究人员用于实验和原型开发。",
      "summary_es": "GPT-2 es un modelo de lenguaje generativo de código abierto desarrollado por OpenAI. Destaca por su capacidad para generar texto coherente y contextualmente relevante. Es ampliamente utilizado en tareas como generación de texto, completado de frases y chatbots. Su arquitectura de transformer y disponibilidad pública lo hacen ideal para investigación y aplicaciones prácticas."
    },
    {
      "id": "distilbert/distilbert-base-uncased",
      "source": "hf",
      "name": "distilbert-base-uncased",
      "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "safetensors",
        "distilbert",
        "fill-mask",
        "exbert",
        "en",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "arxiv:1910.01108",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 12201728,
        "hf_likes": 755
      },
      "score": 24780.956000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "DistilBERT-base-uncased 是一个轻量化的 BERT 模型，通过知识蒸馏技术将 BERT 参数量减少 40%，同时保持 97% 的语言理解能力。它适用于文本分类、情感分析、命名实体识别等自然语言处理任务。该模型在保证较高性能的同时显著提升了推理速度，适合计算资源受限或对延迟敏感的应用场景。作为 Hugging Face 生态中备受欢迎的模型之一，它被广泛用于学术研究及工业部署。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "DistilBERT is a smaller, faster version of BERT, designed for efficient natural language understanding tasks. It retains 97% of BERT's performance while being 40% smaller and 60% faster. Ideal for applications like text classification, sentiment analysis, and question answering where computational resources are limited. Well-suited for production environments requiring real-time inference or deployment on edge devices.",
      "summary_zh": "DistilBERT-base-uncased 是一个轻量化的 BERT 模型，通过知识蒸馏技术将 BERT 参数量减少 40%，同时保持 97% 的语言理解能力。它适用于文本分类、情感分析、命名实体识别等自然语言处理任务。该模型在保证较高性能的同时显著提升了推理速度，适合计算资源受限或对延迟敏感的应用场景。作为 Hugging Face 生态中备受欢迎的模型之一，它被广泛用于学术研究及工业部署。",
      "summary_es": "DistilBERT es un modelo de lenguaje BERT optimizado, con 40% menos parámetros pero 60% más rápido. Ideal para clasificación de texto, análisis de sentimientos y NER. Perfecto para aplicaciones con recursos limitados."
    },
    {
      "id": "FacebookAI/roberta-large",
      "source": "hf",
      "name": "roberta-large",
      "url": "https://huggingface.co/FacebookAI/roberta-large",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "onnx",
        "safetensors",
        "roberta",
        "fill-mask",
        "exbert",
        "en",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "arxiv:1907.11692",
        "arxiv:1806.02847",
        "license:mit",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 12171005,
        "hf_likes": 245
      },
      "score": 24464.510000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "RoBERTa-large是基于BERT架构优化的预训练语言模型，由Facebook AI开发。它在多个自然语言处理任务上表现优异，包括文本分类、命名实体识别和情感分析。模型通过移除下一句预测任务并采用更大规模数据训练，显著提升了语义理解能力。适用于需要高精度文本理解的研究或工业场景，如智能问答和文档分析。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "RoBERTa-large is a robust transformer-based language model optimized for masked language modeling. It excels in a wide range of natural language understanding tasks, including text classification, named entity recognition, and sentiment analysis. Its key strengths lie in its large-scale pretraining and fine-tuning capabilities, making it highly effective for both research and production use. The model is particularly well-suited for applications requiring deep contextual understanding and high accuracy.",
      "summary_zh": "RoBERTa-large是基于BERT架构优化的预训练语言模型，由Facebook AI开发。它在多个自然语言处理任务上表现优异，包括文本分类、命名实体识别和情感分析。模型通过移除下一句预测任务并采用更大规模数据训练，显著提升了语义理解能力。适用于需要高精度文本理解的研究或工业场景，如智能问答和文档分析。",
      "summary_es": "RoBERTa-large es un modelo de lenguaje basado en Transformers, optimizado para tareas de procesamiento de lenguaje natural. Destaca por su alto rendimiento en clasificación de texto, análisis de sentimientos y comprensión lectora. Es ampliamente utilizado en investigación y aplicaciones empresariales que requieren precisión y escalabilidad."
    },
    {
      "id": "amazon/chronos-t5-small",
      "source": "hf",
      "name": "chronos-t5-small",
      "url": "https://huggingface.co/amazon/chronos-t5-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "t5",
        "text2text-generation",
        "time series",
        "forecasting",
        "pretrained models",
        "foundation models",
        "time series foundation models",
        "time-series",
        "time-series-forecasting",
        "arxiv:2403.07815",
        "arxiv:1910.10683",
        "license:apache-2.0",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 11891514,
        "hf_likes": 131
      },
      "score": 23848.528000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Chronos-T5-small是亚马逊推出的轻量级时间序列预测模型，基于T5架构进行预训练。该模型专为单变量时间序列数据设计，能够直接生成未来数值预测，无需复杂的特征工程。其核心亮点在于通过大规模合成时间序列数据进行预训练，具备优秀的零样本和少样本泛化能力。适用于金融、零售、物联网等领域的快速时间序列分析任务，尤其适合资源受限或需要快速原型验证的场景。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Chronos-T5-small is a compact time series forecasting model from Amazon, based on the T5 architecture. It excels at predicting future values from historical data across domains like finance, energy, and retail. Its strengths include efficient training, strong zero-shot performance, and ease of fine-tuning for specific datasets. This model is well-suited for applications requiring lightweight, accurate, and adaptable forecasting.",
      "summary_zh": "Chronos-T5-small是亚马逊推出的轻量级时间序列预测模型，基于T5架构进行预训练。该模型专为单变量时间序列数据设计，能够直接生成未来数值预测，无需复杂的特征工程。其核心亮点在于通过大规模合成时间序列数据进行预训练，具备优秀的零样本和少样本泛化能力。适用于金融、零售、物联网等领域的快速时间序列分析任务，尤其适合资源受限或需要快速原型验证的场景。",
      "summary_es": "Chronos-T5-small es un modelo de series temporales de código abierto desarrollado por Amazon. Basado en T5, está diseñado para predecir datos secuenciales con alta precisión. Sus puntos fuertes incluyen escalabilidad y eficiencia computacional. Es ideal para aplicaciones en finanzas, logística y análisis de datos en tiempo real."
    },
    {
      "id": "google/electra-base-discriminator",
      "source": "hf",
      "name": "electra-base-discriminator",
      "url": "https://huggingface.co/google/electra-base-discriminator",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "electra",
        "pretraining",
        "en",
        "arxiv:1406.2661",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 11457730,
        "hf_likes": 64
      },
      "score": 22947.46,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ELECTRA-base-discriminator是由Google开发的一种基于Transformer的预训练语言模型，采用判别式预训练方法。与传统的生成式预训练不同，该模型通过区分真实输入与替换后的输入进行训练，显著提升了训练效率。它在多项自然语言处理任务中表现优异，适用于文本分类、命名实体识别和情感分析等场景。该模型在Hugging Face平台上的高下载量反映了其广泛的应用和良好的实用性。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "ELECTRA-base-discriminator is a pre-trained transformer model designed for natural language understanding tasks. It excels in identifying whether input tokens are original or replaced, making it effective for tasks like text classification, token classification, and sentence-pair analysis. Its efficiency and strong performance on benchmarks like GLUE make it suitable for research and production applications. The model is widely used for fine-tuning on domain-specific datasets.",
      "summary_zh": "ELECTRA-base-discriminator是由Google开发的一种基于Transformer的预训练语言模型，采用判别式预训练方法。与传统的生成式预训练不同，该模型通过区分真实输入与替换后的输入进行训练，显著提升了训练效率。它在多项自然语言处理任务中表现优异，适用于文本分类、命名实体识别和情感分析等场景。该模型在Hugging Face平台上的高下载量反映了其广泛的应用和良好的实用性。",
      "summary_es": "ELECTRA-base-discriminator es un modelo de lenguaje preentrenado que detecta tokens reemplazados en texto. Su arquitectura eficiente permite un entrenamiento más rápido que otros modelos similares. Ideal para tareas de detección de errores, corrección gramatical y filtrado de contenido. Ampliamente utilizado en procesamiento de lenguaje natural y aplicaciones de análisis textual."
    },
    {
      "id": "FacebookAI/roberta-base",
      "source": "hf",
      "name": "roberta-base",
      "url": "https://huggingface.co/FacebookAI/roberta-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "safetensors",
        "roberta",
        "fill-mask",
        "exbert",
        "en",
        "dataset:bookcorpus",
        "dataset:wikipedia",
        "arxiv:1907.11692",
        "arxiv:1806.02847",
        "license:mit",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 11306955,
        "hf_likes": 525
      },
      "score": 22876.41,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "RoBERTa-base 是基于 BERT 架构优化的预训练语言模型，由 Facebook AI 开发。它在 BERT 的基础上移除了下一句预测任务，并采用更大规模数据和更长的训练时间，显著提升了模型性能。该模型适用于多种自然语言处理任务，如文本分类、命名实体识别和情感分析。其通用性强，适合作为各类下游任务的基准模型或特征提取器。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "RoBERTa-base is a robust, general-purpose language model optimized for masked language modeling. It excels in text classification, sentiment analysis, and question answering, offering strong performance across diverse NLP tasks. Its architecture builds on BERT with improved pretraining techniques, making it widely applicable for research and production use. The model is open-source and supports fine-tuning for domain-specific applications.",
      "summary_zh": "RoBERTa-base 是基于 BERT 架构优化的预训练语言模型，由 Facebook AI 开发。它在 BERT 的基础上移除了下一句预测任务，并采用更大规模数据和更长的训练时间，显著提升了模型性能。该模型适用于多种自然语言处理任务，如文本分类、命名实体识别和情感分析。其通用性强，适合作为各类下游任务的基准模型或特征提取器。",
      "summary_es": "RoBERTa-base es un modelo de lenguaje basado en BERT, optimizado para tareas de procesamiento de lenguaje natural. Destaca por su entrenamiento robusto sin tareas de predicción de oraciones, mejorando el rendimiento en clasificación de texto, análisis de sentimientos y respuesta a preguntas. Es ampliamente utilizado en investigación y aplicaciones empresariales para NLP."
    },
    {
      "id": "context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16",
      "source": "hf",
      "name": "meta-llama-Llama-3.2-3B-Instruct-FP16",
      "url": "https://huggingface.co/context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "facebook",
        "meta",
        "pytorch",
        "llama-3",
        "conversational",
        "en",
        "de",
        "fr",
        "it",
        "pt",
        "hi",
        "es",
        "th",
        "arxiv:2204.05149",
        "arxiv:2405.16406",
        "license:llama3.2",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 10703152,
        "hf_likes": 6
      },
      "score": 21409.304,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "这是一个基于Meta Llama 3.2架构的指令微调模型，采用FP16精度优化，参数量为30亿。该模型专为对话和指令跟随任务设计，适用于聊天机器人、内容生成和代码辅助等场景。其轻量化设计使其能够在消费级硬件上高效运行，同时保持较强的语言理解和生成能力。该模型适合开发者和研究者用于构建本地化AI应用或进行轻量级NLP实验。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Meta's Llama-3.2-3B-Instruct-FP16 is a 3-billion parameter instruction-tuned language model optimized for efficient inference. It excels in tasks like text generation, summarization, and question answering, with strong performance in reasoning and coding. Its FP16 precision balances speed and accuracy, making it suitable for deployment on consumer-grade hardware. Ideal for developers and researchers seeking a lightweight yet capable model for prototyping and production applications.",
      "summary_zh": "这是一个基于Meta Llama 3.2架构的指令微调模型，采用FP16精度优化，参数量为30亿。该模型专为对话和指令跟随任务设计，适用于聊天机器人、内容生成和代码辅助等场景。其轻量化设计使其能够在消费级硬件上高效运行，同时保持较强的语言理解和生成能力。该模型适合开发者和研究者用于构建本地化AI应用或进行轻量级NLP实验。",
      "summary_es": "Modelo de lenguaje de 3B parámetros optimizado para instrucciones en FP16. Destaca por su eficiencia computacional y capacidad de respuesta precisa en tareas conversacionales. Ideal para aplicaciones de asistencia virtual, generación de contenido y procesamiento de lenguaje natural en entornos con recursos limitados."
    },
    {
      "id": "facebook/opt-125m",
      "source": "hf",
      "name": "opt-125m",
      "url": "https://huggingface.co/facebook/opt-125m",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "opt",
        "text-generation",
        "en",
        "arxiv:2205.01068",
        "arxiv:2005.14165",
        "license:other",
        "autotrain_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 10628010,
        "hf_likes": 215
      },
      "score": 21363.52,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "OPT-125M是Meta开源的1.25亿参数语言模型，属于OPT系列的基础版本。该模型采用Transformer架构，支持文本生成、问答和摘要等自然语言处理任务。其轻量化设计适合资源受限的环境，可用于学术研究和小规模实验。模型在通用语料上预训练，支持多种下游任务的微调，适合初学者和研究者探索语言模型的基本能力。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "OPT-125M is a 125 million parameter decoder-only transformer model from Meta AI, designed for text generation and understanding tasks. It is suitable for applications like summarization, translation, and dialogue systems, offering a balance of performance and efficiency for constrained computational environments. Its open-source nature supports research and development in natural language processing.",
      "summary_zh": "OPT-125M是Meta开源的1.25亿参数语言模型，属于OPT系列的基础版本。该模型采用Transformer架构，支持文本生成、问答和摘要等自然语言处理任务。其轻量化设计适合资源受限的环境，可用于学术研究和小规模实验。模型在通用语料上预训练，支持多种下游任务的微调，适合初学者和研究者探索语言模型的基本能力。",
      "summary_es": "OPT-125M es un modelo de lenguaje pequeño de Meta con 125 millones de parámetros. Diseñado para investigación y experimentación, es eficiente en tareas básicas de procesamiento de lenguaje natural. Ideal para pruebas de concepto, educación y aplicaciones con recursos limitados. Su código abierto fomenta la transparencia y la innovación en IA."
    },
    {
      "id": "prajjwal1/bert-tiny",
      "source": "hf",
      "name": "bert-tiny",
      "url": "https://huggingface.co/prajjwal1/bert-tiny",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "BERT",
        "MNLI",
        "NLI",
        "transformer",
        "pre-training",
        "en",
        "arxiv:1908.08962",
        "arxiv:2110.01518",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 10154678,
        "hf_likes": 127
      },
      "score": 20372.856,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bert-tiny是一个轻量级的BERT模型变体，适用于资源受限环境下的自然语言处理任务。该模型在保持BERT核心架构的基础上大幅减少了参数量，显著降低了计算和存储需求。其亮点在于高效推理和快速部署，特别适合移动设备或边缘计算场景。适用于文本分类、情感分析等基础NLP应用，是平衡性能与效率的实用选择。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "BERT-Tiny is a highly compressed version of BERT, designed for resource-constrained environments. It is ideal for lightweight NLP tasks such as text classification, sentiment analysis, and named entity recognition. Despite its small size, it maintains reasonable performance while enabling faster inference and lower memory usage. This makes it suitable for deployment on edge devices or in applications with strict computational limits.",
      "summary_zh": "bert-tiny是一个轻量级的BERT模型变体，适用于资源受限环境下的自然语言处理任务。该模型在保持BERT核心架构的基础上大幅减少了参数量，显著降低了计算和存储需求。其亮点在于高效推理和快速部署，特别适合移动设备或边缘计算场景。适用于文本分类、情感分析等基础NLP应用，是平衡性能与效率的实用选择。",
      "summary_es": "BERT-Tiny es un modelo de lenguaje compacto basado en BERT, optimizado para eficiencia computacional. Ideal para dispositivos con recursos limitados, mantiene capacidades sólidas en tareas de NLP como clasificación de texto y análisis de sentimientos. Su pequeño tamaño permite despliegues rápidos sin sacrificar rendimiento básico."
    },
    {
      "id": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
      "source": "hf",
      "name": "paraphrase-multilingual-MiniLM-L12-v2",
      "url": "https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "sentence-transformers",
        "pytorch",
        "tf",
        "onnx",
        "safetensors",
        "openvino",
        "bert",
        "feature-extraction",
        "sentence-similarity",
        "transformers",
        "multilingual",
        "ar",
        "bg",
        "ca",
        "cs",
        "da",
        "de",
        "el",
        "en",
        "es",
        "et",
        "fa",
        "fi",
        "fr",
        "gl",
        "gu",
        "he",
        "hi",
        "hr",
        "hu",
        "hy",
        "id",
        "it",
        "ja",
        "ka",
        "ko",
        "ku",
        "lt",
        "lv",
        "mk",
        "mn",
        "mr",
        "ms",
        "my",
        "nb",
        "nl",
        "pl",
        "pt",
        "ro",
        "ru",
        "sk",
        "sl",
        "sq",
        "sr",
        "sv",
        "th",
        "tr",
        "uk",
        "ur",
        "vi",
        "arxiv:1908.10084",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-embeddings-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 9894144,
        "hf_likes": 1009
      },
      "score": 20292.788,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "paraphrase-multilingual-MiniLM-L12-v2 是一个多语言句子嵌入模型，基于 MiniLM 架构，支持 50 多种语言。该模型专门用于生成语义相似的句子表示，适用于文本相似度计算、语义搜索和文本聚类等任务。其轻量化设计在保持较高性能的同时提升了推理速度，适合多语言环境下的实时应用。该模型在 Hugging Face 平台受到广泛关注，周下载量接近千万，适用于跨语言信息检索和内容匹配等场景。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "A multilingual sentence transformer fine-tuned for paraphrase identification and semantic similarity. Excels in cross-lingual tasks like retrieval, clustering, and duplicate detection. Efficient due to its compact MiniLM architecture, supporting 50+ languages. Ideal for multilingual NLP applications requiring semantic understanding without heavy computational demands.",
      "summary_zh": "paraphrase-multilingual-MiniLM-L12-v2 是一个多语言句子嵌入模型，基于 MiniLM 架构，支持 50 多种语言。该模型专门用于生成语义相似的句子表示，适用于文本相似度计算、语义搜索和文本聚类等任务。其轻量化设计在保持较高性能的同时提升了推理速度，适合多语言环境下的实时应用。该模型在 Hugging Face 平台受到广泛关注，周下载量接近千万，适用于跨语言信息检索和内容匹配等场景。",
      "summary_es": "Modelo de embeddings multilingüe para detección de paráfrasis y similitud semántica. Basado en MiniLM-L12, procesa 50+ idiomas. Ideal para búsqueda semántica, clustering de textos y deduplicación de contenido. Optimizado para eficiencia sin sacrificar precisión."
    },
    {
      "id": "omni-research/Tarsier2-Recap-7b",
      "source": "hf",
      "name": "Tarsier2-Recap-7b",
      "url": "https://huggingface.co/omni-research/Tarsier2-Recap-7b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "safetensors",
        "video LLM",
        "arxiv:2501.07888",
        "license:apache-2.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 8475547,
        "hf_likes": 17
      },
      "score": 16959.594,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Tarsier2-Recap-7b是一个基于Transformer架构的开源语言模型，专注于文本摘要与内容提炼任务。该模型在7B参数规模下实现了高效的推理性能，支持对长文档进行关键信息提取和结构化重组。其核心优势在于能够处理复杂语境下的语义理解，同时保持生成内容的连贯性与准确性。适用于新闻摘要、会议纪要生成、学术论文提炼等需要自动化文本处理的应用场景。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Tarsier2-Recap-7b is a 7-billion-parameter language model designed for efficient text summarization and information extraction. It excels at condensing lengthy documents, meeting notes, and research papers into concise, coherent summaries. Its strengths include strong performance with minimal computational overhead, making it suitable for real-time applications and resource-constrained environments. The model is applicable for academic, business, and content curation workflows where rapid and accurate summarization is essential.",
      "summary_zh": "Tarsier2-Recap-7b是一个基于Transformer架构的开源语言模型，专注于文本摘要与内容提炼任务。该模型在7B参数规模下实现了高效的推理性能，支持对长文档进行关键信息提取和结构化重组。其核心优势在于能够处理复杂语境下的语义理解，同时保持生成内容的连贯性与准确性。适用于新闻摘要、会议纪要生成、学术论文提炼等需要自动化文本处理的应用场景。",
      "summary_es": "Modelo de visión por computador para resúmenes automáticos de imágenes. Especializado en generar descripciones concisas de contenido visual. Ideal para aplicaciones de accesibilidad, indexación multimedia y análisis automatizado de imágenes. Basado en arquitectura transformer optimizada para tareas de comprensión visual."
    },
    {
      "id": "openai/clip-vit-large-patch14",
      "source": "hf",
      "name": "clip-vit-large-patch14",
      "url": "https://huggingface.co/openai/clip-vit-large-patch14",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "safetensors",
        "clip",
        "zero-shot-image-classification",
        "vision",
        "arxiv:2103.00020",
        "arxiv:1908.04913",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 8416345,
        "hf_likes": 1859
      },
      "score": 17762.19,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "CLIP-ViT-Large-Patch14 是一个基于 Transformer 架构的多模态视觉-语言模型，由 OpenAI 开发。它能够同时理解图像和文本，通过对比学习实现跨模态语义匹配。该模型在图像分类、图像检索和零样本识别等任务上表现优异，尤其适用于需要图文关联的应用场景。其预训练权重开源可用，便于研究者和开发者快速集成到多模态项目中。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "CLIP-ViT-Large-Patch14 is a vision-language model that excels in zero-shot image classification and cross-modal retrieval. It pairs a Vision Transformer (ViT) with a text encoder to understand and match images with natural language descriptions. Its strengths include strong generalization across diverse visual tasks without task-specific training. It is widely applicable for content moderation, image search, and multimodal AI applications.",
      "summary_zh": "CLIP-ViT-Large-Patch14 是一个基于 Transformer 架构的多模态视觉-语言模型，由 OpenAI 开发。它能够同时理解图像和文本，通过对比学习实现跨模态语义匹配。该模型在图像分类、图像检索和零样本识别等任务上表现优异，尤其适用于需要图文关联的应用场景。其预训练权重开源可用，便于研究者和开发者快速集成到多模态项目中。",
      "summary_es": "Modelo de visión y lenguaje CLIP con arquitectura ViT-L/14. Combina imágenes y texto en un espacio semántico compartido, permitiendo búsqueda multimodal, clasificación zero-shot y generación de embeddings. Destaca por su escalabilidad y transferencia a múltiples dominios sin fine-tuning. Casos de uso: sistemas de recomendación, moderación de contenido y aplicaciones de búsqueda visual."
    },
    {
      "id": "facebook/bart-base",
      "source": "hf",
      "name": "bart-base",
      "url": "https://huggingface.co/facebook/bart-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "safetensors",
        "bart",
        "feature-extraction",
        "en",
        "arxiv:1910.13461",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 8339807,
        "hf_likes": 197
      },
      "score": 16778.114,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BART-base是由Facebook开发的一种基于Transformer的序列到序列预训练模型。该模型采用去噪自编码器架构，通过重构被破坏的文本进行预训练，具备强大的文本生成和理解能力。其主要亮点包括在文本摘要、问答和对话生成等任务上的优异表现，同时支持多种自然语言处理应用。BART-base适用于需要高质量文本生成或转换的场景，如新闻摘要生成、机器翻译辅助以及对话系统构建。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "BART-base is a transformer-based encoder-decoder model designed for sequence-to-sequence tasks. It excels in text generation, summarization, and translation, leveraging its bidirectional encoder and autoregressive decoder for robust performance. Its strengths include fine-tuning flexibility and strong results on various benchmarks with relatively modest computational requirements. Well-suited for research and applications needing efficient, high-quality text transformation.",
      "summary_zh": "BART-base是由Facebook开发的一种基于Transformer的序列到序列预训练模型。该模型采用去噪自编码器架构，通过重构被破坏的文本进行预训练，具备强大的文本生成和理解能力。其主要亮点包括在文本摘要、问答和对话生成等任务上的优异表现，同时支持多种自然语言处理应用。BART-base适用于需要高质量文本生成或转换的场景，如新闻摘要生成、机器翻译辅助以及对话系统构建。",
      "summary_es": "BART-base es un modelo de secuencia a secuencia para tareas de generación y transformación de texto. Destaca en resumen, parafraseo y traducción no supervisada. Su arquitectura bidireccional permite comprensión contextual robusta. Ideal para procesamiento de lenguaje natural con alta precisión."
    },
    {
      "id": "FacebookAI/xlm-roberta-base",
      "source": "hf",
      "name": "xlm-roberta-base",
      "url": "https://huggingface.co/FacebookAI/xlm-roberta-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "onnx",
        "safetensors",
        "xlm-roberta",
        "fill-mask",
        "exbert",
        "multilingual",
        "af",
        "am",
        "ar",
        "as",
        "az",
        "be",
        "bg",
        "bn",
        "br",
        "bs",
        "ca",
        "cs",
        "cy",
        "da",
        "de",
        "el",
        "en",
        "eo",
        "es",
        "et",
        "eu",
        "fa",
        "fi",
        "fr",
        "fy",
        "ga",
        "gd",
        "gl",
        "gu",
        "ha",
        "he",
        "hi",
        "hr",
        "hu",
        "hy",
        "id",
        "is",
        "it",
        "ja",
        "jv",
        "ka",
        "kk",
        "km",
        "kn",
        "ko",
        "ku",
        "ky",
        "la",
        "lo",
        "lt",
        "lv",
        "mg",
        "mk",
        "ml",
        "mn",
        "mr",
        "ms",
        "my",
        "ne",
        "nl",
        "no",
        "om",
        "or",
        "pa",
        "pl",
        "ps",
        "pt",
        "ro",
        "ru",
        "sa",
        "sd",
        "si",
        "sk",
        "sl",
        "so",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "th",
        "tl",
        "tr",
        "ug",
        "uk",
        "ur",
        "uz",
        "vi",
        "xh",
        "yi",
        "zh",
        "arxiv:1911.02116",
        "license:mit",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 8224582,
        "hf_likes": 728
      },
      "score": 16813.164,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "xlm-roberta-base 是一个基于 RoBERTa 架构的多语言预训练语言模型，由 Facebook AI 开发。该模型在 100 种语言的大规模语料上进行训练，具备强大的跨语言理解能力。其核心亮点在于无需语言对齐即可处理多语言任务，适用于文本分类、命名实体识别和语义相似度计算等场景。该模型在 Hugging Face 平台广受欢迎，适用于需要高效多语言 NLP 解决方案的研究和工业应用。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "XLM-RoBERTa-base is a multilingual language model pretrained on 100 languages. It excels at cross-lingual understanding tasks like text classification, named entity recognition, and question answering. Its key strength is strong zero-shot transfer performance across languages without task-specific training. It is widely used for building multilingual NLP applications and benchmarking cross-lingual models.",
      "summary_zh": "xlm-roberta-base 是一个基于 RoBERTa 架构的多语言预训练语言模型，由 Facebook AI 开发。该模型在 100 种语言的大规模语料上进行训练，具备强大的跨语言理解能力。其核心亮点在于无需语言对齐即可处理多语言任务，适用于文本分类、命名实体识别和语义相似度计算等场景。该模型在 Hugging Face 平台广受欢迎，适用于需要高效多语言 NLP 解决方案的研究和工业应用。",
      "summary_es": "Modelo de lenguaje multilingüe basado en RoBERTa, optimizado para procesamiento de texto en 100 idiomas. Destaca por su capacidad de representación contextual cruzada y alto rendimiento en tareas como clasificación, NER y QA. Ideal para aplicaciones multilingües y transfer learning."
    },
    {
      "id": "google/vit-base-patch16-224-in21k",
      "source": "hf",
      "name": "vit-base-patch16-224-in21k",
      "url": "https://huggingface.co/google/vit-base-patch16-224-in21k",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "safetensors",
        "vit",
        "image-feature-extraction",
        "vision",
        "dataset:imagenet-21k",
        "arxiv:2010.11929",
        "arxiv:2006.03677",
        "license:apache-2.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 8187499,
        "hf_likes": 371
      },
      "score": 16560.498,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "这是一个基于Vision Transformer (ViT)架构的预训练图像分类模型，由Google开发。模型使用ImageNet-21k数据集进行预训练，支持输入224x224像素的图像，并采用16x16的图像块分割策略。该模型在图像分类任务上表现出色，尤其适合需要高精度识别的大规模图像数据集场景。开发者可以基于此模型进行微调，应用于医疗影像分析、自动驾驶或工业质检等领域。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "A Vision Transformer (ViT) model pre-trained on ImageNet-21k, designed for image classification tasks. It processes images as 16x16 patches and supports input resolutions of 224x224 pixels. Ideal for transfer learning in computer vision applications, offering strong performance and flexibility for fine-tuning on custom datasets. Well-suited for research and production use where high accuracy and scalability are required.",
      "summary_zh": "这是一个基于Vision Transformer (ViT)架构的预训练图像分类模型，由Google开发。模型使用ImageNet-21k数据集进行预训练，支持输入224x224像素的图像，并采用16x16的图像块分割策略。该模型在图像分类任务上表现出色，尤其适合需要高精度识别的大规模图像数据集场景。开发者可以基于此模型进行微调，应用于医疗影像分析、自动驾驶或工业质检等领域。",
      "summary_es": "Modelo de clasificación de imágenes basado en Vision Transformer. Entrenado con 21k clases de ImageNet, procesa imágenes de 224x224 píxeles divididas en parches de 16x16. Destaca por su precisión en reconocimiento visual y transferencia a tareas específicas. Ideal para aplicaciones de visión artificial e investigación."
    },
    {
      "id": "trpakov/vit-face-expression",
      "source": "hf",
      "name": "vit-face-expression",
      "url": "https://huggingface.co/trpakov/vit-face-expression",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "vit",
        "image-classification",
        "doi:10.57967/hf/2289",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 8073901,
        "hf_likes": 78
      },
      "score": 16186.802,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "vit-face-expression是一个基于Vision Transformer架构的面部表情识别模型。该模型能够从输入图像中检测并分类人类面部表情，支持包括快乐、悲伤、愤怒、惊讶等常见情绪类别。其核心亮点在于结合了ViT的全局特征提取能力，在表情识别任务上表现出较高的准确性和鲁棒性。适用于人机交互、情感分析、心理学研究以及智能监控等场景，为开发者提供了便捷且高效的表情识别解决方案。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "A Vision Transformer (ViT) fine-tuned for facial expression recognition, achieving high accuracy across diverse datasets. Ideal for emotion analysis in human-computer interaction, mental health monitoring, and user experience research. Its transformer architecture enables robust performance with varying lighting and facial orientations. Suitable for integration into applications requiring real-time or batch processing of facial emotion data.",
      "summary_zh": "vit-face-expression是一个基于Vision Transformer架构的面部表情识别模型。该模型能够从输入图像中检测并分类人类面部表情，支持包括快乐、悲伤、愤怒、惊讶等常见情绪类别。其核心亮点在于结合了ViT的全局特征提取能力，在表情识别任务上表现出较高的准确性和鲁棒性。适用于人机交互、情感分析、心理学研究以及智能监控等场景，为开发者提供了便捷且高效的表情识别解决方案。",
      "summary_es": "Modelo de visión por computadora basado en Vision Transformer (ViT) para reconocimiento de expresiones faciales. Detecta emociones como alegría, tristeza, enojo o sorpresa en imágenes. Su arquitectura ViT garantiza alta precisión y eficiencia en el procesamiento. Útil para análisis de comportamiento, investigación psicológica o sistemas interactivos."
    },
    {
      "id": "facebook/contriever",
      "source": "hf",
      "name": "contriever",
      "url": "https://huggingface.co/facebook/contriever",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "bert",
        "arxiv:2112.09118",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 8065264,
        "hf_likes": 63
      },
      "score": 16162.028,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Contriever是Facebook开发的无监督密集检索模型，通过对比学习从大规模文本语料中学习通用文本表示。该模型无需标注数据即可生成高质量的文本嵌入，适用于信息检索、语义相似度计算和文档匹配等任务。其核心优势在于能够有效捕捉文本语义信息，并在零样本和少样本场景下表现优异。Contriever特别适合需要高效文本检索或语义搜索的应用，如知识库构建和智能问答系统。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Contriever is a dense retrieval model designed for efficient and scalable text search. It excels at finding relevant documents or passages from large collections based on semantic similarity rather than exact keyword matching. Its strengths include strong performance on retrieval tasks, robustness across domains, and compatibility with standard vector search libraries. It is widely applicable for tasks like open-domain question answering, document retrieval, and information extraction.",
      "summary_zh": "Contriever是Facebook开发的无监督密集检索模型，通过对比学习从大规模文本语料中学习通用文本表示。该模型无需标注数据即可生成高质量的文本嵌入，适用于信息检索、语义相似度计算和文档匹配等任务。其核心优势在于能够有效捕捉文本语义信息，并在零样本和少样本场景下表现优异。Contriever特别适合需要高效文本检索或语义搜索的应用，如知识库构建和智能问答系统。",
      "summary_es": "Contriever es un modelo de recuperación de información basado en transformers. Utiliza aprendizaje contrastivo para generar representaciones densas de texto, optimizando la similitud semántica. Es ideal para sistemas de búsqueda, recomendación y clustering de documentos. Su principal ventaja es la eficiencia en la recuperación de información relevante sin dependencia de palabras clave exactas."
    },
    {
      "id": "openai/gpt-oss-20b",
      "source": "hf",
      "name": "gpt-oss-20b",
      "url": "https://huggingface.co/openai/gpt-oss-20b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "gpt_oss",
        "text-generation",
        "vllm",
        "conversational",
        "arxiv:2508.10925",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "8-bit",
        "mxfp4",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 7808773,
        "hf_likes": 3541
      },
      "score": 17388.046000000002,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "GPT-OSS-20B 是 OpenAI 发布的一个开源语言模型，参数量为 200 亿，基于 Transformer 架构构建。该模型支持多种自然语言处理任务，包括文本生成、摘要、翻译和问答等。其训练数据涵盖广泛领域，具备较强的上下文理解与逻辑推理能力。适用于研究人员、开发者以及企业用户进行模型实验、应用开发和任务优化。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "GPT-OSS-20B is a 20-billion-parameter open-source language model developed by OpenAI. It excels in natural language understanding and generation tasks, making it suitable for applications like text summarization, translation, and conversational AI. Its large scale and open availability enable researchers and developers to experiment with and build upon advanced AI capabilities. The model's high download count reflects its broad utility and adoption in the AI community.",
      "summary_zh": "GPT-OSS-20B 是 OpenAI 发布的一个开源语言模型，参数量为 200 亿，基于 Transformer 架构构建。该模型支持多种自然语言处理任务，包括文本生成、摘要、翻译和问答等。其训练数据涵盖广泛领域，具备较强的上下文理解与逻辑推理能力。适用于研究人员、开发者以及企业用户进行模型实验、应用开发和任务优化。",
      "summary_es": "GPT-OSS-20B es un modelo de lenguaje de 20 mil millones de parámetros de código abierto. Diseñado para generación de texto, resumen y consultas en lenguaje natural. Su gran tamaño lo hace útil para tareas complejas como análisis de documentos y asistencia automatizada. Ideal para desarrolladores e investigadores que requieren un modelo potente y accesible."
    },
    {
      "id": "pyannote/segmentation",
      "source": "hf",
      "name": "segmentation",
      "url": "https://huggingface.co/pyannote/segmentation",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "pyannote-audio",
        "pytorch",
        "pyannote",
        "pyannote-audio-model",
        "audio",
        "voice",
        "speech",
        "speaker",
        "speaker-segmentation",
        "voice-activity-detection",
        "overlapped-speech-detection",
        "resegmentation",
        "arxiv:2104.04045",
        "license:mit",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 7555385,
        "hf_likes": 638
      },
      "score": 15429.77,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "pyannote/segmentation 是一个基于深度学习的音频分割模型，专注于语音活动检测和说话人分割任务。该模型能够自动识别音频中的语音片段，并区分不同说话人的声音区域。其核心优势在于高精度的分割性能，适用于处理会议录音、播客或电话通话等多说话人场景。该模型基于 PyTorch 实现，支持端到端的推理流程，可广泛应用于语音处理、转录和分析等任务。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Pyannote's segmentation model is a speaker diarization tool that segments and labels audio by speaker. It is widely used for transcribing meetings, interviews, and podcasts, providing accurate speaker separation. Its strengths include robust performance across diverse audio conditions and integration with the Hugging Face ecosystem. This model is applicable for researchers, developers, and organizations needing automated audio analysis.",
      "summary_zh": "pyannote/segmentation 是一个基于深度学习的音频分割模型，专注于语音活动检测和说话人分割任务。该模型能够自动识别音频中的语音片段，并区分不同说话人的声音区域。其核心优势在于高精度的分割性能，适用于处理会议录音、播客或电话通话等多说话人场景。该模型基于 PyTorch 实现，支持端到端的推理流程，可广泛应用于语音处理、转录和分析等任务。",
      "summary_es": "Pyannote Segmentation es un modelo de segmentación de audio de código abierto que identifica regiones de habla y silencio en grabaciones. Utiliza aprendizaje profundo para delimitar segmentos de voz con alta precisión temporal. Es ideal para preprocesamiento de ASR, análisis de conversaciones y diarización de hablantes. Su arquitectura eficiente permite procesamiento en tiempo real y batch."
    },
    {
      "id": "meta-llama/Llama-3.2-1B-Instruct",
      "source": "hf",
      "name": "Llama-3.2-1B-Instruct",
      "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "facebook",
        "meta",
        "pytorch",
        "llama-3",
        "conversational",
        "en",
        "de",
        "fr",
        "it",
        "pt",
        "hi",
        "es",
        "th",
        "arxiv:2204.05149",
        "arxiv:2405.16406",
        "license:llama3.2",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 7527168,
        "hf_likes": 1069
      },
      "score": 15588.836000000001,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Llama-3.2-1B-Instruct 是 Meta 推出的轻量级指令微调语言模型，参数量为 10 亿。该模型专为高效推理和部署设计，适用于资源受限环境，如移动设备和边缘计算场景。其核心优势在于平衡了模型性能与计算效率，支持多轮对话、文本生成和任务导向型交互。该模型适合用于聊天助手、内容摘要、代码补全等实际应用，尤其适合对延迟和计算资源敏感的场景。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Llama-3.2-1B-Instruct is a compact, instruction-tuned language model designed for efficient deployment on resource-constrained devices. It excels in tasks like text generation, summarization, and question answering, making it suitable for edge computing, chatbots, and lightweight AI applications. Its small size enables fast inference with lower computational costs, while maintaining solid performance for everyday language tasks. Ideal for developers seeking a balance between capability and efficiency in embedded or mobile environments.",
      "summary_zh": "Llama-3.2-1B-Instruct 是 Meta 推出的轻量级指令微调语言模型，参数量为 10 亿。该模型专为高效推理和部署设计，适用于资源受限环境，如移动设备和边缘计算场景。其核心优势在于平衡了模型性能与计算效率，支持多轮对话、文本生成和任务导向型交互。该模型适合用于聊天助手、内容摘要、代码补全等实际应用，尤其适合对延迟和计算资源敏感的场景。",
      "summary_es": "Llama-3.2-1B-Instruct es un modelo de lenguaje pequeño y eficiente optimizado para instrucciones. Destaca por su bajo consumo de recursos y alta velocidad de inferencia, ideal para dispositivos con capacidad limitada. Es útil en aplicaciones de chatbots, generación de texto y automatización de tareas simples. Su diseño compacto lo hace adecuado para entornos de producción con restricciones de hardware."
    },
    {
      "id": "Qwen/Qwen2.5-7B-Instruct",
      "source": "hf",
      "name": "Qwen2.5-7B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "qwen2",
        "text-generation",
        "chat",
        "conversational",
        "en",
        "arxiv:2309.00071",
        "arxiv:2407.10671",
        "base_model:Qwen/Qwen2.5-7B",
        "base_model:finetune:Qwen/Qwen2.5-7B",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 7511497,
        "hf_likes": 796
      },
      "score": 15420.994,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2.5-7B-Instruct 是阿里云推出的一款开源大语言模型，基于 Qwen2.5 架构优化，专为指令跟随任务设计。该模型具备 70 亿参数，在多项基准测试中表现出色，尤其擅长代码生成、数学推理和自然语言理解。其优化后的推理能力使其适用于智能助手、代码补全、教育辅助等场景。模型支持多轮对话，并具备较强的上下文理解能力，适合开发者和研究人员用于构建高效的 AI 应用。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model optimized for conversational and task-oriented applications. It excels in code generation, reasoning, and multilingual tasks, making it suitable for chatbots, content creation, and programming assistance. Its compact size allows for efficient deployment on consumer hardware while maintaining strong performance. The model is open-source and widely adopted, as reflected in its high download and engagement metrics.",
      "summary_zh": "Qwen2.5-7B-Instruct 是阿里云推出的一款开源大语言模型，基于 Qwen2.5 架构优化，专为指令跟随任务设计。该模型具备 70 亿参数，在多项基准测试中表现出色，尤其擅长代码生成、数学推理和自然语言理解。其优化后的推理能力使其适用于智能助手、代码补全、教育辅助等场景。模型支持多轮对话，并具备较强的上下文理解能力，适合开发者和研究人员用于构建高效的 AI 应用。",
      "summary_es": "Qwen2.5-7B-Instruct es un modelo de lenguaje de 7 mil millones de parámetros optimizado para instrucciones. Destaca por su eficiencia, versatilidad en tareas conversacionales y generación de código. Ideal para asistentes virtuales, automatización de respuestas y desarrollo de aplicaciones de IA accesibles."
    },
    {
      "id": "BAAI/bge-base-en-v1.5",
      "source": "hf",
      "name": "bge-base-en-v1.5",
      "url": "https://huggingface.co/BAAI/bge-base-en-v1.5",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "sentence-transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "bert",
        "feature-extraction",
        "sentence-similarity",
        "transformers",
        "mteb",
        "en",
        "arxiv:2401.03462",
        "arxiv:2312.15503",
        "arxiv:2311.13534",
        "arxiv:2310.07554",
        "arxiv:2309.07597",
        "license:mit",
        "model-index",
        "autotrain_compatible",
        "text-embeddings-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 7434960,
        "hf_likes": 347
      },
      "score": 15043.42,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bge-base-en-v1.5 是由北京智源人工智能研究院（BAAI）开发的开源文本嵌入模型，适用于英文文本的向量化表示。该模型基于BERT架构，通过大规模预训练和对比学习优化，显著提升了语义检索和文本相似度计算的性能。其核心亮点在于支持高效的语义搜索、问答匹配和文档检索任务，尤其适合构建智能搜索引擎或推荐系统。该模型在Hugging Face平台广受欢迎，适用于需要高精度文本理解的应用场景。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "BGE-Base-EN-v1.5 is a general-purpose English embedding model designed for semantic search, retrieval, and clustering tasks. It excels in generating high-quality text embeddings, enabling efficient similarity matching and information retrieval. The model is well-suited for applications like document search, recommendation systems, and question-answering pipelines. Its strong performance and broad applicability make it a reliable choice for embedding-based workflows.",
      "summary_zh": "bge-base-en-v1.5 是由北京智源人工智能研究院（BAAI）开发的开源文本嵌入模型，适用于英文文本的向量化表示。该模型基于BERT架构，通过大规模预训练和对比学习优化，显著提升了语义检索和文本相似度计算的性能。其核心亮点在于支持高效的语义搜索、问答匹配和文档检索任务，尤其适合构建智能搜索引擎或推荐系统。该模型在Hugging Face平台广受欢迎，适用于需要高精度文本理解的应用场景。",
      "summary_es": "Modelo de embeddings de texto en inglés para representaciones semánticas densas. Destaca por su eficiencia en búsqueda y recuperación de información, clustering y clasificación de documentos. Casos de uso incluye sistemas de recomendación y motores de búsqueda semántica."
    },
    {
      "id": "Qwen/Qwen2.5-3B-Instruct",
      "source": "hf",
      "name": "Qwen2.5-3B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "qwen2",
        "text-generation",
        "chat",
        "conversational",
        "en",
        "arxiv:2407.10671",
        "base_model:Qwen/Qwen2.5-3B",
        "base_model:finetune:Qwen/Qwen2.5-3B",
        "license:other",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 7018030,
        "hf_likes": 310
      },
      "score": 14191.06,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2.5-3B-Instruct 是阿里云推出的一款轻量级开源指令微调语言模型，参数量为 30 亿。该模型基于 Qwen2.5 架构优化，具备较强的推理能力和多语言支持，适用于对话生成、任务执行和代码理解等场景。其设计注重效率与性能平衡，适合部署在资源受限的环境中，如边缘设备或本地服务器。模型在 Hugging Face 平台获得广泛关注，一周内下载量超过 700 万，显示出较高的社区认可度。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Qwen2.5-3B-Instruct is a compact, instruction-tuned language model optimized for efficient inference and deployment. It excels in tasks like text generation, summarization, and question answering, making it suitable for resource-constrained environments. Its strong performance and open-source availability support applications in chatbots, content creation, and educational tools. Ideal for developers seeking a balance between capability and computational efficiency.",
      "summary_zh": "Qwen2.5-3B-Instruct 是阿里云推出的一款轻量级开源指令微调语言模型，参数量为 30 亿。该模型基于 Qwen2.5 架构优化，具备较强的推理能力和多语言支持，适用于对话生成、任务执行和代码理解等场景。其设计注重效率与性能平衡，适合部署在资源受限的环境中，如边缘设备或本地服务器。模型在 Hugging Face 平台获得广泛关注，一周内下载量超过 700 万，显示出较高的社区认可度。",
      "summary_es": "Qwen2.5-3B-Instruct es un modelo de lenguaje pequeño optimizado para instrucciones. Destaca por su eficiencia en tareas de diálogo, generación de texto y resolución de problemas. Ideal para aplicaciones en dispositivos con recursos limitados, chatbots y automatización de respuestas. Su tamaño compacto permite despliegues rápidos sin sacrificar rendimiento."
    },
    {
      "id": "meta-llama/Llama-3.1-8B-Instruct",
      "source": "hf",
      "name": "Llama-3.1-8B-Instruct",
      "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "facebook",
        "meta",
        "pytorch",
        "llama-3",
        "conversational",
        "en",
        "de",
        "fr",
        "it",
        "pt",
        "hi",
        "es",
        "th",
        "arxiv:2204.05149",
        "base_model:meta-llama/Llama-3.1-8B",
        "base_model:finetune:meta-llama/Llama-3.1-8B",
        "license:llama3.1",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 6885240,
        "hf_likes": 4631
      },
      "score": 16085.98,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Llama-3.1-8B-Instruct 是 Meta 推出的开源指令微调语言模型，参数量为 80 亿。该模型基于 Llama 3 架构优化，专门针对指令遵循任务进行训练，能够更准确地理解和执行用户指令。其亮点在于支持多轮对话、代码生成、文本摘要等多种任务，同时具备较强的推理能力和较低的幻觉率。适用于聊天助手、内容创作、编程辅助等场景，尤其适合需要高效且可控文本生成的应用。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Llama-3.1-8B-Instruct is a powerful open-source language model optimized for instruction-following tasks. It excels in generating coherent, context-aware responses for applications like chatbots, content creation, and code assistance. With its 8-billion-parameter architecture, it balances performance and efficiency, making it suitable for both research and production use. Its strong performance on benchmarks and broad applicability make it a versatile tool for developers and researchers.",
      "summary_zh": "Llama-3.1-8B-Instruct 是 Meta 推出的开源指令微调语言模型，参数量为 80 亿。该模型基于 Llama 3 架构优化，专门针对指令遵循任务进行训练，能够更准确地理解和执行用户指令。其亮点在于支持多轮对话、代码生成、文本摘要等多种任务，同时具备较强的推理能力和较低的幻觉率。适用于聊天助手、内容创作、编程辅助等场景，尤其适合需要高效且可控文本生成的应用。",
      "summary_es": "Llama-3.1-8B-Instruct es un modelo de lenguaje de 8 mil millones de parámetros optimizado para instrucciones. Destaca por su eficiencia en tareas de generación de texto, resúmenes y asistencia conversacional. Su tamaño compacto permite despliegues en entornos con recursos limitados, ideal para aplicaciones educativas, chatbots y automatización de respuestas."
    },
    {
      "id": "pyannote/voice-activity-detection",
      "source": "hf",
      "name": "voice-activity-detection",
      "url": "https://huggingface.co/pyannote/voice-activity-detection",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "pyannote-audio",
        "pyannote",
        "pyannote-audio-pipeline",
        "audio",
        "voice",
        "speech",
        "speaker",
        "voice-activity-detection",
        "automatic-speech-recognition",
        "dataset:ami",
        "dataset:dihard",
        "dataset:voxconverse",
        "license:mit",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 6025552,
        "hf_likes": 210
      },
      "score": 12156.104,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "这是一个基于深度学习的语音活动检测（VAD）模型，用于识别音频中是否包含人声。该模型能够有效区分语音片段和非语音片段（如静音或背景噪声），适用于音频预处理、语音识别增强和通话质量优化等场景。其核心优势在于高准确率和低延迟，支持实时处理，可广泛应用于语音通信、会议转录和智能助手等领域。该模型在 Hugging Face 平台受到广泛关注，下载量和用户评分均较高。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Pyannote's Voice Activity Detection (VAD) is a robust open-source model for identifying speech segments in audio. It excels in preprocessing for speech recognition, transcription, and speaker diarization tasks. Its high download count reflects widespread adoption in research and production pipelines. The model is particularly useful for applications requiring efficient and accurate segmentation of audio streams.",
      "summary_zh": "这是一个基于深度学习的语音活动检测（VAD）模型，用于识别音频中是否包含人声。该模型能够有效区分语音片段和非语音片段（如静音或背景噪声），适用于音频预处理、语音识别增强和通话质量优化等场景。其核心优势在于高准确率和低延迟，支持实时处理，可广泛应用于语音通信、会议转录和智能助手等领域。该模型在 Hugging Face 平台受到广泛关注，下载量和用户评分均较高。",
      "summary_es": "Detector de actividad vocal basado en PyAnnote. Identifica segmentos de habla en audio con alta precisión. Usa aprendizaje profundo para análisis en tiempo real. Ideal para transcripciones, análisis de llamadas y procesamiento de voz."
    },
    {
      "id": "BAAI/bge-m3",
      "source": "hf",
      "name": "bge-m3",
      "url": "https://huggingface.co/BAAI/bge-m3",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "sentence-transformers",
        "pytorch",
        "onnx",
        "xlm-roberta",
        "feature-extraction",
        "sentence-similarity",
        "arxiv:2402.03216",
        "arxiv:2004.04906",
        "arxiv:2106.14807",
        "arxiv:2107.05720",
        "arxiv:2004.12832",
        "license:mit",
        "autotrain_compatible",
        "text-embeddings-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 5824147,
        "hf_likes": 2363
      },
      "score": 12829.794,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BGE-M3是由北京智源人工智能研究院开发的多功能文本嵌入模型，支持密集检索、稀疏检索和多向量表示三种模式。该模型在多个基准测试中表现优异，尤其在跨语言检索和长文本处理方面具有显著优势。适用于搜索引擎、文档匹配、多语言语义相似度计算等场景。其开源特性及强大的泛化能力使其成为研究和工业应用的理想选择。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "BGE-M3 is a versatile embedding model supporting dense, sparse, and multi-vector retrieval. It excels in multilingual and cross-lingual tasks, making it suitable for search, retrieval-augmented generation (RAG), and semantic similarity applications. Its strong performance across diverse benchmarks and languages makes it a robust choice for scalable information retrieval systems.",
      "summary_zh": "BGE-M3是由北京智源人工智能研究院开发的多功能文本嵌入模型，支持密集检索、稀疏检索和多向量表示三种模式。该模型在多个基准测试中表现优异，尤其在跨语言检索和长文本处理方面具有显著优势。适用于搜索引擎、文档匹配、多语言语义相似度计算等场景。其开源特性及强大的泛化能力使其成为研究和工业应用的理想选择。",
      "summary_es": "BGE-M3 es un modelo de embedding multilingüe de código abierto. Destaca por su capacidad para generar representaciones densas, dispersas y de colBERT. Es ideal para recuperación de información, búsqueda semántica y aplicaciones multilingües. Su diseño flexible permite adaptarse a diversos casos de uso en procesamiento de lenguaje natural."
    },
    {
      "id": "nlpaueb/legal-bert-base-uncased",
      "source": "hf",
      "name": "legal-bert-base-uncased",
      "url": "https://huggingface.co/nlpaueb/legal-bert-base-uncased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "bert",
        "pretraining",
        "legal",
        "fill-mask",
        "en",
        "license:cc-by-sa-4.0",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 5608821,
        "hf_likes": 271
      },
      "score": 11353.142,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Legal-BERT-Base-Uncased是一个基于BERT架构的预训练语言模型，专门针对法律领域文本优化。该模型在大量法律文档上进行训练，能够更好地理解和处理法律术语、条款及复杂句式。适用于法律文档分类、信息提取、合同分析等任务，为法律科技应用提供高效支持。其开源特性便于研究人员和开发者进行定制化部署与扩展。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Legal-BERT-Base-Uncased is a domain-specific language model fine-tuned on legal texts. It excels in legal document analysis, contract review, and case law summarization. Its strengths include improved accuracy in legal terminology understanding and context-aware predictions. This model is particularly useful for legal professionals, researchers, and applications requiring automated processing of legal documents.",
      "summary_zh": "Legal-BERT-Base-Uncased是一个基于BERT架构的预训练语言模型，专门针对法律领域文本优化。该模型在大量法律文档上进行训练，能够更好地理解和处理法律术语、条款及复杂句式。适用于法律文档分类、信息提取、合同分析等任务，为法律科技应用提供高效支持。其开源特性便于研究人员和开发者进行定制化部署与扩展。",
      "summary_es": "Legal-BERT es un modelo de lenguaje especializado en documentos legales, basado en BERT. Optimizado para procesar textos jurídicos complejos, destaca en tareas como clasificación, extracción de información y análisis de sentencias. Su entrenamiento en corpus legal mejora precisión en contextos normativos. Casos de uso incluyen automatización de revisiones contractuales y asistencia en investigación jurídica."
    },
    {
      "id": "Qwen/Qwen3-0.6B",
      "source": "hf",
      "name": "Qwen3-0.6B",
      "url": "https://huggingface.co/Qwen/Qwen3-0.6B",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "qwen3",
        "text-generation",
        "conversational",
        "arxiv:2505.09388",
        "base_model:Qwen/Qwen3-0.6B-Base",
        "base_model:finetune:Qwen/Qwen3-0.6B-Base",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 5516940,
        "hf_likes": 629
      },
      "score": 11348.380000000001,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen3-0.6B 是阿里云推出的一款轻量级开源语言模型，参数量为6亿。该模型基于Transformer架构，支持中英文双语处理，适用于资源受限环境下的自然语言理解与生成任务。其亮点在于高效推理和较低的计算开销，同时保持了良好的性能表现。适用于移动设备、边缘计算以及需要快速响应的AI应用场景。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Qwen3-0.6B is a compact, open-source language model with 0.6 billion parameters, designed for efficient inference and deployment on resource-constrained devices. It excels in tasks like text generation, summarization, and question answering, making it suitable for lightweight applications in chatbots, content creation, and educational tools. Its popularity, evidenced by high download rates, reflects its balance of performance and accessibility for developers and researchers.",
      "summary_zh": "Qwen3-0.6B 是阿里云推出的一款轻量级开源语言模型，参数量为6亿。该模型基于Transformer架构，支持中英文双语处理，适用于资源受限环境下的自然语言理解与生成任务。其亮点在于高效推理和较低的计算开销，同时保持了良好的性能表现。适用于移动设备、边缘计算以及需要快速响应的AI应用场景。",
      "summary_es": "Qwen3-0.6B es un modelo de lenguaje pequeño y eficiente con 600 millones de parámetros. Diseñado para tareas de procesamiento de lenguaje natural, es ideal para dispositivos con recursos limitados. Su principal fortaleza es el equilibrio entre rendimiento y velocidad, permitiendo su uso en aplicaciones en tiempo real. Casos de uso incluyen chatbots ligeros, análisis de texto y generación de respuestas rápidas."
    },
    {
      "id": "autogluon/chronos-bolt-base",
      "source": "hf",
      "name": "chronos-bolt-base",
      "url": "https://huggingface.co/autogluon/chronos-bolt-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "safetensors",
        "t5",
        "time series",
        "forecasting",
        "pretrained models",
        "foundation models",
        "time series foundation models",
        "time-series",
        "time-series-forecasting",
        "arxiv:1910.10683",
        "arxiv:2403.07815",
        "license:apache-2.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 5488213,
        "hf_likes": 26
      },
      "score": 10989.426,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Chronos-Bolt-Base 是一个轻量级时间序列预测模型，基于 Transformer 架构设计，适用于单变量时间序列的快速预测任务。该模型通过预训练和微调机制，能够高效处理多种时间序列数据，无需复杂的特征工程。其亮点在于模型规模小、推理速度快，同时保持较高的预测准确性，适合资源受限或对实时性要求较高的场景。典型应用包括能源需求预测、销售趋势分析和设备异常检测等。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Chronos-Bolt-Base is a lightweight, open-source time series forecasting model designed for efficient and scalable predictions. It excels in univariate forecasting tasks, offering strong baseline performance with minimal computational overhead. The model is well-suited for applications in finance, IoT, and resource monitoring where fast, reliable forecasts are needed. Its simplicity and ease of integration make it a practical choice for developers and researchers working with time series data.",
      "summary_zh": "Chronos-Bolt-Base 是一个轻量级时间序列预测模型，基于 Transformer 架构设计，适用于单变量时间序列的快速预测任务。该模型通过预训练和微调机制，能够高效处理多种时间序列数据，无需复杂的特征工程。其亮点在于模型规模小、推理速度快，同时保持较高的预测准确性，适合资源受限或对实时性要求较高的场景。典型应用包括能源需求预测、销售趋势分析和设备异常检测等。",
      "summary_es": "Modelo de series temporales ligero para predicción univariante. Basado en arquitectura transformer, optimizado para inferencia rápida. Ideal para aplicaciones con recursos limitados o predicciones en tiempo real."
    },
    {
      "id": "colbert-ir/colbertv2.0",
      "source": "hf",
      "name": "colbertv2.0",
      "url": "https://huggingface.co/colbert-ir/colbertv2.0",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "bert",
        "ColBERT",
        "en",
        "arxiv:2004.12832",
        "arxiv:2007.00814",
        "arxiv:2101.00436",
        "arxiv:2112.01488",
        "arxiv:2205.09707",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 5388853,
        "hf_likes": 285
      },
      "score": 10920.206,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ColBERTv2.0 是一个基于深度学习的检索模型，适用于高效的大规模文本检索任务。它通过将查询和文档分别编码为向量，并利用交互式匹配机制提升检索精度。该模型在保持高召回率的同时显著降低了计算开销，适用于搜索引擎、问答系统和推荐系统等场景。其开源实现和预训练权重为研究者和开发者提供了便捷的使用途径。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "ColBERTv2.0 is a dense retrieval model optimized for efficient and accurate information retrieval. It excels in semantic search tasks, offering strong performance with lower computational overhead compared to traditional cross-encoders. Ideal for applications like document retrieval, question answering, and recommendation systems, it balances speed and precision. Its open availability makes it a practical choice for both research and production environments.",
      "summary_zh": "ColBERTv2.0 是一个基于深度学习的检索模型，适用于高效的大规模文本检索任务。它通过将查询和文档分别编码为向量，并利用交互式匹配机制提升检索精度。该模型在保持高召回率的同时显著降低了计算开销，适用于搜索引擎、问答系统和推荐系统等场景。其开源实现和预训练权重为研究者和开发者提供了便捷的使用途径。",
      "summary_es": "ColBERTv2.0 es un modelo de recuperación de información densa que indexa y busca documentos mediante representaciones vectoriales. Destaca por su eficiencia en búsqueda semántica y escalabilidad para grandes colecciones de texto. Ideal para motores de búsqueda, QA y sistemas de recomendación con alta precisión."
    },
    {
      "id": "facebook/esmfold_v1",
      "source": "hf",
      "name": "esmfold_v1",
      "url": "https://huggingface.co/facebook/esmfold_v1",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "esm",
        "license:mit",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 5388021,
        "hf_likes": 41
      },
      "score": 10796.542,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ESMFold v1是由Meta AI开发的开源蛋白质结构预测模型，基于大规模蛋白质语言模型ESM-2构建。该模型能够仅从蛋白质的氨基酸序列直接预测其三维结构，无需依赖多序列比对。其预测速度快、精度高，适用于大规模蛋白质结构预测任务，尤其适合生物医学研究、药物发现和蛋白质设计等场景。该模型在Hugging Face平台开源，便于研究人员和开发者直接使用。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "ESMFold v1 is a high-performance protein structure prediction model developed by Meta AI. It leverages evolutionary scale modeling to accurately predict 3D protein structures from amino acid sequences. The model is particularly useful for researchers in bioinformatics and drug discovery, offering rapid and reliable predictions without the need for multiple sequence alignments. Its open-source availability and strong performance make it a valuable tool for advancing structural biology and therapeutic development.",
      "summary_zh": "ESMFold v1是由Meta AI开发的开源蛋白质结构预测模型，基于大规模蛋白质语言模型ESM-2构建。该模型能够仅从蛋白质的氨基酸序列直接预测其三维结构，无需依赖多序列比对。其预测速度快、精度高，适用于大规模蛋白质结构预测任务，尤其适合生物医学研究、药物发现和蛋白质设计等场景。该模型在Hugging Face平台开源，便于研究人员和开发者直接使用。",
      "summary_es": "ESMFold v1 es un modelo de predicción de estructuras proteicas basado en redes neuronales. Utiliza secuencias de aminoácidos para predecir estructuras 3D con alta precisión y velocidad. Es ideal para investigación biológica, diseño de fármacos y estudios de biología estructural. Su principal ventaja es la eficiencia computacional sin sacrificar precisión."
    },
    {
      "id": "Comfy-Org/Wan_2.2_ComfyUI_Repackaged",
      "source": "hf",
      "name": "Wan_2.2_ComfyUI_Repackaged",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "diffusion-single-file",
        "comfyui",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 5280276,
        "hf_likes": 313
      },
      "score": 10717.052,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Wan_2.2_ComfyUI_Repackaged 是一个基于 ComfyUI 框架的 Stable Diffusion 模型优化版本，专为图像生成任务设计。该模型在保持高质量图像输出的同时，显著提升了生成速度和资源利用效率，适用于本地部署和批量图像生成场景。其亮点包括优化的推理流程、更低的显存占用以及对多种自定义插件的良好兼容性。该模型适合需要高效、稳定图像生成能力的开发者和创作者使用。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Wan_2.2_ComfyUI_Repackaged is a repackaged version of the Wan 2.2 model optimized for use with ComfyUI, a popular node-based interface for stable diffusion workflows. It enables efficient image generation and manipulation, particularly suited for creative and artistic applications. The high download count reflects its strong community adoption and ease of integration. Ideal for users seeking streamlined access to advanced AI image synthesis within ComfyUI environments.",
      "summary_zh": "Wan_2.2_ComfyUI_Repackaged 是一个基于 ComfyUI 框架的 Stable Diffusion 模型优化版本，专为图像生成任务设计。该模型在保持高质量图像输出的同时，显著提升了生成速度和资源利用效率，适用于本地部署和批量图像生成场景。其亮点包括优化的推理流程、更低的显存占用以及对多种自定义插件的良好兼容性。该模型适合需要高效、稳定图像生成能力的开发者和创作者使用。",
      "summary_es": "Wan 2.2 ComfyUI Repackaged es una distribución optimizada del modelo de generación de imágenes Wan 2.2 para ComfyUI. Destaca por su facilidad de instalación y uso, integración nativa con la interfaz de nodos, y alta compatibilidad con workflows personalizados. Ideal para artistas digitales e investigadores que buscan generar imágenes de alta calidad con control granular sobre el proceso de inferencia."
    },
    {
      "id": "Qwen/Qwen2.5-1.5B-Instruct",
      "source": "hf",
      "name": "Qwen2.5-1.5B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "qwen2",
        "text-generation",
        "chat",
        "conversational",
        "en",
        "arxiv:2407.10671",
        "base_model:Qwen/Qwen2.5-1.5B",
        "base_model:finetune:Qwen/Qwen2.5-1.5B",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 5102307,
        "hf_likes": 513
      },
      "score": 10461.114,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2.5-1.5B-Instruct 是阿里云推出的一款轻量级指令微调语言模型，参数量为 1.5B。该模型基于 Qwen2.5 架构优化，具备较强的自然语言理解和生成能力，适用于对话、问答、文本摘要等任务。其轻量化设计使其能够在资源受限的环境中高效运行，适合部署在边缘设备或对推理速度有较高要求的场景。该模型在开源社区中广受欢迎，下载量和点赞数均表现突出。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Qwen2.5-1.5B-Instruct is a compact instruction-tuned language model optimized for efficient deployment. It excels in text generation, summarization, and question answering, making it suitable for chatbots, content creation, and lightweight AI assistants. Its small size enables fast inference on consumer hardware while maintaining strong performance for its parameter count. Ideal for applications requiring responsive, cost-effective language processing without heavy computational demands.",
      "summary_zh": "Qwen2.5-1.5B-Instruct 是阿里云推出的一款轻量级指令微调语言模型，参数量为 1.5B。该模型基于 Qwen2.5 架构优化，具备较强的自然语言理解和生成能力，适用于对话、问答、文本摘要等任务。其轻量化设计使其能够在资源受限的环境中高效运行，适合部署在边缘设备或对推理速度有较高要求的场景。该模型在开源社区中广受欢迎，下载量和点赞数均表现突出。",
      "summary_es": "Modelo de lenguaje ligero (1.5B parámetros) optimizado para instrucciones. Destaca por su eficiencia computacional, capacidad multilingüe y bajo consumo de recursos. Ideal para aplicaciones en dispositivos con limitaciones hardware, chatbots rápidos y procesamiento de texto en entornos restringidos."
    },
    {
      "id": "BAAI/bge-small-en-v1.5",
      "source": "hf",
      "name": "bge-small-en-v1.5",
      "url": "https://huggingface.co/BAAI/bge-small-en-v1.5",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "sentence-transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "bert",
        "feature-extraction",
        "sentence-similarity",
        "transformers",
        "mteb",
        "en",
        "arxiv:2401.03462",
        "arxiv:2312.15503",
        "arxiv:2311.13534",
        "arxiv:2310.07554",
        "arxiv:2309.07597",
        "license:mit",
        "model-index",
        "autotrain_compatible",
        "text-embeddings-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4988603,
        "hf_likes": 372
      },
      "score": 10163.206,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "bge-small-en-v1.5 是一个轻量级英文文本嵌入模型，由北京智源人工智能研究院（BAAI）开发。该模型基于 Sentence-BERT 架构优化，适用于语义搜索、文本相似度计算和检索增强生成（RAG）等任务。其核心优势在于平衡了性能与效率，在保持较高语义理解能力的同时显著降低了计算资源需求。该模型适合部署在资源受限的环境中，如边缘设备或需要快速响应的应用场景。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "BGE-small-en-v1.5 is a compact English text embedding model optimized for semantic similarity and retrieval tasks. It excels in applications like search, clustering, and recommendation systems, offering a balance between performance and efficiency. With strong performance on benchmarks and a small footprint, it is well-suited for production environments with resource constraints. Its popularity reflects its reliability for both research and practical deployment.",
      "summary_zh": "bge-small-en-v1.5 是一个轻量级英文文本嵌入模型，由北京智源人工智能研究院（BAAI）开发。该模型基于 Sentence-BERT 架构优化，适用于语义搜索、文本相似度计算和检索增强生成（RAG）等任务。其核心优势在于平衡了性能与效率，在保持较高语义理解能力的同时显著降低了计算资源需求。该模型适合部署在资源受限的环境中，如边缘设备或需要快速响应的应用场景。",
      "summary_es": "Modelo de embeddings de texto en inglés, optimizado para similitud semántica y búsqueda. Eficiente en tamaño y rendimiento, ideal para aplicaciones de recuperación de información, clustering y clasificación de documentos."
    },
    {
      "id": "coqui/XTTS-v2",
      "source": "hf",
      "name": "XTTS-v2",
      "url": "https://huggingface.co/coqui/XTTS-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "coqui",
        "text-to-speech",
        "license:other",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4799057,
        "hf_likes": 3040
      },
      "score": 11118.114,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "XTTS-v2 是一个高质量的多语言文本转语音模型，支持语音克隆功能。它能够基于几秒钟的参考音频生成与说话人音色高度相似的合成语音，同时支持多种语言和跨语言语音合成。该模型在语音自然度、情感表达和口音还原方面表现优异，适用于有声内容创作、语音助手、本地化项目以及无障碍服务等场景。开发者可以通过 Hugging Face 平台快速集成并使用这一模型。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "XTTS-v2 is a multilingual text-to-speech model supporting voice cloning with minimal reference audio. It excels in generating natural, expressive speech across languages, making it ideal for audiobook narration, voiceovers, and accessibility tools. Its open-source nature and strong community adoption highlight its reliability and versatility for both research and production use.",
      "summary_zh": "XTTS-v2 是一个高质量的多语言文本转语音模型，支持语音克隆功能。它能够基于几秒钟的参考音频生成与说话人音色高度相似的合成语音，同时支持多种语言和跨语言语音合成。该模型在语音自然度、情感表达和口音还原方面表现优异，适用于有声内容创作、语音助手、本地化项目以及无障碍服务等场景。开发者可以通过 Hugging Face 平台快速集成并使用这一模型。",
      "summary_es": "XTTS-v2 es un modelo de síntesis de voz multilingüe que genera habla natural a partir de texto. Destaca por su capacidad de clonación de voz con pocos datos de referencia y soporta múltiples idiomas. Ideal para aplicaciones de accesibilidad, narración automática y generación de contenido multimedia."
    },
    {
      "id": "dphn/dolphin-2.9.1-yi-1.5-34b",
      "source": "hf",
      "name": "dolphin-2.9.1-yi-1.5-34b",
      "url": "https://huggingface.co/dphn/dolphin-2.9.1-yi-1.5-34b",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "generated_from_trainer",
        "axolotl",
        "conversational",
        "dataset:cognitivecomputations/Dolphin-2.9",
        "dataset:teknium/OpenHermes-2.5",
        "dataset:m-a-p/CodeFeedback-Filtered-Instruction",
        "dataset:cognitivecomputations/dolphin-coder",
        "dataset:cognitivecomputations/samantha-data",
        "dataset:microsoft/orca-math-word-problems-200k",
        "dataset:Locutusque/function-calling-chatml",
        "dataset:internlm/Agent-FLAN",
        "base_model:01-ai/Yi-1.5-34B",
        "base_model:finetune:01-ai/Yi-1.5-34B",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4702460,
        "hf_likes": 39
      },
      "score": 9424.42,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "dolphin-2.9.1-yi-1.5-34b 是一个基于 Yi-34B 语言模型微调的开源对话模型，由社区开发者 dphn 发布。该模型在保持 Yi-34B 强大推理能力的基础上，通过高质量数据微调提升了对话生成的自然度和实用性。其亮点在于支持多轮对话、代码生成、逻辑推理等任务，适用于聊天助手、内容创作和编程辅助等场景。模型在 Hugging Face 平台获得较高下载量，显示出社区对其性能的认可。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Dolphin 2.9.1 Yi 1.5 34B is a fine-tuned language model based on Yi-34B, optimized for instruction following and conversational tasks. It excels in generating coherent, context-aware responses across diverse topics, making it suitable for chatbots, content creation, and research assistance. Its strong performance and open-source availability support developers in building AI-driven applications without proprietary constraints. The model's high download count reflects its practical utility and community adoption.",
      "summary_zh": "dolphin-2.9.1-yi-1.5-34b 是一个基于 Yi-34B 语言模型微调的开源对话模型，由社区开发者 dphn 发布。该模型在保持 Yi-34B 强大推理能力的基础上，通过高质量数据微调提升了对话生成的自然度和实用性。其亮点在于支持多轮对话、代码生成、逻辑推理等任务，适用于聊天助手、内容创作和编程辅助等场景。模型在 Hugging Face 平台获得较高下载量，显示出社区对其性能的认可。",
      "summary_es": "Dolphin 2.9.1 Yi 1.5 34B es un modelo de lenguaje de gran tamaño basado en Yi-34B, optimizado para tareas de procesamiento de lenguaje natural. Destaca por su capacidad de comprensión contextual y generación de respuestas coherentes. Es ideal para aplicaciones de asistencia virtual, análisis de texto y automatización de contenido. Su arquitectura permite un alto rendimiento en entornos de producción."
    },
    {
      "id": "google-bert/bert-base-multilingual-cased",
      "source": "hf",
      "name": "bert-base-multilingual-cased",
      "url": "https://huggingface.co/google-bert/bert-base-multilingual-cased",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "safetensors",
        "bert",
        "fill-mask",
        "multilingual",
        "af",
        "sq",
        "ar",
        "an",
        "hy",
        "ast",
        "az",
        "ba",
        "eu",
        "bar",
        "be",
        "bn",
        "inc",
        "bs",
        "br",
        "bg",
        "my",
        "ca",
        "ceb",
        "ce",
        "zh",
        "cv",
        "hr",
        "cs",
        "da",
        "nl",
        "en",
        "et",
        "fi",
        "fr",
        "gl",
        "ka",
        "de",
        "el",
        "gu",
        "ht",
        "he",
        "hi",
        "hu",
        "is",
        "io",
        "id",
        "ga",
        "it",
        "ja",
        "jv",
        "kn",
        "kk",
        "ky",
        "ko",
        "la",
        "lv",
        "lt",
        "roa",
        "nds",
        "lm",
        "mk",
        "mg",
        "ms",
        "ml",
        "mr",
        "mn",
        "min",
        "ne",
        "new",
        "nb",
        "nn",
        "oc",
        "fa",
        "pms",
        "pl",
        "pt",
        "pa",
        "ro",
        "ru",
        "sco",
        "sr",
        "scn",
        "sk",
        "sl",
        "aze",
        "es",
        "su",
        "sw",
        "sv",
        "tl",
        "tg",
        "th",
        "ta",
        "tt",
        "te",
        "tr",
        "uk",
        "ud",
        "uz",
        "vi",
        "vo",
        "war",
        "cy",
        "fry",
        "pnb",
        "yo",
        "dataset:wikipedia",
        "arxiv:1810.04805",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4659250,
        "hf_likes": 530
      },
      "score": 9583.5,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "BERT-base-multilingual-cased 是一个多语言预训练语言模型，由 Google 开发并开源。该模型基于 Transformer 架构，支持 104 种语言，适用于跨语言的文本理解任务，如文本分类、命名实体识别和问答系统。其亮点在于能够处理多语言输入，并在不同语言间实现语义对齐，适用于全球化应用场景。该模型在 Hugging Face 平台上广受欢迎，下载量和使用率较高。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "BERT-base-multilingual-cased is a transformer-based model pre-trained on text from 104 languages. It excels in multilingual NLP tasks such as text classification, named entity recognition, and question answering. Its key strength is cross-lingual transfer, enabling effective performance even with limited language-specific data. This model is widely applicable for building scalable, language-agnostic NLP systems.",
      "summary_zh": "BERT-base-multilingual-cased 是一个多语言预训练语言模型，由 Google 开发并开源。该模型基于 Transformer 架构，支持 104 种语言，适用于跨语言的文本理解任务，如文本分类、命名实体识别和问答系统。其亮点在于能够处理多语言输入，并在不同语言间实现语义对齐，适用于全球化应用场景。该模型在 Hugging Face 平台上广受欢迎，下载量和使用率较高。",
      "summary_es": "Modelo BERT multilingüe preentrenado para procesamiento de lenguaje natural. Soporta 104 idiomas, ideal para tareas como clasificación de texto, análisis de sentimientos y extracción de entidades. Su arquitectura basada en transformers permite un alto rendimiento en aplicaciones multilingües. Ampliamente utilizado en investigación y desarrollo de sistemas NLP."
    },
    {
      "id": "sentence-transformers/gtr-t5-base",
      "source": "hf",
      "name": "gtr-t5-base",
      "url": "https://huggingface.co/sentence-transformers/gtr-t5-base",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "sentence-transformers",
        "pytorch",
        "safetensors",
        "t5",
        "feature-extraction",
        "sentence-similarity",
        "en",
        "arxiv:2112.07899",
        "license:apache-2.0",
        "autotrain_compatible",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4568932,
        "hf_likes": 25
      },
      "score": 9150.364,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "gtr-t5-base是基于T5架构的文本嵌入模型，专注于生成高质量的句子向量表示。该模型通过对比学习进行训练，能够有效捕捉语义信息，适用于文本检索、语义相似度计算和聚类任务。其优势在于平衡了计算效率与表示能力，适合处理大规模文本数据。典型应用场景包括搜索引擎优化、推荐系统和文档去重。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "GTR-T5-base is a text embedding model based on T5, fine-tuned for generating dense vector representations of sentences or paragraphs. It excels in semantic search, retrieval, and clustering tasks, offering strong performance in cross-lingual and monolingual settings. Its balanced efficiency and accuracy make it suitable for applications like document similarity, recommendation systems, and information retrieval. The model is widely adopted due to its versatility and robust performance across diverse domains.",
      "summary_zh": "gtr-t5-base是基于T5架构的文本嵌入模型，专注于生成高质量的句子向量表示。该模型通过对比学习进行训练，能够有效捕捉语义信息，适用于文本检索、语义相似度计算和聚类任务。其优势在于平衡了计算效率与表示能力，适合处理大规模文本数据。典型应用场景包括搜索引擎优化、推荐系统和文档去重。",
      "summary_es": "Modelo de embeddings de texto basado en T5. Genera representaciones vectoriales densas para búsqueda semántica, clustering y clasificación. Destaca por su eficiencia en recuperación de información y similitud textual. Ideal para sistemas de recomendación y motores de búsqueda semánticos."
    },
    {
      "id": "openai/whisper-large-v3",
      "source": "hf",
      "name": "whisper-large-v3",
      "url": "https://huggingface.co/openai/whisper-large-v3",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "jax",
        "safetensors",
        "whisper",
        "automatic-speech-recognition",
        "audio",
        "hf-asr-leaderboard",
        "en",
        "zh",
        "de",
        "es",
        "ru",
        "ko",
        "fr",
        "ja",
        "pt",
        "tr",
        "pl",
        "ca",
        "nl",
        "ar",
        "sv",
        "it",
        "id",
        "hi",
        "fi",
        "vi",
        "he",
        "uk",
        "el",
        "ms",
        "cs",
        "ro",
        "da",
        "hu",
        "ta",
        "no",
        "th",
        "ur",
        "hr",
        "bg",
        "lt",
        "la",
        "mi",
        "ml",
        "cy",
        "sk",
        "te",
        "fa",
        "lv",
        "bn",
        "sr",
        "az",
        "sl",
        "kn",
        "et",
        "mk",
        "br",
        "eu",
        "is",
        "hy",
        "ne",
        "mn",
        "bs",
        "kk",
        "sq",
        "sw",
        "gl",
        "mr",
        "pa",
        "si",
        "km",
        "sn",
        "yo",
        "so",
        "af",
        "oc",
        "ka",
        "be",
        "tg",
        "sd",
        "gu",
        "am",
        "yi",
        "lo",
        "uz",
        "fo",
        "ht",
        "ps",
        "tk",
        "nn",
        "mt",
        "sa",
        "lb",
        "my",
        "bo",
        "tl",
        "mg",
        "as",
        "tt",
        "haw",
        "ln",
        "ha",
        "ba",
        "jw",
        "su",
        "arxiv:2212.04356",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4534605,
        "hf_likes": 4913
      },
      "score": 11525.710000000001,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Whisper-large-v3 是 OpenAI 推出的开源语音识别模型，支持多语言转录和翻译任务。该模型基于大规模音频数据训练，具备高精度的语音转文本能力，适用于多种音频场景。其亮点包括强大的噪声鲁棒性、跨语言支持以及端到端的处理流程，无需额外预处理。适用于视频字幕生成、会议记录、多语言内容翻译等实际应用场景。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Whisper-large-v3 is a powerful automatic speech recognition (ASR) model designed for transcribing audio in multiple languages. It excels in handling diverse accents, background noise, and technical vocabulary, making it suitable for applications like transcription services, subtitling, and voice assistants. Its open-source availability allows integration into research, commercial tools, and accessibility solutions. The model balances high accuracy with broad language support, though it requires substantial computational resources for optimal performance.",
      "summary_zh": "Whisper-large-v3 是 OpenAI 推出的开源语音识别模型，支持多语言转录和翻译任务。该模型基于大规模音频数据训练，具备高精度的语音转文本能力，适用于多种音频场景。其亮点包括强大的噪声鲁棒性、跨语言支持以及端到端的处理流程，无需额外预处理。适用于视频字幕生成、会议记录、多语言内容翻译等实际应用场景。",
      "summary_es": "Whisper-large-v3 es un modelo de reconocimiento de voz multilingüe de OpenAI. Destaca por su alta precisión en transcripción y traducción automática, soportando 99 idiomas. Es ideal para aplicaciones de subtitulado, análisis de audio y procesamiento de contenido multilingüe. Su arquitectura robusta lo hace adecuado tanto para investigación como para implementaciones productivas."
    },
    {
      "id": "google-t5/t5-small",
      "source": "hf",
      "name": "t5-small",
      "url": "https://huggingface.co/google-t5/t5-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "tf",
        "jax",
        "rust",
        "onnx",
        "safetensors",
        "t5",
        "text2text-generation",
        "summarization",
        "translation",
        "en",
        "fr",
        "ro",
        "de",
        "multilingual",
        "dataset:c4",
        "arxiv:1805.12471",
        "arxiv:1708.00055",
        "arxiv:1704.05426",
        "arxiv:1606.05250",
        "arxiv:1808.09121",
        "arxiv:1810.12885",
        "arxiv:1905.10044",
        "arxiv:1910.09700",
        "license:apache-2.0",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4480628,
        "hf_likes": 488
      },
      "score": 9205.256,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "t5-small是谷歌推出的轻量级文本生成模型，基于Transformer架构，适用于多种自然语言处理任务。该模型支持文本摘要、翻译、问答和文本分类，具有参数少、推理速度快的特点。其预训练设计使其能够通过简单的提示适应不同下游任务，适合资源受限环境或需要快速部署的场景。开发者可将其用于原型验证或轻量级应用开发。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "t5-small is a compact, efficient text-to-text transformer model from Google. It excels at a wide range of NLP tasks, including summarization, translation, and question answering, by framing them as text generation problems. Its small size makes it suitable for resource-constrained environments, such as edge devices or applications with limited computational power. It is widely used for prototyping and lightweight production deployments.",
      "summary_zh": "t5-small是谷歌推出的轻量级文本生成模型，基于Transformer架构，适用于多种自然语言处理任务。该模型支持文本摘要、翻译、问答和文本分类，具有参数少、推理速度快的特点。其预训练设计使其能够通过简单的提示适应不同下游任务，适合资源受限环境或需要快速部署的场景。开发者可将其用于原型验证或轻量级应用开发。",
      "summary_es": "T5-small es un modelo de texto-a-texto compacto para tareas de procesamiento de lenguaje natural. Ideal para traducción, resumen y clasificación de texto con recursos limitados. Su arquitectura unificada simplifica el ajuste para múltiples aplicaciones."
    },
    {
      "id": "google/t5gemma-b-b-prefixlm",
      "source": "hf",
      "name": "t5gemma-b-b-prefixlm",
      "url": "https://huggingface.co/google/t5gemma-b-b-prefixlm",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "t5gemma",
        "text2text-generation",
        "arxiv:2504.06225",
        "arxiv:2009.03300",
        "arxiv:1905.07830",
        "arxiv:1911.11641",
        "arxiv:1905.10044",
        "arxiv:1907.10641",
        "arxiv:1911.01547",
        "arxiv:1705.03551",
        "arxiv:2107.03374",
        "arxiv:2108.07732",
        "arxiv:2110.14168",
        "arxiv:2103.03874",
        "arxiv:2304.06364",
        "arxiv:2206.04615",
        "base_model:google/t5gemma-b-b-prefixlm",
        "base_model:finetune:google/t5gemma-b-b-prefixlm",
        "license:gemma",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4427910,
        "hf_likes": 8
      },
      "score": 8859.82,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "t5gemma-b-b-prefixlm 是 Google 推出的一个基于 T5 和 Gemma 架构的预训练语言模型，专注于前缀语言建模任务。该模型结合了编码器-解码器结构，适用于文本生成、摘要、翻译等多种自然语言处理任务。其亮点在于高效的多任务学习能力和较强的泛化性能，能够处理不同长度的输入和输出。适用于需要高质量文本生成和语义理解的应用场景，如对话系统、内容创作和自动化文档处理。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "T5Gemma-B-B-PrefixLM is a versatile encoder-decoder model combining T5 and Gemma architectures, optimized for prefix language modeling. It excels in text generation, summarization, and question answering tasks, leveraging bidirectional context for improved coherence. Its strengths include efficient handling of long sequences and robust performance across diverse domains. Ideal for research and applications requiring nuanced language understanding and generation.",
      "summary_zh": "t5gemma-b-b-prefixlm 是 Google 推出的一个基于 T5 和 Gemma 架构的预训练语言模型，专注于前缀语言建模任务。该模型结合了编码器-解码器结构，适用于文本生成、摘要、翻译等多种自然语言处理任务。其亮点在于高效的多任务学习能力和较强的泛化性能，能够处理不同长度的输入和输出。适用于需要高质量文本生成和语义理解的应用场景，如对话系统、内容创作和自动化文档处理。",
      "summary_es": "Modelo T5-Gemma de Google para generación de texto. Combina arquitecturas T5 y Gemma para tareas de lenguaje natural. Destaca por su eficiencia en inferencia y capacidad de procesamiento de prefijos. Ideal para aplicaciones de generación de texto y procesamiento de lenguaje natural."
    },
    {
      "id": "trl-internal-testing/tiny-Qwen2ForCausalLM-2.5",
      "source": "hf",
      "name": "tiny-Qwen2ForCausalLM-2.5",
      "url": "https://huggingface.co/trl-internal-testing/tiny-Qwen2ForCausalLM-2.5",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "qwen2",
        "text-generation",
        "trl",
        "conversational",
        "autotrain_compatible",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4417381,
        "hf_likes": 1
      },
      "score": 8835.262,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "tiny-Qwen2ForCausalLM-2.5 是一个轻量级的因果语言模型，基于 Qwen2 架构设计，适用于文本生成任务。该模型参数量较小，但保持了良好的推理能力，适合在资源受限的环境中部署。其主要亮点包括高效的推理速度和较低的计算开销，可用于对话生成、文本补全等场景。该模型适用于需要快速响应的应用，如聊天机器人或辅助写作工具。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "tiny-Qwen2ForCausalLM-2.5 is a compact, open-source language model optimized for causal language modeling tasks. It is well-suited for lightweight applications such as text generation, summarization, and question answering in resource-constrained environments. Its small size ensures fast inference and low computational overhead, making it ideal for edge devices or prototyping. Despite its compact architecture, it maintains reasonable performance for basic NLP use cases.",
      "summary_zh": "tiny-Qwen2ForCausalLM-2.5 是一个轻量级的因果语言模型，基于 Qwen2 架构设计，适用于文本生成任务。该模型参数量较小，但保持了良好的推理能力，适合在资源受限的环境中部署。其主要亮点包括高效的推理速度和较低的计算开销，可用于对话生成、文本补全等场景。该模型适用于需要快速响应的应用，如聊天机器人或辅助写作工具。",
      "summary_es": "Modelo causal de lenguaje pequeño basado en Qwen2. Ideal para pruebas de rendimiento y prototipado rápido. Optimizado para inferencia eficiente en entornos con recursos limitados. Útil en desarrollo de agentes conversacionales y generación de texto básica."
    },
    {
      "id": "Comfy-Org/Wan_2.1_ComfyUI_repackaged",
      "source": "hf",
      "name": "Wan_2.1_ComfyUI_repackaged",
      "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "diffusion-single-file",
        "comfyui",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4373437,
        "hf_likes": 746
      },
      "score": 9119.874,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Wan_2.1_ComfyUI_repackaged 是一个基于 ComfyUI 框架重新封装的图像生成模型，适用于本地部署和自定义工作流。该模型在保持 Wan 2.1 原有生成能力的基础上，优化了与 ComfyUI 的兼容性，提升了用户操作的便捷性。其亮点在于支持节点式界面，允许用户灵活调整生成参数，适用于艺术创作、设计原型和实验性图像生成等场景。该版本在社区中广受欢迎，尤其适合熟悉 ComfyUI 工作流的用户。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Wan 2.1 ComfyUI Repackaged is a user-friendly, repackaged version of the Wan 2.1 model optimized for the ComfyUI interface. It enables efficient image generation and editing workflows, particularly for creative and design tasks. Its strengths include ease of integration, stable performance, and broad compatibility with ComfyUI extensions. This makes it suitable for artists, developers, and hobbyists seeking streamlined AI-assisted visual content creation.",
      "summary_zh": "Wan_2.1_ComfyUI_repackaged 是一个基于 ComfyUI 框架重新封装的图像生成模型，适用于本地部署和自定义工作流。该模型在保持 Wan 2.1 原有生成能力的基础上，优化了与 ComfyUI 的兼容性，提升了用户操作的便捷性。其亮点在于支持节点式界面，允许用户灵活调整生成参数，适用于艺术创作、设计原型和实验性图像生成等场景。该版本在社区中广受欢迎，尤其适合熟悉 ComfyUI 工作流的用户。",
      "summary_es": "Wan_2.1_ComfyUI_repackaged es un modelo de generación de imágenes optimizado para ComfyUI. Destaca por su alta calidad visual y versatilidad en la creación de ilustraciones y arte digital. Su integración con ComfyUI facilita flujos de trabajo personalizados y procesamiento por lotes. Ideal para artistas digitales y creadores de contenido que buscan resultados detallados y coherentes."
    },
    {
      "id": "jinaai/jina-embeddings-v3",
      "source": "hf",
      "name": "jina-embeddings-v3",
      "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "feature-extraction",
        "sentence-similarity",
        "mteb",
        "sentence-transformers",
        "custom_code",
        "multilingual",
        "af",
        "am",
        "ar",
        "as",
        "az",
        "be",
        "bg",
        "bn",
        "br",
        "bs",
        "ca",
        "cs",
        "cy",
        "da",
        "de",
        "el",
        "en",
        "eo",
        "es",
        "et",
        "eu",
        "fa",
        "fi",
        "fr",
        "fy",
        "ga",
        "gd",
        "gl",
        "gu",
        "ha",
        "he",
        "hi",
        "hr",
        "hu",
        "hy",
        "id",
        "is",
        "it",
        "ja",
        "jv",
        "ka",
        "kk",
        "km",
        "kn",
        "ko",
        "ku",
        "ky",
        "la",
        "lo",
        "lt",
        "lv",
        "mg",
        "mk",
        "ml",
        "mn",
        "mr",
        "ms",
        "my",
        "ne",
        "nl",
        "no",
        "om",
        "or",
        "pa",
        "pl",
        "ps",
        "pt",
        "ro",
        "ru",
        "sa",
        "sd",
        "si",
        "sk",
        "sl",
        "so",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "th",
        "tl",
        "tr",
        "ug",
        "uk",
        "ur",
        "uz",
        "vi",
        "xh",
        "yi",
        "zh",
        "arxiv:2409.10173",
        "license:cc-by-nc-4.0",
        "model-index",
        "region:eu"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4347061,
        "hf_likes": 1068
      },
      "score": 9228.122,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Jina Embeddings V3 是一个开源文本嵌入模型，支持 8192 上下文长度，适用于多语言文本检索、语义搜索和相似度计算等任务。该模型在多个基准测试中表现优异，尤其在跨语言场景下具有较高的泛化能力。其亮点在于支持 100 多种语言，同时保持了较高的计算效率和较低的部署成本。适用于构建搜索引擎、推荐系统、文档分析等应用场景。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Jina Embeddings v3 is a high-performance text embedding model designed for semantic search, retrieval, and clustering tasks. It supports 8K context length and 8192 output dimensions, making it suitable for long-document processing and cross-lingual applications. The model excels in both English and multilingual contexts, offering strong performance on benchmarks like MTEB. It is open-source and optimized for practical deployment in search engines, recommendation systems, and AI-driven content analysis.",
      "summary_zh": "Jina Embeddings V3 是一个开源文本嵌入模型，支持 8192 上下文长度，适用于多语言文本检索、语义搜索和相似度计算等任务。该模型在多个基准测试中表现优异，尤其在跨语言场景下具有较高的泛化能力。其亮点在于支持 100 多种语言，同时保持了较高的计算效率和较低的部署成本。适用于构建搜索引擎、推荐系统、文档分析等应用场景。",
      "summary_es": "Jina Embeddings v3 es un modelo de embeddings de texto de código abierto, optimizado para búsqueda semántica y recuperación de información. Destaca por su alta eficiencia en tareas de RAG (Retrieval-Augmented Generation) y clustering de documentos. Es ideal para aplicaciones de búsqueda empresarial, recomendación de contenido y análisis de similitud textual."
    },
    {
      "id": "Qwen/Qwen2.5-VL-7B-Instruct",
      "source": "hf",
      "name": "Qwen2.5-VL-7B-Instruct",
      "url": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "qwen2_5_vl",
        "image-to-text",
        "multimodal",
        "image-text-to-text",
        "conversational",
        "en",
        "arxiv:2309.00071",
        "arxiv:2409.12191",
        "arxiv:2308.12966",
        "license:apache-2.0",
        "text-generation-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4255390,
        "hf_likes": 1245
      },
      "score": 9133.28,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Qwen2.5-VL-7B-Instruct 是一个多模态大语言模型，支持图像和文本输入，能够理解并生成自然语言响应。该模型基于 Qwen2.5 架构，具备 70 亿参数，在视觉-语言任务中表现优异，适用于图像问答、视觉推理和对话生成等场景。其亮点在于高效的推理能力和对复杂多模态任务的适配性，适合用于智能助手、内容分析和自动化客服等应用。模型开源且支持本地部署，为开发者和研究者提供了灵活的使用选择。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "Qwen2.5-VL-7B-Instruct is a 7-billion-parameter multimodal model designed for vision-language tasks. It excels in image understanding, visual question answering, and multimodal reasoning, making it suitable for applications in content analysis, education, and accessibility tools. Its strong performance and efficient size enable deployment in resource-constrained environments. The model is open-source and supports fine-tuning for specialized use cases.",
      "summary_zh": "Qwen2.5-VL-7B-Instruct 是一个多模态大语言模型，支持图像和文本输入，能够理解并生成自然语言响应。该模型基于 Qwen2.5 架构，具备 70 亿参数，在视觉-语言任务中表现优异，适用于图像问答、视觉推理和对话生成等场景。其亮点在于高效的推理能力和对复杂多模态任务的适配性，适合用于智能助手、内容分析和自动化客服等应用。模型开源且支持本地部署，为开发者和研究者提供了灵活的使用选择。",
      "summary_es": "Modelo de visión y lenguaje de 7B parámetros para tareas multimodales. Destaca en comprensión visual, generación de texto a partir de imágenes y razonamiento visual. Ideal para aplicaciones de análisis de imágenes, descripciones automáticas y asistentes visuales inteligentes."
    },
    {
      "id": "sentence-transformers/paraphrase-MiniLM-L6-v2",
      "source": "hf",
      "name": "paraphrase-MiniLM-L6-v2",
      "url": "https://huggingface.co/sentence-transformers/paraphrase-MiniLM-L6-v2",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "sentence-transformers",
        "pytorch",
        "tf",
        "onnx",
        "safetensors",
        "openvino",
        "bert",
        "feature-extraction",
        "sentence-similarity",
        "transformers",
        "arxiv:1908.10084",
        "license:apache-2.0",
        "autotrain_compatible",
        "text-embeddings-inference",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4236953,
        "hf_likes": 144
      },
      "score": 8545.906,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "paraphrase-MiniLM-L6-v2 是一个基于 MiniLM 架构的轻量级句子嵌入模型，专门用于语义相似度计算和文本复述检测。该模型通过对比学习训练，能够高效生成高质量的句子向量表示，适用于语义搜索、重复内容识别和文本聚类等任务。其参数量较小但性能优秀，在多个基准测试中表现稳定，尤其适合资源受限或需要快速响应的应用场景。该模型支持多语言文本处理，可广泛应用于搜索引擎优化、智能问答和文档去重等领域。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "A compact sentence transformer optimized for paraphrase identification and semantic similarity tasks. Excels in efficient text comparison, clustering, and retrieval with minimal computational overhead. Ideal for applications requiring fast, accurate semantic matching in resource-constrained environments.",
      "summary_zh": "paraphrase-MiniLM-L6-v2 是一个基于 MiniLM 架构的轻量级句子嵌入模型，专门用于语义相似度计算和文本复述检测。该模型通过对比学习训练，能够高效生成高质量的句子向量表示，适用于语义搜索、重复内容识别和文本聚类等任务。其参数量较小但性能优秀，在多个基准测试中表现稳定，尤其适合资源受限或需要快速响应的应用场景。该模型支持多语言文本处理，可广泛应用于搜索引擎优化、智能问答和文档去重等领域。",
      "summary_es": "Modelo de embeddings para detección de similitud semántica y paráfrasis. Basado en MiniLM-L6, genera representaciones vectoriales de texto. Usos: búsqueda semántica, clustering de documentos y deduplicación de contenido. Eficiente para aplicaciones con recursos limitados."
    },
    {
      "id": "Kijai/WanVideo_comfy",
      "source": "hf",
      "name": "WanVideo_comfy",
      "url": "https://huggingface.co/Kijai/WanVideo_comfy",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "diffusion-single-file",
        "comfyui",
        "base_model:Wan-AI/Wan2.1-VACE-1.3B",
        "base_model:finetune:Wan-AI/Wan2.1-VACE-1.3B",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4092644,
        "hf_likes": 1423
      },
      "score": 8896.788,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "WanVideo_comfy 是一个基于 ComfyUI 的视频生成模型，专注于高质量、可控的视频内容创作。该模型支持文本到视频和图像到视频的生成，适用于动画制作、创意内容生成和动态视觉设计等场景。其亮点在于能够生成流畅且细节丰富的视频片段，同时提供灵活的节点式工作流，方便用户进行精细化调整。该模型适合需要定制化视频内容的创作者和技术团队使用。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "WanVideo_comfy is a diffusion-based video generation model designed for creating short video clips from text prompts. It excels at producing smooth, coherent animations and is particularly useful for content creators, artists, and developers seeking to generate dynamic visuals. The model integrates seamlessly with ComfyUI workflows, offering flexibility and ease of use. Its high download count reflects strong community adoption for applications in entertainment, prototyping, and digital art.",
      "summary_zh": "WanVideo_comfy 是一个基于 ComfyUI 的视频生成模型，专注于高质量、可控的视频内容创作。该模型支持文本到视频和图像到视频的生成，适用于动画制作、创意内容生成和动态视觉设计等场景。其亮点在于能够生成流畅且细节丰富的视频片段，同时提供灵活的节点式工作流，方便用户进行精细化调整。该模型适合需要定制化视频内容的创作者和技术团队使用。",
      "summary_es": "WanVideo_comfy es un nodo para ComfyUI que permite generar videos a partir de texto. Su principal fortaleza es la integración fluida con flujos de trabajo de IA, facilitando la creación de contenido visual dinámico. Es ideal para artistas digitales, creadores de contenido e investigadores que necesitan prototipar animaciones o secuencias visuales de forma rápida y personalizable."
    },
    {
      "id": "timm/resnet50.a1_in1k",
      "source": "hf",
      "name": "resnet50.a1_in1k",
      "url": "https://huggingface.co/timm/resnet50.a1_in1k",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "timm",
        "pytorch",
        "safetensors",
        "image-classification",
        "transformers",
        "arxiv:2110.00476",
        "arxiv:1512.03385",
        "license:apache-2.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "hf_downloads_7d": 4086268,
        "hf_likes": 39
      },
      "score": 8192.036,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "ResNet50.a1_in1k 是基于 ResNet-50 架构的深度残差网络模型，在 ImageNet-1k 数据集上完成训练。该模型通过引入改进的训练策略和正则化技术，显著提升了图像分类任务的准确性和泛化能力。其核心亮点在于优化了模型收敛速度和特征表达能力，适用于图像识别、目标检测以及迁移学习等场景。该模型在开源社区中广受欢迎，可作为计算机视觉任务的高效基线模型。",
      "updated_at": "2025-09-18T19:21:47.074Z",
      "summary_en": "ResNet50.a1_in1k is a variant of the ResNet-50 architecture, pretrained on ImageNet-1k with aggressive augmentation. It excels in image classification tasks, offering strong performance and robustness due to its enhanced training regimen. The model is well-suited for transfer learning in computer vision applications, including object detection and segmentation. Its high download count reflects widespread adoption and reliability in both research and production environments.",
      "summary_zh": "ResNet50.a1_in1k 是基于 ResNet-50 架构的深度残差网络模型，在 ImageNet-1k 数据集上完成训练。该模型通过引入改进的训练策略和正则化技术，显著提升了图像分类任务的准确性和泛化能力。其核心亮点在于优化了模型收敛速度和特征表达能力，适用于图像识别、目标检测以及迁移学习等场景。该模型在开源社区中广受欢迎，可作为计算机视觉任务的高效基线模型。",
      "summary_es": "ResNet50.a1_in1k es una variante optimizada de ResNet-50 entrenada en ImageNet-1k. Ofrece alta precisión en clasificación de imágenes con mejoras en estabilidad y velocidad de entrenamiento. Ideal para aplicaciones de visión por computadora, transfer learning y despliegue en producción."
    }
  ]
}