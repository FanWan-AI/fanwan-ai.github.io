{
  "version": 1,
  "updated_at": "2025-09-27T16:29:20.296Z",
  "by_category": {
    "image_classification": [
      {
        "id": "timm/mobilenetv3_small_100.lamb_in1k",
        "source": "hf",
        "name": "mobilenetv3_small_100.lamb_in1k",
        "url": "https://huggingface.co/timm/mobilenetv3_small_100.lamb_in1k",
        "tags": [
          "timm",
          "pytorch",
          "safetensors",
          "image-classification",
          "transformers",
          "dataset:imagenet-1k",
          "arxiv:2110.00476",
          "arxiv:1905.02244",
          "license:apache-2.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 119940003,
          "likes_total": 38,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "MobileNetV3-Small-100是一种专为移动和边缘设备优化的轻量级卷积神经网络。基于MobileNetV3架构，采用深度可分离卷积和压缩激励模块提高效率。此特定变体使用LAMB优化器在ImageNet-1k数据集上训练。核心能力包括图像分类，具有极低计算需求。主要优势在于高速推理、小内存占用和能效高，同时保持合理精度。典型应用场景包括移动视觉应用、嵌入式系统和实时图像识别，特别适用于计算资源受限的环境。该模型通过神经网络架构搜索技术优化，平衡了速度与准确性的权衡。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification"
        ],
        "summary_en": "MobileNetV3-Small-100 is a lightweight convolutional neural network optimized for mobile and edge devices. Based on the MobileNetV3 architecture, it uses depthwise separable convolutions and squeeze-and-excitation modules for efficiency. This specific variant employs LAMB optimizer training on ImageNet-1k. Core capabilities include image classification with minimal computational requirements. Strengths are high speed, low memory footprint, and energy efficiency while maintaining reasonable accuracy. Typical use cases include mobile vision applications, embedded systems, and real-time image recognition where computational resources are constrained.",
        "summary_zh": "MobileNetV3-Small-100是一种专为移动和边缘设备优化的轻量级卷积神经网络。基于MobileNetV3架构，采用深度可分离卷积和压缩激励模块提高效率。此特定变体使用LAMB优化器在ImageNet-1k数据集上训练。核心能力包括图像分类，具有极低计算需求。主要优势在于高速推理、小内存占用和能效高，同时保持合理精度。典型应用场景包括移动视觉应用、嵌入式系统和实时图像识别，特别适用于计算资源受限的环境。该模型通过神经网络架构搜索技术优化，平衡了速度与准确性的权衡。",
        "summary_es": "MobileNetV3-Small-100 is a lightweight convolutional neural network optimized for mobile and edge devices. Based on the MobileNetV3 architecture, it uses depthwise separable convolutions and squeeze-and-excitation modules for efficiency. This specific variant employs LAMB optimizer training on ImageNet-1k. Core capabilities include image classification with minimal computational requirements. Strengths are high speed, low memory footprint, and energy efficiency while maintaining reasonable accuracy. Typical use cases include mobile vision applications, embedded systems, and real-time image recognition where computational resources are constrained."
      },
      {
        "id": "Falconsai/nsfw_image_detection",
        "source": "hf",
        "name": "nsfw_image_detection",
        "url": "https://huggingface.co/Falconsai/nsfw_image_detection",
        "tags": [
          "transformers",
          "pytorch",
          "safetensors",
          "vit",
          "image-classification",
          "arxiv:2010.11929",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 99881324,
          "likes_total": 826,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "image_text_alignment",
          "auto_evaluation_models",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems.",
        "summary_zh": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "summary_es": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems."
      },
      {
        "id": "trpakov/vit-face-expression",
        "source": "hf",
        "name": "vit-face-expression",
        "url": "https://huggingface.co/trpakov/vit-face-expression",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "vit",
          "image-classification",
          "doi:10.57967/hf/2289",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 9225303,
          "likes_total": 80,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "vit-face-expression是一个基于Vision Transformer架构的面部表情分类模型，专门用于识别七种基本情绪：愤怒、厌恶、恐惧、快乐、中性、悲伤和惊讶。该模型支持ONNX和PyTorch格式，可通过Transformers库便捷部署。核心优势包括高效的面部图像处理能力和与Hugging Face生态系统的无缝集成。典型应用场景涵盖心理学研究中的情绪分析、用户体验测试、内容审核系统以及需要实时情绪识别的人机交互应用。模型采用Apache 2.0许可，提供了安全张量格式，适用于生产环境中的情感计算任务。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "tool_use",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "vit-face-expression is a Vision Transformer model fine-tuned for facial expression classification. It identifies seven basic emotions: anger, disgust, fear, happiness, neutrality, sadness, and surprise. The model is compatible with ONNX and PyTorch, optimized for deployment via Transformers library. Its strengths include efficient processing of facial images and integration with Hugging Face ecosystem. Typical use cases encompass emotion analysis in psychology research, user experience testing, content moderation, and human-computer interaction systems requiring real-time emotional state recognition from visual inputs.",
        "summary_zh": "vit-face-expression是一个基于Vision Transformer架构的面部表情分类模型，专门用于识别七种基本情绪：愤怒、厌恶、恐惧、快乐、中性、悲伤和惊讶。该模型支持ONNX和PyTorch格式，可通过Transformers库便捷部署。核心优势包括高效的面部图像处理能力和与Hugging Face生态系统的无缝集成。典型应用场景涵盖心理学研究中的情绪分析、用户体验测试、内容审核系统以及需要实时情绪识别的人机交互应用。模型采用Apache 2.0许可，提供了安全张量格式，适用于生产环境中的情感计算任务。",
        "summary_es": "vit-face-expression is a Vision Transformer model fine-tuned for facial expression classification. It identifies seven basic emotions: anger, disgust, fear, happiness, neutrality, sadness, and surprise. The model is compatible with ONNX and PyTorch, optimized for deployment via Transformers library. Its strengths include efficient processing of facial images and integration with Hugging Face ecosystem. Typical use cases encompass emotion analysis in psychology research, user experience testing, content moderation, and human-computer interaction systems requiring real-time emotional state recognition from visual inputs."
      },
      {
        "id": "google/vit-base-patch16-224-in21k",
        "source": "hf",
        "name": "vit-base-patch16-224-in21k",
        "url": "https://huggingface.co/google/vit-base-patch16-224-in21k",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "vit",
          "image-feature-extraction",
          "vision",
          "dataset:imagenet-21k",
          "arxiv:2010.11929",
          "arxiv:2006.03677",
          "license:apache-2.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6354784,
          "likes_total": 372,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该Vision Transformer（ViT）基础模型通过将图像分割为16x16像素块，将其作为序列进行基于Transformer的分析。在ImageNet-21k上预训练，擅长图像分类和特征提取，无需卷积层。核心优势包括强大的迁移学习性能、对大规模数据集的可扩展性以及多框架兼容性（PyTorch、TensorFlow、JAX）。典型应用场景包括针对特定视觉任务进行微调、作为下游应用的特征提取器，以及在计算机视觉研究中与卷积神经网络进行基准测试。该模型基于Transformer架构，将图像处理转化为序列问题，展示了在视觉任务中替代传统卷积方法的有效",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification"
        ],
        "summary_en": "The Vision Transformer (ViT) base model processes images by dividing them into 16x16 pixel patches, treating them as sequences for transformer-based analysis. Pre-trained on ImageNet-21k, it excels at image classification and feature extraction without convolutional layers. Core strengths include strong transfer learning performance, scalability to large datasets, and compatibility with multiple frameworks (PyTorch, TensorFlow, JAX). Typical use cases involve fine-tuning for specific vision tasks, serving as a feature extractor for downstream applications, and benchmarking against convolutional neural networks in computer vision research.",
        "summary_zh": "该Vision Transformer（ViT）基础模型通过将图像分割为16x16像素块，将其作为序列进行基于Transformer的分析。在ImageNet-21k上预训练，擅长图像分类和特征提取，无需卷积层。核心优势包括强大的迁移学习性能、对大规模数据集的可扩展性以及多框架兼容性（PyTorch、TensorFlow、JAX）。典型应用场景包括针对特定视觉任务进行微调、作为下游应用的特征提取器，以及在计算机视觉研究中与卷积神经网络进行基准测试。该模型基于Transformer架构，将图像处理转化为序列问题，展示了在视觉任务中替代传统卷积方法的有效",
        "summary_es": "The Vision Transformer (ViT) base model processes images by dividing them into 16x16 pixel patches, treating them as sequences for transformer-based analysis. Pre-trained on ImageNet-21k, it excels at image classification and feature extraction without convolutional layers. Core strengths include strong transfer learning performance, scalability to large datasets, and compatibility with multiple frameworks (PyTorch, TensorFlow, JAX). Typical use cases involve fine-tuning for specific vision tasks, serving as a feature extractor for downstream applications, and benchmarking against convolutional neural networks in computer vision research."
      }
    ],
    "object_detection": [
      {
        "id": "Falconsai/nsfw_image_detection",
        "source": "hf",
        "name": "nsfw_image_detection",
        "url": "https://huggingface.co/Falconsai/nsfw_image_detection",
        "tags": [
          "transformers",
          "pytorch",
          "safetensors",
          "vit",
          "image-classification",
          "arxiv:2010.11929",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 99881324,
          "likes_total": 826,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "image_text_alignment",
          "auto_evaluation_models",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems.",
        "summary_zh": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "summary_es": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems."
      },
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "tech4humans/yolov8s-signature-detector",
        "source": "hf",
        "name": "yolov8s-signature-detector",
        "url": "https://huggingface.co/tech4humans/yolov8s-signature-detector",
        "tags": [
          "ultralytics",
          "tensorboard",
          "onnx",
          "object-detection",
          "signature-detection",
          "yolo",
          "yolov8",
          "pytorch",
          "dataset:tech4humans/signature-detection",
          "base_model:Ultralytics/YOLOv8",
          "base_model:quantized:Ultralytics/YOLOv8",
          "license:agpl-3.0",
          "model-index",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 40068912,
          "likes_total": 44,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "yolov8s-signature-detector 是一个专门用于文档中签名检测的目标识别模型。该模型基于 Ultralytics YOLOv8 架构构建，提供自动化的签名定位功能。它使用专门的签名检测数据集进行训练，支持 ONNX 和 PyTorch 等多种部署格式。主要优势在于为文档处理流程提供高效的签名识别能力。典型应用场景包括自动化文档验证系统、数字归档管理以及需要签名检测的行政处理流程。该模型专注于提升文档处理中签名识别的准确性和效率，适用于各种需要自动检测签名的业务场景。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection"
        ],
        "summary_en": "The yolov8s-signature-detector is an object detection model specifically designed to identify signatures in documents. Built on Ultralytics YOLOv8 architecture, it provides automated signature localization capabilities. The model is trained on a specialized signature detection dataset and supports multiple deployment formats including ONNX and PyTorch. Its primary strength lies in efficient signature recognition for document processing workflows. Typical use cases include automated document verification, digital archiving systems, and administrative processing where signature detection is required.",
        "summary_zh": "yolov8s-signature-detector 是一个专门用于文档中签名检测的目标识别模型。该模型基于 Ultralytics YOLOv8 架构构建，提供自动化的签名定位功能。它使用专门的签名检测数据集进行训练，支持 ONNX 和 PyTorch 等多种部署格式。主要优势在于为文档处理流程提供高效的签名识别能力。典型应用场景包括自动化文档验证系统、数字归档管理以及需要签名检测的行政处理流程。该模型专注于提升文档处理中签名识别的准确性和效率，适用于各种需要自动检测签名的业务场景。",
        "summary_es": "The yolov8s-signature-detector is an object detection model specifically designed to identify signatures in documents. Built on Ultralytics YOLOv8 architecture, it provides automated signature localization capabilities. The model is trained on a specialized signature detection dataset and supports multiple deployment formats including ONNX and PyTorch. Its primary strength lies in efficient signature recognition for document processing workflows. Typical use cases include automated document verification, digital archiving systems, and administrative processing where signature detection is required."
      }
    ],
    "semantic_segmentation": [
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "Bingsu/adetailer",
        "source": "hf",
        "name": "adetailer",
        "url": "https://huggingface.co/Bingsu/adetailer",
        "tags": [
          "ultralytics",
          "pytorch",
          "dataset:wider_face",
          "dataset:skytnt/anime-segmentation",
          "doi:10.57967/hf/3633",
          "license:apache-2.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 15085828,
          "likes_total": 617,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "ADetailer 是一款计算机视觉工具，旨在自动检测并增强图像中的细节，特别是面部和其他区域。其核心功能包括对象检测、分割和修复，以提升图像质量。优势在于处理动漫风格内容和真实世界面部图像，利用了 anime-segmentation 和 WiderFace 等数据集。典型应用场景涉及对生成或真实图像进行后处理，以优化细节、去除伪影或增强特定区域，无需人工干预。该工具基于 PyTorch 构建，采用 Apache 2.0 开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "ltr",
          "training_data_anonymization",
          "training_data_copyright"
        ],
        "summary_en": "ADetailer is a computer vision tool designed to automatically detect and enhance details in images, particularly faces and other regions. Its core capabilities include object detection, segmentation, and inpainting to improve image quality. Strengths lie in handling anime-style content and real-world facial images, leveraging datasets like anime-segmentation and WiderFace. Typical use cases involve post-processing generated or real images to refine details, remove artifacts, or enhance specific areas without manual intervention. The tool is built on PyTorch and is open-source under Apache 2.0 license.",
        "summary_zh": "ADetailer 是一款计算机视觉工具，旨在自动检测并增强图像中的细节，特别是面部和其他区域。其核心功能包括对象检测、分割和修复，以提升图像质量。优势在于处理动漫风格内容和真实世界面部图像，利用了 anime-segmentation 和 WiderFace 等数据集。典型应用场景涉及对生成或真实图像进行后处理，以优化细节、去除伪影或增强特定区域，无需人工干预。该工具基于 PyTorch 构建，采用 Apache 2.0 开源许可证。",
        "summary_es": "ADetailer is a computer vision tool designed to automatically detect and enhance details in images, particularly faces and other regions. Its core capabilities include object detection, segmentation, and inpainting to improve image quality. Strengths lie in handling anime-style content and real-world facial images, leveraging datasets like anime-segmentation and WiderFace. Typical use cases involve post-processing generated or real images to refine details, remove artifacts, or enhance specific areas without manual intervention. The tool is built on PyTorch and is open-source under Apache 2.0 license."
      },
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "instance_segmentation": [
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "Bingsu/adetailer",
        "source": "hf",
        "name": "adetailer",
        "url": "https://huggingface.co/Bingsu/adetailer",
        "tags": [
          "ultralytics",
          "pytorch",
          "dataset:wider_face",
          "dataset:skytnt/anime-segmentation",
          "doi:10.57967/hf/3633",
          "license:apache-2.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 15085828,
          "likes_total": 617,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "ADetailer 是一款计算机视觉工具，旨在自动检测并增强图像中的细节，特别是面部和其他区域。其核心功能包括对象检测、分割和修复，以提升图像质量。优势在于处理动漫风格内容和真实世界面部图像，利用了 anime-segmentation 和 WiderFace 等数据集。典型应用场景涉及对生成或真实图像进行后处理，以优化细节、去除伪影或增强特定区域，无需人工干预。该工具基于 PyTorch 构建，采用 Apache 2.0 开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "ltr",
          "training_data_anonymization",
          "training_data_copyright"
        ],
        "summary_en": "ADetailer is a computer vision tool designed to automatically detect and enhance details in images, particularly faces and other regions. Its core capabilities include object detection, segmentation, and inpainting to improve image quality. Strengths lie in handling anime-style content and real-world facial images, leveraging datasets like anime-segmentation and WiderFace. Typical use cases involve post-processing generated or real images to refine details, remove artifacts, or enhance specific areas without manual intervention. The tool is built on PyTorch and is open-source under Apache 2.0 license.",
        "summary_zh": "ADetailer 是一款计算机视觉工具，旨在自动检测并增强图像中的细节，特别是面部和其他区域。其核心功能包括对象检测、分割和修复，以提升图像质量。优势在于处理动漫风格内容和真实世界面部图像，利用了 anime-segmentation 和 WiderFace 等数据集。典型应用场景涉及对生成或真实图像进行后处理，以优化细节、去除伪影或增强特定区域，无需人工干预。该工具基于 PyTorch 构建，采用 Apache 2.0 开源许可证。",
        "summary_es": "ADetailer is a computer vision tool designed to automatically detect and enhance details in images, particularly faces and other regions. Its core capabilities include object detection, segmentation, and inpainting to improve image quality. Strengths lie in handling anime-style content and real-world facial images, leveraging datasets like anime-segmentation and WiderFace. Typical use cases involve post-processing generated or real images to refine details, remove artifacts, or enhance specific areas without manual intervention. The tool is built on PyTorch and is open-source under Apache 2.0 license."
      },
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "panoptic_segmentation": [
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "Bingsu/adetailer",
        "source": "hf",
        "name": "adetailer",
        "url": "https://huggingface.co/Bingsu/adetailer",
        "tags": [
          "ultralytics",
          "pytorch",
          "dataset:wider_face",
          "dataset:skytnt/anime-segmentation",
          "doi:10.57967/hf/3633",
          "license:apache-2.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 15085828,
          "likes_total": 617,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "ADetailer 是一款计算机视觉工具，旨在自动检测并增强图像中的细节，特别是面部和其他区域。其核心功能包括对象检测、分割和修复，以提升图像质量。优势在于处理动漫风格内容和真实世界面部图像，利用了 anime-segmentation 和 WiderFace 等数据集。典型应用场景涉及对生成或真实图像进行后处理，以优化细节、去除伪影或增强特定区域，无需人工干预。该工具基于 PyTorch 构建，采用 Apache 2.0 开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "ltr",
          "training_data_anonymization",
          "training_data_copyright"
        ],
        "summary_en": "ADetailer is a computer vision tool designed to automatically detect and enhance details in images, particularly faces and other regions. Its core capabilities include object detection, segmentation, and inpainting to improve image quality. Strengths lie in handling anime-style content and real-world facial images, leveraging datasets like anime-segmentation and WiderFace. Typical use cases involve post-processing generated or real images to refine details, remove artifacts, or enhance specific areas without manual intervention. The tool is built on PyTorch and is open-source under Apache 2.0 license.",
        "summary_zh": "ADetailer 是一款计算机视觉工具，旨在自动检测并增强图像中的细节，特别是面部和其他区域。其核心功能包括对象检测、分割和修复，以提升图像质量。优势在于处理动漫风格内容和真实世界面部图像，利用了 anime-segmentation 和 WiderFace 等数据集。典型应用场景涉及对生成或真实图像进行后处理，以优化细节、去除伪影或增强特定区域，无需人工干预。该工具基于 PyTorch 构建，采用 Apache 2.0 开源许可证。",
        "summary_es": "ADetailer is a computer vision tool designed to automatically detect and enhance details in images, particularly faces and other regions. Its core capabilities include object detection, segmentation, and inpainting to improve image quality. Strengths lie in handling anime-style content and real-world facial images, leveraging datasets like anime-segmentation and WiderFace. Typical use cases involve post-processing generated or real images to refine details, remove artifacts, or enhance specific areas without manual intervention. The tool is built on PyTorch and is open-source under Apache 2.0 license."
      },
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "text_to_image": [
      {
        "id": "Falconsai/nsfw_image_detection",
        "source": "hf",
        "name": "nsfw_image_detection",
        "url": "https://huggingface.co/Falconsai/nsfw_image_detection",
        "tags": [
          "transformers",
          "pytorch",
          "safetensors",
          "vit",
          "image-classification",
          "arxiv:2010.11929",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 99881324,
          "likes_total": 826,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "image_text_alignment",
          "auto_evaluation_models",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems.",
        "summary_zh": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "summary_es": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems."
      },
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "Comfy-Org/Wan_2.2_ComfyUI_Repackaged",
        "source": "hf",
        "name": "Wan_2.2_ComfyUI_Repackaged",
        "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged",
        "tags": [
          "diffusion-single-file",
          "comfyui",
          "region:us"
        ],
        "stats": {
          "downloads_total": 5031107,
          "likes_total": 344,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Wan_2.2_ComfyUI_Repackaged 是针对 ComfyUI 工作流管理优化的 Wan 2.2 AI 图像生成模型的重新封装版本。其主要目的是提供单文件扩散模型，简化在 ComfyUI 节点式界面中的部署和集成。核心能力包括基于稳定扩散的图像生成，并增强工作流自动化的兼容性。关键优势在于其简化的封装结构、降低的设置复杂性以及与 ComfyUI 的无缝集成。典型应用场景涵盖 ComfyUI 生态系统内的 AI 辅助数字艺术创作、批量图像处理以及实验性工作流测试，特别适合需要快速部署和稳定运行的图像生成项目。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "text_to_image"
        ],
        "summary_en": "Wan_2.2_ComfyUI_Repackaged is a repackaged version of the Wan 2.2 AI image generation model optimized for ComfyUI workflow management. Its primary purpose is to provide a single-file diffusion model that simplifies deployment and integration within ComfyUI's node-based interface. Core capabilities include stable diffusion-based image generation with enhanced compatibility for workflow automation. Key strengths lie in its streamlined packaging, reduced setup complexity, and seamless ComfyUI integration. Typical use cases involve AI-assisted digital art creation, batch image processing, and experimental workflow testing within the ComfyUI ecosystem.",
        "summary_zh": "Wan_2.2_ComfyUI_Repackaged 是针对 ComfyUI 工作流管理优化的 Wan 2.2 AI 图像生成模型的重新封装版本。其主要目的是提供单文件扩散模型，简化在 ComfyUI 节点式界面中的部署和集成。核心能力包括基于稳定扩散的图像生成，并增强工作流自动化的兼容性。关键优势在于其简化的封装结构、降低的设置复杂性以及与 ComfyUI 的无缝集成。典型应用场景涵盖 ComfyUI 生态系统内的 AI 辅助数字艺术创作、批量图像处理以及实验性工作流测试，特别适合需要快速部署和稳定运行的图像生成项目。",
        "summary_es": "Wan_2.2_ComfyUI_Repackaged is a repackaged version of the Wan 2.2 AI image generation model optimized for ComfyUI workflow management. Its primary purpose is to provide a single-file diffusion model that simplifies deployment and integration within ComfyUI's node-based interface. Core capabilities include stable diffusion-based image generation with enhanced compatibility for workflow automation. Key strengths lie in its streamlined packaging, reduced setup complexity, and seamless ComfyUI integration. Typical use cases involve AI-assisted digital art creation, batch image processing, and experimental workflow testing within the ComfyUI ecosystem."
      },
      {
        "id": "AUTOMATIC1111/stable-diffusion-webui",
        "source": "github",
        "name": "stable-diffusion-webui",
        "url": "https://github.com/AUTOMATIC1111/stable-diffusion-webui",
        "tags": [
          "ai",
          "ai-art",
          "deep-learning",
          "diffusion",
          "gradio",
          "image-generation",
          "image2image",
          "img2img",
          "pytorch",
          "stable-diffusion",
          "text2image",
          "torch",
          "txt2img",
          "unstable",
          "upscaling",
          "web"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:56:06Z",
        "added_at": "2025-09-27",
        "summary": "Stable Diffusion web UI",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09996438547156578,
        "task_keys": [
          "text_to_image"
        ],
        "summary_en": "The Stable Diffusion web UI by AUTOMATIC1111 is a browser-based interface for Stable Diffusion, an AI image generation model. It enables users to create, modify, and enhance images through text prompts and image inputs. Core capabilities include text-to-image generation, image-to-image translation, inpainting, outpainting, and upscaling. Strengths are its extensive customization options, support for various models and extensions, and user-friendly Gradio interface. Typical use cases encompass digital art creation, photo editing, concept visualization, and AI experimentation. The project facilitates accessible interaction with advanced diffusion models without requiring command-line expertise.",
        "summary_zh": "AUTOMATIC1111开发的Stable Diffusion web UI是基于浏览器的Stable Diffusion AI图像生成模型界面。该工具允许用户通过文本提示和图像输入来创建、修改和增强图像。核心功能包括文生图、图生图、局部重绘、画幅扩展和图像超分辨率。其优势在于提供广泛的定制选项、支持多种模型和扩展插件，以及采用用户友好的Gradio界面。典型应用场景涵盖数字艺术创作、照片编辑、概念可视化和AI实验。该项目通过简化高级扩散模型的操作，降低了技术门槛，使用户无需命令行专业知识即可进行交互。开源项目",
        "summary_es": "The Stable Diffusion web UI by AUTOMATIC1111 is a browser-based interface for Stable Diffusion, an AI image generation model. It enables users to create, modify, and enhance images through text prompts and image inputs. Core capabilities include text-to-image generation, image-to-image translation, inpainting, outpainting, and upscaling. Strengths are its extensive customization options, support for various models and extensions, and user-friendly Gradio interface. Typical use cases encompass digital art creation, photo editing, concept visualization, and AI experimentation. The project facilitates accessible interaction with advanced diffusion models without requiring command-line expertise."
      }
    ],
    "text_to_video": [
      {
        "id": "openai-community/gpt2",
        "source": "hf",
        "name": "gpt2",
        "url": "https://huggingface.co/openai-community/gpt2",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "tflite",
          "rust",
          "onnx",
          "safetensors",
          "gpt2",
          "text-generation",
          "exbert",
          "en",
          "doi:10.57967/hf/0039",
          "license:mit",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11902438,
          "likes_total": 2955,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "GPT-2是由OpenAI开发的基于Transformer架构的语言生成模型，主要用于文本生成任务。其核心能力是通过输入提示预测后续文本内容，实现连贯的文本延续。主要优势包括在零样本设置下无需特定任务训练即可生成高质量文本、能够跨多个领域生成类人文本内容以及开源可访问性。典型应用场景涵盖创意写作辅助、对话系统原型开发、内容摘要生成和代码自动补全。该模型在开放式文本补全方面表现突出，能够在长文本输出中保持上下文相关性，同时支",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "text_to_image",
          "text_to_video",
          "code_generation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "inference_acceleration",
          "auto_evaluation_models",
          "molecular_generation"
        ],
        "summary_en": "GPT-2 is a transformer-based language model developed by OpenAI for text generation tasks. Its core capability involves predicting subsequent text based on input prompts, enabling coherent continuation of text. Key strengths include strong performance in zero-shot settings without task-specific training, generating human-like text across diverse domains, and open-source availability. Typical use cases encompass creative writing assistance, conversational AI prototyping, content summarization, and code generation. The model demonstrates particular effectiveness in open-ended text completion while maintaining contextual relevance throughout extended outputs.",
        "summary_zh": "GPT-2是由OpenAI开发的基于Transformer架构的语言生成模型，主要用于文本生成任务。其核心能力是通过输入提示预测后续文本内容，实现连贯的文本延续。主要优势包括在零样本设置下无需特定任务训练即可生成高质量文本、能够跨多个领域生成类人文本内容以及开源可访问性。典型应用场景涵盖创意写作辅助、对话系统原型开发、内容摘要生成和代码自动补全。该模型在开放式文本补全方面表现突出，能够在长文本输出中保持上下文相关性，同时支",
        "summary_es": "GPT-2 is a transformer-based language model developed by OpenAI for text generation tasks. Its core capability involves predicting subsequent text based on input prompts, enabling coherent continuation of text. Key strengths include strong performance in zero-shot settings without task-specific training, generating human-like text across diverse domains, and open-source availability. Typical use cases encompass creative writing assistance, conversational AI prototyping, content summarization, and code generation. The model demonstrates particular effectiveness in open-ended text completion while maintaining contextual relevance throughout extended outputs."
      },
      {
        "id": "omni-research/Tarsier2-Recap-7b",
        "source": "hf",
        "name": "Tarsier2-Recap-7b",
        "url": "https://huggingface.co/omni-research/Tarsier2-Recap-7b",
        "tags": [
          "safetensors",
          "video LLM",
          "arxiv:2501.07888",
          "license:apache-2.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 10283648,
          "likes_total": 19,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Tarsier2-Recap-7b 是一个拥有70亿参数的专业视频语言模型，专门用于深度视频理解与内容概括。其核心能力在于处理视频流数据并生成全面的文本描述和摘要。该模型擅长从视觉序列中提取关键信息，并将其转化为连贯的叙述文本。典型应用场景包括自动化视频字幕生成、媒体资料库的内容分析、以及教育或纪录片素材的摘要制作。基于arXiv:2501.07888的研究成果，采用safetensors格式和Apache 2.0开源协议，在跨模态理解任务中表现出色，特别在保持内容准确性和结构完整性方面具有",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "text_to_video",
          "llm_pretraining"
        ],
        "summary_en": "Tarsier2-Recap-7b is a 7-billion-parameter video language model designed for comprehensive video understanding and summarization. Its core capability involves processing video content to generate detailed textual descriptions and summaries. The model excels at extracting key information from visual sequences and converting it into coherent narratives. Typical use cases include automated video captioning, content analysis for media archives, and generating summaries for educational or documentary footage. Based on research from arXiv:2501.07888, it employs safetensors format and operates under Apache 2.0 license, demonstrating strong performance in multimodal understanding tasks.",
        "summary_zh": "Tarsier2-Recap-7b 是一个拥有70亿参数的专业视频语言模型，专门用于深度视频理解与内容概括。其核心能力在于处理视频流数据并生成全面的文本描述和摘要。该模型擅长从视觉序列中提取关键信息，并将其转化为连贯的叙述文本。典型应用场景包括自动化视频字幕生成、媒体资料库的内容分析、以及教育或纪录片素材的摘要制作。基于arXiv:2501.07888的研究成果，采用safetensors格式和Apache 2.0开源协议，在跨模态理解任务中表现出色，特别在保持内容准确性和结构完整性方面具有",
        "summary_es": "Tarsier2-Recap-7b is a 7-billion-parameter video language model designed for comprehensive video understanding and summarization. Its core capability involves processing video content to generate detailed textual descriptions and summaries. The model excels at extracting key information from visual sequences and converting it into coherent narratives. Typical use cases include automated video captioning, content analysis for media archives, and generating summaries for educational or documentary footage. Based on research from arXiv:2501.07888, it employs safetensors format and operates under Apache 2.0 license, demonstrating strong performance in multimodal understanding tasks."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "yt-dlp/yt-dlp",
        "source": "github",
        "name": "yt-dlp",
        "url": "https://github.com/yt-dlp/yt-dlp",
        "tags": [
          "cli",
          "downloader",
          "python",
          "sponsorblock",
          "youtube-dl",
          "youtube-downloader",
          "yt-dlp"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:54:58Z",
        "added_at": "2025-09-27",
        "summary": "A feature-rich command-line audio/video downloader",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09997275475385814,
        "task_keys": [
          "text_to_video"
        ],
        "summary_en": "yt-dlp is a Python-based command-line audio/video downloader forked from youtube-dl. Its primary purpose is to download media from thousands of sites including YouTube, with core capabilities supporting various formats, resolutions, and metadata extraction. Key strengths include frequent updates to bypass platform restrictions, SponsorBlock integration for ad skipping, and extensive customization options. Typical use cases involve archiving content, offline viewing, and batch downloading. It maintains compatibility with youtube-dl while adding significant enhancements and reliability improvements.",
        "summary_zh": "yt-dlp 是一个基于 Python 的命令行音视频下载工具，是从 youtube-dl 分支而来。其主要目的是从包括 YouTube 在内的数千个网站下载媒体内容，核心功能支持多种格式、分辨率以及元数据提取。关键优势包括频繁更新以绕过平台限制、集成 SponsorBlock 实现广告跳过，以及提供广泛的定制选项。典型使用场景涉及内容存档、离线观看和批量下载。它在保持与 youtube-dl 兼容性的同时，增加了显著的增强功能和可靠性改进。",
        "summary_es": "yt-dlp is a Python-based command-line audio/video downloader forked from youtube-dl. Its primary purpose is to download media from thousands of sites including YouTube, with core capabilities supporting various formats, resolutions, and metadata extraction. Key strengths include frequent updates to bypass platform restrictions, SponsorBlock integration for ad skipping, and extensive customization options. Typical use cases involve archiving content, offline viewing, and batch downloading. It maintains compatibility with youtube-dl while adding significant enhancements and reliability improvements."
      },
      {
        "id": "ytdl-org/youtube-dl",
        "source": "github",
        "name": "youtube-dl",
        "url": "https://github.com/ytdl-org/youtube-dl",
        "tags": [],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:49:18Z",
        "added_at": "2025-09-28",
        "summary": "Command-line program to download videos from YouTube.com and other video sites",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09990828695097581,
        "task_keys": [
          "text_to_video"
        ],
        "summary_en": "youtube-dl is a command-line program designed to download videos from YouTube and numerous other video platforms. Its core capability involves extracting video and audio content from websites that typically restrict direct downloading. Key strengths include extensive site support, regular updates to bypass restrictions, and command-line efficiency for automation. Typical use cases include archival of online content, offline viewing, educational material preservation, and integration into larger media processing workflows. The tool operates without graphical interface, relying on precise commands for batch processing and customization.",
        "summary_zh": "youtube-dl 是一个命令行程序，专门用于从 YouTube 及众多其他视频网站下载视频。其核心功能是从通常限制直接下载的网站提取视频和音频内容。主要优势包括支持大量网站、定期更新以绕过限制，以及命令行的高效自动化特性。典型应用场景包括在线内容存档、离线观看、教育资料保存，以及集成到更大的媒体处理工作流中。该工具无需图形界面，依靠精确命令进行批量处理和自定义设置，适合技术用户进行高效的媒体下载和管理操作。",
        "summary_es": "youtube-dl is a command-line program designed to download videos from YouTube and numerous other video platforms. Its core capability involves extracting video and audio content from websites that typically restrict direct downloading. Key strengths include extensive site support, regular updates to bypass restrictions, and command-line efficiency for automation. Typical use cases include archival of online content, offline viewing, educational material preservation, and integration into larger media processing workflows. The tool operates without graphical interface, relying on precise commands for batch processing and customization."
      }
    ],
    "3d_reconstruction": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "mrdoob/three.js",
        "source": "github",
        "name": "three.js",
        "url": "https://github.com/mrdoob/three.js",
        "tags": [
          "3d",
          "augmented-reality",
          "canvas",
          "html5",
          "javascript",
          "svg",
          "virtual-reality",
          "webaudio",
          "webgl",
          "webgl2",
          "webgpu",
          "webxr"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:02:26Z",
        "added_at": "2025-09-27",
        "summary": "JavaScript 3D Library.",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09993342136323158,
        "task_keys": [
          "3d_reconstruction"
        ],
        "summary_en": "Three.js is a cross-browser JavaScript library and API used to create and display animated 3D computer graphics in a web browser using WebGL. Its primary purpose is to simplify the complex process of 3D rendering for web applications. Core capabilities include scene graph management, materials, lighting, cameras, geometries, and animation systems. Key strengths are its extensive documentation, large community support, and broad browser compatibility. Typical use cases encompass data visualization, games, architectural presentations, product configurators, and interactive educational content that runs directly in browsers without plugins.",
        "summary_zh": "Three.js 是一个跨浏览器的 JavaScript 库和 API，主要用于在网页浏览器中使用 WebGL 创建和展示动画 3D 计算机图形。其核心目的是简化网页应用中的复杂 3D 渲染流程。该库具备场景图管理、材质系统、光照控制、相机设置、几何体构建和动画处理等核心功能。主要优势包括详尽的文档资料、庞大的开发者社区支持以及广泛的浏览器兼容性。典型应用场景涵盖数据可视化、网页游戏、建筑展示、产品配置器和交互式教育内容，这些应用可直接在浏览器中运行，无需安装额外插",
        "summary_es": "Three.js is a cross-browser JavaScript library and API used to create and display animated 3D computer graphics in a web browser using WebGL. Its primary purpose is to simplify the complex process of 3D rendering for web applications. Core capabilities include scene graph management, materials, lighting, cameras, geometries, and animation systems. Key strengths are its extensive documentation, large community support, and broad browser compatibility. Typical use cases encompass data visualization, games, architectural presentations, product configurators, and interactive educational content that runs directly in browsers without plugins."
      }
    ],
    "nerf": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "super_resolution": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      }
    ],
    "denoising": [
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "distilbert/distilbert-base-uncased",
        "source": "hf",
        "name": "distilbert-base-uncased",
        "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "distilbert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1910.01108",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11617607,
          "likes_total": 762,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX.",
        "summary_zh": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "summary_es": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "restoration": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      }
    ],
    "medical_image_processing": [
      {
        "id": "Falconsai/nsfw_image_detection",
        "source": "hf",
        "name": "nsfw_image_detection",
        "url": "https://huggingface.co/Falconsai/nsfw_image_detection",
        "tags": [
          "transformers",
          "pytorch",
          "safetensors",
          "vit",
          "image-classification",
          "arxiv:2010.11929",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 99881324,
          "likes_total": 826,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "image_text_alignment",
          "auto_evaluation_models",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems.",
        "summary_zh": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "summary_es": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems."
      },
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      }
    ],
    "remote_sensing_image_processing": [
      {
        "id": "Falconsai/nsfw_image_detection",
        "source": "hf",
        "name": "nsfw_image_detection",
        "url": "https://huggingface.co/Falconsai/nsfw_image_detection",
        "tags": [
          "transformers",
          "pytorch",
          "safetensors",
          "vit",
          "image-classification",
          "arxiv:2010.11929",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 99881324,
          "likes_total": 826,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "image_text_alignment",
          "auto_evaluation_models",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems.",
        "summary_zh": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "summary_es": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems."
      },
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "vqa": [
      {
        "id": "Qwen/Qwen2.5-VL-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-VL-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2_5_vl",
          "image-to-text",
          "multimodal",
          "image-text-to-text",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2409.12191",
          "arxiv:2308.12966",
          "license:apache-2.0",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 4301984,
          "likes_total": 1267,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Qwen2.5-VL-7B-Instruct 是一个拥有70亿参数的多模态人工智能模型，专为视觉语言理解和指令跟随而设计。该模型能够同时处理图像和文本输入，生成连贯的文本响应。核心功能包括图像描述生成、视觉问答和多模态对话。主要优势在于模型尺寸紧凑、推理效率高，且在视觉推理任务上表现优异。典型应用场景涵盖人工智能助手、内容分析工具以及需要图像文本集成处理的教育应用。该模型支持多语言交互，并与标准部署框架兼容，适用于实际生产环境。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_text_alignment",
          "multimodal_understanding_generation",
          "visual_grounding",
          "vqa",
          "lightweight_multimodal_model"
        ],
        "summary_en": "Qwen2.5-VL-7B-Instruct is a 7-billion parameter multimodal AI model designed for visual-language understanding and instruction following. It processes both images and text inputs to generate coherent textual responses. Core capabilities include image captioning, visual question answering, and multimodal conversations. Strengths encompass its compact size, efficient inference, and strong performance on visual reasoning tasks. Typical use cases involve AI assistants, content analysis tools, and educational applications requiring integrated image-text processing. The model supports multiple languages and is compatible with standard deployment frameworks.",
        "summary_zh": "Qwen2.5-VL-7B-Instruct 是一个拥有70亿参数的多模态人工智能模型，专为视觉语言理解和指令跟随而设计。该模型能够同时处理图像和文本输入，生成连贯的文本响应。核心功能包括图像描述生成、视觉问答和多模态对话。主要优势在于模型尺寸紧凑、推理效率高，且在视觉推理任务上表现优异。典型应用场景涵盖人工智能助手、内容分析工具以及需要图像文本集成处理的教育应用。该模型支持多语言交互，并与标准部署框架兼容，适用于实际生产环境。",
        "summary_es": "Qwen2.5-VL-7B-Instruct is a 7-billion parameter multimodal AI model designed for visual-language understanding and instruction following. It processes both images and text inputs to generate coherent textual responses. Core capabilities include image captioning, visual question answering, and multimodal conversations. Strengths encompass its compact size, efficient inference, and strong performance on visual reasoning tasks. Typical use cases involve AI assistants, content analysis tools, and educational applications requiring integrated image-text processing. The model supports multiple languages and is compatible with standard deployment frameworks."
      }
    ],
    "visual_grounding": [
      {
        "id": "Qwen/Qwen2.5-VL-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-VL-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2_5_vl",
          "image-to-text",
          "multimodal",
          "image-text-to-text",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2409.12191",
          "arxiv:2308.12966",
          "license:apache-2.0",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 4301984,
          "likes_total": 1267,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Qwen2.5-VL-7B-Instruct 是一个拥有70亿参数的多模态人工智能模型，专为视觉语言理解和指令跟随而设计。该模型能够同时处理图像和文本输入，生成连贯的文本响应。核心功能包括图像描述生成、视觉问答和多模态对话。主要优势在于模型尺寸紧凑、推理效率高，且在视觉推理任务上表现优异。典型应用场景涵盖人工智能助手、内容分析工具以及需要图像文本集成处理的教育应用。该模型支持多语言交互，并与标准部署框架兼容，适用于实际生产环境。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_text_alignment",
          "multimodal_understanding_generation",
          "visual_grounding",
          "vqa",
          "lightweight_multimodal_model"
        ],
        "summary_en": "Qwen2.5-VL-7B-Instruct is a 7-billion parameter multimodal AI model designed for visual-language understanding and instruction following. It processes both images and text inputs to generate coherent textual responses. Core capabilities include image captioning, visual question answering, and multimodal conversations. Strengths encompass its compact size, efficient inference, and strong performance on visual reasoning tasks. Typical use cases involve AI assistants, content analysis tools, and educational applications requiring integrated image-text processing. The model supports multiple languages and is compatible with standard deployment frameworks.",
        "summary_zh": "Qwen2.5-VL-7B-Instruct 是一个拥有70亿参数的多模态人工智能模型，专为视觉语言理解和指令跟随而设计。该模型能够同时处理图像和文本输入，生成连贯的文本响应。核心功能包括图像描述生成、视觉问答和多模态对话。主要优势在于模型尺寸紧凑、推理效率高，且在视觉推理任务上表现优异。典型应用场景涵盖人工智能助手、内容分析工具以及需要图像文本集成处理的教育应用。该模型支持多语言交互，并与标准部署框架兼容，适用于实际生产环境。",
        "summary_es": "Qwen2.5-VL-7B-Instruct is a 7-billion parameter multimodal AI model designed for visual-language understanding and instruction following. It processes both images and text inputs to generate coherent textual responses. Core capabilities include image captioning, visual question answering, and multimodal conversations. Strengths encompass its compact size, efficient inference, and strong performance on visual reasoning tasks. Typical use cases involve AI assistants, content analysis tools, and educational applications requiring integrated image-text processing. The model supports multiple languages and is compatible with standard deployment frameworks."
      },
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "lightweight_visual_model": [
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "huggingface/transformers",
        "source": "github",
        "name": "transformers",
        "url": "https://github.com/huggingface/transformers",
        "tags": [
          "audio",
          "deep-learning",
          "deepseek",
          "gemma",
          "glm",
          "hacktoberfest",
          "llm",
          "machine-learning",
          "model-hub",
          "natural-language-processing",
          "nlp",
          "pretrained-models",
          "python",
          "pytorch",
          "pytorch-transformers",
          "qwen",
          "speech-recognition",
          "transformer",
          "vlm"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:04:48Z",
        "added_at": "2025-09-27",
        "summary": "🤗 Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09996249573059768,
        "task_keys": [
          "lightweight_visual_model",
          "llm_pretraining",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "nlp_bias_mitigation",
          "asr",
          "lightweight_multimodal_model",
          "inference_acceleration"
        ],
        "summary_en": "Hugging Face Transformers is an open-source Python library providing state-of-the-art machine learning models for text, vision, audio, and multimodal applications. It offers thousands of pretrained models for both inference and training, supporting popular architectures like Transformer, LLM, VLM, and audio models. Core capabilities include easy model loading, fine-tuning, and deployment across frameworks like PyTorch. Strengths include its extensive model hub, community support, and comprehensive documentation. Typical use cases span natural language processing, speech recognition, computer vision, and multimodal AI tasks.",
        "summary_zh": "Hugging Face Transformers 是一个开源 Python 库，为文本、视觉、音频和多模态应用提供最先进的机器学习模型。该库包含数千个预训练模型，支持推理和训练，涵盖 Transformer、大语言模型、视觉语言模型和音频模型等流行架构。核心功能包括简易模型加载、微调和跨框架部署（如 PyTorch）。主要优势在于其庞大的模型库、活跃的社区支持和全面的文档。典型应用场景包括自然语言处理、语音识别、计算机视觉和多模态人工智能任务，适用于研究和生产环境。",
        "summary_es": "Hugging Face Transformers is an open-source Python library providing state-of-the-art machine learning models for text, vision, audio, and multimodal applications. It offers thousands of pretrained models for both inference and training, supporting popular architectures like Transformer, LLM, VLM, and audio models. Core capabilities include easy model loading, fine-tuning, and deployment across frameworks like PyTorch. Strengths include its extensive model hub, community support, and comprehensive documentation. Typical use cases span natural language processing, speech recognition, computer vision, and multimodal AI tasks."
      }
    ],
    "llm_pretraining": [
      {
        "id": "google/electra-base-discriminator",
        "source": "hf",
        "name": "electra-base-discriminator",
        "url": "https://huggingface.co/google/electra-base-discriminator",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "electra",
          "pretraining",
          "en",
          "arxiv:1406.2661",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 16009189,
          "likes_total": 65,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "ELECTRA-base-discriminator是谷歌开发的一种预训练语言模型，采用名为“替换令牌检测”的创新预训练方法。与BERT预测掩码令牌不同，该模型通过区分原始令牌和由小型生成器网络创建的合理替换令牌来进行训练，这种方法显著提高了预训练的计算效率。模型擅长理解文本中的上下文关系，可作为各种自然语言处理任务的强大基础。典型应用场景包括文本分类、命名实体识别和问答系统，通常在特定数据集上进行微调后使用。该模型支持多种框架，具有高效的预",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "llm_pretraining",
          "training_data_anonymization",
          "training_data_copyright"
        ],
        "summary_en": "ELECTRA-base-discriminator is a pre-trained language model developed by Google that uses a novel pre-training approach called replaced token detection. Instead of predicting masked tokens like BERT, it distinguishes between original and plausible replacement tokens generated by a small generator network. This method makes pre-training more computationally efficient. The model excels at understanding contextual relationships in text and serves as a strong foundation for various natural language processing tasks. Typical use cases include text classification, named entity recognition, and question answering when fine-tuned on specific datasets.",
        "summary_zh": "ELECTRA-base-discriminator是谷歌开发的一种预训练语言模型，采用名为“替换令牌检测”的创新预训练方法。与BERT预测掩码令牌不同，该模型通过区分原始令牌和由小型生成器网络创建的合理替换令牌来进行训练，这种方法显著提高了预训练的计算效率。模型擅长理解文本中的上下文关系，可作为各种自然语言处理任务的强大基础。典型应用场景包括文本分类、命名实体识别和问答系统，通常在特定数据集上进行微调后使用。该模型支持多种框架，具有高效的预",
        "summary_es": "ELECTRA-base-discriminator is a pre-trained language model developed by Google that uses a novel pre-training approach called replaced token detection. Instead of predicting masked tokens like BERT, it distinguishes between original and plausible replacement tokens generated by a small generator network. This method makes pre-training more computationally efficient. The model excels at understanding contextual relationships in text and serves as a strong foundation for various natural language processing tasks. Typical use cases include text classification, named entity recognition, and question answering when fine-tuned on specific datasets."
      },
      {
        "id": "omni-research/Tarsier2-Recap-7b",
        "source": "hf",
        "name": "Tarsier2-Recap-7b",
        "url": "https://huggingface.co/omni-research/Tarsier2-Recap-7b",
        "tags": [
          "safetensors",
          "video LLM",
          "arxiv:2501.07888",
          "license:apache-2.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 10283648,
          "likes_total": 19,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Tarsier2-Recap-7b 是一个拥有70亿参数的专业视频语言模型，专门用于深度视频理解与内容概括。其核心能力在于处理视频流数据并生成全面的文本描述和摘要。该模型擅长从视觉序列中提取关键信息，并将其转化为连贯的叙述文本。典型应用场景包括自动化视频字幕生成、媒体资料库的内容分析、以及教育或纪录片素材的摘要制作。基于arXiv:2501.07888的研究成果，采用safetensors格式和Apache 2.0开源协议，在跨模态理解任务中表现出色，特别在保持内容准确性和结构完整性方面具有",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "text_to_video",
          "llm_pretraining"
        ],
        "summary_en": "Tarsier2-Recap-7b is a 7-billion-parameter video language model designed for comprehensive video understanding and summarization. Its core capability involves processing video content to generate detailed textual descriptions and summaries. The model excels at extracting key information from visual sequences and converting it into coherent narratives. Typical use cases include automated video captioning, content analysis for media archives, and generating summaries for educational or documentary footage. Based on research from arXiv:2501.07888, it employs safetensors format and operates under Apache 2.0 license, demonstrating strong performance in multimodal understanding tasks.",
        "summary_zh": "Tarsier2-Recap-7b 是一个拥有70亿参数的专业视频语言模型，专门用于深度视频理解与内容概括。其核心能力在于处理视频流数据并生成全面的文本描述和摘要。该模型擅长从视觉序列中提取关键信息，并将其转化为连贯的叙述文本。典型应用场景包括自动化视频字幕生成、媒体资料库的内容分析、以及教育或纪录片素材的摘要制作。基于arXiv:2501.07888的研究成果，采用safetensors格式和Apache 2.0开源协议，在跨模态理解任务中表现出色，特别在保持内容准确性和结构完整性方面具有",
        "summary_es": "Tarsier2-Recap-7b is a 7-billion-parameter video language model designed for comprehensive video understanding and summarization. Its core capability involves processing video content to generate detailed textual descriptions and summaries. The model excels at extracting key information from visual sequences and converting it into coherent narratives. Typical use cases include automated video captioning, content analysis for media archives, and generating summaries for educational or documentary footage. Based on research from arXiv:2501.07888, it employs safetensors format and operates under Apache 2.0 license, demonstrating strong performance in multimodal understanding tasks."
      },
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "ollama/ollama",
        "source": "github",
        "name": "ollama",
        "url": "https://github.com/ollama/ollama",
        "tags": [
          "deepseek",
          "gemma",
          "gemma3",
          "gemma3n",
          "go",
          "golang",
          "gpt-oss",
          "llama",
          "llama2",
          "llama3",
          "llava",
          "llm",
          "llms",
          "mistral",
          "ollama",
          "phi4",
          "qwen"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:57:49Z",
        "added_at": "2025-09-28",
        "summary": "Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09996592814373871,
        "task_keys": [
          "llm_pretraining"
        ],
        "summary_en": "Ollama is an open-source platform designed to simplify the deployment and operation of large language models locally. Its core capability enables users to run various models like Llama, Mistral, and Gemma directly on their machines without cloud dependencies. Strengths include easy setup via command-line tools, efficient model management, and support for multiple architectures. Typical use cases involve local AI development, private model testing, and educational experimentation with LLMs, providing a flexible alternative to cloud-based services.",
        "summary_zh": "Ollama是一个开源平台，旨在简化大型语言模型在本地环境的部署和运行。其核心能力是让用户能够在自己的机器上直接运行Llama、Mistral、Gemma等多种模型，无需依赖云端服务。平台优势包括通过命令行工具实现简易安装、高效的模型管理功能以及对多种架构的兼容支持。典型应用场景涵盖本地人工智能开发、私有模型测试以及LLM的教育实践，为开发者提供了相比云端方案更灵活的自主控制方案。该工具特别适合需要数据隐私或离线使用的技术研究场景。",
        "summary_es": "Ollama is an open-source platform designed to simplify the deployment and operation of large language models locally. Its core capability enables users to run various models like Llama, Mistral, and Gemma directly on their machines without cloud dependencies. Strengths include easy setup via command-line tools, efficient model management, and support for multiple architectures. Typical use cases involve local AI development, private model testing, and educational experimentation with LLMs, providing a flexible alternative to cloud-based services."
      },
      {
        "id": "huggingface/transformers",
        "source": "github",
        "name": "transformers",
        "url": "https://github.com/huggingface/transformers",
        "tags": [
          "audio",
          "deep-learning",
          "deepseek",
          "gemma",
          "glm",
          "hacktoberfest",
          "llm",
          "machine-learning",
          "model-hub",
          "natural-language-processing",
          "nlp",
          "pretrained-models",
          "python",
          "pytorch",
          "pytorch-transformers",
          "qwen",
          "speech-recognition",
          "transformer",
          "vlm"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:04:48Z",
        "added_at": "2025-09-27",
        "summary": "🤗 Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09996249573059768,
        "task_keys": [
          "lightweight_visual_model",
          "llm_pretraining",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "nlp_bias_mitigation",
          "asr",
          "lightweight_multimodal_model",
          "inference_acceleration"
        ],
        "summary_en": "Hugging Face Transformers is an open-source Python library providing state-of-the-art machine learning models for text, vision, audio, and multimodal applications. It offers thousands of pretrained models for both inference and training, supporting popular architectures like Transformer, LLM, VLM, and audio models. Core capabilities include easy model loading, fine-tuning, and deployment across frameworks like PyTorch. Strengths include its extensive model hub, community support, and comprehensive documentation. Typical use cases span natural language processing, speech recognition, computer vision, and multimodal AI tasks.",
        "summary_zh": "Hugging Face Transformers 是一个开源 Python 库，为文本、视觉、音频和多模态应用提供最先进的机器学习模型。该库包含数千个预训练模型，支持推理和训练，涵盖 Transformer、大语言模型、视觉语言模型和音频模型等流行架构。核心功能包括简易模型加载、微调和跨框架部署（如 PyTorch）。主要优势在于其庞大的模型库、活跃的社区支持和全面的文档。典型应用场景包括自然语言处理、语音识别、计算机视觉和多模态人工智能任务，适用于研究和生产环境。",
        "summary_es": "Hugging Face Transformers is an open-source Python library providing state-of-the-art machine learning models for text, vision, audio, and multimodal applications. It offers thousands of pretrained models for both inference and training, supporting popular architectures like Transformer, LLM, VLM, and audio models. Core capabilities include easy model loading, fine-tuning, and deployment across frameworks like PyTorch. Strengths include its extensive model hub, community support, and comprehensive documentation. Typical use cases span natural language processing, speech recognition, computer vision, and multimodal AI tasks."
      }
    ],
    "instruction_tuning": [
      {
        "id": "google/gemma-3-1b-it",
        "source": "hf",
        "name": "gemma-3-1b-it",
        "url": "https://huggingface.co/google/gemma-3-1b-it",
        "tags": [
          "transformers",
          "safetensors",
          "gemma3_text",
          "text-generation",
          "conversational",
          "arxiv:1905.07830",
          "arxiv:1905.10044",
          "arxiv:1911.11641",
          "arxiv:1904.09728",
          "arxiv:1705.03551",
          "arxiv:1911.01547",
          "arxiv:1907.10641",
          "arxiv:1903.00161",
          "arxiv:2009.03300",
          "arxiv:2304.06364",
          "arxiv:2103.03874",
          "arxiv:2110.14168",
          "arxiv:2311.12022",
          "arxiv:2108.07732",
          "arxiv:2107.03374",
          "arxiv:2210.03057",
          "arxiv:2106.03193",
          "arxiv:1910.11856",
          "arxiv:2502.12404",
          "arxiv:2502.21228",
          "arxiv:2404.16816",
          "arxiv:2104.12756",
          "arxiv:2311.16502",
          "arxiv:2203.10244",
          "arxiv:2404.12390",
          "arxiv:1810.12440",
          "arxiv:1908.02660",
          "arxiv:2312.11805",
          "base_model:google/gemma-3-1b-pt",
          "base_model:finetune:google/gemma-3-1b-pt",
          "license:gemma",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 5753213,
          "likes_total": 629,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Gemma 3 1B-IT是谷歌开发的轻量级11亿参数指令调优语言模型，专为高效部署设计。基于Transformer架构，支持多语言文本生成、代码补全和推理任务。核心优势包括快速推理速度、低资源需求和开放可访问性。典型应用场景涵盖聊天机器人、内容创作、编程辅助和教育工具等需要优先考虑计算效率而非极致性能的场合。该模型在能力与实用部署约束之间实现了良好平衡，适用于资源受限环境下的AI应用。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "instruction_tuning"
        ],
        "summary_en": "Gemma 3 1B-IT is Google's lightweight 1.1 billion parameter instruction-tuned language model designed for efficient deployment. Built on transformer architecture, it supports multilingual text generation, code completion, and reasoning tasks. Key strengths include fast inference speed, low resource requirements, and open accessibility. Typical use cases encompass chatbots, content creation, programming assistance, and educational tools where computational efficiency is prioritized over maximum performance. The model balances capability with practical deployment constraints.",
        "summary_zh": "Gemma 3 1B-IT是谷歌开发的轻量级11亿参数指令调优语言模型，专为高效部署设计。基于Transformer架构，支持多语言文本生成、代码补全和推理任务。核心优势包括快速推理速度、低资源需求和开放可访问性。典型应用场景涵盖聊天机器人、内容创作、编程辅助和教育工具等需要优先考虑计算效率而非极致性能的场合。该模型在能力与实用部署约束之间实现了良好平衡，适用于资源受限环境下的AI应用。",
        "summary_es": "Gemma 3 1B-IT is Google's lightweight 1.1 billion parameter instruction-tuned language model designed for efficient deployment. Built on transformer architecture, it supports multilingual text generation, code completion, and reasoning tasks. Key strengths include fast inference speed, low resource requirements, and open accessibility. Typical use cases encompass chatbots, content creation, programming assistance, and educational tools where computational efficiency is prioritized over maximum performance. The model balances capability with practical deployment constraints."
      },
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "rlhf": [],
    "rag": [],
    "code_generation": [
      {
        "id": "openai-community/gpt2",
        "source": "hf",
        "name": "gpt2",
        "url": "https://huggingface.co/openai-community/gpt2",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "tflite",
          "rust",
          "onnx",
          "safetensors",
          "gpt2",
          "text-generation",
          "exbert",
          "en",
          "doi:10.57967/hf/0039",
          "license:mit",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11902438,
          "likes_total": 2955,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "GPT-2是由OpenAI开发的基于Transformer架构的语言生成模型，主要用于文本生成任务。其核心能力是通过输入提示预测后续文本内容，实现连贯的文本延续。主要优势包括在零样本设置下无需特定任务训练即可生成高质量文本、能够跨多个领域生成类人文本内容以及开源可访问性。典型应用场景涵盖创意写作辅助、对话系统原型开发、内容摘要生成和代码自动补全。该模型在开放式文本补全方面表现突出，能够在长文本输出中保持上下文相关性，同时支",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "text_to_image",
          "text_to_video",
          "code_generation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "inference_acceleration",
          "auto_evaluation_models",
          "molecular_generation"
        ],
        "summary_en": "GPT-2 is a transformer-based language model developed by OpenAI for text generation tasks. Its core capability involves predicting subsequent text based on input prompts, enabling coherent continuation of text. Key strengths include strong performance in zero-shot settings without task-specific training, generating human-like text across diverse domains, and open-source availability. Typical use cases encompass creative writing assistance, conversational AI prototyping, content summarization, and code generation. The model demonstrates particular effectiveness in open-ended text completion while maintaining contextual relevance throughout extended outputs.",
        "summary_zh": "GPT-2是由OpenAI开发的基于Transformer架构的语言生成模型，主要用于文本生成任务。其核心能力是通过输入提示预测后续文本内容，实现连贯的文本延续。主要优势包括在零样本设置下无需特定任务训练即可生成高质量文本、能够跨多个领域生成类人文本内容以及开源可访问性。典型应用场景涵盖创意写作辅助、对话系统原型开发、内容摘要生成和代码自动补全。该模型在开放式文本补全方面表现突出，能够在长文本输出中保持上下文相关性，同时支",
        "summary_es": "GPT-2 is a transformer-based language model developed by OpenAI for text generation tasks. Its core capability involves predicting subsequent text based on input prompts, enabling coherent continuation of text. Key strengths include strong performance in zero-shot settings without task-specific training, generating human-like text across diverse domains, and open-source availability. Typical use cases encompass creative writing assistance, conversational AI prototyping, content summarization, and code generation. The model demonstrates particular effectiveness in open-ended text completion while maintaining contextual relevance throughout extended outputs."
      },
      {
        "id": "facebook/opt-125m",
        "source": "hf",
        "name": "opt-125m",
        "url": "https://huggingface.co/facebook/opt-125m",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "opt",
          "text-generation",
          "en",
          "arxiv:2205.01068",
          "arxiv:2005.14165",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "region:us"
        ],
        "stats": {
          "downloads_total": 8602519,
          "likes_total": 218,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "OPT-125M是Meta AI开发的Open Pre-trained Transformer系列中的1.25亿参数仅解码器变压器语言模型，作为较大OPT模型的缩小版本，主要用于研究和实验目的。该模型能够根据输入提示生成连贯文本，支持多种自然语言处理任务。其主要优势包括面向研究用途的开放可访问性、支持多种框架（PyTorch、TensorFlow、JAX）的兼容性以及高效的推理能力。典型应用场景涵盖文本生成实验、变压器架构的教育演示、小规模语言模型性能基准测试，以及作为理解更大规模语言模型工作原理的入门工具。该模型特别适合计",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "text_to_image",
          "text_to_video",
          "code_generation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "inference_acceleration",
          "auto_evaluation_models",
          "molecular_generation"
        ],
        "summary_en": "OPT-125M is a 125 million parameter decoder-only transformer language model developed by Meta AI as part of the Open Pre-trained Transformer series. It serves as a smaller-scale version of larger OPT models for research and experimentation. The model generates coherent text based on input prompts and supports various natural language processing tasks. Its primary strengths include open accessibility for research purposes, compatibility with multiple frameworks (PyTorch, TensorFlow, JAX), and efficient inference capabilities. Typical use cases encompass text generation experiments, educational demonstrations of transformer architectures, and benchmarking smaller-scale language model performance.",
        "summary_zh": "OPT-125M是Meta AI开发的Open Pre-trained Transformer系列中的1.25亿参数仅解码器变压器语言模型，作为较大OPT模型的缩小版本，主要用于研究和实验目的。该模型能够根据输入提示生成连贯文本，支持多种自然语言处理任务。其主要优势包括面向研究用途的开放可访问性、支持多种框架（PyTorch、TensorFlow、JAX）的兼容性以及高效的推理能力。典型应用场景涵盖文本生成实验、变压器架构的教育演示、小规模语言模型性能基准测试，以及作为理解更大规模语言模型工作原理的入门工具。该模型特别适合计",
        "summary_es": "OPT-125M is a 125 million parameter decoder-only transformer language model developed by Meta AI as part of the Open Pre-trained Transformer series. It serves as a smaller-scale version of larger OPT models for research and experimentation. The model generates coherent text based on input prompts and supports various natural language processing tasks. Its primary strengths include open accessibility for research purposes, compatibility with multiple frameworks (PyTorch, TensorFlow, JAX), and efficient inference capabilities. Typical use cases encompass text generation experiments, educational demonstrations of transformer architectures, and benchmarking smaller-scale language model performance."
      },
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "structured_reasoning": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "Genymobile/scrcpy",
        "source": "github",
        "name": "scrcpy",
        "url": "https://github.com/Genymobile/scrcpy",
        "tags": [
          "android",
          "c",
          "ffmpeg",
          "libav",
          "mirroring",
          "recording",
          "screen",
          "sdl2"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:52:25Z",
        "added_at": "2025-09-27",
        "summary": "Display and control your Android device",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09993912760112483,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "3d_reconstruction",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "multilingual_processing",
          "low_resource_language",
          "kg_construction",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "graph_augmented_reco",
          "model_compression",
          "compilation_optimization",
          "inference_acceleration",
          "privacy_computing",
          "adversarial_attack",
          "content_moderation",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_copyright",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "robot_dialogue_logic"
        ],
        "summary_en": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management.",
        "summary_zh": "scrcpy 是一款开源应用程序，用于通过 USB 或 TCP/IP 在计算机上显示和控制 Android 设备。其实时流式传输设备屏幕，延迟极低，并允许通过计算机键盘和鼠标进行完全控制。核心功能包括屏幕镜像、音频转发、设备控制和屏幕录制。优势在于高性能、无需 root 权限以及跨平台兼容性。典型用例包括应用程序开发测试、演示、游戏和远程设备管理。该项目采用 C 语言开发，基于 FFmpeg、libav 和 SDL2 库，在 GitHub 上拥有超过 12.9 万星标，显示出广泛的社区认可和使用。",
        "summary_es": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management."
      }
    ],
    "tool_use": [
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "distilbert/distilbert-base-uncased",
        "source": "hf",
        "name": "distilbert-base-uncased",
        "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "distilbert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1910.01108",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11617607,
          "likes_total": 762,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX.",
        "summary_zh": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "summary_es": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "facebook/contriever",
        "source": "hf",
        "name": "contriever",
        "url": "https://huggingface.co/facebook/contriever",
        "tags": [
          "transformers",
          "pytorch",
          "bert",
          "arxiv:2112.09118",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Contriever是Facebook开发的稠密检索模型，无需标注的查询-文档对即可学习文本表示。该模型采用对比学习方法，使语义相似的文本在嵌入空间中更接近。基于BERT架构，通过自监督目标在大规模无标注语料上训练。主要优势包括有效的零样本检索能力和跨领域强性能，无需任务特定微调。典型应用场景包括文档检索、语义搜索和信息检索系统，特别适用于标注训练数据稀缺或不可得的情况。模型通过无监督方式学习通用文本表示，在各种检索任务中表现",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "tool_use",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Contriever is a dense retrieval model developed by Facebook that learns text representations without requiring labeled query-document pairs. It uses a contrastive learning approach where semantically similar texts are brought closer in embedding space. The model is based on BERT architecture and trained on large-scale unlabeled corpora through self-supervised objectives. Key strengths include effective zero-shot retrieval capabilities and strong performance across diverse domains without task-specific fine-tuning. Typical use cases include document retrieval, semantic search, and information retrieval systems where labeled training data is scarce or unavailable.",
        "summary_zh": "Contriever是Facebook开发的稠密检索模型，无需标注的查询-文档对即可学习文本表示。该模型采用对比学习方法，使语义相似的文本在嵌入空间中更接近。基于BERT架构，通过自监督目标在大规模无标注语料上训练。主要优势包括有效的零样本检索能力和跨领域强性能，无需任务特定微调。典型应用场景包括文档检索、语义搜索和信息检索系统，特别适用于标注训练数据稀缺或不可得的情况。模型通过无监督方式学习通用文本表示，在各种检索任务中表现",
        "summary_es": "Contriever is a dense retrieval model developed by Facebook that learns text representations without requiring labeled query-document pairs. It uses a contrastive learning approach where semantically similar texts are brought closer in embedding space. The model is based on BERT architecture and trained on large-scale unlabeled corpora through self-supervised objectives. Key strengths include effective zero-shot retrieval capabilities and strong performance across diverse domains without task-specific fine-tuning. Typical use cases include document retrieval, semantic search, and information retrieval systems where labeled training data is scarce or unavailable."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "Qwen/Qwen3-0.6B",
        "source": "hf",
        "name": "Qwen3-0.6B",
        "url": "https://huggingface.co/Qwen/Qwen3-0.6B",
        "tags": [
          "transformers",
          "safetensors",
          "qwen3",
          "text-generation",
          "conversational",
          "arxiv:2505.09388",
          "base_model:Qwen/Qwen3-0.6B-Base",
          "base_model:finetune:Qwen/Qwen3-0.6B-Base",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6417337,
          "likes_total": 649,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen3-0.6B是由Qwen开发的紧凑型0.6亿参数语言模型，专为高效文本生成任务设计。该模型基于Qwen3-0.6B-Base基础架构，优化用于资源受限环境的对话式AI应用。核心能力包括自然语言理解与生成，支持基于Transformer的推理架构。主要优势在于采用Apache 2.0开源许可，兼容微调和自动训练工具，并能与Hugging Face等流行框架集成。典型应用场景涵盖聊天机器人、文本补全等轻量级AI任务，特别适用于计算效率优先而非极致性能要求的部署环境。模型在Hugging Face平台已获得广泛下载，体现了其在实际应用中的实",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "tool_use",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen3-0.6B is a compact 0.6 billion parameter language model developed by Qwen, designed for efficient text generation tasks. It serves as a conversational AI model built upon the Qwen3-0.6B-Base foundation, optimized for deployment in resource-constrained environments. Core capabilities include natural language understanding and generation, supporting transformer-based inference. Strengths include Apache 2.0 licensing for open use, compatibility with fine-tuning and auto-training tools, and integration with popular frameworks like Hugging Face. Typical use cases involve chatbots, text completion, and lightweight AI applications where computational efficiency is prioritized over maximum performance.",
        "summary_zh": "Qwen3-0.6B是由Qwen开发的紧凑型0.6亿参数语言模型，专为高效文本生成任务设计。该模型基于Qwen3-0.6B-Base基础架构，优化用于资源受限环境的对话式AI应用。核心能力包括自然语言理解与生成，支持基于Transformer的推理架构。主要优势在于采用Apache 2.0开源许可，兼容微调和自动训练工具，并能与Hugging Face等流行框架集成。典型应用场景涵盖聊天机器人、文本补全等轻量级AI任务，特别适用于计算效率优先而非极致性能要求的部署环境。模型在Hugging Face平台已获得广泛下载，体现了其在实际应用中的实",
        "summary_es": "Qwen3-0.6B is a compact 0.6 billion parameter language model developed by Qwen, designed for efficient text generation tasks. It serves as a conversational AI model built upon the Qwen3-0.6B-Base foundation, optimized for deployment in resource-constrained environments. Core capabilities include natural language understanding and generation, supporting transformer-based inference. Strengths include Apache 2.0 licensing for open use, compatibility with fine-tuning and auto-training tools, and integration with popular frameworks like Hugging Face. Typical use cases involve chatbots, text completion, and lightweight AI applications where computational efficiency is prioritized over maximum performance."
      }
    ],
    "lora_adapter": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      }
    ],
    "multilingual_processing": [
      {
        "id": "FacebookAI/xlm-roberta-base",
        "source": "hf",
        "name": "xlm-roberta-base",
        "url": "https://huggingface.co/FacebookAI/xlm-roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "xlm-roberta",
          "fill-mask",
          "exbert",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:1911.02116",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7771691,
          "likes_total": 732,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "xlm-roberta-base是由Facebook AI开发的多语言掩码语言模型，基于RoBERTa架构改进而成。该模型支持100种语言，使用CommonCrawl的大规模多语言文本进行预训练。主要优势在于无需平行语料即可实现跨语言理解，在零样本跨语言迁移任务中表现优异。核心功能包括多语言文本分类、命名实体识别和问答系统。技术特点包括改进的预训练目标、更好的跨语言表示对齐以及高效的多语言处理能力。典型应用场景涵盖多语言内容分析、跨语言信息检索、多语言客服系统以及需要同时处理",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "multilingual_processing",
          "auto_evaluation_models"
        ],
        "summary_en": "xlm-roberta-base is a multilingual masked language model developed by Facebook AI, based on the RoBERTa architecture. It supports 100 languages and is pretrained on large-scale multilingual text from CommonCrawl. The model excels at cross-lingual understanding tasks without requiring parallel data. Core capabilities include text classification, named entity recognition, and question answering across languages. Its strengths lie in robust zero-shot cross-lingual transfer performance and efficient representation learning. Typical use cases involve multilingual content analysis, cross-lingual information retrieval, and building applications that require understanding multiple languages simultaneously.",
        "summary_zh": "xlm-roberta-base是由Facebook AI开发的多语言掩码语言模型，基于RoBERTa架构改进而成。该模型支持100种语言，使用CommonCrawl的大规模多语言文本进行预训练。主要优势在于无需平行语料即可实现跨语言理解，在零样本跨语言迁移任务中表现优异。核心功能包括多语言文本分类、命名实体识别和问答系统。技术特点包括改进的预训练目标、更好的跨语言表示对齐以及高效的多语言处理能力。典型应用场景涵盖多语言内容分析、跨语言信息检索、多语言客服系统以及需要同时处理",
        "summary_es": "xlm-roberta-base is a multilingual masked language model developed by Facebook AI, based on the RoBERTa architecture. It supports 100 languages and is pretrained on large-scale multilingual text from CommonCrawl. The model excels at cross-lingual understanding tasks without requiring parallel data. Core capabilities include text classification, named entity recognition, and question answering across languages. Its strengths lie in robust zero-shot cross-lingual transfer performance and efficient representation learning. Typical use cases involve multilingual content analysis, cross-lingual information retrieval, and building applications that require understanding multiple languages simultaneously."
      },
      {
        "id": "google-t5/t5-small",
        "source": "hf",
        "name": "t5-small",
        "url": "https://huggingface.co/google-t5/t5-small",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "onnx",
          "safetensors",
          "t5",
          "text2text-generation",
          "summarization",
          "translation",
          "en",
          "fr",
          "ro",
          "de",
          "multilingual",
          "dataset:c4",
          "arxiv:1805.12471",
          "arxiv:1708.00055",
          "arxiv:1704.05426",
          "arxiv:1606.05250",
          "arxiv:1808.09121",
          "arxiv:1810.12885",
          "arxiv:1905.10044",
          "arxiv:1910.09700",
          "license:apache-2.0",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 4970400,
          "likes_total": 492,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "T5-small是谷歌开发的紧凑型文本到文本转换Transformer模型，将所有自然语言处理任务统一为文本生成问题。该模型基于T5架构，使用统一的前缀提示将分类、翻译等任务转换为文本输出。支持英语、德语、法语等多语言，并在C4数据集上进行预训练。模型体积小巧，适合资源受限环境，同时在摘要生成、问答系统、文本分类等多种NLP应用中保持合理性能。其核心优势在于统一的文本到文本框架简化了多任务处理流程。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "text_to_image",
          "text_to_video",
          "code_generation",
          "multilingual_processing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "inference_acceleration",
          "training_data_anonymization",
          "training_data_copyright",
          "molecular_generation"
        ],
        "summary_en": "T5-small is a compact text-to-text transformer model from Google that treats all NLP tasks as text generation problems. Based on the T5 architecture, it converts inputs like classification or translation into text outputs using consistent prefix prompts. The model supports multiple languages including English, German, and French, and was pre-trained on the C4 dataset. Its small size makes it suitable for resource-constrained environments while maintaining reasonable performance across various NLP applications such as summarization, question answering, and text classification tasks.",
        "summary_zh": "T5-small是谷歌开发的紧凑型文本到文本转换Transformer模型，将所有自然语言处理任务统一为文本生成问题。该模型基于T5架构，使用统一的前缀提示将分类、翻译等任务转换为文本输出。支持英语、德语、法语等多语言，并在C4数据集上进行预训练。模型体积小巧，适合资源受限环境，同时在摘要生成、问答系统、文本分类等多种NLP应用中保持合理性能。其核心优势在于统一的文本到文本框架简化了多任务处理流程。",
        "summary_es": "T5-small is a compact text-to-text transformer model from Google that treats all NLP tasks as text generation problems. Based on the T5 architecture, it converts inputs like classification or translation into text outputs using consistent prefix prompts. The model supports multiple languages including English, German, and French, and was pre-trained on the C4 dataset. Its small size makes it suitable for resource-constrained environments while maintaining reasonable performance across various NLP applications such as summarization, question answering, and text classification tasks."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      }
    ],
    "low_resource_language": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      },
      {
        "id": "EbookFoundation/free-programming-books",
        "source": "github",
        "name": "free-programming-books",
        "url": "https://github.com/EbookFoundation/free-programming-books",
        "tags": [
          "books",
          "education",
          "hacktoberfest",
          "list",
          "resource"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:01:07Z",
        "added_at": "2025-09-27",
        "summary": ":books: Freely available programming books",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998706514989548,
        "task_keys": [
          "low_resource_language",
          "low_resource_medical_ai",
          "low_resource_voice_assistant"
        ],
        "summary_en": "The free-programming-books repository provides a comprehensive collection of freely available programming books and educational resources. Its primary purpose is to compile and organize programming knowledge accessible to everyone without cost. Core capabilities include categorizing resources by programming language, technology domain, and resource type. Key strengths are the extensive multilingual coverage, community-driven curation, and regular updates. Typical use cases include self-learning programming, academic reference, professional skill development, and educational institutions seeking free teaching materials. The project maintains high-quality standards through community contributions and verification.",
        "summary_zh": "free-programming-books 项目是一个收集和整理免费编程书籍与教育资源的综合性知识库。其主要目的是为全球学习者提供无需付费即可获取的编程学习材料。核心功能包括按编程语言、技术领域和资源类型进行分类整理，支持多语言内容收录。项目优势在于资源覆盖面广、社区驱动更新维护、内容质量经过验证。典型应用场景包括编程自学、学术参考、职业技能提升以及教育机构寻找免费教材。该项目通过社区协作确保资源的时效性和准确性，已成为编程",
        "summary_es": "The free-programming-books repository provides a comprehensive collection of freely available programming books and educational resources. Its primary purpose is to compile and organize programming knowledge accessible to everyone without cost. Core capabilities include categorizing resources by programming language, technology domain, and resource type. Key strengths are the extensive multilingual coverage, community-driven curation, and regular updates. Typical use cases include self-learning programming, academic reference, professional skill development, and educational institutions seeking free teaching materials. The project maintains high-quality standards through community contributions and verification."
      },
      {
        "id": "f/awesome-chatgpt-prompts",
        "source": "github",
        "name": "awesome-chatgpt-prompts",
        "url": "https://github.com/f/awesome-chatgpt-prompts",
        "tags": [
          "bots",
          "chatbot",
          "chatgpt",
          "chatgpt-api",
          "language"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T13:53:00Z",
        "added_at": "2025-09-28",
        "summary": "This repo includes ChatGPT prompt curation to use ChatGPT and other LLM tools better.",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.0999750689647807,
        "task_keys": [
          "low_resource_language"
        ],
        "summary_en": "The awesome-chatgpt-prompts repository is a comprehensive collection of curated prompts designed to enhance interactions with ChatGPT and other large language models. Its primary purpose is to provide users with effective conversation starters and task-specific templates that maximize AI utility. Core capabilities include prompt organization by use case, structured formatting for easy implementation, and community-contributed content. Key strengths are its extensive prompt library, practical applicability across domains, and open-source accessibility. Typical use cases span creative writing assistance, technical problem-solving, educational support, and productivity enhancement through optimized AI interactions.",
        "summary_zh": "awesome-chatgpt-prompts 项目是一个精心策划的提示词集合库，专门用于优化用户与ChatGPT及其他大语言模型的交互体验。其主要目的是通过提供有效的对话启动器和任务特定模板来最大化人工智能工具的实用性。核心功能包括按使用场景分类的提示词组织、易于实现的结构化格式以及社区贡献内容。项目优势在于其广泛的提示词库、跨领域实际应用性以及开源可访问性。典型应用场景涵盖创意写作辅助、技术问题解决、教育支持以及通过优化AI交互提升工作",
        "summary_es": "The awesome-chatgpt-prompts repository is a comprehensive collection of curated prompts designed to enhance interactions with ChatGPT and other large language models. Its primary purpose is to provide users with effective conversation starters and task-specific templates that maximize AI utility. Core capabilities include prompt organization by use case, structured formatting for easy implementation, and community-contributed content. Key strengths are its extensive prompt library, practical applicability across domains, and open-source accessibility. Typical use cases span creative writing assistance, technical problem-solving, educational support, and productivity enhancement through optimized AI interactions."
      },
      {
        "id": "golang/go",
        "source": "github",
        "name": "go",
        "url": "https://github.com/golang/go",
        "tags": [
          "go",
          "golang",
          "language",
          "programming-language"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:35:11Z",
        "added_at": "2025-09-28",
        "summary": "The Go programming language",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09995204495118498,
        "task_keys": [
          "low_resource_language"
        ],
        "summary_en": "Go is an open-source programming language developed at Google, designed for building efficient, reliable software at scale. Its core capabilities include built-in concurrency support through goroutines and channels, fast compilation, static typing with garbage collection, and a comprehensive standard library. Key strengths are excellent performance, simplicity with minimal syntax, strong tooling, and cross-platform compatibility. Typical use cases include web servers, cloud infrastructure, distributed systems, command-line tools, and network applications where concurrent processing and high performance are essential.",
        "summary_zh": "Go 是由 Google 开发的开源编程语言，专为构建高效、可靠的大规模软件而设计。其核心能力包括通过 goroutine 和 channel 实现的内置并发支持、快速编译、带垃圾回收的静态类型系统以及全面的标准库。主要优势在于出色的性能表现、语法简洁易学、强大的工具链支持和跨平台兼容性。典型应用场景包括 Web 服务器、云基础设施、分布式系统、命令行工具和网络应用，特别适用于需要高并发处理和高性能要求的场合。该语言注重开发效率和代码可维护性，适合现代软件工",
        "summary_es": "Go is an open-source programming language developed at Google, designed for building efficient, reliable software at scale. Its core capabilities include built-in concurrency support through goroutines and channels, fast compilation, static typing with garbage collection, and a comprehensive standard library. Key strengths are excellent performance, simplicity with minimal syntax, strong tooling, and cross-platform compatibility. Typical use cases include web servers, cloud infrastructure, distributed systems, command-line tools, and network applications where concurrent processing and high performance are essential."
      }
    ],
    "knowledge_editing": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      }
    ],
    "nlp_data_synthesis": [
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "google-bert/bert-base-uncased",
        "source": "hf",
        "name": "bert-base-uncased",
        "url": "https://huggingface.co/google-bert/bert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "coreml",
          "onnx",
          "safetensors",
          "bert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1810.04805",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 55204102,
          "likes_total": 2417,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "BERT-base-uncased是基于Transformer架构的英语预训练语言模型，在Wikipedia和BookCorpus语料上通过掩码语言建模和下一句预测任务进行训练。该模型采用双向编码器设计，能够深度理解词语在上下文中的语义关系。其主要优势在于强大的语境理解能力和通用性，支持文本分类、命名实体识别、问答系统、情感分析等多种自然语言处理任务。作为uncased版本，模型不区分字母大小写，适用于大多数不需要大小写敏感处理的通用文本分析场景。该模型已成为许多下游NLP应用的基础架构。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright"
        ],
        "summary_en": "BERT-base-uncased is a foundational transformer model pre-trained on English text from Wikipedia and BookCorpus. It employs masked language modeling and next sentence prediction to develop deep bidirectional contextual representations. The model excels at understanding word meanings in context and capturing semantic relationships. Its primary applications include text classification, named entity recognition, question answering, and sentiment analysis. As an uncased model, it treats uppercase and lowercase letters identically, making it suitable for general text processing tasks where case sensitivity is not required.",
        "summary_zh": "BERT-base-uncased是基于Transformer架构的英语预训练语言模型，在Wikipedia和BookCorpus语料上通过掩码语言建模和下一句预测任务进行训练。该模型采用双向编码器设计，能够深度理解词语在上下文中的语义关系。其主要优势在于强大的语境理解能力和通用性，支持文本分类、命名实体识别、问答系统、情感分析等多种自然语言处理任务。作为uncased版本，模型不区分字母大小写，适用于大多数不需要大小写敏感处理的通用文本分析场景。该模型已成为许多下游NLP应用的基础架构。",
        "summary_es": "BERT-base-uncased is a foundational transformer model pre-trained on English text from Wikipedia and BookCorpus. It employs masked language modeling and next sentence prediction to develop deep bidirectional contextual representations. The model excels at understanding word meanings in context and capturing semantic relationships. Its primary applications include text classification, named entity recognition, question answering, and sentiment analysis. As an uncased model, it treats uppercase and lowercase letters identically, making it suitable for general text processing tasks where case sensitivity is not required."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "sindresorhus/awesome",
        "source": "github",
        "name": "awesome",
        "url": "https://github.com/sindresorhus/awesome",
        "tags": [
          "awesome",
          "awesome-list",
          "lists",
          "resources",
          "unicorns"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:56:09Z",
        "added_at": "2025-09-28",
        "summary": "😎 Awesome lists about all kinds of interesting topics",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998513640566759,
        "task_keys": [
          "nlp_data_synthesis"
        ],
        "summary_en": "Awesome is a curated GitHub repository serving as a master list of high-quality resource collections across diverse topics. Its core purpose is to organize and index specialized 'awesome lists' that compile the best tools, libraries, and learning materials in specific domains. Key strengths include comprehensive coverage, rigorous curation standards, and community-driven maintenance. Typical use cases involve developers, researchers, and learners quickly discovering authoritative resources for programming languages, frameworks, software tools, and various technical or creative fields without searching scattered sources.",
        "summary_zh": "Awesome 是一个托管在 GitHub 上的精选仓库，其核心目的是作为一个主列表，系统性地组织和索引涵盖各种有趣主题的专业“awesome lists”。这些列表专门收集特定领域内最优质的工具、库、资源和学习材料。项目的主要优势在于其覆盖范围广泛、内容经过严格筛选、并由社区共同维护更新。典型的应用场景包括：开发人员、研究人员和学习者能够快速发现针对编程语言、框架、软件工具以及其他技术或创意领域的权威资源集合，从而避免在分散的渠道中低效搜寻。",
        "summary_es": "Awesome is a curated GitHub repository serving as a master list of high-quality resource collections across diverse topics. Its core purpose is to organize and index specialized 'awesome lists' that compile the best tools, libraries, and learning materials in specific domains. Key strengths include comprehensive coverage, rigorous curation standards, and community-driven maintenance. Typical use cases involve developers, researchers, and learners quickly discovering authoritative resources for programming languages, frameworks, software tools, and various technical or creative fields without searching scattered sources."
      },
      {
        "id": "huggingface/transformers",
        "source": "github",
        "name": "transformers",
        "url": "https://github.com/huggingface/transformers",
        "tags": [
          "audio",
          "deep-learning",
          "deepseek",
          "gemma",
          "glm",
          "hacktoberfest",
          "llm",
          "machine-learning",
          "model-hub",
          "natural-language-processing",
          "nlp",
          "pretrained-models",
          "python",
          "pytorch",
          "pytorch-transformers",
          "qwen",
          "speech-recognition",
          "transformer",
          "vlm"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:04:48Z",
        "added_at": "2025-09-27",
        "summary": "🤗 Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09996249573059768,
        "task_keys": [
          "lightweight_visual_model",
          "llm_pretraining",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "nlp_bias_mitigation",
          "asr",
          "lightweight_multimodal_model",
          "inference_acceleration"
        ],
        "summary_en": "Hugging Face Transformers is an open-source Python library providing state-of-the-art machine learning models for text, vision, audio, and multimodal applications. It offers thousands of pretrained models for both inference and training, supporting popular architectures like Transformer, LLM, VLM, and audio models. Core capabilities include easy model loading, fine-tuning, and deployment across frameworks like PyTorch. Strengths include its extensive model hub, community support, and comprehensive documentation. Typical use cases span natural language processing, speech recognition, computer vision, and multimodal AI tasks.",
        "summary_zh": "Hugging Face Transformers 是一个开源 Python 库，为文本、视觉、音频和多模态应用提供最先进的机器学习模型。该库包含数千个预训练模型，支持推理和训练，涵盖 Transformer、大语言模型、视觉语言模型和音频模型等流行架构。核心功能包括简易模型加载、微调和跨框架部署（如 PyTorch）。主要优势在于其庞大的模型库、活跃的社区支持和全面的文档。典型应用场景包括自然语言处理、语音识别、计算机视觉和多模态人工智能任务，适用于研究和生产环境。",
        "summary_es": "Hugging Face Transformers is an open-source Python library providing state-of-the-art machine learning models for text, vision, audio, and multimodal applications. It offers thousands of pretrained models for both inference and training, supporting popular architectures like Transformer, LLM, VLM, and audio models. Core capabilities include easy model loading, fine-tuning, and deployment across frameworks like PyTorch. Strengths include its extensive model hub, community support, and comprehensive documentation. Typical use cases span natural language processing, speech recognition, computer vision, and multimodal AI tasks."
      },
      {
        "id": "Chalarangelo/30-seconds-of-code",
        "source": "github",
        "name": "30-seconds-of-code",
        "url": "https://github.com/Chalarangelo/30-seconds-of-code",
        "tags": [
          "astro",
          "awesome-list",
          "css",
          "education",
          "es6-javascript",
          "git",
          "html",
          "javascript",
          "learn-to-code",
          "learning-resources",
          "nodejs",
          "programming",
          "snippets"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:58:11Z",
        "added_at": "2025-09-28",
        "summary": "Coding articles to level up your development skills",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09986828539246478,
        "task_keys": [
          "nlp_data_synthesis"
        ],
        "summary_en": "30 Seconds of Code is an educational JavaScript resource providing concise code snippets for skill development. Its core capability lies in offering practical, reusable code examples covering ES6 JavaScript, Node.js, HTML, CSS, and Git. Key strengths include quick comprehension through brief explanations and immediate applicability across web development contexts. Typical use cases involve learning modern JavaScript features, solving common programming problems efficiently, and discovering optimized implementation patterns for both beginners and experienced developers seeking to enhance their coding proficiency.",
        "summary_zh": "30秒代码是一个教育性JavaScript资源库，旨在通过简洁的代码片段提升开发技能。其核心能力在于提供涵盖ES6 JavaScript、Node.js、HTML、CSS和Git的实用可复用代码示例。主要优势包括通过简短解释实现快速理解，以及跨Web开发场景的即时适用性。典型使用场景包括学习现代JavaScript特性、高效解决常见编程问题，以及为初学者和经验丰富的开发者发现优化实现模式，从而系统性地提高编码水平。该项目专注于代码质量而非营销宣传，强调实际开发价值。",
        "summary_es": "30 Seconds of Code is an educational JavaScript resource providing concise code snippets for skill development. Its core capability lies in offering practical, reusable code examples covering ES6 JavaScript, Node.js, HTML, CSS, and Git. Key strengths include quick comprehension through brief explanations and immediate applicability across web development contexts. Typical use cases involve learning modern JavaScript features, solving common programming problems efficiently, and discovering optimized implementation patterns for both beginners and experienced developers seeking to enhance their coding proficiency."
      }
    ],
    "nlp_data_distillation": [
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "google-bert/bert-base-uncased",
        "source": "hf",
        "name": "bert-base-uncased",
        "url": "https://huggingface.co/google-bert/bert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "coreml",
          "onnx",
          "safetensors",
          "bert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1810.04805",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 55204102,
          "likes_total": 2417,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "BERT-base-uncased是基于Transformer架构的英语预训练语言模型，在Wikipedia和BookCorpus语料上通过掩码语言建模和下一句预测任务进行训练。该模型采用双向编码器设计，能够深度理解词语在上下文中的语义关系。其主要优势在于强大的语境理解能力和通用性，支持文本分类、命名实体识别、问答系统、情感分析等多种自然语言处理任务。作为uncased版本，模型不区分字母大小写，适用于大多数不需要大小写敏感处理的通用文本分析场景。该模型已成为许多下游NLP应用的基础架构。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright"
        ],
        "summary_en": "BERT-base-uncased is a foundational transformer model pre-trained on English text from Wikipedia and BookCorpus. It employs masked language modeling and next sentence prediction to develop deep bidirectional contextual representations. The model excels at understanding word meanings in context and capturing semantic relationships. Its primary applications include text classification, named entity recognition, question answering, and sentiment analysis. As an uncased model, it treats uppercase and lowercase letters identically, making it suitable for general text processing tasks where case sensitivity is not required.",
        "summary_zh": "BERT-base-uncased是基于Transformer架构的英语预训练语言模型，在Wikipedia和BookCorpus语料上通过掩码语言建模和下一句预测任务进行训练。该模型采用双向编码器设计，能够深度理解词语在上下文中的语义关系。其主要优势在于强大的语境理解能力和通用性，支持文本分类、命名实体识别、问答系统、情感分析等多种自然语言处理任务。作为uncased版本，模型不区分字母大小写，适用于大多数不需要大小写敏感处理的通用文本分析场景。该模型已成为许多下游NLP应用的基础架构。",
        "summary_es": "BERT-base-uncased is a foundational transformer model pre-trained on English text from Wikipedia and BookCorpus. It employs masked language modeling and next sentence prediction to develop deep bidirectional contextual representations. The model excels at understanding word meanings in context and capturing semantic relationships. Its primary applications include text classification, named entity recognition, question answering, and sentiment analysis. As an uncased model, it treats uppercase and lowercase letters identically, making it suitable for general text processing tasks where case sensitivity is not required."
      },
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "huggingface/transformers",
        "source": "github",
        "name": "transformers",
        "url": "https://github.com/huggingface/transformers",
        "tags": [
          "audio",
          "deep-learning",
          "deepseek",
          "gemma",
          "glm",
          "hacktoberfest",
          "llm",
          "machine-learning",
          "model-hub",
          "natural-language-processing",
          "nlp",
          "pretrained-models",
          "python",
          "pytorch",
          "pytorch-transformers",
          "qwen",
          "speech-recognition",
          "transformer",
          "vlm"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:04:48Z",
        "added_at": "2025-09-27",
        "summary": "🤗 Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09996249573059768,
        "task_keys": [
          "lightweight_visual_model",
          "llm_pretraining",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "nlp_bias_mitigation",
          "asr",
          "lightweight_multimodal_model",
          "inference_acceleration"
        ],
        "summary_en": "Hugging Face Transformers is an open-source Python library providing state-of-the-art machine learning models for text, vision, audio, and multimodal applications. It offers thousands of pretrained models for both inference and training, supporting popular architectures like Transformer, LLM, VLM, and audio models. Core capabilities include easy model loading, fine-tuning, and deployment across frameworks like PyTorch. Strengths include its extensive model hub, community support, and comprehensive documentation. Typical use cases span natural language processing, speech recognition, computer vision, and multimodal AI tasks.",
        "summary_zh": "Hugging Face Transformers 是一个开源 Python 库，为文本、视觉、音频和多模态应用提供最先进的机器学习模型。该库包含数千个预训练模型，支持推理和训练，涵盖 Transformer、大语言模型、视觉语言模型和音频模型等流行架构。核心功能包括简易模型加载、微调和跨框架部署（如 PyTorch）。主要优势在于其庞大的模型库、活跃的社区支持和全面的文档。典型应用场景包括自然语言处理、语音识别、计算机视觉和多模态人工智能任务，适用于研究和生产环境。",
        "summary_es": "Hugging Face Transformers is an open-source Python library providing state-of-the-art machine learning models for text, vision, audio, and multimodal applications. It offers thousands of pretrained models for both inference and training, supporting popular architectures like Transformer, LLM, VLM, and audio models. Core capabilities include easy model loading, fine-tuning, and deployment across frameworks like PyTorch. Strengths include its extensive model hub, community support, and comprehensive documentation. Typical use cases span natural language processing, speech recognition, computer vision, and multimodal AI tasks."
      }
    ],
    "dialogue_system_optimization": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      }
    ],
    "nlp_bias_mitigation": [
      {
        "id": "nlpaueb/legal-bert-base-uncased",
        "source": "hf",
        "name": "legal-bert-base-uncased",
        "url": "https://huggingface.co/nlpaueb/legal-bert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "bert",
          "pretraining",
          "legal",
          "fill-mask",
          "en",
          "license:cc-by-sa-4.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 5574178,
          "likes_total": 271,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Legal-BERT-Base-Uncased 是基于 BERT 架构、专门针对法律文本预训练的英语语言模型，使用欧盟法律文档进行训练。其核心目的是提升法律文档的自然语言处理能力，具备掩码语言建模和法律文本理解功能。主要优势包括针对法律术语的领域专业化训练，以及支持 PyTorch、TensorFlow 和 JAX 等多框架兼容性。典型应用场景涵盖法律文件分析、合同审查、法律研究辅助，以及需要精确理解法律语言的自动化文本处理任务，适用于法律科技和文档处理工作流。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "llm_pretraining",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "nlp_bias_mitigation",
          "training_data_anonymization",
          "training_data_copyright"
        ],
        "summary_en": "Legal-BERT-Base-Uncased is a specialized BERT model pretrained on extensive English legal text from the European Union. Its purpose is to enhance natural language processing for legal documents. Core capabilities include masked language modeling for text completion and legal text understanding. Strengths are domain-specific training on legal terminology and compatibility with major ML frameworks. Typical use cases involve legal document analysis, contract review, legal research assistance, and automated legal text processing tasks requiring accurate comprehension of legal language.",
        "summary_zh": "Legal-BERT-Base-Uncased 是基于 BERT 架构、专门针对法律文本预训练的英语语言模型，使用欧盟法律文档进行训练。其核心目的是提升法律文档的自然语言处理能力，具备掩码语言建模和法律文本理解功能。主要优势包括针对法律术语的领域专业化训练，以及支持 PyTorch、TensorFlow 和 JAX 等多框架兼容性。典型应用场景涵盖法律文件分析、合同审查、法律研究辅助，以及需要精确理解法律语言的自动化文本处理任务，适用于法律科技和文档处理工作流。",
        "summary_es": "Legal-BERT-Base-Uncased is a specialized BERT model pretrained on extensive English legal text from the European Union. Its purpose is to enhance natural language processing for legal documents. Core capabilities include masked language modeling for text completion and legal text understanding. Strengths are domain-specific training on legal terminology and compatibility with major ML frameworks. Typical use cases involve legal document analysis, contract review, legal research assistance, and automated legal text processing tasks requiring accurate comprehension of legal language."
      },
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "BAAI/bge-base-en-v1.5",
        "source": "hf",
        "name": "bge-base-en-v1.5",
        "url": "https://huggingface.co/BAAI/bge-base-en-v1.5",
        "tags": [
          "sentence-transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "bert",
          "feature-extraction",
          "sentence-similarity",
          "transformers",
          "mteb",
          "en",
          "arxiv:2401.03462",
          "arxiv:2312.15503",
          "arxiv:2311.13534",
          "arxiv:2310.07554",
          "arxiv:2309.07597",
          "license:mit",
          "model-index",
          "autotrain_compatible",
          "text-embeddings-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BGE-base-en-v1.5是由北京智源人工智能研究院开发的英文文本嵌入模型，旨在将文本转换为高维向量表示以支持语义相似性任务。其核心能力在于生成能够捕捉语义信息的稠密嵌入，适用于语义搜索、文本聚类和检索增强生成等应用。该模型的优势包括在MTEB基准测试中的优异表现、高效的推理速度以及与PyTorch、ONNX等主流框架的兼容性。典型应用场景包括构建搜索引擎、推荐系统，以及为大型语言模型提供上下文知识增强，特别适合需要处理英文文本的工业",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BGE-base-en-v1.5 is an English text embedding model developed by BAAI, designed to convert text into high-dimensional vector representations for semantic similarity tasks. Its core capability lies in generating dense embeddings that capture semantic meaning, enabling applications like semantic search, text clustering, and retrieval-augmented generation. Strengths include strong performance on MTEB benchmarks, efficient inference, and compatibility with popular frameworks like PyTorch and ONNX. Typical use cases include building search engines, recommendation systems, and enhancing LLMs with contextual knowledge.",
        "summary_zh": "BGE-base-en-v1.5是由北京智源人工智能研究院开发的英文文本嵌入模型，旨在将文本转换为高维向量表示以支持语义相似性任务。其核心能力在于生成能够捕捉语义信息的稠密嵌入，适用于语义搜索、文本聚类和检索增强生成等应用。该模型的优势包括在MTEB基准测试中的优异表现、高效的推理速度以及与PyTorch、ONNX等主流框架的兼容性。典型应用场景包括构建搜索引擎、推荐系统，以及为大型语言模型提供上下文知识增强，特别适合需要处理英文文本的工业",
        "summary_es": "BGE-base-en-v1.5 is an English text embedding model developed by BAAI, designed to convert text into high-dimensional vector representations for semantic similarity tasks. Its core capability lies in generating dense embeddings that capture semantic meaning, enabling applications like semantic search, text clustering, and retrieval-augmented generation. Strengths include strong performance on MTEB benchmarks, efficient inference, and compatibility with popular frameworks like PyTorch and ONNX. Typical use cases include building search engines, recommendation systems, and enhancing LLMs with contextual knowledge."
      },
      {
        "id": "BAAI/bge-m3",
        "source": "hf",
        "name": "bge-m3",
        "url": "https://huggingface.co/BAAI/bge-m3",
        "tags": [
          "sentence-transformers",
          "pytorch",
          "onnx",
          "xlm-roberta",
          "feature-extraction",
          "sentence-similarity",
          "arxiv:2402.03216",
          "arxiv:2004.04906",
          "arxiv:2106.14807",
          "arxiv:2107.05720",
          "arxiv:2004.12832",
          "license:mit",
          "autotrain_compatible",
          "text-embeddings-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 5870877,
          "likes_total": 2379,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BGE-M3是由北京智源人工智能研究院开发的多语言文本嵌入模型，旨在为100多种语言生成高质量的向量表示。该模型的核心能力采用多功能设计，同时支持稠密向量、稀疏向量和多向量三种表示方式。主要优势包括出色的跨语言检索性能、高效处理长达8192个标记的文档能力，以及兼容多种推理框架的灵活性。典型应用场景涵盖多语言语义搜索、文档检索、文本聚类和相似性比较等任务，特别适用于需要跨语言理解的智能信息处理系统。模型基于XLM-RoBERTa",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "tool_use",
          "nlp_bias_mitigation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BGE-M3 is a multilingual embedding model developed by BAAI for generating dense vector representations of text. Its core capability lies in producing high-quality embeddings across 100+ languages using a multi-functionality approach that supports dense, sparse, and multi-vector representations. Key strengths include strong cross-lingual retrieval performance, efficient handling of long documents up to 8192 tokens, and compatibility with multiple inference frameworks. Typical use cases encompass multilingual semantic search, document retrieval, clustering, and similarity comparison tasks where cross-language understanding is required.",
        "summary_zh": "BGE-M3是由北京智源人工智能研究院开发的多语言文本嵌入模型，旨在为100多种语言生成高质量的向量表示。该模型的核心能力采用多功能设计，同时支持稠密向量、稀疏向量和多向量三种表示方式。主要优势包括出色的跨语言检索性能、高效处理长达8192个标记的文档能力，以及兼容多种推理框架的灵活性。典型应用场景涵盖多语言语义搜索、文档检索、文本聚类和相似性比较等任务，特别适用于需要跨语言理解的智能信息处理系统。模型基于XLM-RoBERTa",
        "summary_es": "BGE-M3 is a multilingual embedding model developed by BAAI for generating dense vector representations of text. Its core capability lies in producing high-quality embeddings across 100+ languages using a multi-functionality approach that supports dense, sparse, and multi-vector representations. Key strengths include strong cross-lingual retrieval performance, efficient handling of long documents up to 8192 tokens, and compatibility with multiple inference frameworks. Typical use cases encompass multilingual semantic search, document retrieval, clustering, and similarity comparison tasks where cross-language understanding is required."
      },
      {
        "id": "BAAI/bge-small-en-v1.5",
        "source": "hf",
        "name": "bge-small-en-v1.5",
        "url": "https://huggingface.co/BAAI/bge-small-en-v1.5",
        "tags": [
          "sentence-transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "bert",
          "feature-extraction",
          "sentence-similarity",
          "transformers",
          "mteb",
          "en",
          "arxiv:2401.03462",
          "arxiv:2312.15503",
          "arxiv:2311.13534",
          "arxiv:2310.07554",
          "arxiv:2309.07597",
          "license:mit",
          "model-index",
          "autotrain_compatible",
          "text-embeddings-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 4867805,
          "likes_total": 372,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BGE-small-en-v1.5是北京智源人工智能研究院开发的紧凑型英文文本嵌入模型，专门用于将文本高效转换为密集向量表示。该模型拥有4170万参数，在性能和计算效率之间取得平衡，支持最长512个标记的序列处理。其核心能力包括语义相似度计算、信息检索和文本聚类分析，特别适用于计算资源有限但需要快速推理的场景。该模型在多项自然语言处理基准测试中表现出色，能够为中小规模应用提供高质量的文本嵌入服务，典型用例包括文档检索、问答系统",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BGE-small-en-v1.5 is a compact English text embedding model developed by BAAI, designed to efficiently convert text into dense vector representations. With 41.7M parameters, it balances performance and computational efficiency, supporting sequence lengths up to 512 tokens. The model excels in semantic similarity tasks, retrieval applications, and clustering analysis. It's particularly suitable for resource-constrained environments requiring fast inference while maintaining competitive embedding quality across various NLP benchmarks.",
        "summary_zh": "BGE-small-en-v1.5是北京智源人工智能研究院开发的紧凑型英文文本嵌入模型，专门用于将文本高效转换为密集向量表示。该模型拥有4170万参数，在性能和计算效率之间取得平衡，支持最长512个标记的序列处理。其核心能力包括语义相似度计算、信息检索和文本聚类分析，特别适用于计算资源有限但需要快速推理的场景。该模型在多项自然语言处理基准测试中表现出色，能够为中小规模应用提供高质量的文本嵌入服务，典型用例包括文档检索、问答系统",
        "summary_es": "BGE-small-en-v1.5 is a compact English text embedding model developed by BAAI, designed to efficiently convert text into dense vector representations. With 41.7M parameters, it balances performance and computational efficiency, supporting sequence lengths up to 512 tokens. The model excels in semantic similarity tasks, retrieval applications, and clustering analysis. It's particularly suitable for resource-constrained environments requiring fast inference while maintaining competitive embedding quality across various NLP benchmarks."
      }
    ],
    "image_text_alignment": [
      {
        "id": "Falconsai/nsfw_image_detection",
        "source": "hf",
        "name": "nsfw_image_detection",
        "url": "https://huggingface.co/Falconsai/nsfw_image_detection",
        "tags": [
          "transformers",
          "pytorch",
          "safetensors",
          "vit",
          "image-classification",
          "arxiv:2010.11929",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 99881324,
          "likes_total": 826,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "image_text_alignment",
          "auto_evaluation_models",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems.",
        "summary_zh": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "summary_es": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems."
      },
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "multimodal_understanding_generation": [
      {
        "id": "openai-community/gpt2",
        "source": "hf",
        "name": "gpt2",
        "url": "https://huggingface.co/openai-community/gpt2",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "tflite",
          "rust",
          "onnx",
          "safetensors",
          "gpt2",
          "text-generation",
          "exbert",
          "en",
          "doi:10.57967/hf/0039",
          "license:mit",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11902438,
          "likes_total": 2955,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "GPT-2是由OpenAI开发的基于Transformer架构的语言生成模型，主要用于文本生成任务。其核心能力是通过输入提示预测后续文本内容，实现连贯的文本延续。主要优势包括在零样本设置下无需特定任务训练即可生成高质量文本、能够跨多个领域生成类人文本内容以及开源可访问性。典型应用场景涵盖创意写作辅助、对话系统原型开发、内容摘要生成和代码自动补全。该模型在开放式文本补全方面表现突出，能够在长文本输出中保持上下文相关性，同时支",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "text_to_image",
          "text_to_video",
          "code_generation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "inference_acceleration",
          "auto_evaluation_models",
          "molecular_generation"
        ],
        "summary_en": "GPT-2 is a transformer-based language model developed by OpenAI for text generation tasks. Its core capability involves predicting subsequent text based on input prompts, enabling coherent continuation of text. Key strengths include strong performance in zero-shot settings without task-specific training, generating human-like text across diverse domains, and open-source availability. Typical use cases encompass creative writing assistance, conversational AI prototyping, content summarization, and code generation. The model demonstrates particular effectiveness in open-ended text completion while maintaining contextual relevance throughout extended outputs.",
        "summary_zh": "GPT-2是由OpenAI开发的基于Transformer架构的语言生成模型，主要用于文本生成任务。其核心能力是通过输入提示预测后续文本内容，实现连贯的文本延续。主要优势包括在零样本设置下无需特定任务训练即可生成高质量文本、能够跨多个领域生成类人文本内容以及开源可访问性。典型应用场景涵盖创意写作辅助、对话系统原型开发、内容摘要生成和代码自动补全。该模型在开放式文本补全方面表现突出，能够在长文本输出中保持上下文相关性，同时支",
        "summary_es": "GPT-2 is a transformer-based language model developed by OpenAI for text generation tasks. Its core capability involves predicting subsequent text based on input prompts, enabling coherent continuation of text. Key strengths include strong performance in zero-shot settings without task-specific training, generating human-like text across diverse domains, and open-source availability. Typical use cases encompass creative writing assistance, conversational AI prototyping, content summarization, and code generation. The model demonstrates particular effectiveness in open-ended text completion while maintaining contextual relevance throughout extended outputs."
      },
      {
        "id": "facebook/opt-125m",
        "source": "hf",
        "name": "opt-125m",
        "url": "https://huggingface.co/facebook/opt-125m",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "opt",
          "text-generation",
          "en",
          "arxiv:2205.01068",
          "arxiv:2005.14165",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "region:us"
        ],
        "stats": {
          "downloads_total": 8602519,
          "likes_total": 218,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "OPT-125M是Meta AI开发的Open Pre-trained Transformer系列中的1.25亿参数仅解码器变压器语言模型，作为较大OPT模型的缩小版本，主要用于研究和实验目的。该模型能够根据输入提示生成连贯文本，支持多种自然语言处理任务。其主要优势包括面向研究用途的开放可访问性、支持多种框架（PyTorch、TensorFlow、JAX）的兼容性以及高效的推理能力。典型应用场景涵盖文本生成实验、变压器架构的教育演示、小规模语言模型性能基准测试，以及作为理解更大规模语言模型工作原理的入门工具。该模型特别适合计",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "text_to_image",
          "text_to_video",
          "code_generation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "inference_acceleration",
          "auto_evaluation_models",
          "molecular_generation"
        ],
        "summary_en": "OPT-125M is a 125 million parameter decoder-only transformer language model developed by Meta AI as part of the Open Pre-trained Transformer series. It serves as a smaller-scale version of larger OPT models for research and experimentation. The model generates coherent text based on input prompts and supports various natural language processing tasks. Its primary strengths include open accessibility for research purposes, compatibility with multiple frameworks (PyTorch, TensorFlow, JAX), and efficient inference capabilities. Typical use cases encompass text generation experiments, educational demonstrations of transformer architectures, and benchmarking smaller-scale language model performance.",
        "summary_zh": "OPT-125M是Meta AI开发的Open Pre-trained Transformer系列中的1.25亿参数仅解码器变压器语言模型，作为较大OPT模型的缩小版本，主要用于研究和实验目的。该模型能够根据输入提示生成连贯文本，支持多种自然语言处理任务。其主要优势包括面向研究用途的开放可访问性、支持多种框架（PyTorch、TensorFlow、JAX）的兼容性以及高效的推理能力。典型应用场景涵盖文本生成实验、变压器架构的教育演示、小规模语言模型性能基准测试，以及作为理解更大规模语言模型工作原理的入门工具。该模型特别适合计",
        "summary_es": "OPT-125M is a 125 million parameter decoder-only transformer language model developed by Meta AI as part of the Open Pre-trained Transformer series. It serves as a smaller-scale version of larger OPT models for research and experimentation. The model generates coherent text based on input prompts and supports various natural language processing tasks. Its primary strengths include open accessibility for research purposes, compatibility with multiple frameworks (PyTorch, TensorFlow, JAX), and efficient inference capabilities. Typical use cases encompass text generation experiments, educational demonstrations of transformer architectures, and benchmarking smaller-scale language model performance."
      },
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "asr": [
      {
        "id": "pyannote/speaker-diarization-3.1",
        "source": "hf",
        "name": "speaker-diarization-3.1",
        "url": "https://huggingface.co/pyannote/speaker-diarization-3.1",
        "tags": [
          "pyannote-audio",
          "pyannote",
          "pyannote-audio-pipeline",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "automatic-speech-recognition",
          "arxiv:2111.14448",
          "arxiv:2012.01477",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 16673680,
          "likes_total": 1169,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote speaker-diarization-3.1 是一个音频处理流程，专门用于自动分割和标记录音中的说话人身份。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该系统擅长处理多人对话场景，具有高时间精度，特别适用于会议转录、广播监控和对话分析等典型用例。基于 arXiv:2012.01477 和 arXiv:2111.14448 的研究成果，这款 MIT 许可的工具能够处理音频并输出结构化的时间线，准确识别“谁在何时说话”，在各种声学条件下均表现出稳定性能。该工具通过先进的深度学习技术实现对连续语音流的实",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "asr",
          "speaker_separation",
          "vector_retrieval",
          "graph_augmented_reco",
          "auto_evaluation_models",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote speaker-diarization-3.1 is an audio processing pipeline that automatically segments and labels speaker identities in audio recordings. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The system excels at handling multi-speaker conversations with high temporal precision, making it particularly strong for meeting transcriptions, broadcast monitoring, and conversational analysis. Based on research from arXiv:2012.01477 and arXiv:2111.14448, this MIT-licensed tool processes audio to output structured timelines identifying 'who spoke when' with robust performance across various acoustic conditions.",
        "summary_zh": "Pyannote speaker-diarization-3.1 是一个音频处理流程，专门用于自动分割和标记录音中的说话人身份。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该系统擅长处理多人对话场景，具有高时间精度，特别适用于会议转录、广播监控和对话分析等典型用例。基于 arXiv:2012.01477 和 arXiv:2111.14448 的研究成果，这款 MIT 许可的工具能够处理音频并输出结构化的时间线，准确识别“谁在何时说话”，在各种声学条件下均表现出稳定性能。该工具通过先进的深度学习技术实现对连续语音流的实",
        "summary_es": "Pyannote speaker-diarization-3.1 is an audio processing pipeline that automatically segments and labels speaker identities in audio recordings. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The system excels at handling multi-speaker conversations with high temporal precision, making it particularly strong for meeting transcriptions, broadcast monitoring, and conversational analysis. Based on research from arXiv:2012.01477 and arXiv:2111.14448, this MIT-licensed tool processes audio to output structured timelines identifying 'who spoke when' with robust performance across various acoustic conditions."
      },
      {
        "id": "pyannote/voice-activity-detection",
        "source": "hf",
        "name": "voice-activity-detection",
        "url": "https://huggingface.co/pyannote/voice-activity-detection",
        "tags": [
          "pyannote-audio",
          "pyannote",
          "pyannote-audio-pipeline",
          "audio",
          "voice",
          "speech",
          "speaker",
          "voice-activity-detection",
          "automatic-speech-recognition",
          "dataset:ami",
          "dataset:dihard",
          "dataset:voxconverse",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 4987990,
          "likes_total": 211,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "pyannote/语音活动检测模型是一款专门用于检测音频录音中语音片段的工具。其主要目的是识别人类语音存在与静默或背景噪声的时段。核心能力包括使用深度学习算法对语音区域进行精确的时间分割。关键优势在于对AMI、DIHARD和VoxConverse等挑战性数据集的高准确性，以及在各种声学条件下的稳健性能。典型应用场景包括语音识别系统的预处理、会议转录、播客编辑和说话人日志管道。该MIT许可的模型针对英语语音检测进行了优化，适用于需要精确语音边",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "asr",
          "speaker_separation",
          "vector_retrieval",
          "graph_augmented_reco",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "The pyannote/voice-activity-detection model is a specialized tool for detecting speech segments in audio recordings. Its primary purpose is to identify when human speech is present versus silence or background noise. Core capabilities include precise temporal segmentation of speech regions using deep learning algorithms. Key strengths include high accuracy on challenging datasets like AMI, DIHARD, and VoxConverse, and robust performance across diverse acoustic conditions. Typical use cases involve preprocessing for speech recognition systems, meeting transcription, podcast editing, and speaker diarization pipelines. The MIT-licensed model is optimized for English speech detection.",
        "summary_zh": "pyannote/语音活动检测模型是一款专门用于检测音频录音中语音片段的工具。其主要目的是识别人类语音存在与静默或背景噪声的时段。核心能力包括使用深度学习算法对语音区域进行精确的时间分割。关键优势在于对AMI、DIHARD和VoxConverse等挑战性数据集的高准确性，以及在各种声学条件下的稳健性能。典型应用场景包括语音识别系统的预处理、会议转录、播客编辑和说话人日志管道。该MIT许可的模型针对英语语音检测进行了优化，适用于需要精确语音边",
        "summary_es": "The pyannote/voice-activity-detection model is a specialized tool for detecting speech segments in audio recordings. Its primary purpose is to identify when human speech is present versus silence or background noise. Core capabilities include precise temporal segmentation of speech regions using deep learning algorithms. Key strengths include high accuracy on challenging datasets like AMI, DIHARD, and VoxConverse, and robust performance across diverse acoustic conditions. Typical use cases involve preprocessing for speech recognition systems, meeting transcription, podcast editing, and speaker diarization pipelines. The MIT-licensed model is optimized for English speech detection."
      },
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "openai/whisper-large-v3",
        "source": "hf",
        "name": "whisper-large-v3",
        "url": "https://huggingface.co/openai/whisper-large-v3",
        "tags": [
          "transformers",
          "pytorch",
          "jax",
          "safetensors",
          "whisper",
          "automatic-speech-recognition",
          "audio",
          "hf-asr-leaderboard",
          "en",
          "zh",
          "de",
          "es",
          "ru",
          "ko",
          "fr",
          "ja",
          "pt",
          "tr",
          "pl",
          "ca",
          "nl",
          "ar",
          "sv",
          "it",
          "id",
          "hi",
          "fi",
          "vi",
          "he",
          "uk",
          "el",
          "ms",
          "cs",
          "ro",
          "da",
          "hu",
          "ta",
          "no",
          "th",
          "ur",
          "hr",
          "bg",
          "lt",
          "la",
          "mi",
          "ml",
          "cy",
          "sk",
          "te",
          "fa",
          "lv",
          "bn",
          "sr",
          "az",
          "sl",
          "kn",
          "et",
          "mk",
          "br",
          "eu",
          "is",
          "hy",
          "ne",
          "mn",
          "bs",
          "kk",
          "sq",
          "sw",
          "gl",
          "mr",
          "pa",
          "si",
          "km",
          "sn",
          "yo",
          "so",
          "af",
          "oc",
          "ka",
          "be",
          "tg",
          "sd",
          "gu",
          "am",
          "yi",
          "lo",
          "uz",
          "fo",
          "ht",
          "ps",
          "tk",
          "nn",
          "mt",
          "sa",
          "lb",
          "my",
          "bo",
          "tl",
          "mg",
          "as",
          "tt",
          "haw",
          "ln",
          "ha",
          "ba",
          "jw",
          "su",
          "arxiv:2212.04356",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 4337851,
          "likes_total": 4948,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Whisper-large-v3是OpenAI开发的高级自动语音识别模型，专门用于多语言转录和翻译任务。该模型的核心能力包括将99种语言的语音音频转换为文本，并支持翻译成英语。其主要优势在于能够处理不同口音和音频条件，无需针对特定任务进行微调即可保持稳定性能。典型应用场景涵盖转录服务、无障碍工具、媒体字幕生成和多语言通信支持。基于Transformer架构，该模型能够处理不同时长和质量的音频输入，在其广泛的语言覆盖范围内保持较高的准确性和鲁棒性，适用",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "asr"
        ],
        "summary_en": "Whisper-large-v3 is OpenAI's advanced automatic speech recognition model designed for multilingual transcription and translation. Its core capability involves converting spoken audio into text across 99 languages, with additional translation functionality into English. The model's strengths include robust performance on diverse accents and audio conditions without requiring task-specific fine-tuning. Typical use cases span transcription services, accessibility tools, media subtitling, and multilingual communication support. Based on transformer architecture, it handles various audio durations and quality levels while maintaining accuracy across its extensive language coverage.",
        "summary_zh": "Whisper-large-v3是OpenAI开发的高级自动语音识别模型，专门用于多语言转录和翻译任务。该模型的核心能力包括将99种语言的语音音频转换为文本，并支持翻译成英语。其主要优势在于能够处理不同口音和音频条件，无需针对特定任务进行微调即可保持稳定性能。典型应用场景涵盖转录服务、无障碍工具、媒体字幕生成和多语言通信支持。基于Transformer架构，该模型能够处理不同时长和质量的音频输入，在其广泛的语言覆盖范围内保持较高的准确性和鲁棒性，适用",
        "summary_es": "Whisper-large-v3 is OpenAI's advanced automatic speech recognition model designed for multilingual transcription and translation. Its core capability involves converting spoken audio into text across 99 languages, with additional translation functionality into English. The model's strengths include robust performance on diverse accents and audio conditions without requiring task-specific fine-tuning. Typical use cases span transcription services, accessibility tools, media subtitling, and multilingual communication support. Based on transformer architecture, it handles various audio durations and quality levels while maintaining accuracy across its extensive language coverage."
      },
      {
        "id": "laion/clap-htsat-fused",
        "source": "hf",
        "name": "clap-htsat-fused",
        "url": "https://huggingface.co/laion/clap-htsat-fused",
        "tags": [
          "transformers",
          "pytorch",
          "safetensors",
          "clap",
          "feature-extraction",
          "arxiv:2211.06687",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "CLAP-HTSAT-Fused 是一种基于对比学习的多模态模型，旨在建立音频与文本之间的语义关联。其主要用途是通过学习音频信号和自然语言描述的联合表示，实现跨模态检索和分类任务。核心能力包括生成音频-文本嵌入向量、支持零样本音频分类以及基于内容的音频检索。该模型的显著优势在于融合了HTSAT音频编码器和CLAP对比学习框架，能够处理从环境声音到音乐等多种音频类型。典型应用场景涵盖音频标签标注、声音事件检测、多媒体搜索系统以及需要",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "asr",
          "multimodal_understanding_generation"
        ],
        "summary_en": "CLAP-HTSAT-Fused is a contrastive learning model that bridges audio and text modalities. Its primary purpose is to enable cross-modal retrieval and classification by learning joint representations between audio signals and natural language descriptions. Core capabilities include audio-text embedding generation, zero-shot audio classification, and content-based audio retrieval. Key strengths are the fusion of HTSAT audio encoder with CLAP's contrastive framework, supporting diverse audio types from environmental sounds to music. Typical use cases involve audio tagging, sound event detection, multimedia search systems, and audio content understanding applications where semantic alignment between sound and text is required.",
        "summary_zh": "CLAP-HTSAT-Fused 是一种基于对比学习的多模态模型，旨在建立音频与文本之间的语义关联。其主要用途是通过学习音频信号和自然语言描述的联合表示，实现跨模态检索和分类任务。核心能力包括生成音频-文本嵌入向量、支持零样本音频分类以及基于内容的音频检索。该模型的显著优势在于融合了HTSAT音频编码器和CLAP对比学习框架，能够处理从环境声音到音乐等多种音频类型。典型应用场景涵盖音频标签标注、声音事件检测、多媒体搜索系统以及需要",
        "summary_es": "CLAP-HTSAT-Fused is a contrastive learning model that bridges audio and text modalities. Its primary purpose is to enable cross-modal retrieval and classification by learning joint representations between audio signals and natural language descriptions. Core capabilities include audio-text embedding generation, zero-shot audio classification, and content-based audio retrieval. Key strengths are the fusion of HTSAT audio encoder with CLAP's contrastive framework, supporting diverse audio types from environmental sounds to music. Typical use cases involve audio tagging, sound event detection, multimedia search systems, and audio content understanding applications where semantic alignment between sound and text is required."
      }
    ],
    "tts": [
      {
        "id": "coqui/XTTS-v2",
        "source": "hf",
        "name": "XTTS-v2",
        "url": "https://huggingface.co/coqui/XTTS-v2",
        "tags": [
          "coqui",
          "text-to-speech",
          "license:other",
          "region:us"
        ],
        "stats": {
          "downloads_total": 5562668,
          "likes_total": 3059,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "XTTS-v2是由Coqui开发的多语言文本转语音模型，能够根据文本输入生成自然流畅的语音。其核心能力在于仅需6秒语音样本即可实现高质量的声音克隆，支持英语、西班牙语、法语、中文等13种语言。主要优势包括跨语言声音复制、情感语调控制和高效率推理。典型应用场景涵盖有声读物播讲、语音助手定制、内容本地化以及视障用户的辅助工具。该模型在声音相似度和自然度方面达到业界领先水平，特别适合需要个性化语音合成的商业和教育应用，同",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "tts"
        ],
        "summary_en": "XTTS-v2 is a multilingual text-to-speech model developed by Coqui that generates natural speech from text input. Its core capability lies in producing high-quality audio using just a 6-second voice sample for cloning, supporting 13 languages including English, Spanish, French, and Mandarin. Key strengths include cross-lingual voice cloning, emotional tone control, and efficient inference. Typical use cases encompass audiobook narration, voice assistant customization, content localization, and accessibility tools for visually impaired users. The model achieves state-of-the-art performance in voice similarity and naturalness.",
        "summary_zh": "XTTS-v2是由Coqui开发的多语言文本转语音模型，能够根据文本输入生成自然流畅的语音。其核心能力在于仅需6秒语音样本即可实现高质量的声音克隆，支持英语、西班牙语、法语、中文等13种语言。主要优势包括跨语言声音复制、情感语调控制和高效率推理。典型应用场景涵盖有声读物播讲、语音助手定制、内容本地化以及视障用户的辅助工具。该模型在声音相似度和自然度方面达到业界领先水平，特别适合需要个性化语音合成的商业和教育应用，同",
        "summary_es": "XTTS-v2 is a multilingual text-to-speech model developed by Coqui that generates natural speech from text input. Its core capability lies in producing high-quality audio using just a 6-second voice sample for cloning, supporting 13 languages including English, Spanish, French, and Mandarin. Key strengths include cross-lingual voice cloning, emotional tone control, and efficient inference. Typical use cases encompass audiobook narration, voice assistant customization, content localization, and accessibility tools for visually impaired users. The model achieves state-of-the-art performance in voice similarity and naturalness."
      }
    ],
    "slu": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "speaker_separation": [
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "pyannote/wespeaker-voxceleb-resnet34-LM",
        "source": "hf",
        "name": "wespeaker-voxceleb-resnet34-LM",
        "url": "https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "wespeaker",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-recognition",
          "speaker-verification",
          "speaker-identification",
          "speaker-embedding",
          "dataset:voxceleb",
          "license:cc-by-4.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 17739550,
          "likes_total": 76,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "wespeaker-voxceleb-resnet34-LM 是一个专门用于说话人识别的模型，其核心功能是从音频中提取具有区分性的说话人嵌入向量。该模型采用基于 VoxCeleb 数据集训练的 ResNet-34 架构，并集成了语言模型评分机制以提升验证准确性。主要优势包括在不同声学条件下的稳定表现和高效的说话人区分能力。典型应用场景涵盖说话人验证、身份识别任务以及需要区分不同说话人的语音日记系统。该模型能够处理原始语音信号并生成固定维度的表征向量，适用于需要精确说话人辨别的",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "low_resource_voice_assistant"
        ],
        "summary_en": "The wespeaker-voxceleb-resnet34-LM model is a speaker recognition system designed to extract distinctive speaker embeddings from audio. Its core capability involves processing speech signals to generate fixed-dimensional vectors that uniquely represent speaker characteristics. The model employs a ResNet-34 architecture trained on the VoxCeleb dataset, enhanced with language model scoring for improved verification accuracy. Key strengths include robust performance across diverse acoustic conditions and effective speaker discrimination. Typical use cases encompass speaker verification, identification tasks, and speaker diarization systems where distinguishing between different speakers is essential.",
        "summary_zh": "wespeaker-voxceleb-resnet34-LM 是一个专门用于说话人识别的模型，其核心功能是从音频中提取具有区分性的说话人嵌入向量。该模型采用基于 VoxCeleb 数据集训练的 ResNet-34 架构，并集成了语言模型评分机制以提升验证准确性。主要优势包括在不同声学条件下的稳定表现和高效的说话人区分能力。典型应用场景涵盖说话人验证、身份识别任务以及需要区分不同说话人的语音日记系统。该模型能够处理原始语音信号并生成固定维度的表征向量，适用于需要精确说话人辨别的",
        "summary_es": "The wespeaker-voxceleb-resnet34-LM model is a speaker recognition system designed to extract distinctive speaker embeddings from audio. Its core capability involves processing speech signals to generate fixed-dimensional vectors that uniquely represent speaker characteristics. The model employs a ResNet-34 architecture trained on the VoxCeleb dataset, enhanced with language model scoring for improved verification accuracy. Key strengths include robust performance across diverse acoustic conditions and effective speaker discrimination. Typical use cases encompass speaker verification, identification tasks, and speaker diarization systems where distinguishing between different speakers is essential."
      },
      {
        "id": "pyannote/segmentation",
        "source": "hf",
        "name": "segmentation",
        "url": "https://huggingface.co/pyannote/segmentation",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "arxiv:2104.04045",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6612709,
          "likes_total": 641,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote/segmentation 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志化和音频分割任务。其核心功能包括检测说话人转换、识别语音活动以及发现重叠语音。该模型的优势在于能够精确地将音频分割为单一说话人区域，并能准确检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和对话分析，在这些场景中确定“谁在何时说话”至关重要。基于 arXiv:2104.04045 的研究成果，这个 MIT 许可的模型可作为构建完整说话人日志化系统的基础组件，为音频处理管道",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "tool_use",
          "nlp_bias_mitigation",
          "speaker_separation",
          "vector_retrieval",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Pyannote/segmentation is a PyTorch-based neural network model for speaker diarization and audio segmentation tasks. Its core capabilities include speaker change detection, voice activity detection, and overlapped speech identification in audio streams. The model's strengths lie in its ability to precisely segment audio into speaker-homogeneous regions and detect when multiple speakers talk simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and conversational analysis where identifying 'who spoke when' is crucial. Based on research published in arXiv:2104.04045, this MIT-licensed model serves as a fundamental component for building complete speaker diarization systems.",
        "summary_zh": "Pyannote/segmentation 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志化和音频分割任务。其核心功能包括检测说话人转换、识别语音活动以及发现重叠语音。该模型的优势在于能够精确地将音频分割为单一说话人区域，并能准确检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和对话分析，在这些场景中确定“谁在何时说话”至关重要。基于 arXiv:2104.04045 的研究成果，这个 MIT 许可的模型可作为构建完整说话人日志化系统的基础组件，为音频处理管道",
        "summary_es": "Pyannote/segmentation is a PyTorch-based neural network model for speaker diarization and audio segmentation tasks. Its core capabilities include speaker change detection, voice activity detection, and overlapped speech identification in audio streams. The model's strengths lie in its ability to precisely segment audio into speaker-homogeneous regions and detect when multiple speakers talk simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and conversational analysis where identifying 'who spoke when' is crucial. Based on research published in arXiv:2104.04045, this MIT-licensed model serves as a fundamental component for building complete speaker diarization systems."
      }
    ],
    "noise_separation": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "full_duplex_dialogue": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "avsr": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "multimodal_dialogue_system": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "Snailclimb/JavaGuide",
        "source": "github",
        "name": "JavaGuide",
        "url": "https://github.com/Snailclimb/JavaGuide",
        "tags": [
          "algorithms",
          "interview",
          "java",
          "jvm",
          "mysql",
          "redis",
          "spring",
          "system",
          "system-design",
          "zookeeper"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:32:40Z",
        "added_at": "2025-09-27",
        "summary": "「Java学习+面试指南」一份涵盖大部分 Java 程序员所需要掌握的核心知识。准备 Java 面试，首选 JavaGuide！",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09973029133671205,
        "task_keys": [
          "dialogue_system_optimization",
          "multimodal_dialogue_system"
        ],
        "summary_en": "JavaGuide is a comprehensive learning and interview preparation resource for Java developers. It covers essential Java programming concepts, JVM internals, database technologies like MySQL and Redis, and popular frameworks including Spring. The project provides systematic knowledge organization, practical examples, and interview-focused content. Its strengths include extensive coverage of core Java technologies, real-world application scenarios, and continuous updates. Typical use cases include Java interview preparation, systematic learning of Java ecosystem technologies, and reference for developers working with Java-based systems and distributed architectures.",
        "summary_zh": "JavaGuide 是一个面向 Java 开发者的综合性学习与面试准备资源库。该项目系统整理了 Java 程序员需要掌握的核心知识体系，涵盖 Java 编程基础、JVM 原理、MySQL 和 Redis 等数据库技术，以及 Spring 等主流框架。项目特点包括知识结构清晰完整、内容实用性强、持续更新维护。主要优势在于覆盖了 Java 技术栈的关键领域，提供了大量面试常见问题和实际应用场景。典型使用场景包括 Java 面试准备、Java 技术体系系统学习、以及作为开发 Java 应用和分布式系统的技术参考文档。",
        "summary_es": "JavaGuide is a comprehensive learning and interview preparation resource for Java developers. It covers essential Java programming concepts, JVM internals, database technologies like MySQL and Redis, and popular frameworks including Spring. The project provides systematic knowledge organization, practical examples, and interview-focused content. Its strengths include extensive coverage of core Java technologies, real-world application scenarios, and continuous updates. Typical use cases include Java interview preparation, systematic learning of Java ecosystem technologies, and reference for developers working with Java-based systems and distributed architectures."
      }
    ],
    "lightweight_multimodal_model": [
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "huggingface/transformers",
        "source": "github",
        "name": "transformers",
        "url": "https://github.com/huggingface/transformers",
        "tags": [
          "audio",
          "deep-learning",
          "deepseek",
          "gemma",
          "glm",
          "hacktoberfest",
          "llm",
          "machine-learning",
          "model-hub",
          "natural-language-processing",
          "nlp",
          "pretrained-models",
          "python",
          "pytorch",
          "pytorch-transformers",
          "qwen",
          "speech-recognition",
          "transformer",
          "vlm"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:04:48Z",
        "added_at": "2025-09-27",
        "summary": "🤗 Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09996249573059768,
        "task_keys": [
          "lightweight_visual_model",
          "llm_pretraining",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "nlp_bias_mitigation",
          "asr",
          "lightweight_multimodal_model",
          "inference_acceleration"
        ],
        "summary_en": "Hugging Face Transformers is an open-source Python library providing state-of-the-art machine learning models for text, vision, audio, and multimodal applications. It offers thousands of pretrained models for both inference and training, supporting popular architectures like Transformer, LLM, VLM, and audio models. Core capabilities include easy model loading, fine-tuning, and deployment across frameworks like PyTorch. Strengths include its extensive model hub, community support, and comprehensive documentation. Typical use cases span natural language processing, speech recognition, computer vision, and multimodal AI tasks.",
        "summary_zh": "Hugging Face Transformers 是一个开源 Python 库，为文本、视觉、音频和多模态应用提供最先进的机器学习模型。该库包含数千个预训练模型，支持推理和训练，涵盖 Transformer、大语言模型、视觉语言模型和音频模型等流行架构。核心功能包括简易模型加载、微调和跨框架部署（如 PyTorch）。主要优势在于其庞大的模型库、活跃的社区支持和全面的文档。典型应用场景包括自然语言处理、语音识别、计算机视觉和多模态人工智能任务，适用于研究和生产环境。",
        "summary_es": "Hugging Face Transformers is an open-source Python library providing state-of-the-art machine learning models for text, vision, audio, and multimodal applications. It offers thousands of pretrained models for both inference and training, supporting popular architectures like Transformer, LLM, VLM, and audio models. Core capabilities include easy model loading, fine-tuning, and deployment across frameworks like PyTorch. Strengths include its extensive model hub, community support, and comprehensive documentation. Typical use cases span natural language processing, speech recognition, computer vision, and multimodal AI tasks."
      }
    ],
    "gnn": [],
    "kg_construction": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "Genymobile/scrcpy",
        "source": "github",
        "name": "scrcpy",
        "url": "https://github.com/Genymobile/scrcpy",
        "tags": [
          "android",
          "c",
          "ffmpeg",
          "libav",
          "mirroring",
          "recording",
          "screen",
          "sdl2"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:52:25Z",
        "added_at": "2025-09-27",
        "summary": "Display and control your Android device",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09993912760112483,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "3d_reconstruction",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "multilingual_processing",
          "low_resource_language",
          "kg_construction",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "graph_augmented_reco",
          "model_compression",
          "compilation_optimization",
          "inference_acceleration",
          "privacy_computing",
          "adversarial_attack",
          "content_moderation",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_copyright",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "robot_dialogue_logic"
        ],
        "summary_en": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management.",
        "summary_zh": "scrcpy 是一款开源应用程序，用于通过 USB 或 TCP/IP 在计算机上显示和控制 Android 设备。其实时流式传输设备屏幕，延迟极低，并允许通过计算机键盘和鼠标进行完全控制。核心功能包括屏幕镜像、音频转发、设备控制和屏幕录制。优势在于高性能、无需 root 权限以及跨平台兼容性。典型用例包括应用程序开发测试、演示、游戏和远程设备管理。该项目采用 C 语言开发，基于 FFmpeg、libav 和 SDL2 库，在 GitHub 上拥有超过 12.9 万星标，显示出广泛的社区认可和使用。",
        "summary_es": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management."
      }
    ],
    "kg_reasoning": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "general_recommendation": [
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "distilbert/distilbert-base-uncased",
        "source": "hf",
        "name": "distilbert-base-uncased",
        "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "distilbert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1910.01108",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11617607,
          "likes_total": 762,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX.",
        "summary_zh": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "summary_es": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "vertical_recommendation": [
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "distilbert/distilbert-base-uncased",
        "source": "hf",
        "name": "distilbert-base-uncased",
        "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "distilbert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1910.01108",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11617607,
          "likes_total": 762,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX.",
        "summary_zh": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "summary_es": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "vector_retrieval": [
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "pyannote/wespeaker-voxceleb-resnet34-LM",
        "source": "hf",
        "name": "wespeaker-voxceleb-resnet34-LM",
        "url": "https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "wespeaker",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-recognition",
          "speaker-verification",
          "speaker-identification",
          "speaker-embedding",
          "dataset:voxceleb",
          "license:cc-by-4.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 17739550,
          "likes_total": 76,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "wespeaker-voxceleb-resnet34-LM 是一个专门用于说话人识别的模型，其核心功能是从音频中提取具有区分性的说话人嵌入向量。该模型采用基于 VoxCeleb 数据集训练的 ResNet-34 架构，并集成了语言模型评分机制以提升验证准确性。主要优势包括在不同声学条件下的稳定表现和高效的说话人区分能力。典型应用场景涵盖说话人验证、身份识别任务以及需要区分不同说话人的语音日记系统。该模型能够处理原始语音信号并生成固定维度的表征向量，适用于需要精确说话人辨别的",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "low_resource_voice_assistant"
        ],
        "summary_en": "The wespeaker-voxceleb-resnet34-LM model is a speaker recognition system designed to extract distinctive speaker embeddings from audio. Its core capability involves processing speech signals to generate fixed-dimensional vectors that uniquely represent speaker characteristics. The model employs a ResNet-34 architecture trained on the VoxCeleb dataset, enhanced with language model scoring for improved verification accuracy. Key strengths include robust performance across diverse acoustic conditions and effective speaker discrimination. Typical use cases encompass speaker verification, identification tasks, and speaker diarization systems where distinguishing between different speakers is essential.",
        "summary_zh": "wespeaker-voxceleb-resnet34-LM 是一个专门用于说话人识别的模型，其核心功能是从音频中提取具有区分性的说话人嵌入向量。该模型采用基于 VoxCeleb 数据集训练的 ResNet-34 架构，并集成了语言模型评分机制以提升验证准确性。主要优势包括在不同声学条件下的稳定表现和高效的说话人区分能力。典型应用场景涵盖说话人验证、身份识别任务以及需要区分不同说话人的语音日记系统。该模型能够处理原始语音信号并生成固定维度的表征向量，适用于需要精确说话人辨别的",
        "summary_es": "The wespeaker-voxceleb-resnet34-LM model is a speaker recognition system designed to extract distinctive speaker embeddings from audio. Its core capability involves processing speech signals to generate fixed-dimensional vectors that uniquely represent speaker characteristics. The model employs a ResNet-34 architecture trained on the VoxCeleb dataset, enhanced with language model scoring for improved verification accuracy. Key strengths include robust performance across diverse acoustic conditions and effective speaker discrimination. Typical use cases encompass speaker verification, identification tasks, and speaker diarization systems where distinguishing between different speakers is essential."
      },
      {
        "id": "pyannote/segmentation",
        "source": "hf",
        "name": "segmentation",
        "url": "https://huggingface.co/pyannote/segmentation",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "arxiv:2104.04045",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6612709,
          "likes_total": 641,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote/segmentation 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志化和音频分割任务。其核心功能包括检测说话人转换、识别语音活动以及发现重叠语音。该模型的优势在于能够精确地将音频分割为单一说话人区域，并能准确检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和对话分析，在这些场景中确定“谁在何时说话”至关重要。基于 arXiv:2104.04045 的研究成果，这个 MIT 许可的模型可作为构建完整说话人日志化系统的基础组件，为音频处理管道",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "tool_use",
          "nlp_bias_mitigation",
          "speaker_separation",
          "vector_retrieval",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Pyannote/segmentation is a PyTorch-based neural network model for speaker diarization and audio segmentation tasks. Its core capabilities include speaker change detection, voice activity detection, and overlapped speech identification in audio streams. The model's strengths lie in its ability to precisely segment audio into speaker-homogeneous regions and detect when multiple speakers talk simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and conversational analysis where identifying 'who spoke when' is crucial. Based on research published in arXiv:2104.04045, this MIT-licensed model serves as a fundamental component for building complete speaker diarization systems.",
        "summary_zh": "Pyannote/segmentation 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志化和音频分割任务。其核心功能包括检测说话人转换、识别语音活动以及发现重叠语音。该模型的优势在于能够精确地将音频分割为单一说话人区域，并能准确检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和对话分析，在这些场景中确定“谁在何时说话”至关重要。基于 arXiv:2104.04045 的研究成果，这个 MIT 许可的模型可作为构建完整说话人日志化系统的基础组件，为音频处理管道",
        "summary_es": "Pyannote/segmentation is a PyTorch-based neural network model for speaker diarization and audio segmentation tasks. Its core capabilities include speaker change detection, voice activity detection, and overlapped speech identification in audio streams. The model's strengths lie in its ability to precisely segment audio into speaker-homogeneous regions and detect when multiple speakers talk simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and conversational analysis where identifying 'who spoke when' is crucial. Based on research published in arXiv:2104.04045, this MIT-licensed model serves as a fundamental component for building complete speaker diarization systems."
      }
    ],
    "vector_db_optimization": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      }
    ],
    "metric_learning": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "TheAlgorithms/Python",
        "source": "github",
        "name": "Python",
        "url": "https://github.com/TheAlgorithms/Python",
        "tags": [
          "algorithm",
          "algorithm-competitions",
          "algorithms-implemented",
          "algos",
          "community-driven",
          "education",
          "hacktoberfest",
          "interview",
          "learn",
          "practice",
          "python",
          "searches",
          "sorting-algorithms",
          "sorts"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:03:26Z",
        "added_at": "2025-09-27",
        "summary": "All Algorithms implemented in Python",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09997537753028456,
        "task_keys": [
          "metric_learning",
          "contrastive_learning",
          "federated_learning"
        ],
        "summary_en": "TheAlgorithms/Python is a comprehensive GitHub repository containing implementations of numerous algorithms in Python. Its primary purpose is educational, serving as a learning resource for students, developers, and programming enthusiasts. The project covers fundamental algorithms including sorting methods, search techniques, data structures, and mathematical computations. Key strengths include its extensive collection, clean code examples, and community-driven development. Typical use cases involve studying algorithm concepts, preparing for technical interviews, and serving as reference material for algorithm implementation in Python projects.",
        "summary_zh": "TheAlgorithms/Python 是一个在 GitHub 上托管的大型开源项目，其主要目的是使用 Python 编程语言实现各种经典算法，服务于教育和学习。该项目涵盖了排序算法、搜索算法、数据结构、数学计算等多个核心领域，代码示例清晰规范。其显著优势在于算法覆盖全面、代码质量高且由社区共同维护更新。典型应用场景包括计算机科学学生自学算法原理、开发者准备技术面试时参考实现、以及作为实际项目中算法应用的代码库参考。该项目通过众包模式发展，已成为重要的算法",
        "summary_es": "TheAlgorithms/Python is a comprehensive GitHub repository containing implementations of numerous algorithms in Python. Its primary purpose is educational, serving as a learning resource for students, developers, and programming enthusiasts. The project covers fundamental algorithms including sorting methods, search techniques, data structures, and mathematical computations. Key strengths include its extensive collection, clean code examples, and community-driven development. Typical use cases involve studying algorithm concepts, preparing for technical interviews, and serving as reference material for algorithm implementation in Python projects."
      }
    ],
    "contrastive_learning": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "TheAlgorithms/Python",
        "source": "github",
        "name": "Python",
        "url": "https://github.com/TheAlgorithms/Python",
        "tags": [
          "algorithm",
          "algorithm-competitions",
          "algorithms-implemented",
          "algos",
          "community-driven",
          "education",
          "hacktoberfest",
          "interview",
          "learn",
          "practice",
          "python",
          "searches",
          "sorting-algorithms",
          "sorts"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:03:26Z",
        "added_at": "2025-09-27",
        "summary": "All Algorithms implemented in Python",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09997537753028456,
        "task_keys": [
          "metric_learning",
          "contrastive_learning",
          "federated_learning"
        ],
        "summary_en": "TheAlgorithms/Python is a comprehensive GitHub repository containing implementations of numerous algorithms in Python. Its primary purpose is educational, serving as a learning resource for students, developers, and programming enthusiasts. The project covers fundamental algorithms including sorting methods, search techniques, data structures, and mathematical computations. Key strengths include its extensive collection, clean code examples, and community-driven development. Typical use cases involve studying algorithm concepts, preparing for technical interviews, and serving as reference material for algorithm implementation in Python projects.",
        "summary_zh": "TheAlgorithms/Python 是一个在 GitHub 上托管的大型开源项目，其主要目的是使用 Python 编程语言实现各种经典算法，服务于教育和学习。该项目涵盖了排序算法、搜索算法、数据结构、数学计算等多个核心领域，代码示例清晰规范。其显著优势在于算法覆盖全面、代码质量高且由社区共同维护更新。典型应用场景包括计算机科学学生自学算法原理、开发者准备技术面试时参考实现、以及作为实际项目中算法应用的代码库参考。该项目通过众包模式发展，已成为重要的算法",
        "summary_es": "TheAlgorithms/Python is a comprehensive GitHub repository containing implementations of numerous algorithms in Python. Its primary purpose is educational, serving as a learning resource for students, developers, and programming enthusiasts. The project covers fundamental algorithms including sorting methods, search techniques, data structures, and mathematical computations. Key strengths include its extensive collection, clean code examples, and community-driven development. Typical use cases involve studying algorithm concepts, preparing for technical interviews, and serving as reference material for algorithm implementation in Python projects."
      }
    ],
    "ltr": [
      {
        "id": "Bingsu/adetailer",
        "source": "hf",
        "name": "adetailer",
        "url": "https://huggingface.co/Bingsu/adetailer",
        "tags": [
          "ultralytics",
          "pytorch",
          "dataset:wider_face",
          "dataset:skytnt/anime-segmentation",
          "doi:10.57967/hf/3633",
          "license:apache-2.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 15085828,
          "likes_total": 617,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "ADetailer 是一款计算机视觉工具，旨在自动检测并增强图像中的细节，特别是面部和其他区域。其核心功能包括对象检测、分割和修复，以提升图像质量。优势在于处理动漫风格内容和真实世界面部图像，利用了 anime-segmentation 和 WiderFace 等数据集。典型应用场景涉及对生成或真实图像进行后处理，以优化细节、去除伪影或增强特定区域，无需人工干预。该工具基于 PyTorch 构建，采用 Apache 2.0 开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "ltr",
          "training_data_anonymization",
          "training_data_copyright"
        ],
        "summary_en": "ADetailer is a computer vision tool designed to automatically detect and enhance details in images, particularly faces and other regions. Its core capabilities include object detection, segmentation, and inpainting to improve image quality. Strengths lie in handling anime-style content and real-world facial images, leveraging datasets like anime-segmentation and WiderFace. Typical use cases involve post-processing generated or real images to refine details, remove artifacts, or enhance specific areas without manual intervention. The tool is built on PyTorch and is open-source under Apache 2.0 license.",
        "summary_zh": "ADetailer 是一款计算机视觉工具，旨在自动检测并增强图像中的细节，特别是面部和其他区域。其核心功能包括对象检测、分割和修复，以提升图像质量。优势在于处理动漫风格内容和真实世界面部图像，利用了 anime-segmentation 和 WiderFace 等数据集。典型应用场景涉及对生成或真实图像进行后处理，以优化细节、去除伪影或增强特定区域，无需人工干预。该工具基于 PyTorch 构建，采用 Apache 2.0 开源许可证。",
        "summary_es": "ADetailer is a computer vision tool designed to automatically detect and enhance details in images, particularly faces and other regions. Its core capabilities include object detection, segmentation, and inpainting to improve image quality. Strengths lie in handling anime-style content and real-world facial images, leveraging datasets like anime-segmentation and WiderFace. Typical use cases involve post-processing generated or real images to refine details, remove artifacts, or enhance specific areas without manual intervention. The tool is built on PyTorch and is open-source under Apache 2.0 license."
      },
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "neural_retrieval": [
      {
        "id": "colbert-ir/colbertv2.0",
        "source": "hf",
        "name": "colbertv2.0",
        "url": "https://huggingface.co/colbert-ir/colbertv2.0",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "bert",
          "ColBERT",
          "en",
          "arxiv:2004.12832",
          "arxiv:2007.00814",
          "arxiv:2101.00436",
          "arxiv:2112.01488",
          "arxiv:2205.09707",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6840796,
          "likes_total": 286,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "ColBERTv2.0是一种基于神经网络的检索模型，通过延迟交互机制提升信息检索效果。它使用BERT分别编码查询和文档，然后通过令牌级嵌入之间的高效MaxSim操作计算相关性。该方法在效果和可扩展性之间取得平衡，支持十亿级规模搜索。核心优势包括高准确性、与现有索引兼容性以及高效的GPU利用率。典型应用场景涵盖网络搜索、企业文档检索和问答系统，适用于需要精确匹配和大规模处理的关键任务。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "neural_retrieval"
        ],
        "summary_en": "ColBERTv2.0 is a neural retrieval model that enhances information retrieval through late interaction. It encodes queries and documents separately using BERT, then computes relevance via efficient MaxSim operations between their token-level embeddings. This approach balances effectiveness with scalability, supporting billion-scale searches. Core strengths include high accuracy, compatibility with existing indexes, and efficient GPU utilization. Typical use cases involve web search, enterprise document retrieval, and question-answering systems where precise matching and scalability are critical.",
        "summary_zh": "ColBERTv2.0是一种基于神经网络的检索模型，通过延迟交互机制提升信息检索效果。它使用BERT分别编码查询和文档，然后通过令牌级嵌入之间的高效MaxSim操作计算相关性。该方法在效果和可扩展性之间取得平衡，支持十亿级规模搜索。核心优势包括高准确性、与现有索引兼容性以及高效的GPU利用率。典型应用场景涵盖网络搜索、企业文档检索和问答系统，适用于需要精确匹配和大规模处理的关键任务。",
        "summary_es": "ColBERTv2.0 is a neural retrieval model that enhances information retrieval through late interaction. It encodes queries and documents separately using BERT, then computes relevance via efficient MaxSim operations between their token-level embeddings. This approach balances effectiveness with scalability, supporting billion-scale searches. Core strengths include high accuracy, compatibility with existing indexes, and efficient GPU utilization. Typical use cases involve web search, enterprise document retrieval, and question-answering systems where precise matching and scalability are critical."
      },
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "graph_augmented_reco": [
      {
        "id": "pyannote/wespeaker-voxceleb-resnet34-LM",
        "source": "hf",
        "name": "wespeaker-voxceleb-resnet34-LM",
        "url": "https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "wespeaker",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-recognition",
          "speaker-verification",
          "speaker-identification",
          "speaker-embedding",
          "dataset:voxceleb",
          "license:cc-by-4.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 17739550,
          "likes_total": 76,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "wespeaker-voxceleb-resnet34-LM 是一个专门用于说话人识别的模型，其核心功能是从音频中提取具有区分性的说话人嵌入向量。该模型采用基于 VoxCeleb 数据集训练的 ResNet-34 架构，并集成了语言模型评分机制以提升验证准确性。主要优势包括在不同声学条件下的稳定表现和高效的说话人区分能力。典型应用场景涵盖说话人验证、身份识别任务以及需要区分不同说话人的语音日记系统。该模型能够处理原始语音信号并生成固定维度的表征向量，适用于需要精确说话人辨别的",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "low_resource_voice_assistant"
        ],
        "summary_en": "The wespeaker-voxceleb-resnet34-LM model is a speaker recognition system designed to extract distinctive speaker embeddings from audio. Its core capability involves processing speech signals to generate fixed-dimensional vectors that uniquely represent speaker characteristics. The model employs a ResNet-34 architecture trained on the VoxCeleb dataset, enhanced with language model scoring for improved verification accuracy. Key strengths include robust performance across diverse acoustic conditions and effective speaker discrimination. Typical use cases encompass speaker verification, identification tasks, and speaker diarization systems where distinguishing between different speakers is essential.",
        "summary_zh": "wespeaker-voxceleb-resnet34-LM 是一个专门用于说话人识别的模型，其核心功能是从音频中提取具有区分性的说话人嵌入向量。该模型采用基于 VoxCeleb 数据集训练的 ResNet-34 架构，并集成了语言模型评分机制以提升验证准确性。主要优势包括在不同声学条件下的稳定表现和高效的说话人区分能力。典型应用场景涵盖说话人验证、身份识别任务以及需要区分不同说话人的语音日记系统。该模型能够处理原始语音信号并生成固定维度的表征向量，适用于需要精确说话人辨别的",
        "summary_es": "The wespeaker-voxceleb-resnet34-LM model is a speaker recognition system designed to extract distinctive speaker embeddings from audio. Its core capability involves processing speech signals to generate fixed-dimensional vectors that uniquely represent speaker characteristics. The model employs a ResNet-34 architecture trained on the VoxCeleb dataset, enhanced with language model scoring for improved verification accuracy. Key strengths include robust performance across diverse acoustic conditions and effective speaker discrimination. Typical use cases encompass speaker verification, identification tasks, and speaker diarization systems where distinguishing between different speakers is essential."
      },
      {
        "id": "pyannote/speaker-diarization-3.1",
        "source": "hf",
        "name": "speaker-diarization-3.1",
        "url": "https://huggingface.co/pyannote/speaker-diarization-3.1",
        "tags": [
          "pyannote-audio",
          "pyannote",
          "pyannote-audio-pipeline",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "automatic-speech-recognition",
          "arxiv:2111.14448",
          "arxiv:2012.01477",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 16673680,
          "likes_total": 1169,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote speaker-diarization-3.1 是一个音频处理流程，专门用于自动分割和标记录音中的说话人身份。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该系统擅长处理多人对话场景，具有高时间精度，特别适用于会议转录、广播监控和对话分析等典型用例。基于 arXiv:2012.01477 和 arXiv:2111.14448 的研究成果，这款 MIT 许可的工具能够处理音频并输出结构化的时间线，准确识别“谁在何时说话”，在各种声学条件下均表现出稳定性能。该工具通过先进的深度学习技术实现对连续语音流的实",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "asr",
          "speaker_separation",
          "vector_retrieval",
          "graph_augmented_reco",
          "auto_evaluation_models",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote speaker-diarization-3.1 is an audio processing pipeline that automatically segments and labels speaker identities in audio recordings. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The system excels at handling multi-speaker conversations with high temporal precision, making it particularly strong for meeting transcriptions, broadcast monitoring, and conversational analysis. Based on research from arXiv:2012.01477 and arXiv:2111.14448, this MIT-licensed tool processes audio to output structured timelines identifying 'who spoke when' with robust performance across various acoustic conditions.",
        "summary_zh": "Pyannote speaker-diarization-3.1 是一个音频处理流程，专门用于自动分割和标记录音中的说话人身份。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该系统擅长处理多人对话场景，具有高时间精度，特别适用于会议转录、广播监控和对话分析等典型用例。基于 arXiv:2012.01477 和 arXiv:2111.14448 的研究成果，这款 MIT 许可的工具能够处理音频并输出结构化的时间线，准确识别“谁在何时说话”，在各种声学条件下均表现出稳定性能。该工具通过先进的深度学习技术实现对连续语音流的实",
        "summary_es": "Pyannote speaker-diarization-3.1 is an audio processing pipeline that automatically segments and labels speaker identities in audio recordings. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The system excels at handling multi-speaker conversations with high temporal precision, making it particularly strong for meeting transcriptions, broadcast monitoring, and conversational analysis. Based on research from arXiv:2012.01477 and arXiv:2111.14448, this MIT-licensed tool processes audio to output structured timelines identifying 'who spoke when' with robust performance across various acoustic conditions."
      },
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "model_compression": [
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      }
    ],
    "model_quantization": [
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      }
    ],
    "model_distillation": [
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      }
    ],
    "compilation_optimization": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      }
    ],
    "inference_acceleration": [
      {
        "id": "sentence-transformers/all-MiniLM-L6-v2",
        "source": "hf",
        "name": "all-MiniLM-L6-v2",
        "url": "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2",
        "tags": [
          "sentence-transformers",
          "pytorch",
          "tf",
          "rust",
          "onnx",
          "safetensors",
          "openvino",
          "bert",
          "feature-extraction",
          "sentence-similarity",
          "transformers",
          "en",
          "dataset:s2orc",
          "dataset:flax-sentence-embeddings/stackexchange_xml",
          "dataset:ms_marco",
          "dataset:gooaq",
          "dataset:yahoo_answers_topics",
          "dataset:code_search_net",
          "dataset:search_qa",
          "dataset:eli5",
          "dataset:snli",
          "dataset:multi_nli",
          "dataset:wikihow",
          "dataset:natural_questions",
          "dataset:trivia_qa",
          "dataset:embedding-data/sentence-compression",
          "dataset:embedding-data/flickr30k-captions",
          "dataset:embedding-data/altlex",
          "dataset:embedding-data/simple-wiki",
          "dataset:embedding-data/QQP",
          "dataset:embedding-data/SPECTER",
          "dataset:embedding-data/PAQ_pairs",
          "dataset:embedding-data/WikiAnswers",
          "arxiv:1904.06472",
          "arxiv:2102.07033",
          "arxiv:2104.08727",
          "arxiv:1704.05179",
          "arxiv:1810.09305",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-embeddings-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 91098802,
          "likes_total": 3932,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "all-MiniLM-L6-v2 是一个紧凑型句子转换模型，专门用于高效生成文本嵌入向量。该模型将文本映射到384维向量空间，支持语义相似度计算。核心功能包括句子嵌入生成、语义搜索和文本聚类。主要优势在于模型体积小（80MB）、推理速度快，同时保持竞争力的性能表现。典型应用场景涵盖信息检索、重复内容检测、推荐系统和文本分类任务。模型采用知识蒸馏技术，在QQP、WikiAnswers、MS MARCO等多个数据集上进行训练，适用于需要平衡效率与准确性的自然语言处理应用。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "inference_acceleration"
        ],
        "summary_en": "The all-MiniLM-L6-v2 model is a compact sentence transformer designed for efficient text embedding generation. It maps text to 384-dimensional vectors, enabling semantic similarity comparisons. Core capabilities include sentence embeddings, semantic search, and clustering. Strengths lie in its small size (80MB) and fast inference while maintaining competitive performance. Typical use cases encompass information retrieval, duplicate detection, recommendation systems, and text classification tasks. The model was trained using knowledge distillation techniques on diverse datasets including QQP, WikiAnswers, and MS MARCO.",
        "summary_zh": "all-MiniLM-L6-v2 是一个紧凑型句子转换模型，专门用于高效生成文本嵌入向量。该模型将文本映射到384维向量空间，支持语义相似度计算。核心功能包括句子嵌入生成、语义搜索和文本聚类。主要优势在于模型体积小（80MB）、推理速度快，同时保持竞争力的性能表现。典型应用场景涵盖信息检索、重复内容检测、推荐系统和文本分类任务。模型采用知识蒸馏技术，在QQP、WikiAnswers、MS MARCO等多个数据集上进行训练，适用于需要平衡效率与准确性的自然语言处理应用。",
        "summary_es": "The all-MiniLM-L6-v2 model is a compact sentence transformer designed for efficient text embedding generation. It maps text to 384-dimensional vectors, enabling semantic similarity comparisons. Core capabilities include sentence embeddings, semantic search, and clustering. Strengths lie in its small size (80MB) and fast inference while maintaining competitive performance. Typical use cases encompass information retrieval, duplicate detection, recommendation systems, and text classification tasks. The model was trained using knowledge distillation techniques on diverse datasets including QQP, WikiAnswers, and MS MARCO."
      },
      {
        "id": "sentence-transformers/all-mpnet-base-v2",
        "source": "hf",
        "name": "all-mpnet-base-v2",
        "url": "https://huggingface.co/sentence-transformers/all-mpnet-base-v2",
        "tags": [
          "sentence-transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "openvino",
          "mpnet",
          "fill-mask",
          "feature-extraction",
          "sentence-similarity",
          "transformers",
          "text-embeddings-inference",
          "en",
          "dataset:s2orc",
          "dataset:flax-sentence-embeddings/stackexchange_xml",
          "dataset:ms_marco",
          "dataset:gooaq",
          "dataset:yahoo_answers_topics",
          "dataset:code_search_net",
          "dataset:search_qa",
          "dataset:eli5",
          "dataset:snli",
          "dataset:multi_nli",
          "dataset:wikihow",
          "dataset:natural_questions",
          "dataset:trivia_qa",
          "dataset:embedding-data/sentence-compression",
          "dataset:embedding-data/flickr30k-captions",
          "dataset:embedding-data/altlex",
          "dataset:embedding-data/simple-wiki",
          "dataset:embedding-data/QQP",
          "dataset:embedding-data/SPECTER",
          "dataset:embedding-data/PAQ_pairs",
          "dataset:embedding-data/WikiAnswers",
          "arxiv:1904.06472",
          "arxiv:2102.07033",
          "arxiv:2104.08727",
          "arxiv:1704.05179",
          "arxiv:1810.09305",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 16899677,
          "likes_total": 1163,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "all-mpnet-base-v2是基于MPNet架构的句子嵌入模型，旨在将文本转换为密集向量表示。其核心能力是生成高质量的语义相似性任务嵌入向量，优势在于在语义文本相似性基准测试中表现优异，并能高效处理多样化文本类型。典型应用场景包括语义搜索、信息检索、相似文档聚类和复述检测。该模型在QQP、WikiAnswers和MS MARCO等多个数据集上进行训练，以增强跨领域的泛化能力。训练结合了对比学习目标，优化了嵌入空间中的语义关系捕获。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "inference_acceleration"
        ],
        "summary_en": "all-mpnet-base-v2 is a sentence embedding model based on MPNet architecture, designed to convert text into dense vector representations. Its core capability is generating high-quality embeddings for semantic similarity tasks. Strengths include superior performance on semantic textual similarity benchmarks and efficient handling of diverse text types. Typical use cases encompass semantic search, information retrieval, clustering similar documents, and paraphrase detection. The model was trained on multiple datasets including QQP, WikiAnswers, and MS MARCO to enhance generalization across domains.",
        "summary_zh": "all-mpnet-base-v2是基于MPNet架构的句子嵌入模型，旨在将文本转换为密集向量表示。其核心能力是生成高质量的语义相似性任务嵌入向量，优势在于在语义文本相似性基准测试中表现优异，并能高效处理多样化文本类型。典型应用场景包括语义搜索、信息检索、相似文档聚类和复述检测。该模型在QQP、WikiAnswers和MS MARCO等多个数据集上进行训练，以增强跨领域的泛化能力。训练结合了对比学习目标，优化了嵌入空间中的语义关系捕获。",
        "summary_es": "all-mpnet-base-v2 is a sentence embedding model based on MPNet architecture, designed to convert text into dense vector representations. Its core capability is generating high-quality embeddings for semantic similarity tasks. Strengths include superior performance on semantic textual similarity benchmarks and efficient handling of diverse text types. Typical use cases encompass semantic search, information retrieval, clustering similar documents, and paraphrase detection. The model was trained on multiple datasets including QQP, WikiAnswers, and MS MARCO to enhance generalization across domains."
      },
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        "source": "hf",
        "name": "paraphrase-multilingual-MiniLM-L12-v2",
        "url": "https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        "tags": [
          "sentence-transformers",
          "pytorch",
          "tf",
          "onnx",
          "safetensors",
          "openvino",
          "bert",
          "feature-extraction",
          "sentence-similarity",
          "transformers",
          "multilingual",
          "ar",
          "bg",
          "ca",
          "cs",
          "da",
          "de",
          "el",
          "en",
          "es",
          "et",
          "fa",
          "fi",
          "fr",
          "gl",
          "gu",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "it",
          "ja",
          "ka",
          "ko",
          "ku",
          "lt",
          "lv",
          "mk",
          "mn",
          "mr",
          "ms",
          "my",
          "nb",
          "nl",
          "pl",
          "pt",
          "ro",
          "ru",
          "sk",
          "sl",
          "sq",
          "sr",
          "sv",
          "th",
          "tr",
          "uk",
          "ur",
          "vi",
          "arxiv:1908.10084",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-embeddings-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "该多语言句子嵌入模型可为超过50种语言的文本生成语义向量表示，基于BERT架构并采用MiniLM知识蒸馏技术，输出384维嵌入向量专门优化语义相似度任务。主要用途是实现跨语言文本比较和检索，核心能力包括多语言释义识别、语义搜索和跨语言聚类。关键优势在于12层Transformer的高效性能、无需语言特定调优的多语言支持，以及精度与速度的平衡。典型应用场景涵盖多语言文档检索、重复内容检测，以及需要跨语言一致表示的语义相似度应用。模型通过统",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "inference_acceleration"
        ],
        "summary_en": "This multilingual sentence embedding model generates semantically meaningful vector representations for text in over 50 languages. Based on BERT architecture with MiniLM distillation, it produces 384-dimensional embeddings optimized for semantic similarity tasks. Its primary purpose is enabling cross-lingual text comparison and retrieval. Core capabilities include paraphrase identification, semantic search, and clustering across languages. Key strengths are efficient performance with 12 transformer layers, multilingual support without language-specific tuning, and balanced accuracy-speed tradeoff. Typical use cases involve multilingual document retrieval, duplicate detection, and semantic similarity applications requiring consistent representations across diverse languages.",
        "summary_zh": "该多语言句子嵌入模型可为超过50种语言的文本生成语义向量表示，基于BERT架构并采用MiniLM知识蒸馏技术，输出384维嵌入向量专门优化语义相似度任务。主要用途是实现跨语言文本比较和检索，核心能力包括多语言释义识别、语义搜索和跨语言聚类。关键优势在于12层Transformer的高效性能、无需语言特定调优的多语言支持，以及精度与速度的平衡。典型应用场景涵盖多语言文档检索、重复内容检测，以及需要跨语言一致表示的语义相似度应用。模型通过统",
        "summary_es": "This multilingual sentence embedding model generates semantically meaningful vector representations for text in over 50 languages. Based on BERT architecture with MiniLM distillation, it produces 384-dimensional embeddings optimized for semantic similarity tasks. Its primary purpose is enabling cross-lingual text comparison and retrieval. Core capabilities include paraphrase identification, semantic search, and clustering across languages. Key strengths are efficient performance with 12 transformer layers, multilingual support without language-specific tuning, and balanced accuracy-speed tradeoff. Typical use cases involve multilingual document retrieval, duplicate detection, and semantic similarity applications requiring consistent representations across diverse languages."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "openai/gpt-oss-20b",
        "source": "hf",
        "name": "gpt-oss-20b",
        "url": "https://huggingface.co/openai/gpt-oss-20b",
        "tags": [
          "transformers",
          "safetensors",
          "gpt_oss",
          "text-generation",
          "vllm",
          "conversational",
          "arxiv:2508.10925",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "8-bit",
          "mxfp4",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6749481,
          "likes_total": 3612,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "GPT-OSS-20B是OpenAI开发的200亿参数开源语言模型，专为文本生成任务设计。核心能力包括自然语言理解、对话交互和内容创作。主要优势在于采用Apache 2.0许可支持商业应用，8位量化实现高效部署，并与Transformers、vLLM等主流框架兼容。典型应用场景涵盖聊天机器人、自动化内容生成和学术研究。该模型支持多轮对话，在保持强大文本处理性能的同时，通过模型优化技术提升推理效率，适用于多样化的自然语言处理需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "inference_acceleration"
        ],
        "summary_en": "GPT-OSS-20B is a 20-billion-parameter open-source language model developed by OpenAI, designed for text generation tasks. Its core capabilities include natural language understanding, conversational interaction, and content creation. Key strengths are its Apache 2.0 license enabling commercial use, 8-bit quantization for efficient deployment, and compatibility with popular frameworks like Transformers and vLLM. Typical use cases involve chatbots, automated content generation, and research applications. The model supports multi-turn dialogues and is optimized for inference efficiency while maintaining strong performance across diverse text-based tasks.",
        "summary_zh": "GPT-OSS-20B是OpenAI开发的200亿参数开源语言模型，专为文本生成任务设计。核心能力包括自然语言理解、对话交互和内容创作。主要优势在于采用Apache 2.0许可支持商业应用，8位量化实现高效部署，并与Transformers、vLLM等主流框架兼容。典型应用场景涵盖聊天机器人、自动化内容生成和学术研究。该模型支持多轮对话，在保持强大文本处理性能的同时，通过模型优化技术提升推理效率，适用于多样化的自然语言处理需求。",
        "summary_es": "GPT-OSS-20B is a 20-billion-parameter open-source language model developed by OpenAI, designed for text generation tasks. Its core capabilities include natural language understanding, conversational interaction, and content creation. Key strengths are its Apache 2.0 license enabling commercial use, 8-bit quantization for efficient deployment, and compatibility with popular frameworks like Transformers and vLLM. Typical use cases involve chatbots, automated content generation, and research applications. The model supports multi-turn dialogues and is optimized for inference efficiency while maintaining strong performance across diverse text-based tasks."
      }
    ],
    "federated_learning": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      }
    ],
    "privacy_computing": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "Genymobile/scrcpy",
        "source": "github",
        "name": "scrcpy",
        "url": "https://github.com/Genymobile/scrcpy",
        "tags": [
          "android",
          "c",
          "ffmpeg",
          "libav",
          "mirroring",
          "recording",
          "screen",
          "sdl2"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:52:25Z",
        "added_at": "2025-09-27",
        "summary": "Display and control your Android device",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09993912760112483,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "3d_reconstruction",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "multilingual_processing",
          "low_resource_language",
          "kg_construction",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "graph_augmented_reco",
          "model_compression",
          "compilation_optimization",
          "inference_acceleration",
          "privacy_computing",
          "adversarial_attack",
          "content_moderation",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_copyright",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "robot_dialogue_logic"
        ],
        "summary_en": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management.",
        "summary_zh": "scrcpy 是一款开源应用程序，用于通过 USB 或 TCP/IP 在计算机上显示和控制 Android 设备。其实时流式传输设备屏幕，延迟极低，并允许通过计算机键盘和鼠标进行完全控制。核心功能包括屏幕镜像、音频转发、设备控制和屏幕录制。优势在于高性能、无需 root 权限以及跨平台兼容性。典型用例包括应用程序开发测试、演示、游戏和远程设备管理。该项目采用 C 语言开发，基于 FFmpeg、libav 和 SDL2 库，在 GitHub 上拥有超过 12.9 万星标，显示出广泛的社区认可和使用。",
        "summary_es": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management."
      }
    ],
    "adversarial_attack": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "Genymobile/scrcpy",
        "source": "github",
        "name": "scrcpy",
        "url": "https://github.com/Genymobile/scrcpy",
        "tags": [
          "android",
          "c",
          "ffmpeg",
          "libav",
          "mirroring",
          "recording",
          "screen",
          "sdl2"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:52:25Z",
        "added_at": "2025-09-27",
        "summary": "Display and control your Android device",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09993912760112483,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "3d_reconstruction",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "multilingual_processing",
          "low_resource_language",
          "kg_construction",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "graph_augmented_reco",
          "model_compression",
          "compilation_optimization",
          "inference_acceleration",
          "privacy_computing",
          "adversarial_attack",
          "content_moderation",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_copyright",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "robot_dialogue_logic"
        ],
        "summary_en": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management.",
        "summary_zh": "scrcpy 是一款开源应用程序，用于通过 USB 或 TCP/IP 在计算机上显示和控制 Android 设备。其实时流式传输设备屏幕，延迟极低，并允许通过计算机键盘和鼠标进行完全控制。核心功能包括屏幕镜像、音频转发、设备控制和屏幕录制。优势在于高性能、无需 root 权限以及跨平台兼容性。典型用例包括应用程序开发测试、演示、游戏和远程设备管理。该项目采用 C 语言开发，基于 FFmpeg、libav 和 SDL2 库，在 GitHub 上拥有超过 12.9 万星标，显示出广泛的社区认可和使用。",
        "summary_es": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management."
      }
    ],
    "adversarial_defense": [
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "distilbert/distilbert-base-uncased",
        "source": "hf",
        "name": "distilbert-base-uncased",
        "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "distilbert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1910.01108",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11617607,
          "likes_total": 762,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX.",
        "summary_zh": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "summary_es": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "red_teaming": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "content_moderation": [
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "distilbert/distilbert-base-uncased",
        "source": "hf",
        "name": "distilbert-base-uncased",
        "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "distilbert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1910.01108",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11617607,
          "likes_total": 762,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX.",
        "summary_zh": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "summary_es": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "auto_evaluation_models": [
      {
        "id": "Falconsai/nsfw_image_detection",
        "source": "hf",
        "name": "nsfw_image_detection",
        "url": "https://huggingface.co/Falconsai/nsfw_image_detection",
        "tags": [
          "transformers",
          "pytorch",
          "safetensors",
          "vit",
          "image-classification",
          "arxiv:2010.11929",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 99881324,
          "likes_total": 826,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "image_text_alignment",
          "auto_evaluation_models",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems.",
        "summary_zh": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "summary_es": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems."
      },
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      }
    ],
    "edge_hw_sw_co_design": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      }
    ],
    "xai": [
      {
        "id": "langchain-ai/langchain",
        "source": "github",
        "name": "langchain",
        "url": "https://github.com/langchain-ai/langchain",
        "tags": [
          "ai",
          "anthropic",
          "gemini",
          "langchain",
          "llm",
          "openai",
          "python"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:40:54Z",
        "added_at": "2025-09-27",
        "summary": "🦜🔗 Build context-aware reasoning applications",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09994498840082075,
        "task_keys": [
          "llm_pretraining",
          "xai",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "low_resource_medical_ai"
        ],
        "summary_en": "LangChain is an open-source Python framework designed for building applications powered by large language models (LLMs). Its primary purpose is to enable the development of context-aware reasoning systems that can chain multiple LLM calls and tools together. Core capabilities include prompt templating, memory management, agent creation, and integration with various LLM providers like OpenAI and Anthropic. Key strengths are its modular architecture, extensive documentation, and active community support. Typical use cases include chatbots, question-answering systems, document analysis, and automated workflow applications that require sequential reasoning steps.",
        "summary_zh": "LangChain是一个开源的Python框架，专门用于构建基于大型语言模型（LLM）的应用程序。其主要目的是开发能够将多个LLM调用和工具链接在一起的上下文感知推理系统。核心功能包括提示模板管理、记忆系统、智能体创建以及与OpenAI、Anthropic等多种LLM提供商的集成。该框架的优势在于其模块化架构、详尽的文档支持和活跃的开发者社区。典型应用场景包括聊天机器人、问答系统、文档分析和需要多步骤推理的自动化工作流程，特别适合处理需要上下文记忆和工具调用的复",
        "summary_es": "LangChain is an open-source Python framework designed for building applications powered by large language models (LLMs). Its primary purpose is to enable the development of context-aware reasoning systems that can chain multiple LLM calls and tools together. Core capabilities include prompt templating, memory management, agent creation, and integration with various LLM providers like OpenAI and Anthropic. Key strengths are its modular architecture, extensive documentation, and active community support. Typical use cases include chatbots, question-answering systems, document analysis, and automated workflow applications that require sequential reasoning steps."
      }
    ],
    "ai_ethics_risk_assessment": [
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "distilbert/distilbert-base-uncased",
        "source": "hf",
        "name": "distilbert-base-uncased",
        "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "distilbert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1910.01108",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11617607,
          "likes_total": 762,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX.",
        "summary_zh": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "summary_es": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "training_data_anonymization": [
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "google-bert/bert-base-uncased",
        "source": "hf",
        "name": "bert-base-uncased",
        "url": "https://huggingface.co/google-bert/bert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "coreml",
          "onnx",
          "safetensors",
          "bert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1810.04805",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 55204102,
          "likes_total": 2417,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "BERT-base-uncased是基于Transformer架构的英语预训练语言模型，在Wikipedia和BookCorpus语料上通过掩码语言建模和下一句预测任务进行训练。该模型采用双向编码器设计，能够深度理解词语在上下文中的语义关系。其主要优势在于强大的语境理解能力和通用性，支持文本分类、命名实体识别、问答系统、情感分析等多种自然语言处理任务。作为uncased版本，模型不区分字母大小写，适用于大多数不需要大小写敏感处理的通用文本分析场景。该模型已成为许多下游NLP应用的基础架构。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright"
        ],
        "summary_en": "BERT-base-uncased is a foundational transformer model pre-trained on English text from Wikipedia and BookCorpus. It employs masked language modeling and next sentence prediction to develop deep bidirectional contextual representations. The model excels at understanding word meanings in context and capturing semantic relationships. Its primary applications include text classification, named entity recognition, question answering, and sentiment analysis. As an uncased model, it treats uppercase and lowercase letters identically, making it suitable for general text processing tasks where case sensitivity is not required.",
        "summary_zh": "BERT-base-uncased是基于Transformer架构的英语预训练语言模型，在Wikipedia和BookCorpus语料上通过掩码语言建模和下一句预测任务进行训练。该模型采用双向编码器设计，能够深度理解词语在上下文中的语义关系。其主要优势在于强大的语境理解能力和通用性，支持文本分类、命名实体识别、问答系统、情感分析等多种自然语言处理任务。作为uncased版本，模型不区分字母大小写，适用于大多数不需要大小写敏感处理的通用文本分析场景。该模型已成为许多下游NLP应用的基础架构。",
        "summary_es": "BERT-base-uncased is a foundational transformer model pre-trained on English text from Wikipedia and BookCorpus. It employs masked language modeling and next sentence prediction to develop deep bidirectional contextual representations. The model excels at understanding word meanings in context and capturing semantic relationships. Its primary applications include text classification, named entity recognition, question answering, and sentiment analysis. As an uncased model, it treats uppercase and lowercase letters identically, making it suitable for general text processing tasks where case sensitivity is not required."
      },
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "training_data_copyright": [
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "google-bert/bert-base-uncased",
        "source": "hf",
        "name": "bert-base-uncased",
        "url": "https://huggingface.co/google-bert/bert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "coreml",
          "onnx",
          "safetensors",
          "bert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1810.04805",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 55204102,
          "likes_total": 2417,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "BERT-base-uncased是基于Transformer架构的英语预训练语言模型，在Wikipedia和BookCorpus语料上通过掩码语言建模和下一句预测任务进行训练。该模型采用双向编码器设计，能够深度理解词语在上下文中的语义关系。其主要优势在于强大的语境理解能力和通用性，支持文本分类、命名实体识别、问答系统、情感分析等多种自然语言处理任务。作为uncased版本，模型不区分字母大小写，适用于大多数不需要大小写敏感处理的通用文本分析场景。该模型已成为许多下游NLP应用的基础架构。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright"
        ],
        "summary_en": "BERT-base-uncased is a foundational transformer model pre-trained on English text from Wikipedia and BookCorpus. It employs masked language modeling and next sentence prediction to develop deep bidirectional contextual representations. The model excels at understanding word meanings in context and capturing semantic relationships. Its primary applications include text classification, named entity recognition, question answering, and sentiment analysis. As an uncased model, it treats uppercase and lowercase letters identically, making it suitable for general text processing tasks where case sensitivity is not required.",
        "summary_zh": "BERT-base-uncased是基于Transformer架构的英语预训练语言模型，在Wikipedia和BookCorpus语料上通过掩码语言建模和下一句预测任务进行训练。该模型采用双向编码器设计，能够深度理解词语在上下文中的语义关系。其主要优势在于强大的语境理解能力和通用性，支持文本分类、命名实体识别、问答系统、情感分析等多种自然语言处理任务。作为uncased版本，模型不区分字母大小写，适用于大多数不需要大小写敏感处理的通用文本分析场景。该模型已成为许多下游NLP应用的基础架构。",
        "summary_es": "BERT-base-uncased is a foundational transformer model pre-trained on English text from Wikipedia and BookCorpus. It employs masked language modeling and next sentence prediction to develop deep bidirectional contextual representations. The model excels at understanding word meanings in context and capturing semantic relationships. Its primary applications include text classification, named entity recognition, question answering, and sentiment analysis. As an uncased model, it treats uppercase and lowercase letters identically, making it suitable for general text processing tasks where case sensitivity is not required."
      },
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "model_monitoring": [
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      }
    ],
    "model_iterative_update": [
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      }
    ],
    "fluid_simulation": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "facebook/react",
        "source": "github",
        "name": "react",
        "url": "https://github.com/facebook/react",
        "tags": [
          "declarative",
          "frontend",
          "javascript",
          "library",
          "react",
          "ui"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:11:27Z",
        "added_at": "2025-09-27",
        "summary": "The library for web and native user interfaces.",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.0999880681115978,
        "task_keys": [
          "fluid_simulation"
        ],
        "summary_en": "React is a JavaScript library developed by Facebook for building user interfaces, primarily for web and native applications. Its core capability lies in creating reusable UI components through a declarative programming paradigm. Key strengths include efficient virtual DOM implementation for optimized rendering, component-based architecture for code reusability, and strong ecosystem support. Typical use cases range from single-page applications and dynamic web interfaces to mobile apps using React Native. The library emphasizes predictable state management and unidirectional data flow.",
        "summary_zh": "React是由Facebook开发的JavaScript库，主要用于构建Web和原生应用的用户界面。其核心能力是通过声明式编程范式创建可复用的UI组件。主要优势包括高效的虚拟DOM实现优化渲染性能、基于组件的架构促进代码复用、以及强大的生态系统支持。典型应用场景涵盖单页应用、动态Web界面和使用React Native的移动应用开发。该库强调可预测的状态管理和单向数据流，支持服务器端渲染，并提供开发者工具辅助调试。React的组件化设计模式提高了开发效率和代码可维护性。",
        "summary_es": "React is a JavaScript library developed by Facebook for building user interfaces, primarily for web and native applications. Its core capability lies in creating reusable UI components through a declarative programming paradigm. Key strengths include efficient virtual DOM implementation for optimized rendering, component-based architecture for code reusability, and strong ecosystem support. Typical use cases range from single-page applications and dynamic web interfaces to mobile apps using React Native. The library emphasizes predictable state management and unidirectional data flow."
      }
    ],
    "material_design": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      },
      {
        "id": "flutter/flutter",
        "source": "github",
        "name": "flutter",
        "url": "https://github.com/flutter/flutter",
        "tags": [
          "android",
          "app-framework",
          "cross-platform",
          "dart",
          "dart-platform",
          "desktop",
          "flutter",
          "flutter-package",
          "fuchsia",
          "ios",
          "linux-desktop",
          "macos",
          "material-design",
          "mobile",
          "mobile-development",
          "skia",
          "web",
          "web-framework",
          "windows"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:28:46Z",
        "added_at": "2025-09-27",
        "summary": "Flutter makes it easy and fast to build beautiful apps for mobile and beyond",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998741232780778,
        "task_keys": [
          "material_design"
        ],
        "summary_en": "Flutter is Google's open-source UI framework for building natively compiled applications from a single codebase. Its core capability lies in using the Dart programming language to create high-performance apps with consistent rendering via the Skia graphics engine. Key strengths include hot reload for rapid development, expressive and flexible widgets, and excellent performance comparable to native apps. Typical use cases span mobile (iOS/Android), web, desktop (Windows/macOS/Linux), and embedded platforms, enabling developers to deliver consistent user experiences across multiple devices with efficient development workflows.",
        "summary_zh": "Flutter是谷歌推出的开源UI框架，用于通过单一代码库构建原生编译的应用程序。其核心能力在于使用Dart编程语言，借助Skia图形引擎实现高性能和一致性的渲染效果。主要优势包括热重载快速开发功能、丰富灵活的组件体系，以及可媲美原生应用的性能表现。典型应用场景涵盖移动端（iOS/Android）、Web端、桌面端（Windows/macOS/Linux）和嵌入式平台，使开发者能够高效创建跨设备的一致用户体验，显著提升多平台应用的开发效率。",
        "summary_es": "Flutter is Google's open-source UI framework for building natively compiled applications from a single codebase. Its core capability lies in using the Dart programming language to create high-performance apps with consistent rendering via the Skia graphics engine. Key strengths include hot reload for rapid development, expressive and flexible widgets, and excellent performance comparable to native apps. Typical use cases span mobile (iOS/Android), web, desktop (Windows/macOS/Linux), and embedded platforms, enabling developers to deliver consistent user experiences across multiple devices with efficient development workflows."
      }
    ],
    "drug_molecule_prediction": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "Genymobile/scrcpy",
        "source": "github",
        "name": "scrcpy",
        "url": "https://github.com/Genymobile/scrcpy",
        "tags": [
          "android",
          "c",
          "ffmpeg",
          "libav",
          "mirroring",
          "recording",
          "screen",
          "sdl2"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:52:25Z",
        "added_at": "2025-09-27",
        "summary": "Display and control your Android device",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09993912760112483,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "3d_reconstruction",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "multilingual_processing",
          "low_resource_language",
          "kg_construction",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "graph_augmented_reco",
          "model_compression",
          "compilation_optimization",
          "inference_acceleration",
          "privacy_computing",
          "adversarial_attack",
          "content_moderation",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_copyright",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "robot_dialogue_logic"
        ],
        "summary_en": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management.",
        "summary_zh": "scrcpy 是一款开源应用程序，用于通过 USB 或 TCP/IP 在计算机上显示和控制 Android 设备。其实时流式传输设备屏幕，延迟极低，并允许通过计算机键盘和鼠标进行完全控制。核心功能包括屏幕镜像、音频转发、设备控制和屏幕录制。优势在于高性能、无需 root 权限以及跨平台兼容性。典型用例包括应用程序开发测试、演示、游戏和远程设备管理。该项目采用 C 语言开发，基于 FFmpeg、libav 和 SDL2 库，在 GitHub 上拥有超过 12.9 万星标，显示出广泛的社区认可和使用。",
        "summary_es": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management."
      }
    ],
    "robotic_vision": [
      {
        "id": "openai/clip-vit-base-patch32",
        "source": "hf",
        "name": "clip-vit-base-patch32",
        "url": "https://huggingface.co/openai/clip-vit-base-patch32",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "clip",
          "zero-shot-image-classification",
          "vision",
          "arxiv:2103.00020",
          "arxiv:1908.04913",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 15040512,
          "likes_total": 770,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "CLIP-ViT-Base-Patch32是OpenAI开发的多模态人工智能模型，旨在连接视觉与语言理解。该模型采用Vision Transformer架构，使用32x32像素块处理图像，并结合文本编码器分析自然语言描述。通过在4亿张图像-文本对上训练，模型能够从自然语言监督中学习视觉概念。核心功能是零样本图像分类，无需针对特定任务进行训练即可根据文本描述对图像进行分类。主要优势包括强大的跨任务泛化能力和对分布变化的鲁棒性。典型应用场景涵盖内容审核、图像搜索、视觉问答等视觉理解任务，能",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "image_text_alignment",
          "robotic_vision"
        ],
        "summary_en": "CLIP-ViT-Base-Patch32 is a multimodal AI model developed by OpenAI that connects vision and language. It uses a Vision Transformer (ViT) architecture with 32x32 pixel patches to encode images and a text encoder to process natural language descriptions. The model learns visual concepts from natural language supervision by training on 400 million image-text pairs. Its core capability is zero-shot image classification, where it can classify images into categories described in text without task-specific training. Key strengths include strong generalization across diverse visual tasks and robustness to distribution shifts. Typical use cases include content moderation, image search, and visual question answering.",
        "summary_zh": "CLIP-ViT-Base-Patch32是OpenAI开发的多模态人工智能模型，旨在连接视觉与语言理解。该模型采用Vision Transformer架构，使用32x32像素块处理图像，并结合文本编码器分析自然语言描述。通过在4亿张图像-文本对上训练，模型能够从自然语言监督中学习视觉概念。核心功能是零样本图像分类，无需针对特定任务进行训练即可根据文本描述对图像进行分类。主要优势包括强大的跨任务泛化能力和对分布变化的鲁棒性。典型应用场景涵盖内容审核、图像搜索、视觉问答等视觉理解任务，能",
        "summary_es": "CLIP-ViT-Base-Patch32 is a multimodal AI model developed by OpenAI that connects vision and language. It uses a Vision Transformer (ViT) architecture with 32x32 pixel patches to encode images and a text encoder to process natural language descriptions. The model learns visual concepts from natural language supervision by training on 400 million image-text pairs. Its core capability is zero-shot image classification, where it can classify images into categories described in text without task-specific training. Key strengths include strong generalization across diverse visual tasks and robustness to distribution shifts. Typical use cases include content moderation, image search, and visual question answering."
      },
      {
        "id": "openai/clip-vit-large-patch14",
        "source": "hf",
        "name": "clip-vit-large-patch14",
        "url": "https://huggingface.co/openai/clip-vit-large-patch14",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "clip",
          "zero-shot-image-classification",
          "vision",
          "arxiv:2103.00020",
          "arxiv:1908.04913",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7853847,
          "likes_total": 1866,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "CLIP-ViT-Large-Patch14是OpenAI开发的多模态人工智能模型，旨在实现视觉与语言的联合理解。其主要目的是通过同时处理图像和文本来实现零样本图像分类，无需针对特定任务进行训练。核心能力包括生成图像和文本的联合嵌入表示，使不同模态之间能够直接比较。关键优势在于其能够处理多样化的视觉概念，并通过自然语言监督实现强大的泛化能力。典型应用场景包括基于内容的图像检索、视觉问答、图像描述生成以及多模态搜索。该模型采用Vision Transformer架构，使用较",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "image_text_alignment",
          "robotic_vision"
        ],
        "summary_en": "CLIP-ViT-Large-Patch14 is a multimodal AI model developed by OpenAI that connects vision and language. Its primary purpose is to understand images and text simultaneously, enabling zero-shot image classification without task-specific training. Core capabilities include generating joint embeddings for images and text, allowing direct comparison across modalities. Key strengths are its versatility across diverse visual concepts and robust generalization from natural language supervision. Typical use cases encompass content-based image retrieval, visual question answering, image captioning, and multimodal search applications. The model uses a Vision Transformer architecture with large patch size for efficient image processing.",
        "summary_zh": "CLIP-ViT-Large-Patch14是OpenAI开发的多模态人工智能模型，旨在实现视觉与语言的联合理解。其主要目的是通过同时处理图像和文本来实现零样本图像分类，无需针对特定任务进行训练。核心能力包括生成图像和文本的联合嵌入表示，使不同模态之间能够直接比较。关键优势在于其能够处理多样化的视觉概念，并通过自然语言监督实现强大的泛化能力。典型应用场景包括基于内容的图像检索、视觉问答、图像描述生成以及多模态搜索。该模型采用Vision Transformer架构，使用较",
        "summary_es": "CLIP-ViT-Large-Patch14 is a multimodal AI model developed by OpenAI that connects vision and language. Its primary purpose is to understand images and text simultaneously, enabling zero-shot image classification without task-specific training. Core capabilities include generating joint embeddings for images and text, allowing direct comparison across modalities. Key strengths are its versatility across diverse visual concepts and robust generalization from natural language supervision. Typical use cases encompass content-based image retrieval, visual question answering, image captioning, and multimodal search applications. The model uses a Vision Transformer architecture with large patch size for efficient image processing."
      },
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "robot_motion_planning": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      }
    ],
    "robot_environment_interaction": [
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "distilbert/distilbert-base-uncased",
        "source": "hf",
        "name": "distilbert-base-uncased",
        "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "distilbert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1910.01108",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11617607,
          "likes_total": 762,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX.",
        "summary_zh": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "summary_es": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "molecular_generation": [
      {
        "id": "openai-community/gpt2",
        "source": "hf",
        "name": "gpt2",
        "url": "https://huggingface.co/openai-community/gpt2",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "tflite",
          "rust",
          "onnx",
          "safetensors",
          "gpt2",
          "text-generation",
          "exbert",
          "en",
          "doi:10.57967/hf/0039",
          "license:mit",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11902438,
          "likes_total": 2955,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "GPT-2是由OpenAI开发的基于Transformer架构的语言生成模型，主要用于文本生成任务。其核心能力是通过输入提示预测后续文本内容，实现连贯的文本延续。主要优势包括在零样本设置下无需特定任务训练即可生成高质量文本、能够跨多个领域生成类人文本内容以及开源可访问性。典型应用场景涵盖创意写作辅助、对话系统原型开发、内容摘要生成和代码自动补全。该模型在开放式文本补全方面表现突出，能够在长文本输出中保持上下文相关性，同时支",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "text_to_image",
          "text_to_video",
          "code_generation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "inference_acceleration",
          "auto_evaluation_models",
          "molecular_generation"
        ],
        "summary_en": "GPT-2 is a transformer-based language model developed by OpenAI for text generation tasks. Its core capability involves predicting subsequent text based on input prompts, enabling coherent continuation of text. Key strengths include strong performance in zero-shot settings without task-specific training, generating human-like text across diverse domains, and open-source availability. Typical use cases encompass creative writing assistance, conversational AI prototyping, content summarization, and code generation. The model demonstrates particular effectiveness in open-ended text completion while maintaining contextual relevance throughout extended outputs.",
        "summary_zh": "GPT-2是由OpenAI开发的基于Transformer架构的语言生成模型，主要用于文本生成任务。其核心能力是通过输入提示预测后续文本内容，实现连贯的文本延续。主要优势包括在零样本设置下无需特定任务训练即可生成高质量文本、能够跨多个领域生成类人文本内容以及开源可访问性。典型应用场景涵盖创意写作辅助、对话系统原型开发、内容摘要生成和代码自动补全。该模型在开放式文本补全方面表现突出，能够在长文本输出中保持上下文相关性，同时支",
        "summary_es": "GPT-2 is a transformer-based language model developed by OpenAI for text generation tasks. Its core capability involves predicting subsequent text based on input prompts, enabling coherent continuation of text. Key strengths include strong performance in zero-shot settings without task-specific training, generating human-like text across diverse domains, and open-source availability. Typical use cases encompass creative writing assistance, conversational AI prototyping, content summarization, and code generation. The model demonstrates particular effectiveness in open-ended text completion while maintaining contextual relevance throughout extended outputs."
      },
      {
        "id": "facebook/opt-125m",
        "source": "hf",
        "name": "opt-125m",
        "url": "https://huggingface.co/facebook/opt-125m",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "opt",
          "text-generation",
          "en",
          "arxiv:2205.01068",
          "arxiv:2005.14165",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "region:us"
        ],
        "stats": {
          "downloads_total": 8602519,
          "likes_total": 218,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "OPT-125M是Meta AI开发的Open Pre-trained Transformer系列中的1.25亿参数仅解码器变压器语言模型，作为较大OPT模型的缩小版本，主要用于研究和实验目的。该模型能够根据输入提示生成连贯文本，支持多种自然语言处理任务。其主要优势包括面向研究用途的开放可访问性、支持多种框架（PyTorch、TensorFlow、JAX）的兼容性以及高效的推理能力。典型应用场景涵盖文本生成实验、变压器架构的教育演示、小规模语言模型性能基准测试，以及作为理解更大规模语言模型工作原理的入门工具。该模型特别适合计",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "text_to_image",
          "text_to_video",
          "code_generation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "inference_acceleration",
          "auto_evaluation_models",
          "molecular_generation"
        ],
        "summary_en": "OPT-125M is a 125 million parameter decoder-only transformer language model developed by Meta AI as part of the Open Pre-trained Transformer series. It serves as a smaller-scale version of larger OPT models for research and experimentation. The model generates coherent text based on input prompts and supports various natural language processing tasks. Its primary strengths include open accessibility for research purposes, compatibility with multiple frameworks (PyTorch, TensorFlow, JAX), and efficient inference capabilities. Typical use cases encompass text generation experiments, educational demonstrations of transformer architectures, and benchmarking smaller-scale language model performance.",
        "summary_zh": "OPT-125M是Meta AI开发的Open Pre-trained Transformer系列中的1.25亿参数仅解码器变压器语言模型，作为较大OPT模型的缩小版本，主要用于研究和实验目的。该模型能够根据输入提示生成连贯文本，支持多种自然语言处理任务。其主要优势包括面向研究用途的开放可访问性、支持多种框架（PyTorch、TensorFlow、JAX）的兼容性以及高效的推理能力。典型应用场景涵盖文本生成实验、变压器架构的教育演示、小规模语言模型性能基准测试，以及作为理解更大规模语言模型工作原理的入门工具。该模型特别适合计",
        "summary_es": "OPT-125M is a 125 million parameter decoder-only transformer language model developed by Meta AI as part of the Open Pre-trained Transformer series. It serves as a smaller-scale version of larger OPT models for research and experimentation. The model generates coherent text based on input prompts and supports various natural language processing tasks. Its primary strengths include open accessibility for research purposes, compatibility with multiple frameworks (PyTorch, TensorFlow, JAX), and efficient inference capabilities. Typical use cases encompass text generation experiments, educational demonstrations of transformer architectures, and benchmarking smaller-scale language model performance."
      },
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "Qwen/Qwen2.5-3B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-3B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-3B",
          "base_model:finetune:Qwen/Qwen2.5-3B",
          "license:other",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands.",
        "summary_zh": "Qwen2.5-3B-Instruct是由Qwen开发的30亿参数指令调优语言模型，基于Qwen2.5-3B基础模型构建。其主要目的是实现高效的对话交互和用户指令跟随。核心能力包括文本生成、聊天功能以及通过自然语言提示完成任务。关键优势在于紧凑的模型尺寸便于高效部署，兼容Transformers和文本生成推理等流行框架，并支持多语言（尤其优化英语）。典型应用场景涵盖AI助手、聊天机器人以及需要响应式对话系统且计算需求适中的应用程序。该模型采用Safetensors格式，支持自动训练和端点部署，适用于英语",
        "summary_es": "Qwen2.5-3B-Instruct is a 3-billion-parameter instruction-tuned language model developed by Qwen, built upon the Qwen2.5-3B base model. Its primary purpose is to engage in conversational interactions and follow user instructions effectively. Core capabilities include text generation, chat functionality, and task completion through natural language prompts. Key strengths encompass its compact size for efficient deployment, compatibility with popular frameworks like Transformers and Text Generation Inference, and multilingual support with English optimization. Typical use cases involve AI assistants, chatbots, and applications requiring responsive dialogue systems with moderate computational demands."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "facebook/bart-base",
        "source": "hf",
        "name": "bart-base",
        "url": "https://huggingface.co/facebook/bart-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "safetensors",
          "bart",
          "feature-extraction",
          "en",
          "arxiv:1910.13461",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6295544,
          "likes_total": 199,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation.",
        "summary_zh": "BART-base是一种序列到序列模型，专为文本生成和理解任务设计。它结合了双向编码器表示和自回归解码器，具备文本摘要、翻译和问答等核心能力。该模型的优势在于采用去噪自编码的预训练方法，通过破坏文本并学习重建原始内容来提升性能。典型应用场景包括文档的抽象摘要、语言间的机器翻译以及对话响应生成。作为基础架构，它可针对需要文本转换的各种自然语言处理任务进行微调，适用于处理不同领域的文本数据转换需求。",
        "summary_es": "BART-base is a sequence-to-sequence model designed for text generation and comprehension tasks. It combines bidirectional encoder representations with an autoregressive decoder, enabling capabilities like text summarization, translation, and question answering. The model's strength lies in its pre-training approach using denoising autoencoding, which corrupts text and learns to reconstruct the original. Typical use cases include abstractive summarization of documents, machine translation between languages, and dialogue response generation. It serves as a foundational architecture that can be fine-tuned for various natural language processing applications requiring text transformation."
      }
    ],
    "bioinformatics_analysis": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "Genymobile/scrcpy",
        "source": "github",
        "name": "scrcpy",
        "url": "https://github.com/Genymobile/scrcpy",
        "tags": [
          "android",
          "c",
          "ffmpeg",
          "libav",
          "mirroring",
          "recording",
          "screen",
          "sdl2"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:52:25Z",
        "added_at": "2025-09-27",
        "summary": "Display and control your Android device",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09993912760112483,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "3d_reconstruction",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "multilingual_processing",
          "low_resource_language",
          "kg_construction",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "graph_augmented_reco",
          "model_compression",
          "compilation_optimization",
          "inference_acceleration",
          "privacy_computing",
          "adversarial_attack",
          "content_moderation",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_copyright",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "robot_dialogue_logic"
        ],
        "summary_en": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management.",
        "summary_zh": "scrcpy 是一款开源应用程序，用于通过 USB 或 TCP/IP 在计算机上显示和控制 Android 设备。其实时流式传输设备屏幕，延迟极低，并允许通过计算机键盘和鼠标进行完全控制。核心功能包括屏幕镜像、音频转发、设备控制和屏幕录制。优势在于高性能、无需 root 权限以及跨平台兼容性。典型用例包括应用程序开发测试、演示、游戏和远程设备管理。该项目采用 C 语言开发，基于 FFmpeg、libav 和 SDL2 库，在 GitHub 上拥有超过 12.9 万星标，显示出广泛的社区认可和使用。",
        "summary_es": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management."
      }
    ],
    "time_series_forecasting": [
      {
        "id": "Datadog/Toto-Open-Base-1.0",
        "source": "hf",
        "name": "Toto-Open-Base-1.0",
        "url": "https://huggingface.co/Datadog/Toto-Open-Base-1.0",
        "tags": [
          "transformers",
          "safetensors",
          "time-series-forecasting",
          "foundation models",
          "pretrained models",
          "time series foundation models",
          "time series",
          "time-series",
          "timeseries",
          "forecasting",
          "observability",
          "dataset:Salesforce/GiftEvalPretrain",
          "dataset:autogluon/chronos_datasets",
          "arxiv:2505.14766",
          "license:apache-2.0",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6133487,
          "likes_total": 112,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Toto-Open-Base-1.0是由Datadog开发的预训练时间序列基础模型，专为预测应用设计。其核心能力在于分析时间模式以预测各类数据集的未来数值。主要优势包括与多种端点的兼容性以及在时间序列数据上的稳健性能。典型应用场景涵盖可观测性监控、资源规划和业务指标异常检测。该模型采用Transformer架构，基于Salesforce/GiftEvalPretrain和Autogluon/chronos_datasets等数据集训练而成。作为基础模型，它为运营智能领域的专业预测任务提供支持，适用于需要时序分析的商业和技术环境。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_forecasting",
          "time_series_anomaly_detection"
        ],
        "summary_en": "Toto-Open-Base-1.0 is a pretrained time series foundation model developed by Datadog for forecasting applications. Its core capability involves analyzing temporal patterns to predict future values across diverse datasets. Key strengths include compatibility with various endpoints and robust performance on time-series data. Typical use cases span observability monitoring, resource planning, and anomaly detection in business metrics. The model leverages transformer architecture and is trained on datasets like Salesforce/GiftEvalPretrain and Autogluon/chronos_datasets. It serves as a base model for specialized forecasting tasks in operational intelligence contexts.",
        "summary_zh": "Toto-Open-Base-1.0是由Datadog开发的预训练时间序列基础模型，专为预测应用设计。其核心能力在于分析时间模式以预测各类数据集的未来数值。主要优势包括与多种端点的兼容性以及在时间序列数据上的稳健性能。典型应用场景涵盖可观测性监控、资源规划和业务指标异常检测。该模型采用Transformer架构，基于Salesforce/GiftEvalPretrain和Autogluon/chronos_datasets等数据集训练而成。作为基础模型，它为运营智能领域的专业预测任务提供支持，适用于需要时序分析的商业和技术环境。",
        "summary_es": "Toto-Open-Base-1.0 is a pretrained time series foundation model developed by Datadog for forecasting applications. Its core capability involves analyzing temporal patterns to predict future values across diverse datasets. Key strengths include compatibility with various endpoints and robust performance on time-series data. Typical use cases span observability monitoring, resource planning, and anomaly detection in business metrics. The model leverages transformer architecture and is trained on datasets like Salesforce/GiftEvalPretrain and Autogluon/chronos_datasets. It serves as a base model for specialized forecasting tasks in operational intelligence contexts."
      },
      {
        "id": "thuml/sundial-base-128m",
        "source": "hf",
        "name": "sundial-base-128m",
        "url": "https://huggingface.co/thuml/sundial-base-128m",
        "tags": [
          "safetensors",
          "sundial",
          "time series",
          "time-series",
          "forecasting",
          "foundation models",
          "pretrained models",
          "generative models",
          "time series foundation models",
          "time-series-forecasting",
          "custom_code",
          "dataset:thuml/UTSD",
          "dataset:Salesforce/lotsa_data",
          "dataset:autogluon/chronos_datasets",
          "arxiv:2502.00816",
          "arxiv:2403.07815",
          "license:apache-2.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 5884615,
          "likes_total": 47,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Sundial-base-128m是一个拥有1.28亿参数的时间序列基础模型，专门设计用于预测应用。该模型作为预训练的生成模型，可通过微调适应各种时间序列预测任务。它利用多个数据集进行训练，包括Salesforce/lotsa_data、AutoGluon/chronos_datasets和thuml/UTSD。核心能力包括处理多样化的时间序列模式并生成未来预测。主要优势在于高效的参数利用和基础模型的灵活性。典型应用场景涵盖需求预测、金融预测和工业监控等领域，其中历史模式可用于推断未来趋势。该模型基于Apache 2.0许可证发布，支持安全张量格式。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "lightweight_visual_model",
          "code_generation",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_forecasting",
          "time_series_anomaly_detection"
        ],
        "summary_en": "Sundial-base-128m is a 128-million parameter time series foundation model designed for forecasting applications. It serves as a pretrained generative model that can be fine-tuned for various time series prediction tasks. The model leverages multiple datasets including Salesforce/lotsa_data, AutoGluon/chronos_datasets, and thuml/UTSD for training. Its core capabilities include handling diverse time series patterns and generating future predictions. Strengths include efficient parameter usage and foundation model flexibility. Typical use cases span demand forecasting, financial prediction, and industrial monitoring applications where historical patterns inform future trends.",
        "summary_zh": "Sundial-base-128m是一个拥有1.28亿参数的时间序列基础模型，专门设计用于预测应用。该模型作为预训练的生成模型，可通过微调适应各种时间序列预测任务。它利用多个数据集进行训练，包括Salesforce/lotsa_data、AutoGluon/chronos_datasets和thuml/UTSD。核心能力包括处理多样化的时间序列模式并生成未来预测。主要优势在于高效的参数利用和基础模型的灵活性。典型应用场景涵盖需求预测、金融预测和工业监控等领域，其中历史模式可用于推断未来趋势。该模型基于Apache 2.0许可证发布，支持安全张量格式。",
        "summary_es": "Sundial-base-128m is a 128-million parameter time series foundation model designed for forecasting applications. It serves as a pretrained generative model that can be fine-tuned for various time series prediction tasks. The model leverages multiple datasets including Salesforce/lotsa_data, AutoGluon/chronos_datasets, and thuml/UTSD for training. Its core capabilities include handling diverse time series patterns and generating future predictions. Strengths include efficient parameter usage and foundation model flexibility. Typical use cases span demand forecasting, financial prediction, and industrial monitoring applications where historical patterns inform future trends."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "autogluon/chronos-bolt-base",
        "source": "hf",
        "name": "chronos-bolt-base",
        "url": "https://huggingface.co/autogluon/chronos-bolt-base",
        "tags": [
          "safetensors",
          "t5",
          "time series",
          "forecasting",
          "pretrained models",
          "foundation models",
          "time series foundation models",
          "time-series",
          "time-series-forecasting",
          "arxiv:1910.10683",
          "arxiv:2403.07815",
          "license:apache-2.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 5749495,
          "likes_total": 27,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Chronos-Bolt-Base是由AutoGluon开发的时间序列基础模型，专门用于预测应用。该模型基于T5架构，在大量时间序列数据上进行预训练，支持零样本预测而无需特定任务训练。核心能力包括跨多个领域的单变量时间序列预测。主要优势在于参数高效的设计、Apache 2.0开源许可以及处理多样化预测场景的能力。典型应用场景涵盖零售需求预测、能源负荷预测、金融市场分析和物联网传感器监测，通过迁移学习为时间序列分析提供便捷解决方案。模型采用safetensors格式，支持安全部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "time_series_forecasting"
        ],
        "summary_en": "Chronos-Bolt-Base is a time series foundation model developed by AutoGluon for forecasting applications. Built on T5 architecture and pretrained on extensive time series data, it enables zero-shot forecasting without task-specific training. Core capabilities include univariate time series prediction across various domains. Strengths lie in its parameter-efficient design, Apache 2.0 licensing, and ability to handle diverse forecasting scenarios. Typical use cases span retail demand prediction, energy load forecasting, financial market analysis, and IoT sensor monitoring, providing accessible time series analysis through transfer learning.",
        "summary_zh": "Chronos-Bolt-Base是由AutoGluon开发的时间序列基础模型，专门用于预测应用。该模型基于T5架构，在大量时间序列数据上进行预训练，支持零样本预测而无需特定任务训练。核心能力包括跨多个领域的单变量时间序列预测。主要优势在于参数高效的设计、Apache 2.0开源许可以及处理多样化预测场景的能力。典型应用场景涵盖零售需求预测、能源负荷预测、金融市场分析和物联网传感器监测，通过迁移学习为时间序列分析提供便捷解决方案。模型采用safetensors格式，支持安全部署。",
        "summary_es": "Chronos-Bolt-Base is a time series foundation model developed by AutoGluon for forecasting applications. Built on T5 architecture and pretrained on extensive time series data, it enables zero-shot forecasting without task-specific training. Core capabilities include univariate time series prediction across various domains. Strengths lie in its parameter-efficient design, Apache 2.0 licensing, and ability to handle diverse forecasting scenarios. Typical use cases span retail demand prediction, energy load forecasting, financial market analysis, and IoT sensor monitoring, providing accessible time series analysis through transfer learning."
      },
      {
        "id": "Salesforce/moirai-2.0-R-small",
        "source": "hf",
        "name": "moirai-2.0-R-small",
        "url": "https://huggingface.co/Salesforce/moirai-2.0-R-small",
        "tags": [
          "safetensors",
          "time series",
          "forecasting",
          "pretrained models",
          "foundation models",
          "time series foundation models",
          "time-series",
          "time-series-forecasting",
          "arxiv:2403.07815",
          "arxiv:2402.02592",
          "license:cc-by-nc-4.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Moirai-2.0-R-small是Salesforce开发的时间序列基础模型，专门用于预测应用。该模型作为预训练的基础模型，可针对不同领域的时间序列预测任务进行微调。其核心能力包括处理多样化的时间序列数据模式并生成准确预测。主要优势在于作为紧凑而有效的基础模型，为专业预测应用提供起点。典型应用场景涵盖商业分析、需求预测、资源规划和运营优化等领域，适用于需要基于历史时间序列数据进行预测的各种实际场景。该模型采用CC-BY-NC-4.0许可证，支持安全张量格式，",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "time_series_forecasting"
        ],
        "summary_en": "Moirai-2.0-R-small is a time series foundation model developed by Salesforce for forecasting applications. It serves as a pretrained base model that can be fine-tuned for various time series prediction tasks across different domains. The model's core capabilities include handling diverse time series data patterns and generating accurate forecasts. Its strengths lie in being a compact yet effective foundation model that provides a starting point for specialized forecasting applications. Typical use cases span business analytics, demand forecasting, resource planning, and operational optimization scenarios where historical time series data is available for prediction.",
        "summary_zh": "Moirai-2.0-R-small是Salesforce开发的时间序列基础模型，专门用于预测应用。该模型作为预训练的基础模型，可针对不同领域的时间序列预测任务进行微调。其核心能力包括处理多样化的时间序列数据模式并生成准确预测。主要优势在于作为紧凑而有效的基础模型，为专业预测应用提供起点。典型应用场景涵盖商业分析、需求预测、资源规划和运营优化等领域，适用于需要基于历史时间序列数据进行预测的各种实际场景。该模型采用CC-BY-NC-4.0许可证，支持安全张量格式，",
        "summary_es": "Moirai-2.0-R-small is a time series foundation model developed by Salesforce for forecasting applications. It serves as a pretrained base model that can be fine-tuned for various time series prediction tasks across different domains. The model's core capabilities include handling diverse time series data patterns and generating accurate forecasts. Its strengths lie in being a compact yet effective foundation model that provides a starting point for specialized forecasting applications. Typical use cases span business analytics, demand forecasting, resource planning, and operational optimization scenarios where historical time series data is available for prediction."
      },
      {
        "id": "autogluon/chronos-bolt-small",
        "source": "hf",
        "name": "chronos-bolt-small",
        "url": "https://huggingface.co/autogluon/chronos-bolt-small",
        "tags": [
          "safetensors",
          "t5",
          "time series",
          "forecasting",
          "pretrained models",
          "foundation models",
          "time series foundation models",
          "time-series",
          "time-series-forecasting",
          "arxiv:1910.10683",
          "arxiv:2403.07815",
          "license:apache-2.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Chronos-Bolt-Small是由AutoGluon开发的紧凑型时间序列预测基础模型。该模型基于T5架构，通过将时间序列视为标记序列进行零样本预测，无需重新训练即可处理多样化的单变量时间序列。其核心优势在于计算效率高、适用范围广（涵盖零售、能源等领域），并能有效处理不规则模式。典型应用场景包括需求预测、异常检测和资源规划，为数据有限或专业知识不足的实践者提供易用的AI能力。该模型利用大规模预训练的迁移学习，在保持较小参数规模的同时实现稳健性",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "time_series_forecasting"
        ],
        "summary_en": "Chronos-Bolt-Small is a compact time series forecasting foundation model developed by AutoGluon. Built on T5 architecture, it performs zero-shot forecasting by treating time series as token sequences. The model excels in handling diverse univariate time series without retraining, leveraging transfer learning from large-scale pretraining. Its strengths include computational efficiency, broad applicability across domains like retail and energy, and robust performance on irregular patterns. Typical use cases involve demand forecasting, anomaly detection, and resource planning, providing accessible AI capabilities for practitioners with limited data or expertise.",
        "summary_zh": "Chronos-Bolt-Small是由AutoGluon开发的紧凑型时间序列预测基础模型。该模型基于T5架构，通过将时间序列视为标记序列进行零样本预测，无需重新训练即可处理多样化的单变量时间序列。其核心优势在于计算效率高、适用范围广（涵盖零售、能源等领域），并能有效处理不规则模式。典型应用场景包括需求预测、异常检测和资源规划，为数据有限或专业知识不足的实践者提供易用的AI能力。该模型利用大规模预训练的迁移学习，在保持较小参数规模的同时实现稳健性",
        "summary_es": "Chronos-Bolt-Small is a compact time series forecasting foundation model developed by AutoGluon. Built on T5 architecture, it performs zero-shot forecasting by treating time series as token sequences. The model excels in handling diverse univariate time series without retraining, leveraging transfer learning from large-scale pretraining. Its strengths include computational efficiency, broad applicability across domains like retail and energy, and robust performance on irregular patterns. Typical use cases involve demand forecasting, anomaly detection, and resource planning, providing accessible AI capabilities for practitioners with limited data or expertise."
      },
      {
        "id": "massgravel/Microsoft-Activation-Scripts",
        "source": "github",
        "name": "Microsoft-Activation-Scripts",
        "url": "https://github.com/massgravel/Microsoft-Activation-Scripts",
        "tags": [
          "activator",
          "hwid",
          "kms",
          "kms38",
          "massgrave",
          "massgravel",
          "microsoft",
          "microsoft365",
          "office",
          "office365",
          "ohook",
          "powershell",
          "tsforge",
          "windows",
          "windows-10",
          "windows-11"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:22:25Z",
        "added_at": "2025-09-28",
        "summary": "Open-source Windows and Office activator featuring HWID, Ohook, TSforge, KMS38, and Online KMS activation methods, along with advanced troubleshooting.",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998397917698947,
        "task_keys": [
          "time_series_forecasting"
        ],
        "summary_en": "Microsoft Activation Scripts is an open-source tool designed to activate Microsoft Windows and Office products without official licensing. It employs multiple activation methods including HWID (Hardware ID), Ohook, TSforge, KMS38, and Online KMS to bypass Microsoft's activation system. The project provides advanced troubleshooting capabilities and operates through PowerShell scripts. Its primary strength lies in offering free activation alternatives, though it exists in a legal gray area regarding software licensing compliance. Typical use cases include activating Windows 10/11 and Office 365 installations where users seek to avoid purchasing official licenses.",
        "summary_zh": "Microsoft Activation Scripts 是一个开源工具，旨在无需官方许可即可激活微软Windows和Office产品。该项目采用多种激活方法，包括HWID（硬件ID）、Ohook、TSforge、KMS38和在线KMS，以绕过微软的激活系统。该工具通过PowerShell脚本运行，并提供高级故障排除功能。其主要优势在于提供免费的激活替代方案，但在软件许可合规性方面处于法律灰色地带。典型使用场景包括激活Windows 10/11和Office 365安装，适用于希望避免购买官方许可证的用户。该项目在GitHub上拥有大量关注者，体现了其在特定用户群体中的受欢迎程度。",
        "summary_es": "Microsoft Activation Scripts is an open-source tool designed to activate Microsoft Windows and Office products without official licensing. It employs multiple activation methods including HWID (Hardware ID), Ohook, TSforge, KMS38, and Online KMS to bypass Microsoft's activation system. The project provides advanced troubleshooting capabilities and operates through PowerShell scripts. Its primary strength lies in offering free activation alternatives, though it exists in a legal gray area regarding software licensing compliance. Typical use cases include activating Windows 10/11 and Office 365 installations where users seek to avoid purchasing official licenses."
      }
    ],
    "time_series_anomaly_detection": [
      {
        "id": "Falconsai/nsfw_image_detection",
        "source": "hf",
        "name": "nsfw_image_detection",
        "url": "https://huggingface.co/Falconsai/nsfw_image_detection",
        "tags": [
          "transformers",
          "pytorch",
          "safetensors",
          "vit",
          "image-classification",
          "arxiv:2010.11929",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 99881324,
          "likes_total": 826,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "image_text_alignment",
          "auto_evaluation_models",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems.",
        "summary_zh": "该项目专门用于图像分类，旨在检测图像中的NSFW（不适宜工作场所）内容。基于Vision Transformer架构构建，能够高精度识别露骨或不适宜的视觉材料。模型服务于内容审核目的，帮助平台自动过滤不合适图像。核心能力包括对图像进行安全或NSFW的二元分类。优势在于对各种图像类型的稳健性能以及与标准部署工具的兼容性。典型应用场景涉及社交媒体平台、消息应用和内容托管服务实施自动化内容过滤系统，有效维护网络环境的适宜性，防止不当内容的传",
        "summary_es": "This project provides an image classification model specifically designed to detect NSFW (Not Safe For Work) content in images. Built on Vision Transformer architecture, it can identify explicit or inappropriate visual material with high accuracy. The model serves content moderation purposes, helping platforms automatically filter unsuitable images. Its core capabilities include binary classification of images as safe or NSFW. Strengths include robust performance across diverse image types and compatibility with standard deployment tools. Typical use cases involve social media platforms, messaging apps, and content hosting services implementing automated content filtering systems."
      },
      {
        "id": "dima806/fairface_age_image_detection",
        "source": "hf",
        "name": "fairface_age_image_detection",
        "url": "https://huggingface.co/dima806/fairface_age_image_detection",
        "tags": [
          "transformers",
          "safetensors",
          "vit",
          "image-classification",
          "dataset:nateraw/fairface",
          "base_model:google/vit-base-patch16-224-in21k",
          "base_model:finetune:google/vit-base-patch16-224-in21k",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 61525079,
          "likes_total": 41,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "text_to_image",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "image_text_alignment",
          "lightweight_multimodal_model",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "auto_evaluation_models",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection"
        ],
        "summary_en": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications.",
        "summary_zh": "该项目基于谷歌Vision Transformer（ViT-base-patch16-224-in21k）架构，在FairFace人脸数据集上进行微调，专门用于从面部图像中识别年龄组别。其核心功能是处理224×224像素输入图像，并输出年龄分类概率。主要优势包括ViT模型卓越的视觉识别能力，以及FairFace数据集涵盖多种族群的平衡样本分布，有助于减少人口统计偏差。典型应用场景涉及人口统计分析、适龄内容过滤系统开发，以及计算机视觉领域算法公平性的学术研究。该项目通过微调预训练模型，实现了针对年龄属性的高效分类，适用于需要 demographic 特",
        "summary_es": "This project fine-tunes Google's Vision Transformer (ViT-base-patch16-224-in21k) on the FairFace dataset for age classification from facial images. Its primary purpose is to predict age groups in photographs with improved fairness across diverse demographics. Core capabilities include processing 224x224 pixel images and outputting age category probabilities. Key strengths are the ViT architecture's strong visual recognition performance and the FairFace dataset's balanced racial/ethnic representation. Typical use cases span demographic analysis, age-appropriate content filtering, and research on algorithmic fairness in computer vision applications."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      }
    ],
    "radar_understanding": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      }
    ],
    "lidar_understanding": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      }
    ],
    "low_resource_medical_ai": [
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "meta-llama/Llama-3.1-8B-Instruct",
        "source": "hf",
        "name": "Llama-3.1-8B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "base_model:meta-llama/Llama-3.1-8B",
          "base_model:finetune:meta-llama/Llama-3.1-8B",
          "license:llama3.1",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7228934,
          "likes_total": 4677,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required.",
        "summary_zh": "Llama-3.1-8B-Instruct是由Meta公司开发的对话式人工智能模型，基于拥有80亿参数的Llama 3.1架构。其主要目的是为用户提供多语言（包括英语、西班牙语、法语、德语、意大利语、葡萄牙语和印地语）的指令响应服务。核心能力涵盖自然语言理解、文本生成和任务完成。优势在于多语言支持、对话交互能力以及与微调框架的兼容性。典型应用场景包括聊天机器人、虚拟助手、内容生成和教育应用等需要交互式对话的领域。该模型特��注重安全性和实用性，适用于需要精确指令遵循",
        "summary_es": "Llama-3.1-8B-Instruct is a conversational AI model developed by Meta, based on the Llama 3.1 architecture with 8 billion parameters. Its primary purpose is to provide helpful, safe responses to user instructions across multiple languages including English, Spanish, French, German, Italian, Portuguese, and Hindi. Core capabilities include natural language understanding, text generation, and task completion. Strengths lie in its multilingual support, conversational abilities, and compatibility with fine-tuning frameworks. Typical use cases involve chatbots, virtual assistants, content generation, and educational applications where interactive dialogue is required."
      },
      {
        "id": "EbookFoundation/free-programming-books",
        "source": "github",
        "name": "free-programming-books",
        "url": "https://github.com/EbookFoundation/free-programming-books",
        "tags": [
          "books",
          "education",
          "hacktoberfest",
          "list",
          "resource"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:01:07Z",
        "added_at": "2025-09-27",
        "summary": ":books: Freely available programming books",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998706514989548,
        "task_keys": [
          "low_resource_language",
          "low_resource_medical_ai",
          "low_resource_voice_assistant"
        ],
        "summary_en": "The free-programming-books repository provides a comprehensive collection of freely available programming books and educational resources. Its primary purpose is to compile and organize programming knowledge accessible to everyone without cost. Core capabilities include categorizing resources by programming language, technology domain, and resource type. Key strengths are the extensive multilingual coverage, community-driven curation, and regular updates. Typical use cases include self-learning programming, academic reference, professional skill development, and educational institutions seeking free teaching materials. The project maintains high-quality standards through community contributions and verification.",
        "summary_zh": "free-programming-books 项目是一个收集和整理免费编程书籍与教育资源的综合性知识库。其主要目的是为全球学习者提供无需付费即可获取的编程学习材料。核心功能包括按编程语言、技术领域和资源类型进行分类整理，支持多语言内容收录。项目优势在于资源覆盖面广、社区驱动更新维护、内容质量经过验证。典型应用场景包括编程自学、学术参考、职业技能提升以及教育机构寻找免费教材。该项目通过社区协作确保资源的时效性和准确性，已成为编程",
        "summary_es": "The free-programming-books repository provides a comprehensive collection of freely available programming books and educational resources. Its primary purpose is to compile and organize programming knowledge accessible to everyone without cost. Core capabilities include categorizing resources by programming language, technology domain, and resource type. Key strengths are the extensive multilingual coverage, community-driven curation, and regular updates. Typical use cases include self-learning programming, academic reference, professional skill development, and educational institutions seeking free teaching materials. The project maintains high-quality standards through community contributions and verification."
      }
    ],
    "low_resource_voice_assistant": [
      {
        "id": "pyannote/segmentation-3.0",
        "source": "hf",
        "name": "segmentation-3.0",
        "url": "https://huggingface.co/pyannote/segmentation-3.0",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-diarization",
          "speaker-change-detection",
          "speaker-segmentation",
          "voice-activity-detection",
          "overlapped-speech-detection",
          "resegmentation",
          "license:mit",
          "region:us"
        ],
        "stats": {
          "downloads_total": 18441470,
          "likes_total": 605,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "lightweight_visual_model",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "model_monitoring",
          "model_iterative_update",
          "time_series_anomaly_detection",
          "low_resource_voice_assistant"
        ],
        "summary_en": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments.",
        "summary_zh": "Pyannote segmentation-3.0 是一个基于 PyTorch 的神经网络模型，专门用于说话人日志任务，即将音频流分割为说话人同质区域。其核心功能包括语音活动检测、说话人变更检测和重叠语音检测。该模型擅长识别说话人开始/结束讲话的时间点，并能检测多人同时说话的情况。典型应用场景包括会议转录、广播内容监控和呼叫中心分析。这款 MIT 许可的模型通过处理音频输出带有说话人标签的精确时间片段，为需要准确分离多说话人环境中语音的应用提供支持，特别适用于",
        "summary_es": "Pyannote segmentation-3.0 is a PyTorch-based neural network for speaker diarization, designed to segment audio streams into speaker-homogeneous regions. Its core capabilities include voice activity detection, speaker change detection, and overlapped speech detection. The model excels at identifying when speakers begin/end talking and detecting multiple speakers talking simultaneously. Typical use cases include meeting transcription, broadcast monitoring, and call center analytics. The MIT-licensed model processes audio to output precise temporal segments with speaker labels, supporting applications requiring accurate speaker separation in multi-speaker environments."
      },
      {
        "id": "pyannote/wespeaker-voxceleb-resnet34-LM",
        "source": "hf",
        "name": "wespeaker-voxceleb-resnet34-LM",
        "url": "https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM",
        "tags": [
          "pyannote-audio",
          "pytorch",
          "pyannote",
          "pyannote-audio-model",
          "wespeaker",
          "audio",
          "voice",
          "speech",
          "speaker",
          "speaker-recognition",
          "speaker-verification",
          "speaker-identification",
          "speaker-embedding",
          "dataset:voxceleb",
          "license:cc-by-4.0",
          "region:us"
        ],
        "stats": {
          "downloads_total": 17739550,
          "likes_total": 76,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "wespeaker-voxceleb-resnet34-LM 是一个专门用于说话人识别的模型，其核心功能是从音频中提取具有区分性的说话人嵌入向量。该模型采用基于 VoxCeleb 数据集训练的 ResNet-34 架构，并集成了语言模型评分机制以提升验证准确性。主要优势包括在不同声学条件下的稳定表现和高效的说话人区分能力。典型应用场景涵盖说话人验证、身份识别任务以及需要区分不同说话人的语音日记系统。该模型能够处理原始语音信号并生成固定维度的表征向量，适用于需要精确说话人辨别的",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "lightweight_visual_model",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "speaker_separation",
          "lightweight_multimodal_model",
          "vector_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "low_resource_voice_assistant"
        ],
        "summary_en": "The wespeaker-voxceleb-resnet34-LM model is a speaker recognition system designed to extract distinctive speaker embeddings from audio. Its core capability involves processing speech signals to generate fixed-dimensional vectors that uniquely represent speaker characteristics. The model employs a ResNet-34 architecture trained on the VoxCeleb dataset, enhanced with language model scoring for improved verification accuracy. Key strengths include robust performance across diverse acoustic conditions and effective speaker discrimination. Typical use cases encompass speaker verification, identification tasks, and speaker diarization systems where distinguishing between different speakers is essential.",
        "summary_zh": "wespeaker-voxceleb-resnet34-LM 是一个专门用于说话人识别的模型，其核心功能是从音频中提取具有区分性的说话人嵌入向量。该模型采用基于 VoxCeleb 数据集训练的 ResNet-34 架构，并集成了语言模型评分机制以提升验证准确性。主要优势包括在不同声学条件下的稳定表现和高效的说话人区分能力。典型应用场景涵盖说话人验证、身份识别任务以及需要区分不同说话人的语音日记系统。该模型能够处理原始语音信号并生成固定维度的表征向量，适用于需要精确说话人辨别的",
        "summary_es": "The wespeaker-voxceleb-resnet34-LM model is a speaker recognition system designed to extract distinctive speaker embeddings from audio. Its core capability involves processing speech signals to generate fixed-dimensional vectors that uniquely represent speaker characteristics. The model employs a ResNet-34 architecture trained on the VoxCeleb dataset, enhanced with language model scoring for improved verification accuracy. Key strengths include robust performance across diverse acoustic conditions and effective speaker discrimination. Typical use cases encompass speaker verification, identification tasks, and speaker diarization systems where distinguishing between different speakers is essential."
      },
      {
        "id": "meta-llama/Llama-3.2-1B-Instruct",
        "source": "hf",
        "name": "Llama-3.2-1B-Instruct",
        "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "llama",
          "text-generation",
          "facebook",
          "meta",
          "pytorch",
          "llama-3",
          "conversational",
          "en",
          "de",
          "fr",
          "it",
          "pt",
          "hi",
          "es",
          "th",
          "arxiv:2204.05149",
          "arxiv:2405.16406",
          "license:llama3.2",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7241931,
          "likes_total": 1082,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_video",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "lightweight_visual_model",
          "code_generation",
          "tool_use",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "lightweight_multimodal_model",
          "general_recommendation",
          "vertical_recommendation",
          "vector_db_optimization",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "adversarial_defense",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "model_monitoring",
          "model_iterative_update",
          "material_design",
          "robot_environment_interaction",
          "molecular_generation",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required.",
        "summary_zh": "Llama-3.2-1B-Instruct是由Meta开发的11亿参数语言模型，专门针对指令跟随任务进行优化。其主要目的是理解和执行跨多个领域的用户指令。核心能力包括文本生成、对话交互以及多语言支持（英语、德语、西班牙语、法语、印地语、意大利语、葡萄牙语）。该模型的优势在于其高效参数规模，使其适合资源受限环境，同时保持对话质量。典型应用场景包括聊天机器人、虚拟助手、内容创作和教育工具，特别适用于需要精确指令处理的场合。模型基于Llama 3.2架构，采用PyTorch和SafeTensors格式，支持自动训",
        "summary_es": "Llama-3.2-1B-Instruct is a 1.1 billion parameter language model developed by Meta, optimized for instruction-following tasks. Its primary purpose is to understand and execute user instructions across various domains. Core capabilities include text generation, conversation, and multilingual support (English, German, Spanish, French, Hindi, Italian, Portuguese). Strengths lie in its efficient size, making it suitable for resource-constrained environments while maintaining conversational quality. Typical use cases include chatbots, virtual assistants, content creation, and educational tools where precise instruction handling is required."
      },
      {
        "id": "EbookFoundation/free-programming-books",
        "source": "github",
        "name": "free-programming-books",
        "url": "https://github.com/EbookFoundation/free-programming-books",
        "tags": [
          "books",
          "education",
          "hacktoberfest",
          "list",
          "resource"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:01:07Z",
        "added_at": "2025-09-27",
        "summary": ":books: Freely available programming books",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998706514989548,
        "task_keys": [
          "low_resource_language",
          "low_resource_medical_ai",
          "low_resource_voice_assistant"
        ],
        "summary_en": "The free-programming-books repository provides a comprehensive collection of freely available programming books and educational resources. Its primary purpose is to compile and organize programming knowledge accessible to everyone without cost. Core capabilities include categorizing resources by programming language, technology domain, and resource type. Key strengths are the extensive multilingual coverage, community-driven curation, and regular updates. Typical use cases include self-learning programming, academic reference, professional skill development, and educational institutions seeking free teaching materials. The project maintains high-quality standards through community contributions and verification.",
        "summary_zh": "free-programming-books 项目是一个收集和整理免费编程书籍与教育资源的综合性知识库。其主要目的是为全球学习者提供无需付费即可获取的编程学习材料。核心功能包括按编程语言、技术领域和资源类型进行分类整理，支持多语言内容收录。项目优势在于资源覆盖面广、社区驱动更新维护、内容质量经过验证。典型应用场景包括编程自学、学术参考、职业技能提升以及教育机构寻找免费教材。该项目通过社区协作确保资源的时效性和准确性，已成为编程",
        "summary_es": "The free-programming-books repository provides a comprehensive collection of freely available programming books and educational resources. Its primary purpose is to compile and organize programming knowledge accessible to everyone without cost. Core capabilities include categorizing resources by programming language, technology domain, and resource type. Key strengths are the extensive multilingual coverage, community-driven curation, and regular updates. Typical use cases include self-learning programming, academic reference, professional skill development, and educational institutions seeking free teaching materials. The project maintains high-quality standards through community contributions and verification."
      }
    ],
    "ar_vr_interaction": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "Genymobile/scrcpy",
        "source": "github",
        "name": "scrcpy",
        "url": "https://github.com/Genymobile/scrcpy",
        "tags": [
          "android",
          "c",
          "ffmpeg",
          "libav",
          "mirroring",
          "recording",
          "screen",
          "sdl2"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:52:25Z",
        "added_at": "2025-09-27",
        "summary": "Display and control your Android device",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09993912760112483,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "3d_reconstruction",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "multilingual_processing",
          "low_resource_language",
          "kg_construction",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "graph_augmented_reco",
          "model_compression",
          "compilation_optimization",
          "inference_acceleration",
          "privacy_computing",
          "adversarial_attack",
          "content_moderation",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_copyright",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "robot_dialogue_logic"
        ],
        "summary_en": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management.",
        "summary_zh": "scrcpy 是一款开源应用程序，用于通过 USB 或 TCP/IP 在计算机上显示和控制 Android 设备。其实时流式传输设备屏幕，延迟极低，并允许通过计算机键盘和鼠标进行完全控制。核心功能包括屏幕镜像、音频转发、设备控制和屏幕录制。优势在于高性能、无需 root 权限以及跨平台兼容性。典型用例包括应用程序开发测试、演示、游戏和远程设备管理。该项目采用 C 语言开发，基于 FFmpeg、libav 和 SDL2 库，在 GitHub 上拥有超过 12.9 万星标，显示出广泛的社区认可和使用。",
        "summary_es": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management."
      }
    ],
    "multimodal_temporal_fusion": [
      {
        "id": "FacebookAI/roberta-large",
        "source": "hf",
        "name": "roberta-large",
        "url": "https://huggingface.co/FacebookAI/roberta-large",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "onnx",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 13617741,
          "likes_total": 247,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains.",
        "summary_zh": "RoBERTa-large是由Facebook AI开发的优化版BERT预训练模型，基于论文arxiv:1907.11692。该模型移除了BERT的下句预测目标，采用更大批次和更多数据训练，在GLUE、RACE和SQuAD等基准测试中达到领先水平。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势在于相比BERT的性能提升和高效的预训练方法。典型应用场景涵盖问答系统、情感分析、自然语言推理等多个领域，支持PyTorch、TensorFlow和JAX等多种框架，采用MIT开源许可证。",
        "summary_es": "RoBERTa-large is a robustly optimized BERT pretraining approach developed by Facebook AI. It removes BERT's next-sentence prediction objective and trains with larger batches and more data. The model achieves state-of-the-art results on GLUE, RACE, and SQuAD benchmarks. Core capabilities include masked language modeling for text understanding and generation. Strengths include improved performance over BERT and efficient pretraining methodology. Typical use cases span question answering, sentiment analysis, and natural language inference tasks across various domains."
      },
      {
        "id": "distilbert/distilbert-base-uncased",
        "source": "hf",
        "name": "distilbert-base-uncased",
        "url": "https://huggingface.co/distilbert/distilbert-base-uncased",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "distilbert",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1910.01108",
          "license:apache-2.0",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11617607,
          "likes_total": 762,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX.",
        "summary_zh": "DistilBERT-base-uncased是BERT的蒸馏版本，专为高效自然语言处理而设计。它在保持BERT 97%性能的同时，体积缩小40%，速度提升60%。核心能力包括掩码语言建模和填空任务，用于文本理解。优势在于计算效率高、内存占用小，且准确率与大型模型相当。典型应用场景包括文本分类、情感分析、问答系统和实体识别等资源受限环境。该模型基于BookCorpus和英文维基百科训练，支持PyTorch、TensorFlow和JAX多种框架，适用于需要平衡性能与效率的NLP任务。",
        "summary_es": "DistilBERT-base-uncased is a distilled version of BERT designed for efficient natural language processing. It maintains 97% of BERT's performance while being 40% smaller and 60% faster. Core capabilities include masked language modeling for text understanding and fill-mask tasks. Strengths are computational efficiency, smaller memory footprint, and comparable accuracy to larger models. Typical use cases involve text classification, sentiment analysis, question answering, and entity recognition where resource constraints exist. It's trained on BookCorpus and English Wikipedia, supporting multiple frameworks including PyTorch, TensorFlow, and JAX."
      },
      {
        "id": "FacebookAI/roberta-base",
        "source": "hf",
        "name": "roberta-base",
        "url": "https://huggingface.co/FacebookAI/roberta-base",
        "tags": [
          "transformers",
          "pytorch",
          "tf",
          "jax",
          "rust",
          "safetensors",
          "roberta",
          "fill-mask",
          "exbert",
          "en",
          "dataset:bookcorpus",
          "dataset:wikipedia",
          "arxiv:1907.11692",
          "arxiv:1806.02847",
          "license:mit",
          "autotrain_compatible",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 11583115,
          "likes_total": 529,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding.",
        "summary_zh": "RoBERTa-base是由Facebook AI开发的基于Transformer的语言模型，通过改进训练方法对BERT进行优化。它移除了下一句预测任务，采用动态掩码技术，使用更大的批次和更多训练数据。核心能力包括掩码语言建模，用于文本理解和生成任务。主要优势是在GLUE和SQuAD等基准测试中表现优异，无需改变模型架构。典型应用场景包括文本分类、问答系统、情感分析等自然语言处理任务。该模型作为基础预训练模型，为下游应用提供强大的语言理解能力，支持多种NLP应用的开发部署。",
        "summary_es": "RoBERTa-base is a transformer-based language model developed by Facebook AI, optimized from BERT through improved training methodology. It removes next sentence prediction and uses dynamic masking with larger batches and more data. Core capabilities include masked language modeling for text understanding and generation. Strengths are superior performance on GLUE and SQuAD benchmarks without architectural changes. Typical use cases are text classification, question answering, and sentiment analysis. The model serves as a foundation for downstream NLP applications requiring robust language understanding."
      },
      {
        "id": "prajjwal1/bert-tiny",
        "source": "hf",
        "name": "bert-tiny",
        "url": "https://huggingface.co/prajjwal1/bert-tiny",
        "tags": [
          "transformers",
          "pytorch",
          "BERT",
          "MNLI",
          "NLI",
          "transformer",
          "pre-training",
          "en",
          "arxiv:1908.08962",
          "arxiv:2110.01518",
          "license:mit",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited.",
        "summary_zh": "BERT-tiny 是一种极简的 BERT 变体，专为模型压缩和效率研究而设计。该模型仅包含 440 万个参数，保持了 Transformer 架构但相比标准 BERT 模型大幅减小规模。其核心能力包括掩码语言建模和自然语言推理任务。主要优势在于推理速度快、内存需求低，适用于资源受限环境。典型应用场景包括研究模型蒸馏技术、在移动设备上进行测试、作为 Transformer 机制的教学演示工具，以及在计算资源有限情况下的轻量级文本分类任务。该模型基于 MIT 许可开源，主要用于学术研究和实验目的。",
        "summary_es": "BERT-tiny is a minimal BERT variant designed for research on model compression and efficiency. With only 4.4 million parameters, it maintains the transformer architecture but significantly reduces size compared to standard BERT models. Its core capabilities include masked language modeling and natural language inference tasks. Strengths include fast inference, low memory requirements, and suitability for resource-constrained environments. Typical use cases involve studying model distillation, testing on mobile devices, educational demonstrations of transformer mechanics, and lightweight text classification where computational resources are limited."
      },
      {
        "id": "facebook/contriever",
        "source": "hf",
        "name": "contriever",
        "url": "https://huggingface.co/facebook/contriever",
        "tags": [
          "transformers",
          "pytorch",
          "bert",
          "arxiv:2112.09118",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:39.365Z",
        "added_at": "2025-09-28",
        "summary": "Contriever是Facebook开发的稠密检索模型，无需标注的查询-文档对即可学习文本表示。该模型采用对比学习方法，使语义相似的文本在嵌入空间中更接近。基于BERT架构，通过自监督目标在大规模无标注语料上训练。主要优势包括有效的零样本检索能力和跨领域强性能，无需任务特定微调。典型应用场景包括文档检索、语义搜索和信息检索系统，特别适用于标注训练数据稀缺或不可得的情况。模型通过无监督方式学习通用文本表示，在各种检索任务中表现",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "tool_use",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Contriever is a dense retrieval model developed by Facebook that learns text representations without requiring labeled query-document pairs. It uses a contrastive learning approach where semantically similar texts are brought closer in embedding space. The model is based on BERT architecture and trained on large-scale unlabeled corpora through self-supervised objectives. Key strengths include effective zero-shot retrieval capabilities and strong performance across diverse domains without task-specific fine-tuning. Typical use cases include document retrieval, semantic search, and information retrieval systems where labeled training data is scarce or unavailable.",
        "summary_zh": "Contriever是Facebook开发的稠密检索模型，无需标注的查询-文档对即可学习文本表示。该模型采用对比学习方法，使语义相似的文本在嵌入空间中更接近。基于BERT架构，通过自监督目标在大规模无标注语料上训练。主要优势包括有效的零样本检索能力和跨领域强性能，无需任务特定微调。典型应用场景包括文档检索、语义搜索和信息检索系统，特别适用于标注训练数据稀缺或不可得的情况。模型通过无监督方式学习通用文本表示，在各种检索任务中表现",
        "summary_es": "Contriever is a dense retrieval model developed by Facebook that learns text representations without requiring labeled query-document pairs. It uses a contrastive learning approach where semantically similar texts are brought closer in embedding space. The model is based on BERT architecture and trained on large-scale unlabeled corpora through self-supervised objectives. Key strengths include effective zero-shot retrieval capabilities and strong performance across diverse domains without task-specific fine-tuning. Typical use cases include document retrieval, semantic search, and information retrieval systems where labeled training data is scarce or unavailable."
      },
      {
        "id": "Qwen/Qwen2.5-7B-Instruct",
        "source": "hf",
        "name": "Qwen2.5-7B-Instruct",
        "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
        "tags": [
          "transformers",
          "safetensors",
          "qwen2",
          "text-generation",
          "chat",
          "conversational",
          "en",
          "arxiv:2309.00071",
          "arxiv:2407.10671",
          "base_model:Qwen/Qwen2.5-7B",
          "base_model:finetune:Qwen/Qwen2.5-7B",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 7125867,
          "likes_total": 803,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "denoising",
          "remote_sensing_image_processing",
          "code_generation",
          "tool_use",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "general_recommendation",
          "vertical_recommendation",
          "graph_augmented_reco",
          "inference_acceleration",
          "adversarial_defense",
          "content_moderation",
          "ai_ethics_risk_assessment",
          "robot_environment_interaction",
          "molecular_generation",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access.",
        "summary_zh": "Qwen2.5-7B-Instruct是由Qwen开发的70亿参数指令调优语言模型，专为对话式AI应用设计。核心能力包括自然语言理解、文本生成以及跨多种任务的指令跟随。主要优势涵盖多语言支持（特别是英语）、高效的推理性能，以及与Transformers等流行框架的兼容性。典型应用场景涉及聊天机器人、虚拟助手、内容创作和基于文本的任务自动化。该模型基于Qwen2.5-7B基础架构构建，采用Apache 2.0开源许可，支持安全张量格式和文本生成推理部署，适用于需要平衡性能与资源消耗的智能对话系统。",
        "summary_es": "Qwen2.5-7B-Instruct is a 7-billion-parameter instruction-tuned language model developed by Qwen, designed for conversational AI applications. Its core capabilities include natural language understanding, text generation, and following user instructions across diverse tasks. Key strengths encompass multilingual support (particularly English), efficient inference performance, and compatibility with popular frameworks like Transformers. Typical use cases involve chatbots, virtual assistants, content creation, and text-based task automation. The model builds upon the Qwen2.5-7B base architecture and is licensed under Apache 2.0 for open access."
      },
      {
        "id": "Qwen/Qwen3-0.6B",
        "source": "hf",
        "name": "Qwen3-0.6B",
        "url": "https://huggingface.co/Qwen/Qwen3-0.6B",
        "tags": [
          "transformers",
          "safetensors",
          "qwen3",
          "text-generation",
          "conversational",
          "arxiv:2505.09388",
          "base_model:Qwen/Qwen3-0.6B-Base",
          "base_model:finetune:Qwen/Qwen3-0.6B-Base",
          "license:apache-2.0",
          "autotrain_compatible",
          "text-generation-inference",
          "endpoints_compatible",
          "region:us"
        ],
        "stats": {
          "downloads_total": 6417337,
          "likes_total": 649,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T16:24:38.433Z",
        "added_at": "2025-09-28",
        "summary": "Qwen3-0.6B是由Qwen开发的紧凑型0.6亿参数语言模型，专为高效文本生成任务设计。该模型基于Qwen3-0.6B-Base基础架构，优化用于资源受限环境的对话式AI应用。核心能力包括自然语言理解与生成，支持基于Transformer的推理架构。主要优势在于采用Apache 2.0开源许可，兼容微调和自动训练工具，并能与Hugging Face等流行框架集成。典型应用场景涵盖聊天机器人、文本补全等轻量级AI任务，特别适用于计算效率优先而非极致性能要求的部署环境。模型在Hugging Face平台已获得广泛下载，体现了其在实际应用中的实",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "tool_use",
          "multimodal_temporal_fusion"
        ],
        "summary_en": "Qwen3-0.6B is a compact 0.6 billion parameter language model developed by Qwen, designed for efficient text generation tasks. It serves as a conversational AI model built upon the Qwen3-0.6B-Base foundation, optimized for deployment in resource-constrained environments. Core capabilities include natural language understanding and generation, supporting transformer-based inference. Strengths include Apache 2.0 licensing for open use, compatibility with fine-tuning and auto-training tools, and integration with popular frameworks like Hugging Face. Typical use cases involve chatbots, text completion, and lightweight AI applications where computational efficiency is prioritized over maximum performance.",
        "summary_zh": "Qwen3-0.6B是由Qwen开发的紧凑型0.6亿参数语言模型，专为高效文本生成任务设计。该模型基于Qwen3-0.6B-Base基础架构，优化用于资源受限环境的对话式AI应用。核心能力包括自然语言理解与生成，支持基于Transformer的推理架构。主要优势在于采用Apache 2.0开源许可，兼容微调和自动训练工具，并能与Hugging Face等流行框架集成。典型应用场景涵盖聊天机器人、文本补全等轻量级AI任务，特别适用于计算效率优先而非极致性能要求的部署环境。模型在Hugging Face平台已获得广泛下载，体现了其在实际应用中的实",
        "summary_es": "Qwen3-0.6B is a compact 0.6 billion parameter language model developed by Qwen, designed for efficient text generation tasks. It serves as a conversational AI model built upon the Qwen3-0.6B-Base foundation, optimized for deployment in resource-constrained environments. Core capabilities include natural language understanding and generation, supporting transformer-based inference. Strengths include Apache 2.0 licensing for open use, compatibility with fine-tuning and auto-training tools, and integration with popular frameworks like Hugging Face. Typical use cases involve chatbots, text completion, and lightweight AI applications where computational efficiency is prioritized over maximum performance."
      }
    ],
    "robot_dialogue_logic": [
      {
        "id": "jinaai/jina-embeddings-v3",
        "source": "hf",
        "name": "jina-embeddings-v3",
        "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
        "tags": [
          "transformers",
          "pytorch",
          "onnx",
          "safetensors",
          "feature-extraction",
          "sentence-similarity",
          "mteb",
          "sentence-transformers",
          "custom_code",
          "multilingual",
          "af",
          "am",
          "ar",
          "as",
          "az",
          "be",
          "bg",
          "bn",
          "br",
          "bs",
          "ca",
          "cs",
          "cy",
          "da",
          "de",
          "el",
          "en",
          "eo",
          "es",
          "et",
          "eu",
          "fa",
          "fi",
          "fr",
          "fy",
          "ga",
          "gd",
          "gl",
          "gu",
          "ha",
          "he",
          "hi",
          "hr",
          "hu",
          "hy",
          "id",
          "is",
          "it",
          "ja",
          "jv",
          "ka",
          "kk",
          "km",
          "kn",
          "ko",
          "ku",
          "ky",
          "la",
          "lo",
          "lt",
          "lv",
          "mg",
          "mk",
          "ml",
          "mn",
          "mr",
          "ms",
          "my",
          "ne",
          "nl",
          "no",
          "om",
          "or",
          "pa",
          "pl",
          "ps",
          "pt",
          "ro",
          "ru",
          "sa",
          "sd",
          "si",
          "sk",
          "sl",
          "so",
          "sq",
          "sr",
          "su",
          "sv",
          "sw",
          "ta",
          "te",
          "th",
          "tl",
          "tr",
          "ug",
          "uk",
          "ur",
          "uz",
          "vi",
          "xh",
          "yi",
          "zh",
          "arxiv:2409.10173",
          "license:cc-by-nc-4.0",
          "model-index",
          "region:eu"
        ],
        "stats": {
          "downloads_total": 4528650,
          "likes_total": 1071,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T15:07:54.533Z",
        "added_at": "2025-09-27",
        "summary": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09998912636282772,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "text_to_image",
          "text_to_video",
          "3d_reconstruction",
          "nerf",
          "super_resolution",
          "denoising",
          "restoration",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "visual_grounding",
          "lightweight_visual_model",
          "llm_pretraining",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "lora_adapter",
          "multilingual_processing",
          "low_resource_language",
          "knowledge_editing",
          "nlp_data_synthesis",
          "nlp_data_distillation",
          "dialogue_system_optimization",
          "nlp_bias_mitigation",
          "image_text_alignment",
          "multimodal_understanding_generation",
          "asr",
          "slu",
          "speaker_separation",
          "noise_separation",
          "full_duplex_dialogue",
          "avsr",
          "multimodal_dialogue_system",
          "lightweight_multimodal_model",
          "kg_construction",
          "kg_reasoning",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "ltr",
          "neural_retrieval",
          "graph_augmented_reco",
          "model_compression",
          "model_quantization",
          "model_distillation",
          "compilation_optimization",
          "inference_acceleration",
          "federated_learning",
          "privacy_computing",
          "adversarial_attack",
          "adversarial_defense",
          "red_teaming",
          "content_moderation",
          "auto_evaluation_models",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_anonymization",
          "training_data_copyright",
          "model_monitoring",
          "model_iterative_update",
          "fluid_simulation",
          "material_design",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_motion_planning",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "radar_understanding",
          "lidar_understanding",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "multimodal_temporal_fusion",
          "robot_dialogue_logic"
        ],
        "summary_en": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required.",
        "summary_zh": "Jina Embeddings V3 是一款多语言文本嵌入模型，旨在将100多种语言的文本转换为数值表示。其核心能力在于为不同语言输入生成高质量嵌入向量，有效捕捉语义信息。主要优势包括原生多语言支持无需翻译预处理、跨语言统一向量维度、以及在检索和分类任务中的优异表现。典型应用场景涵盖跨语言文档检索、多语言语义搜索、内容推荐系统和文本分类等领域，特别适用于需要语言无关处理的自然语言处理任务。该模型通过统一架构处理多种语言，为全",
        "summary_es": "Jina Embeddings V3 is a multilingual text embedding model designed to convert text into numerical representations across 100+ languages. Its core capability lies in generating high-quality embeddings that capture semantic meaning for diverse linguistic inputs. Key strengths include native multilingual support without translation overhead, uniform vector dimensions across languages, and strong performance on retrieval and classification tasks. Typical use cases span cross-lingual document retrieval, multilingual semantic search, content recommendation systems, and text classification applications where language-agnostic processing is required."
      },
      {
        "id": "Genymobile/scrcpy",
        "source": "github",
        "name": "scrcpy",
        "url": "https://github.com/Genymobile/scrcpy",
        "tags": [
          "android",
          "c",
          "ffmpeg",
          "libav",
          "mirroring",
          "recording",
          "screen",
          "sdl2"
        ],
        "stats": {
          "downloads_total": 0,
          "likes_total": 0,
          "downloads_7d": 0,
          "likes_7d": 0
        },
        "updated_at": "2025-09-27T14:52:25Z",
        "added_at": "2025-09-27",
        "summary": "Display and control your Android device",
        "flags": {
          "pinned": false,
          "hidden": false
        },
        "score_model": 0.09993912760112483,
        "task_keys": [
          "image_classification",
          "object_detection",
          "semantic_segmentation",
          "instance_segmentation",
          "panoptic_segmentation",
          "3d_reconstruction",
          "medical_image_processing",
          "remote_sensing_image_processing",
          "instruction_tuning",
          "code_generation",
          "structured_reasoning",
          "multilingual_processing",
          "low_resource_language",
          "kg_construction",
          "general_recommendation",
          "vertical_recommendation",
          "vector_retrieval",
          "vector_db_optimization",
          "metric_learning",
          "contrastive_learning",
          "graph_augmented_reco",
          "model_compression",
          "compilation_optimization",
          "inference_acceleration",
          "privacy_computing",
          "adversarial_attack",
          "content_moderation",
          "edge_hw_sw_co_design",
          "ai_ethics_risk_assessment",
          "training_data_copyright",
          "drug_molecule_prediction",
          "robotic_vision",
          "robot_environment_interaction",
          "molecular_generation",
          "bioinformatics_analysis",
          "time_series_forecasting",
          "time_series_anomaly_detection",
          "low_resource_medical_ai",
          "low_resource_voice_assistant",
          "ar_vr_interaction",
          "robot_dialogue_logic"
        ],
        "summary_en": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management.",
        "summary_zh": "scrcpy 是一款开源应用程序，用于通过 USB 或 TCP/IP 在计算机上显示和控制 Android 设备。其实时流式传输设备屏幕，延迟极低，并允许通过计算机键盘和鼠标进行完全控制。核心功能包括屏幕镜像、音频转发、设备控制和屏幕录制。优势在于高性能、无需 root 权限以及跨平台兼容性。典型用例包括应用程序开发测试、演示、游戏和远程设备管理。该项目采用 C 语言开发，基于 FFmpeg、libav 和 SDL2 库，在 GitHub 上拥有超过 12.9 万星标，显示出广泛的社区认可和使用。",
        "summary_es": "scrcpy is an open-source application for displaying and controlling Android devices from a computer via USB or TCP/IP. It streams the device screen in real-time with low latency and allows full control through the computer's keyboard and mouse. Core capabilities include screen mirroring, audio forwarding, device control, and screen recording. Strengths include high performance, no root requirement, and cross-platform compatibility. Typical use cases include app development testing, presentations, gaming, and remote device management."
      }
    ]
  },
  "global_github": [
    {
      "id": "facebook/react",
      "source": "github",
      "name": "react",
      "url": "https://github.com/facebook/react",
      "tags": [
        "declarative",
        "frontend",
        "javascript",
        "library",
        "react",
        "ui"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:24:11Z",
      "summary": "The library for web and native user interfaces.",
      "score_model": 0.0999880681115978
    },
    {
      "id": "public-apis/public-apis",
      "source": "github",
      "name": "public-apis",
      "url": "https://github.com/public-apis/public-apis",
      "tags": [
        "api",
        "apis",
        "dataset",
        "development",
        "free",
        "list",
        "lists",
        "open-source",
        "public",
        "public-api",
        "public-apis",
        "resources",
        "software"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:23:57Z",
      "summary": "A collective list of free APIs",
      "score_model": 0.09998752805404643
    },
    {
      "id": "flutter/flutter",
      "source": "github",
      "name": "flutter",
      "url": "https://github.com/flutter/flutter",
      "tags": [
        "android",
        "app-framework",
        "cross-platform",
        "dart",
        "dart-platform",
        "desktop",
        "flutter",
        "flutter-package",
        "fuchsia",
        "ios",
        "linux-desktop",
        "macos",
        "material-design",
        "mobile",
        "mobile-development",
        "skia",
        "web",
        "web-framework",
        "windows"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:23:54Z",
      "summary": "Flutter makes it easy and fast to build beautiful apps for mobile and beyond",
      "score_model": 0.09998741232780778
    },
    {
      "id": "EbookFoundation/free-programming-books",
      "source": "github",
      "name": "free-programming-books",
      "url": "https://github.com/EbookFoundation/free-programming-books",
      "tags": [
        "books",
        "education",
        "hacktoberfest",
        "list",
        "resource"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:23:45Z",
      "summary": ":books: Freely available programming books",
      "score_model": 0.09998706514989548
    },
    {
      "id": "trimstray/the-book-of-secret-knowledge",
      "source": "github",
      "name": "the-book-of-secret-knowledge",
      "url": "https://github.com/trimstray/the-book-of-secret-knowledge",
      "tags": [
        "awesome",
        "awesome-list",
        "bsd",
        "cheatsheets",
        "devops",
        "guidelines",
        "hacking",
        "hacks",
        "howtos",
        "linux",
        "lists",
        "manuals",
        "one-liners",
        "pentesters",
        "resources",
        "search-engines",
        "security",
        "security-researchers",
        "sysops"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:23:12Z",
      "summary": "A collection of inspiring lists, manuals, cheatsheets, blogs, hacks, one-liners, cli/web tools and more.",
      "score_model": 0.09998579217453059
    },
    {
      "id": "freeCodeCamp/freeCodeCamp",
      "source": "github",
      "name": "freeCodeCamp",
      "url": "https://github.com/freeCodeCamp/freeCodeCamp",
      "tags": [
        "careers",
        "certification",
        "community",
        "curriculum",
        "d3",
        "education",
        "freecodecamp",
        "javascript",
        "learn-to-code",
        "math",
        "nodejs",
        "nonprofits",
        "programming",
        "react",
        "teachers"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:22:59Z",
      "summary": "freeCodeCamp.org's open-source codebase and curriculum. Learn math, programming, and computer science for free.",
      "score_model": 0.09998529070383666
    },
    {
      "id": "sindresorhus/awesome",
      "source": "github",
      "name": "awesome",
      "url": "https://github.com/sindresorhus/awesome",
      "tags": [
        "awesome",
        "awesome-list",
        "lists",
        "resources",
        "unicorns"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:22:55Z",
      "summary": "😎 Awesome lists about all kinds of interesting topics",
      "score_model": 0.09998513640566759
    },
    {
      "id": "jwasham/coding-interview-university",
      "source": "github",
      "name": "coding-interview-university",
      "url": "https://github.com/jwasham/coding-interview-university",
      "tags": [
        "algorithm",
        "algorithms",
        "coding-interview",
        "coding-interviews",
        "computer-science",
        "data-structures",
        "interview",
        "interview-prep",
        "interview-preparation",
        "programming-interviews",
        "software-engineering",
        "study-plan"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:22:54Z",
      "summary": "A complete computer science study plan to become a software engineer.",
      "score_model": 0.09998509783116252
    },
    {
      "id": "yangshun/tech-interview-handbook",
      "source": "github",
      "name": "tech-interview-handbook",
      "url": "https://github.com/yangshun/tech-interview-handbook",
      "tags": [
        "algorithm",
        "algorithm-interview",
        "algorithm-interview-questions",
        "algorithms",
        "behavioral-interviews",
        "coding-interviews",
        "interview-practice",
        "interview-preparation",
        "interview-questions",
        "system-design"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:22:49Z",
      "summary": "💯 Curated coding interview preparation materials for busy software engineers",
      "score_model": 0.09998490495886045
    },
    {
      "id": "ossu/computer-science",
      "source": "github",
      "name": "computer-science",
      "url": "https://github.com/ossu/computer-science",
      "tags": [
        "awesome-list",
        "computer-science",
        "courses",
        "curriculum"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:22:47Z",
      "summary": "🎓 Path to a free self-taught education in Computer Science!",
      "score_model": 0.0999848278100438
    },
    {
      "id": "langflow-ai/langflow",
      "source": "github",
      "name": "langflow",
      "url": "https://github.com/langflow-ai/langflow",
      "tags": [
        "agents",
        "chatgpt",
        "generative-ai",
        "large-language-models",
        "multiagent",
        "react-flow"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:22:28Z",
      "summary": "Langflow is a powerful tool for building and deploying AI-powered agents and workflows.",
      "score_model": 0.09998409489925454
    },
    {
      "id": "massgravel/Microsoft-Activation-Scripts",
      "source": "github",
      "name": "Microsoft-Activation-Scripts",
      "url": "https://github.com/massgravel/Microsoft-Activation-Scripts",
      "tags": [
        "activator",
        "hwid",
        "kms",
        "kms38",
        "massgrave",
        "massgravel",
        "microsoft",
        "microsoft365",
        "office",
        "office365",
        "ohook",
        "powershell",
        "tsforge",
        "windows",
        "windows-10",
        "windows-11"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:22:25Z",
      "summary": "Open-source Windows and Office activator featuring HWID, Ohook, TSforge, KMS38, and Online KMS activation methods, along with advanced troubleshooting.",
      "score_model": 0.09998397917698947
    },
    {
      "id": "avelino/awesome-go",
      "source": "github",
      "name": "awesome-go",
      "url": "https://github.com/avelino/awesome-go",
      "tags": [
        "awesome",
        "awesome-list",
        "go",
        "golang",
        "golang-library",
        "hacktoberfest"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:22:01Z",
      "summary": "A curated list of awesome Go frameworks, libraries and software",
      "score_model": 0.09998305340369047
    },
    {
      "id": "microsoft/PowerToys",
      "source": "github",
      "name": "PowerToys",
      "url": "https://github.com/microsoft/PowerToys",
      "tags": [
        "color-picker",
        "command-palette",
        "desktop",
        "fancyzones",
        "keyboard-manager",
        "microsoft-powertoys",
        "powerrename",
        "powertoys",
        "windows",
        "windows-10",
        "windows-11"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:19:12Z",
      "summary": "Microsoft PowerToys is a collection of utilities that help you customize Windows and streamline everyday tasks",
      "score_model": 0.09997653465940601
    },
    {
      "id": "TheAlgorithms/Python",
      "source": "github",
      "name": "Python",
      "url": "https://github.com/TheAlgorithms/Python",
      "tags": [
        "algorithm",
        "algorithm-competitions",
        "algorithms-implemented",
        "algos",
        "community-driven",
        "education",
        "hacktoberfest",
        "interview",
        "learn",
        "practice",
        "python",
        "searches",
        "sorting-algorithms",
        "sorts"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:18:42Z",
      "summary": "All Algorithms implemented in Python",
      "score_model": 0.09997537753028456
    },
    {
      "id": "f/awesome-chatgpt-prompts",
      "source": "github",
      "name": "awesome-chatgpt-prompts",
      "url": "https://github.com/f/awesome-chatgpt-prompts",
      "tags": [
        "bots",
        "chatbot",
        "chatgpt",
        "chatgpt-api",
        "language"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:18:34Z",
      "summary": "This repo includes ChatGPT prompt curation to use ChatGPT and other LLM tools better.",
      "score_model": 0.0999750689647807
    },
    {
      "id": "yt-dlp/yt-dlp",
      "source": "github",
      "name": "yt-dlp",
      "url": "https://github.com/yt-dlp/yt-dlp",
      "tags": [
        "cli",
        "downloader",
        "python",
        "sponsorblock",
        "youtube-dl",
        "youtube-downloader",
        "yt-dlp"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:17:34Z",
      "summary": "A feature-rich command-line audio/video downloader",
      "score_model": 0.09997275475385814
    },
    {
      "id": "ollama/ollama",
      "source": "github",
      "name": "ollama",
      "url": "https://github.com/ollama/ollama",
      "tags": [
        "deepseek",
        "gemma",
        "gemma3",
        "gemma3n",
        "go",
        "golang",
        "gpt-oss",
        "llama",
        "llama2",
        "llama3",
        "llava",
        "llm",
        "llms",
        "mistral",
        "ollama",
        "phi4",
        "qwen"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:14:37Z",
      "summary": "Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.",
      "score_model": 0.09996592814373871
    },
    {
      "id": "AUTOMATIC1111/stable-diffusion-webui",
      "source": "github",
      "name": "stable-diffusion-webui",
      "url": "https://github.com/AUTOMATIC1111/stable-diffusion-webui",
      "tags": [
        "ai",
        "ai-art",
        "deep-learning",
        "diffusion",
        "gradio",
        "image-generation",
        "image2image",
        "img2img",
        "pytorch",
        "stable-diffusion",
        "text2image",
        "torch",
        "txt2img",
        "unstable",
        "upscaling",
        "web"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:13:57Z",
      "summary": "Stable Diffusion web UI",
      "score_model": 0.09996438547156578
    },
    {
      "id": "tensorflow/tensorflow",
      "source": "github",
      "name": "tensorflow",
      "url": "https://github.com/tensorflow/tensorflow",
      "tags": [
        "deep-learning",
        "deep-neural-networks",
        "distributed",
        "machine-learning",
        "ml",
        "neural-network",
        "python",
        "tensorflow"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:13:52Z",
      "summary": "An Open Source Machine Learning Framework for Everyone",
      "score_model": 0.09996419263921807
    },
    {
      "id": "huggingface/transformers",
      "source": "github",
      "name": "transformers",
      "url": "https://github.com/huggingface/transformers",
      "tags": [
        "audio",
        "deep-learning",
        "deepseek",
        "gemma",
        "glm",
        "hacktoberfest",
        "llm",
        "machine-learning",
        "model-hub",
        "natural-language-processing",
        "nlp",
        "pretrained-models",
        "python",
        "pytorch",
        "pytorch-transformers",
        "qwen",
        "speech-recognition",
        "transformer",
        "vlm"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:13:08Z",
      "summary": "🤗 Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training. ",
      "score_model": 0.09996249573059768
    },
    {
      "id": "github/gitignore",
      "source": "github",
      "name": "gitignore",
      "url": "https://github.com/github/gitignore",
      "tags": [
        "git",
        "gitignore"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:11:14Z",
      "summary": "A collection of useful .gitignore templates",
      "score_model": 0.0999580993286237
    },
    {
      "id": "golang/go",
      "source": "github",
      "name": "go",
      "url": "https://github.com/golang/go",
      "tags": [
        "go",
        "golang",
        "language",
        "programming-language"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:08:37Z",
      "summary": "The Go programming language",
      "score_model": 0.09995204495118498
    },
    {
      "id": "kubernetes/kubernetes",
      "source": "github",
      "name": "kubernetes",
      "url": "https://github.com/kubernetes/kubernetes",
      "tags": [
        "cncf",
        "containers",
        "go",
        "kubernetes"
      ],
      "stats": {
        "downloads_total": 0,
        "likes_total": 0,
        "downloads_7d": 0,
        "likes_7d": 0
      },
      "updated_at": "2025-09-27T16:07:27Z",
      "summary": "Production-Grade Container Scheduling and Management",
      "score_model": 0.09994934566543223
    }
  ]
}