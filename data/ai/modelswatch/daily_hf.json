{
  "version": 1,
  "updated_at": "2025-09-20T15:37:44.873Z",
  "items": [
    {
      "id": "Datadog/Toto-Open-Base-1.0",
      "source": "hf",
      "name": "Toto-Open-Base-1.0",
      "url": "https://huggingface.co/Datadog/Toto-Open-Base-1.0",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "safetensors",
        "time-series-forecasting",
        "foundation models",
        "pretrained models",
        "time series foundation models",
        "time series",
        "time-series",
        "timeseries",
        "forecasting",
        "observability",
        "dataset:Salesforce/GiftEvalPretrain",
        "dataset:autogluon/chronos_datasets",
        "arxiv:2505.14766",
        "license:apache-2.0",
        "endpoints_compatible",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 5156315,
        "likes_total": 109
      },
      "score": 10367.130000000001,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Toto-Open-Base-1.0 是一个基于 Transformer 架构的开源时间序列预测基础模型，适用于多种时序数据分析任务。该模型采用预训练方式，能够有效捕捉时间序列中的长期依赖关系和复杂模式。其亮点在于支持多领域时序数据的统一建模，包括但不限于金融、气象和工业监控等场景。用户可基于该模型进行微调，以适应特定的预测需求，提升时序预测的准确性和泛化能力。",
      "updated_at": "2025-09-20T15:32:29.126Z",
      "summary_en": "Toto-Open-Base-1.0 is a pretrained foundation model for time-series forecasting, built on the Transformers architecture. It excels in handling diverse time-series data, offering robust performance for tasks like demand prediction, anomaly detection, and resource planning. Its strengths include adaptability to various domains and efficient fine-tuning for specific forecasting needs. This model is ideal for researchers and practitioners seeking a scalable, open-source solution for accurate and generalizable time-series analysis.",
      "summary_zh": "Toto-Open-Base-1.0 是一个基于 Transformer 架构的开源时间序列预测基础模型，适用于多种时序数据分析任务。该模型采用预训练方式，能够有效捕捉时间序列中的长期依赖关系和复杂模式。其亮点在于支持多领域时序数据的统一建模，包括但不限于金融、气象和工业监控等场景。用户可基于该模型进行微调，以适应特定的预测需求，提升时序预测的准确性和泛化能力。",
      "summary_es": "Toto-Open-Base-1.0 es un modelo base preentrenado para pronóstico de series temporales. Diseñado para capturar patrones complejos en datos secuenciales, es ideal para aplicaciones en finanzas, IoT y análisis operacional. Su arquitectura basada en transformers permite adaptaciones eficientes a dominios específicos con fine-tuning mínimo.",
      "reason_label": "notable",
      "reason_text": "值得关注的项目：Toto-Open-Base-1.0"
    },
    {
      "id": "thuml/sundial-base-128m",
      "source": "hf",
      "name": "sundial-base-128m",
      "url": "https://huggingface.co/thuml/sundial-base-128m",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "safetensors",
        "sundial",
        "time series",
        "time-series",
        "forecasting",
        "foundation models",
        "pretrained models",
        "generative models",
        "time series foundation models",
        "time-series-forecasting",
        "custom_code",
        "dataset:thuml/UTSD",
        "dataset:Salesforce/lotsa_data",
        "dataset:autogluon/chronos_datasets",
        "arxiv:2502.00816",
        "arxiv:2403.07815",
        "license:apache-2.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4856549,
        "likes_total": 44
      },
      "score": 9735.098,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Sundial-base-128m 是一个基于 Transformer 架构的时间序列预测基础模型，参数量为 1.28 亿。该模型通过大规模时间序列数据预训练，具备较强的时序特征提取和生成能力。其核心亮点在于能够适应多种时间序列任务，包括单变量和多变量预测，同时支持零样本和少样本推理。适用于金融、气象、能源等领域的时序数据分析与预测场景。",
      "updated_at": "2025-09-20T15:32:29.126Z",
      "summary_en": "Sundial-base-128m is a pretrained foundation model for time series forecasting and generation. It supports a wide range of applications, including demand prediction, anomaly detection, and synthetic data generation. Its strengths lie in strong generalization across diverse time series domains and efficient fine-tuning for specific tasks. The model is applicable to both univariate and multivariate forecasting scenarios, making it a versatile tool for researchers and practitioners.",
      "summary_zh": "Sundial-base-128m 是一个基于 Transformer 架构的时间序列预测基础模型，参数量为 1.28 亿。该模型通过大规模时间序列数据预训练，具备较强的时序特征提取和生成能力。其核心亮点在于能够适应多种时间序列任务，包括单变量和多变量预测，同时支持零样本和少样本推理。适用于金融、气象、能源等领域的时序数据分析与预测场景。",
      "summary_es": "Sundial-base-128m es un modelo generativo preentrenado para series temporales. Destaca por su capacidad de predicción en múltiples dominios, usando arquitecturas eficientes. Es ideal para aplicaciones de forecasting en energía, finanzas o clima. Su diseño ligero facilita el despliegue en entornos con recursos limitados.",
      "reason_label": "notable",
      "reason_text": "值得关注的项目：sundial-base-128m"
    },
    {
      "id": "jinaai/jina-embeddings-v3",
      "source": "hf",
      "name": "jina-embeddings-v3",
      "url": "https://huggingface.co/jinaai/jina-embeddings-v3",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "transformers",
        "pytorch",
        "onnx",
        "safetensors",
        "feature-extraction",
        "sentence-similarity",
        "mteb",
        "sentence-transformers",
        "custom_code",
        "multilingual",
        "af",
        "am",
        "ar",
        "as",
        "az",
        "be",
        "bg",
        "bn",
        "br",
        "bs",
        "ca",
        "cs",
        "cy",
        "da",
        "de",
        "el",
        "en",
        "eo",
        "es",
        "et",
        "eu",
        "fa",
        "fi",
        "fr",
        "fy",
        "ga",
        "gd",
        "gl",
        "gu",
        "ha",
        "he",
        "hi",
        "hr",
        "hu",
        "hy",
        "id",
        "is",
        "it",
        "ja",
        "jv",
        "ka",
        "kk",
        "km",
        "kn",
        "ko",
        "ku",
        "ky",
        "la",
        "lo",
        "lt",
        "lv",
        "mg",
        "mk",
        "ml",
        "mn",
        "mr",
        "ms",
        "my",
        "ne",
        "nl",
        "no",
        "om",
        "or",
        "pa",
        "pl",
        "ps",
        "pt",
        "ro",
        "ru",
        "sa",
        "sd",
        "si",
        "sk",
        "sl",
        "so",
        "sq",
        "sr",
        "su",
        "sv",
        "sw",
        "ta",
        "te",
        "th",
        "tl",
        "tr",
        "ug",
        "uk",
        "ur",
        "uz",
        "vi",
        "xh",
        "yi",
        "zh",
        "arxiv:2409.10173",
        "license:cc-by-nc-4.0",
        "model-index",
        "region:eu"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4325612,
        "likes_total": 1068
      },
      "score": 9185.224,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Jina Embeddings V3 是一个多语言文本嵌入模型，支持生成 8192 维的高质量向量表示。该模型基于 Transformer 架构，适用于特征提取、句子相似度计算等任务，在 MTEB 基准测试中表现优异。其亮点在于支持超长上下文（最大 8192 个 token）和跨语言语义理解，适用于多语言搜索、文档检索和语义匹配等场景。模型提供 PyTorch、ONNX 和 SafeTensors 格式，便于集成到现有系统中。",
      "updated_at": "2025-09-20T15:32:29.126Z",
      "summary_en": "Jina Embeddings v3 is a multilingual text embedding model designed for high-performance feature extraction and semantic similarity tasks. It supports multiple languages and is optimized for efficient inference via ONNX and PyTorch. The model excels in benchmarks like MTEB, making it suitable for applications such as search, clustering, and retrieval-augmented generation. Its open-source nature and integration with popular frameworks ensure broad applicability in both research and production environments.",
      "summary_zh": "Jina Embeddings V3 是一个多语言文本嵌入模型，支持生成 8192 维的高质量向量表示。该模型基于 Transformer 架构，适用于特征提取、句子相似度计算等任务，在 MTEB 基准测试中表现优异。其亮点在于支持超长上下文（最大 8192 个 token）和跨语言语义理解，适用于多语言搜索、文档检索和语义匹配等场景。模型提供 PyTorch、ONNX 和 SafeTensors 格式，便于集成到现有系统中。",
      "summary_es": "Jina Embeddings V3 es un modelo de embeddings multilingüe optimizado para similitud semántica y recuperación de información. Destaca por su alta eficiencia en tareas de búsqueda y clustering de texto, con soporte para 30 idiomas. Su arquitectura permite escalar a dominios técnicos y legales. Ideal para sistemas de recomendación y aplicaciones de IA conversacional.",
      "reason_label": "notable",
      "reason_text": "值得关注的项目：jina-embeddings-v3"
    },
    {
      "id": "Salesforce/moirai-2.0-R-small",
      "source": "hf",
      "name": "moirai-2.0-R-small",
      "url": "https://huggingface.co/Salesforce/moirai-2.0-R-small",
      "license": "N/A",
      "lang": "N/A",
      "tags": [
        "safetensors",
        "time series",
        "forecasting",
        "pretrained models",
        "foundation models",
        "time series foundation models",
        "time-series",
        "time-series-forecasting",
        "arxiv:2403.07815",
        "arxiv:2402.02592",
        "license:cc-by-nc-4.0",
        "region:us"
      ],
      "categories": {
        "capabilities": [],
        "scenes": [],
        "lifecycle": []
      },
      "stats": {
        "downloads_total": 4272176,
        "likes_total": 20
      },
      "score": 8554.352,
      "timeline": {
        "t": [],
        "stars": [],
        "downloads": []
      },
      "summary": "Moirai-2.0-R-small 是 Salesforce 开发的一个小型时间序列预测基础模型，基于 Transformer 架构进行预训练。该模型支持多变量预测任务，能够处理多种时间序列数据，包括经济、天气和能源等领域的时序数据。其亮点在于统一的建模框架，能够灵活适应不同频率和长度的输入序列，同时具备零样本和少样本预测能力。适用于需要快速部署且资源受限的场景，如实时监控和短期预测任务。",
      "updated_at": "2025-09-20T15:32:29.126Z",
      "task_keys": [
        "time_series_forecasting"
      ],
      "summary_en": "Moirai-2.0-R-small is a compact foundation model for time series forecasting, pretrained on diverse datasets. It supports zero-shot and few-shot predictions across various domains, including energy, weather, and economics. Its strengths lie in efficient parameter usage and strong generalization without task-specific fine-tuning. Ideal for researchers and practitioners seeking scalable, adaptable forecasting solutions with minimal data requirements.",
      "summary_zh": "Moirai-2.0-R-small 是 Salesforce 开发的一个小型时间序列预测基础模型，基于 Transformer 架构进行预训练。该模型支持多变量预测任务，能够处理多种时间序列数据，包括经济、天气和能源等领域的时序数据。其亮点在于统一的建模框架，能够灵活适应不同频率和长度的输入序列，同时具备零样本和少样本预测能力。适用于需要快速部署且资源受限的场景，如实时监控和短期预测任务。",
      "summary_es": "Moirai-2.0-R-small es un modelo de base para series temporales, preentrenado y de código abierto. Destaca por su capacidad de predicción en múltiples dominios y escalas temporales. Su diseño modular y eficiencia lo hacen adecuado para aplicaciones en finanzas, energía y logística. Incluye soporte para SafeTensors y está respaldado por investigación publicada en arXiv.",
      "reason_label": "notable",
      "reason_text": "值得关注的项目：moirai-2.0-R-small"
    }
  ]
}