---
title: RAG 会被淘汰吗？从“大上下文”到 GraphRAG、检索感知训练与 KBLaM 的 2025 路线图
description: RAG 不会被淘汰，被淘汰的是“天真向量检索 + 生搬硬塞上下文”。本文给出 2025 年 RAG 五件套、评测维度、选型矩阵与 KBLaM 落地范式。
date: 2025-09-02
cover: assets/blog/rag-hero-zh.v5.svg
---

导读：过去一年，“长上下文模型会让 RAG 过时吗？”几乎成了走廊里最常见的讨论。本文不只给答案，还试着讲清楚来龙去脉：为什么很多团队觉得 RAG 不稳、为什么“更大的上下文”仍换不来可信答案，以及 2025 年一套从数据到工程都能落地的方案。

## 摘要（TL;DR）

RAG 不会被淘汰，被淘汰的是**“天真向量检索 + 生搬硬塞上下文”**那一代玩法。2025 年可用的 RAG 栈呈现出“五件套”形态：**结构化检索（GraphRAG）＋ 检索感知训练（Self-RAG / RAFT / RA-DIT）＋ 代理式编排（Agentic RAG + MCP）＋ 新鲜度与流式索引 ＋（必要时）参数级知识更新（微调/模型编辑）**。本文给出工程化评估维度、选型矩阵与落地清单，并结合 **KBLaM** 框架说明如何在高合规/低联网/数据受限环境中做**可信、可控、可解释**的检索增强智能系统。

## 1. 为什么“更大的上下文”不等于 RAG 终点

一个形象的比喻：把所有资料都塞进提示词，就像给模型背了个更大的背包；而检索则像一张会自我更新、会指路的地图。背包再大，也不等于知道去哪、凭什么到达。

长上下文（million-token 级）确实**降低**了检索频率，但并不解决以下刚需：

- **成本与可扩展性**：把大量材料塞进上下文，推理成本随 token 线性甚至超线性增长；海量文档下**检索→精挑证据**仍更经济。
- **时效性**：参数内知识很难做到**分钟级**更新；RAG 的外部知识库可以**实时索引/替换**。
- **可审计与合规**：RAG 的证据链（来源、版本、时间）可落库留痕，满足**强监管行业**（如核/水利/能源）的审计要求。
- **隐私与分域隔离**：在多域、多级密级的企业环境，**把敏感知识外化**到可控的检索与权限体系，比把一切写进参数安全得多。
- **稳健性**：检索—重排—抽取式生成的链路更容易做**单点替换和回归测试**；完全依赖长上下文的“直觉式”生成更难定位问题。

> **小结**：**更大的上下文 ≠ 不再需要检索**；真正被替代的是“把所有 PDF 切块向量化然后一股脑拼接”的老 RAG。

> 小剧场：某能源企业将 3 万页标准作业指导书直接塞入长上下文后，P95 成本飙升且答案不稳定；改为“检索→证据包→抽取式生成”后，时延与费用双降，且答案可复验。

## 2. 天真 RAG 的典型失败模式（你应立刻避免）

如果你觉得 RAG 难用，通常不是“检索错了”，而是“方法不对”。以下陷阱高度常见：

1. **只用向量相似度，忽略结构**：表格/代码/时序数据的语义在纯向量空间里常被冲淡。
2. **粗暴 chunking**：句断/页断导致**证据跨块**；简单 k-NN 检索召回错误证段。
3. **上下文堆砌**：把 20 段检索结果全塞给模型，**引入噪声**、干扰注意力。
4. **缺少重排与类型化检索**：PDF、表格、图谱、代码、FAQ 应分别使用**专门检索器**与**交叉编码重排**。
5. **无新鲜度策略**：法条、规程、行情、舆情类知识**快速过期**，需要**增量抓取 + TTL + 版本切换**。
6. **不做可审计**：缺少“回答→证据片段→原始来源”的**可追溯链路**与离线复验。

## 3. 2025 RAG 五件套

把 RAG 做稳，其实是把“找知识、打包证据、表达答案”几件事拆开做对。2025 年的成熟做法，基本收敛为这“五件套”。

### 3.1 结构化检索（GraphRAG）

- **核心思想**：文本库 + 知识图谱**联合索引**。面向实体/关系/事件/流程，把结构化“骨架”与非结构化“血肉”**联合检索**。
- **什么时候用**：法规条文、工艺流程、设备台账、复杂因果/依赖链；当你需要**跨文档多跳推理**时，GraphRAG 成本更低、答案更稳。
- **工程要点**：
  - 多索引：BM25（强精确匹配）＋ Dense（召回覆盖）＋ Cross-Encoder（最终重排）。
  - 融合策略：**先图后文**（按关系/路径找节点 → 拉取相关原文证据）或**先文后图**（从文档抽实体→在图中补边）。
  - 证据打包：把**路径 + 片段**作为可读“证据包”喂给模型，避免生硬地拼 10 段文本。

例子：法规问答中，先在图谱里找到“条款→术语→适用范围”的路径，再拉取对应段落作为证据包，比直接拼接 10 段文本更稳更省。

### 3.2 检索感知训练（Self-RAG / RA-DIT / RAFT）

- **目标**：让模型“**知道何时检索、检什么**”，而非被动吃上下文。
- **实践**：
  - Self-RAG：生成中**自评与再检索**的循环策略。
  - RA-DIT / RAFT：在微调时引入**检索信号**与**对比/偏好损失**，把“用/不用检索”的决策学进参数。
- **收益**：减少无意义检索与上下文污染，**提升一致性与可解释性**。

类比：教模型“什么时候打开词典、该翻哪一页”，而不是永远把整本词典塞进包里。

### 3.3 Agentic RAG + MCP（工具编排）

- **为什么**：企业问答 ≠ 单轮检索。需要**多步计划（Plan-Execute）**、调用工具（SQL/搜索/代码/仿真）、回填证据。
- **怎么做**：
  - 用 MCP 等统一协议把工具抽象成“**可声明能力**”，由 Agent 决策调用顺序。
  - 加**停止条件/安全阈**（最多检索 N 次、最大费用、最大时延）与**缓存策略**（按意图/证据哈希）。

场景：根因分析需要“查日志→跑 SQL→比对工况→复核规程”，Agent 负责下发步骤与安全阈，RAG 负责提供证据与解释。

### 3.4 新鲜度与流式索引

- **CDC/增量抓取**：对新文档与变更文档快速**切块、嵌入、入库**。
- **TTL 与就地替换**：法规/公告类内容设定 TTL，到期后优先召回**最新版本**。
- **流式评测**：对“近 7 天热点问题”做**滚动离线评测**。

### 3.5 参数级知识更新（可选）

- **何时需要**：重复度极高、答案短、知识稳定（如术语消歧/规范模板）。
- **两条路**：
  - **轻微调**（LoRA/适配器）：把领域语气/格式/步骤写进参数。
  - **模型编辑**（ROME/MEMIT 等）：对个别事实做**外科手术式注入**。
- **注意**：参数注入要配合**外部证据优先**原则与**版本溯源**，避免“过度自信”。

## 4. KBLaM：在受限与高合规场景里的“可信 RAG”基线

当网络受限、合规要求严格，“可追溯”和“可复验”比“更会说话”重要得多。**KBLaM** 提供了一套从知识建模到审计留痕的工程底座。

> 关键词：**可信、可控、可解释**；知识是一等公民；证据链与离线可复验。

### 4.1 总体组件

1. **统一知识层**：文本库（段落/表格/图像描述）＋ **知识图谱**（实体/关系/事件）＋ 元数据（时间、密级、版本）。
2. **检索规划器**：规则 + 学习混合的**Query Planner**（意图识别→类型化检索器路由→多跳/融合策略）。
3. **证据链构建器**：把**来源 URL/文档 ID/版本/时间戳/片段 offset/图谱路径**统一封装到 Evidence Pack。
4. **生成与裁决**：抽取式生成为主，必要时调用结构化工具（SQL/规则引擎）进行**结果校验**。
5. **离线评测与审计**：自动化构造**可重复测试集**（问题—证据—答案），持续监控**正确率/忠实度/证据覆盖**。

### 4.2 最小可用流程（伪代码）

```text
INPUT: question q
1. intent = classify(q)                      # 问题类型/时效性/敏感级
2. plan = plan_query(intent)                 # 选择检索器：Text/Graph/Table/Code
3. C = retrieve_multistage(q, plan)          # BM25 + Dense + Cross-Encoder 重排
4. if plan.requires_graph:
       P = graph_paths(q, entities(C))       # 图谱路径挖掘
       C = merge(C, evidence(P))
5. E = pack_evidence(C, meta={version, time, source, offsets})
6. a0 = generate_answer(q, E)                # 以证据为主的模板化生成
7. if needs_verify(a0):
       a = verify_and_refine(a0, tools={sql, rules, calculators})
   else:
       a = a0
8. log(a, E, cost, latency, hashes)          # 审计/追溯/回放
OUTPUT: a with evidence pack
```

### 4.3 索引与检索实操建议

- **切块**：结构优先（标题/小节/表格单元），辅以语义滑窗（stride 1/3～1/2 chunk）。
- **多路召回**：BM25（强精确）、Dense（扩召回）、**专用检索器**（表格/代码/图谱）；最后用 Cross-Encoder 重排。
- **压缩提示**：把证据压成**要点清单**（带出处编号）再交给模型，减少冗余。
- **新鲜度**：增量嵌入 + TTL + 版本选择策略（“最新优先/最新且稳定/历史快照”可切换）。

## 5. 选型矩阵（2025）

| 场景 | 时效 | 结构化 | 约束 | 推荐路线 |
| --- | --- | --- | --- | --- |
| 政策法规/工艺流程问答 | 中 | 强 | 合规/可审计 | **GraphRAG + Self-RAG/RAFT**；证据包 + 抽取式生成 |
| 运维值守/告警处置 | 高 | 中 | 低联网 | **事件流 + 流式索引 + Agentic RAG**；缓存 & 限流 |
| 标准作业指导书（SOP） | 低 | 中 | 高一致性 | **轻微调 + 模板化抽取**；必要时模型编辑 |
| 舆情/行情/新闻监测 | 极高 | 弱 | 成本敏感 | **实时爬取 + BM25/Dense 混合 + 轻生成** |
| 复杂多跳推理 | 中 | 强 | 解释性 | **GraphRAG + 路径证据可视化 + ReAct/Plan-Execute** |

## 6. 评测与治理（比“是否答对”更重要）

- **Faithfulness（忠实度）**：答案是否严格来自证据？
- **Evidence Coverage（证据覆盖）**：需要几段证据？路径是否完整？
- **Groundedness（落地度）**：有无越权猜测/幻觉？
- **Latency/Cost（P95/成本）**：控制最坏时延与单问成本，上线必查。
- **Change Resilience（变更稳健）**：文档替换/版本更新后，答案是否稳定可复现？
- **审计日志**：问题→计划→证据→答案→工具调用→版本号，全链路留痕。

## 7. 实施清单（落地即可用）

- **数据治理**：脱敏/分域/分级，证据包写入来源、版本与时间戳。
- **检索基线**：BM25 + Dense + Cross-Encoder，类型化检索器（表格/代码/图）。
- **模板化生成**：Claim-Evidence 模板，答案内联 [证据编号]。
- **Agent 安全阈**：最大工具调用次数、预算/时延上限、不可调用名单。
- **离线评测**：构建 1000+ 问题的稳定集；每次部署对比基线。
- **灰度与监控**：召回命中率、重排 NDCG、P95 延迟、失败样本回灌。

> **结论**：RAG 并未过时；**可信、可控、可解释**的 RAG 正处于 2025 最佳实践的中心，KBLaM 给了在高合规/低联网环境下的“落地范式”。

## 参考与延伸阅读（官方来源）

- Self-RAG：[arXiv](https://arxiv.org/abs/2310.11511) · [OpenReview](https://openreview.net/forum?id=VplGxL2Y1c) · [GitHub](https://github.com/AkariAsai/self-rag)
- RAFT（Retrieval-Augmented Fine-Tuning, 2024）：[arXiv](https://arxiv.org/abs/2403.10131)
- RA-DIT（2023）：[arXiv](https://arxiv.org/abs/2310.01352) · [OpenReview](https://openreview.net/forum?id=3p3oI6G7pK)
- GraphRAG：[Microsoft Research Blog](https://microsoft.github.io/graphrag/blog_posts/) · [GitHub](https://github.com/microsoft/graphrag)
- MCP：[Anthropic Announcement](https://www.anthropic.com/news/model-context-protocol) · [GitHub](https://github.com/modelcontextprotocol) · [The Verge](https://www.theverge.com/2024/6/26/24185188/anthropic-model-context-protocol-mcp-ai-tool)
- Google Gemini 1.5（长上下文）：[Official Blog](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)
