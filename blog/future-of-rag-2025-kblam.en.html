<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Is RAG obsolete? 2025 roadmap from “long context” to GraphRAG, Retrieval‑Aware Training and KBLaM</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="RAG isn’t dying—naïve vector RAG with context dumping is. This updated 2025 guide explains why long context can’t replace RAG, how to modernize RAG with GraphRAG and Retrieval‑Aware Training, and how to land it with KBLaM in real systems.">
  <meta name="author" content="Fan Wan">
  <link rel="canonical" href="https://fanwan-ai.github.io/blog/future-of-rag-2025-kblam.en.html">
  <link rel="alternate" hreflang="zh" href="https://fanwan-ai.github.io/blog/future-of-rag-2025-kblam.html">
  <link rel="alternate" hreflang="en" href="https://fanwan-ai.github.io/blog/future-of-rag-2025-kblam.en.html">
  <link rel="alternate" hreflang="es" href="https://fanwan-ai.github.io/blog/future-of-rag-2025-kblam.es.html">
  <meta property="og:type" content="article">
  <meta property="og:title" content="Is RAG obsolete? 2025 roadmap from “long context” to GraphRAG, Retrieval‑Aware Training and KBLaM">
  <meta property="og:description" content="RAG isn’t dying—naïve vector RAG with context dumping is. This updated 2025 guide explains why long context can’t replace RAG, how to modernize RAG with GraphRAG and Retrieval‑Aware Training, and how to land it with KBLaM in real systems.">
  <meta property="og:url" content="https://fanwan-ai.github.io/blog/future-of-rag-2025-kblam.en.html">
  <meta property="og:image" content="https://fanwan-ai.github.io/assets/blog/rag-hero-en.v5.svg">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:secure_url" content="https://fanwan-ai.github.io/assets/blog/rag-hero-en.v5.svg">
  <meta property="og:image:type" content="image/svg+xml">
  <link rel="image_src" href="https://fanwan-ai.github.io/assets/blog/rag-hero-en.v5.svg">
  <meta itemprop="image" content="https://fanwan-ai.github.io/assets/blog/rag-hero-en.v5.svg">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Is RAG obsolete? 2025 roadmap from “long context” to GraphRAG, Retrieval‑Aware Training and KBLaM (with KBLaM)">
  <meta name="twitter:description" content="RAG isn’t dying—naïve vector RAG with context dumping is. This updated 2025 guide explains why long context can’t replace RAG, how to modernize RAG with GraphRAG and Retrieval‑Aware Training, and how to land it with KBLaM in real systems.">
  <meta name="twitter:image" content="https://fanwan-ai.github.io/assets/blog/rag-hero-en.v5.svg">
  <meta name="theme-color" content="#0f172a">
  <link rel="icon" href="../assets/logo.svg" type="image/svg+xml">
  <link rel="stylesheet" href="../style.css">
  <!-- Code highlight (Highlight.js) -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" crossorigin="anonymous" referrerpolicy="no-referrer">
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
  <!-- Math (KaTeX) -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>
  <script>try{var L='en';localStorage.setItem('lang',L);document.documentElement.setAttribute('lang',L);}catch(e){}</script>
  <script defer src="../lang.js"></script>
  <script defer src="../script.js"></script>
  <script defer src="../assets/vendor/qrcode.min.js"></script>
  <script>window.__BLOG_ORDER__ = ["future-of-rag-2025-kblam.html","kblam-project-summary.html"];</script>
</head>
<body>
  <a class="skip-link" href="#main">Skip to main content</a>
  <header>
    <nav class="navbar container">
      <a href="../index.html" class="brand" aria-label="Home">
        <img src="../assets/logo.svg" alt="Fan Wan logo" class="brand-logo" width="28" height="28" />
        <span class="logo"><span class="i18n l-zh">首页</span><span class="i18n l-en">Home</span><span class="i18n l-es">Inicio</span></span>
      </a>
      <ul class="nav-links">
        <li><a href="../index.html"><span class="icon" aria-hidden="true"><svg viewBox="0 0 24 24"><path d="M3 12l9-9 9 9"/><path d="M9 21V9h6v12"/></svg></span> <span class="i18n l-zh">首页</span><span class="i18n l-en">Home</span><span class="i18n l-es">Inicio</span></a></li>
        <li><a href="../about.html"><span class="i18n l-zh">关于我</span><span class="i18n l-en">About</span><span class="i18n l-es">Acerca de</span></a></li>
        <li><a href="../publications.html"><span class="i18n l-zh">学术出版物</span><span class="i18n l-en">Research</span><span class="i18n l-es">Investigación</span></a></li>
        <li><a href="../blog.html"><span class="i18n l-zh">博客</span><span class="i18n l-en">Blog</span><span class="i18n l-es">Blog</span></a></li>
        <li><a href="../contact.html"><span class="i18n l-zh">联系</span><span class="i18n l-en">Contact</span><span class="i18n l-es">Contacto</span></a></li>
      </ul>
      <div class="nav-actions">
        <div class="lang-switcher">
          <button id="lang-button" class="btn outline icon-btn" aria-haspopup="listbox" aria-expanded="false">
            <svg class="icon icon-globe" viewBox="0 0 24 24" aria-hidden="true"><g fill="none" stroke="currentColor" stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="9"/><path d="M3 12h18M12 3a15 15 0 0 1 0 18M12 3a15 15 0 0 0 0 18"/></g></svg>
            <span class="label"></span>
          </button>
          <ul id="lang-menu" class="lang-menu" role="listbox" aria-label="Language" hidden>
            <li role="option" data-lang="en">English</li>
            <li role="option" data-lang="zh">中文</li>
            <li role="option" data-lang="es">Español</li>
          </ul>
        </div>
        <button class="theme-toggle" id="theme-toggle" aria-label="Toggle theme" title="Toggle theme">
          <svg class="icon icon-bulb" viewBox="0 0 24 24" aria-hidden="true"><g fill="none" stroke="currentColor" stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round"><path d="M9 18h6"/><path d="M10 22h4"/><path d="M8.5 15.5c-.9-1-1.5-2.3-1.5-3.8a5 5 0 1 1 10 0c0 1.5-.6 2.8-1.5 3.8-.6.7-1.1 1.4-1.3 2.2H9.8c-.2-.8-.7-1.5-1.3-2.2z"/><path d="M12 2v2"/><path d="M4 10h2"/><path d="M18 10h2"/><path d="M5.5 5.5l1.4 1.4"/><path d="M18.5 5.5l-1.4 1.4"/></g></svg>
          <svg class="icon icon-moon" viewBox="0 0 24 24" aria-hidden="true"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z" fill="none" stroke="currentColor" stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round"/></svg>
          <svg class="icon icon-system" viewBox="0 0 24 24" aria-hidden="true"><g fill="none" stroke="currentColor" stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round"><rect x="3" y="4" width="18" height="12" rx="2" ry="2"/><path d="M8 20h8M12 16v4"/></g></svg>
        </button>
        <div class="hamburger" id="hamburger"><span></span><span></span><span></span></div>
      </div>
    </nav>
  </header>
  <main id="main" class="blog-post">
    <section class="page-hero section">
      <div class="container">
        <div class="i18n-block" data-lang="en">
          <h1 class="post-title">Is RAG obsolete? 2025 roadmap from “long context” to GraphRAG, Retrieval‑Aware Training and KBLaM</h1>
          <p class="muted post-meta">Published on 2025-09-02 · Estimated read 5 min</p>
        </div>
      </div>
    </section>
    <section class="section">
      <div class="container prose">
  <div class="post-hero-art" data-lang="en"><img src="../assets/blog/rag-hero-en.v5.svg" alt="Cover"/></div>
        <nav class="toc card" aria-label="Contents" style="padding:16px;margin:12px 0;"><strong>Contents</strong><ol></ol></nav>
        <article class="i18n-block" data-lang="en">

<h2 id="0-what-problem-does-this-article-solve">0. What problem does this article solve?</h2>

<p>Over the last year, a recurring debate has been: “If LLMs can read a million tokens in one go, do we still need retrieval‑augmented generation (RAG)?” Some argue we can just stuff everything into the prompt; others see RAG as a toolchain with plenty of room to grow.</p>

<p>This article goes beyond a yes/no answer. We explain <b>why</b> long context cannot replace RAG, <b>how</b> to modernize RAG so it stays central in 2025 and beyond, and <b>what it takes</b> to make it work in real projects. It’s our synthesis after surveying the literature and tracking enterprise practice.</p>

<p>We’ll cover:</p>

<ul>
<li><b>Real‑world constraints</b>: why long context can’t solve everything.
</li>
<li><b>Postmortems</b>: why naïve RAG fails in practice.
</li>
<li><b>The “five‑piece set”</b>: a modern engineering solution.
</li>
<li><b>Deep dives</b>: GraphRAG and Retrieval‑Aware Training.
</li>
<li><b>Deployment path</b>: how to run RAG in constrained environments (e.g., domestic servers, air‑gapped).
</li>
<li><b>Improvements and outlook</b>: where RAG should evolve next.
</li>
</ul>

<hr>

<h2 id="1-why-more-context-isnt-the-finish-line">1. Why “more context” isn’t the finish line</h2>

<p>From Gemini 1.5 to Claude 3, context windows have exploded—some to a million tokens. At first glance, that looks like “no more retrieval.” In practice, <b>a bigger backpack doesn’t make a better trip</b>.</p>

<h3 id="11-cost-and-latency-your-budget-is-finite">1.1 Cost and latency: your budget is finite</h3>

<p>More tokens mean more cost and latency. Teams report that cramming a 20k‑character document into 32k+ windows can make a single inference cost &gt;5× more. Under concurrency, P95 latency can jump from &lt;1s to several seconds—unacceptable for interactive apps (support bots, incident triage, etc.).</p>

<h3 id="12-timeliness-knowledge-updates-outrun-parameter-updates">1.2 Timeliness: knowledge updates outrun parameter updates</h3>

<p>Enterprise knowledge changes daily; finance/news/social scenarios can change by the minute. Baking facts into parameters forces frequent fine‑tuning—costly and risky. RAG keeps knowledge external and <b>hot‑swappable</b> without touching the model.</p>

<h3 id="13-compliance-and-auditability-provenance-beats-eloquence">1.3 Compliance and auditability: provenance beats eloquence</h3>

<p>Regulated domains (nuclear, power, water, finance) need not just correct answers but provenance: which doc, which clause, which release. Dump‑prompting mixes versions and loses traceability. RAG logs retrievals, snippets, versions, and timestamps—an auditable trail you can replay.</p>

<h3 id="14-privacy-and-compartmentalization-isolate-by-clearance">1.4 Privacy and compartmentalization: isolate by clearance</h3>

<p>Enterprises segment knowledge by clearance. Shoving everything into one window over‑exposes data. RAG retrieves per‑request within access control boundaries, enforcing isolation.</p>

<p><b>Bottom line</b>: long context is a bigger backpack; RAG is a live map. Real systems need both—complementary, not substitute.</p>

<hr>

<h2 id="2-why-nave-rag-crashespostmortems">2. Why naïve RAG crashes—postmortems</h2>

<p>The first RAG attempt often looks like: chunk PDFs → embed → k‑NN → take top‑k → stuff into the prompt. It “works” in demos but breaks in production. A few real‑world failure modes:</p>

<h3 id="21-vectoronly-structureblind">2.1 Vector‑only, structure‑blind</h3>

<p>After chunking equipment manuals, a team used pure vector search. Asked “What’s valve B’s maintenance interval?”, the retriever returned a “valve size comparison table”—semantically related but not answering the numeric policy. Tables and time‑series need dedicated retrievers.</p>

<h3 id="22-brutal-chunking-fragments-facts">2.2 Brutal chunking fragments facts</h3>

<p>An SOP split by fixed length sliced definitions in half. “Safety conditions: (1) pressure ≥ 0.35 MPa; (2) 35–55 ℃” got split, and the model saw only (1), missing (2).</p>

<h3 id="23-context-stuffing-adds-noise">2.3 Context stuffing adds noise</h3>

<p>Feeding 10–20 chunks “just in case” dilutes attention. In alarm triage, far more text about “principles/history” buried the actionable “steps,” yielding vague answers.</p>

<h3 id="24-freshness-reranking-auditability">2.4 Freshness, re‑ranking, auditability</h3>

<ul>
<li><b>Freshness</b>: no incremental indexing → outdated laws/notices; version policy unclear.
</li>
<li><b>Re‑ranking</b>: no cross‑encoder → “related but not sufficient” comes first.
</li>
<li><b>No audit</b>: answers lack evidence trails regulators can inspect.
</li>
</ul>

<p>The issue isn’t retrieval per se—it’s using the wrong method. Separate retrieval, evidence packaging, generation, and verification to unlock RAG’s value.</p>

<hr>

<h2 id="3-the-new-fivepiece-set-skeleton-pageflipping-tools-freshness-and-minimal-parameter-updates">3. The new “five‑piece set”: skeleton, page‑flipping, tools, freshness, and minimal parameter updates</h2>

<p>From research and deployments, mature 2025 stacks converge on five pieces, each fixing a naïve‑RAG pain point:</p>

<div class="table-wrap"><table><thead><tr><th>Component</th><th>Role</th><th>Where it shines</th><th>Challenges</th></tr></thead><tbody><tr><td>Structured retrieval (GraphRAG)</td><td>Build the knowledge skeleton</td><td>Multi‑doc hops, regulations, SOPs</td><td>KG extraction and upkeep</td></tr><tr><td>Retrieval‑aware training</td><td>Learn when/what to retrieve</td><td>QA and summarization</td><td>Training cost and data</td></tr><tr><td>Agentic orchestration</td><td>Plan multi‑step tools</td><td>Plans, queries, calculations</td><td>Safety and efficiency</td></tr><tr><td>Freshness management</td><td>Keep the index alive</td><td>News, markets, high‑timeliness</td><td>Monitoring and version policy</td></tr><tr><td>Parameter updates (optional)</td><td>Bake small, stable facts</td><td>Templates, disambiguation</td><td>Hallucinations and scope</td></tr></tbody></table></div>

<p>We’ll unpack each piece and how to land it.</p>

<hr>

<h2 id="4-structured-retrieval-graphrag-build-the-skeleton-for-stability">4. Structured retrieval (GraphRAG): build the skeleton for stability</h2>

<p>Graph‑shaped retrieval isn’t new; it’s finally practical at scale. The idea: add a <b>structured skeleton</b> (a KG or entity‑relation graph) alongside unstructured text “flesh.” Complex tasks—regulations, processes, root‑cause analysis—often follow paths along entities and relations.</p>

<h3 id="41-building-the-graph-from-text-to-skeleton">4.1 Building the graph: from text to skeleton</h3>

<p><b>Chunk + extract</b>: chunk by headings/sections/paras with a sliding window; run NER/RE to extract entities/relations into a light KG. Keep entity/edge types simple (2–3 types) to start, e.g., “article → term → applicability” or “device → component → failure mode.”</p>

<p><b>Disambiguate/merge</b>: handle same‑name/different‑entity and synonyms; use fingerprint similarity (Jaccard/Cosine) and rules (geo codes, equipment IDs). Queue low‑confidence items for review.</p>

<h3 id="42-multiretriever-crossencoder-rerank">4.2 Multi‑retriever + cross‑encoder re‑rank</h3>

<p>Combine BM25 (keyword precision) and dense retrieval (semantic recall), then re‑rank top‑K with a cross‑encoder (e.g., bge‑reranker). This slashes “sounds relevant but doesn’t answer” mistakes.</p>

<h3 id="43-path-search-turn-qa-into-route-finding">4.3 Path search: turn QA into route finding</h3>

<p>Augment candidates via KG paths. For “startup conditions of device A,” expand along components, actions, interlocks → pull matching clauses → then fetch the text spans. “Graph‑then‑text” or the inverse both work.</p>

<h3 id="44-evidence-packs-paths-spans-packaged">4.4 Evidence packs: paths + spans, packaged</h3>

<p>Return a structured evidence pack: KG path, text spans, source/ID, version, timestamp, offsets. The generator cites the pack rather than free‑for‑all context, reducing noise and yielding a clear provenance chain.</p>

<hr>

<h2 id="5-retrievalaware-training-teach-models-to-flip-pages-not-memorize">5. Retrieval‑aware training: teach models to “flip pages,” not memorize</h2>

<p>Instead of passively swallowing context, make models aware of when/what to retrieve and how to cite.</p>

<h3 id="51-selfrag-selfcheck-reretrieve-loops">5.1 Self‑RAG: self‑check + re‑retrieve loops</h3>

<p>Draft → self‑evaluate → retrieve more → refine until confidence or step cap. Great for open‑domain QA/long‑form, but control loops and budget carefully.</p>

<h3 id="52-raft-label-noise-vs-evidence-in-training">5.2 RAFT: label noise vs. evidence in training</h3>

<p>Label which retrieved chunks are distractors vs. valid evidence; require inline citations during training. The model learns to ignore noise and cite correctly.</p>

<h3 id="53-radit-twoway-learning-between-retriever-and-generator">5.3 RA‑DIT: two‑way learning between retriever and generator</h3>

<p>First fine‑tune the LLM to cite; then tune retriever parameters (dense/BM25 thresholds) using model outputs so retrieval matches model needs. Best gains, more compute.</p>

<h3 id="54-practical-path-start-small">5.4 Practical path: start small</h3>

<p>If you have annotations, start with RAFT‑style fine‑tuning on Q–A–evidence triples. With little data, bootstrap via synthetic labels then human‑review a slice. For RA‑DIT, iteratively tune recall and re‑rank stages—no need to do everything at once.</p>

<hr>

<h2 id="6-agentic-orchestration-multistep-plans-tool-calls">6. Agentic orchestration: multi‑step plans + tool calls</h2>

<p>Many tasks are not single‑turn. Think: check manual → pull telemetry → compute thresholds → compare maintenance plan → produce steps. RAG handles knowledge; an Agent handles planning and tool calls.</p>

<h3 id="61-tool-registry-and-routing">6.1 Tool registry and routing</h3>

<p>Register tools (SQL, logs, spreadsheets, external APIs) with I/O schemas and permissions. The Agent chooses tools based on intent, feeds outputs back to retrieval/LLM.</p>

<h3 id="62-safety-caps-and-budgets">6.2 Safety caps and budgets</h3>

<p>Hard caps: max 4–6 tool calls; budget per query; P95 latency limits with safe fallbacks (“evidence‑only” answers if over cap).</p>

<h3 id="63-caching-and-replay">6.3 Caching and replay</h3>

<p>Cache common intents via (intent summary + evidence hash). Log tool inputs/outputs for reproducibility and audits.</p>

<hr>

<h2 id="7-freshness-and-streaming-indexes-keep-knowledge-alive">7. Freshness and streaming indexes: keep knowledge alive</h2>

<h3 id="71-cdc-and-incremental-embeddings">7.1 CDC and incremental embeddings</h3>

<p>Capture inserts/updates/deletes; chunk/embed/update indexes hourly or faster for volatile domains.</p>

<h3 id="72-ttl-and-version-policy">7.2 TTL and version policy</h3>

<p>Different TTLs per content type and switchable policies: “latest first,” “stable first,” or “historical snapshot.”</p>

<h3 id="73-rolling-eval-and-monitoring">7.3 Rolling eval and monitoring</h3>

<p>Maintain a last‑7‑days eval set; track recall hit rate, NDCG, P95 latency, and cost. Investigate drift quickly.</p>

<hr>

<h2 id="8-parameterlevel-updates-optional">8. Parameter‑level updates (optional)</h2>

<p>Use LoRA/adapters for style/templates; surgical editing for rare fact fixes. Always keep evidence‑first generation to avoid overconfidence.</p>

<hr>

<h2 id="9-kblam-a-trustworthy-baseline-for-constrained-environments">9. KBLaM: a trustworthy baseline for constrained environments</h2>

<p>We’ve deployed KBLaM on domestic servers with external retrieval and structural encodings. Ideas worth borrowing for “trustworthy, controllable, explainable” RAG.</p>

<h3 id="91-unified-knowledge-layer-text-tables-graphs-metadata">9.1 Unified knowledge layer: text, tables, graphs, metadata</h3>

<p>Unify modalities; use multi‑modal embeddings into one space; record provenance metadata (source/version/time/clearance).</p>

<h3 id="92-evidence-chain-question-evidence-answer">9.2 Evidence chain: question → evidence → answer</h3>

<p>Route by intent; retrieve/re‑rank; expand via KG; build evidence packs (source/version/path/offsets); generate; verify via SQL/rules if needed; log for audits.</p>

<h3 id="93-minimal-viable-flow-pseudo">9.3 Minimal viable flow (pseudo)</h3>

<pre><code class="language-python">
def answer(question):
  intent = classify(question)
  route = select_route(intent)
  candidates = retrieve(question, route)
  if intent.requires_graph:
    path = graph_search(candidates)
    candidates = merge(candidates, path)
  evidence = pack(candidates)
  draft = generate(question, evidence)
  if need_verify(draft):
    ans = verify_and_refine(draft)
  else:
    ans = draft
  log(question, evidence, ans)
  return ans
</code></pre>

<hr>

<h2 id="10-cost-model-and-examples-do-the-math">10. Cost model and examples: do the math</h2>

<h3 id="101-input-tokens-dominate">10.1 Input tokens dominate</h3>

<p>“Dump context” may push inputs to 30k+ tokens; an evidence‑pack approach often needs 1–3 spans (~500–700 tokens each) → ~1.5k–2.1k total—often <b>10× less</b>.</p>

<h3 id="102-retrieval-adds-a-little-cost-saves-a-lot">10.2 Retrieval adds a little cost, saves a lot</h3>

<p>BM25/dense retrieval is cheap; cross‑encoder re‑rankers are small and CPU‑friendly. Overall, “retrieve then generate” wins in most cases.</p>

<h3 id="103-capability-vs-cost-tradeoffs">10.3 Capability vs. cost trade‑offs</h3>

<p>For content creation or truly long citations, hybrid strategies shine: RAG for facts, long context for free‑form prose. Count tokens/calls/costs and choose per need.</p>

<hr>

<h2 id="11-implementation-checklist-from-prototype-to-production">11. Implementation checklist: from prototype to production</h2>

<ol>
<li><b>Data governance</b>: scrub PII; classify by clearance; track source/version.
</li>
<li><b>Chunking</b>: section‑based with sliding windows.
</li>
<li><b>Retrieval baseline</b>: BM25 + dense + re‑rank; add table/code/figure retrievers.
</li>
<li><b>Evidence packs</b>: include <code>source_id</code>, <code>url</code>, <code>version</code>, <code>timestamp</code>, <code>offset</code>, <code>path</code>, with a unique <code>answer_id</code>.
</li>
<li><b>Generation templates</b>: claim‑evidence style with inline citations.
</li>
<li><b>Agent caps</b>: tool list, step/budget limits; cache frequent queries.
</li>
<li><b>Freshness</b>: incremental crawl/embeddings; TTL and version policies; rolling eval.
</li>
<li><b>Monitoring/replay</b>: dashboards for recall/NDCG/P95/cost; replay question→evidence→answer→tools.
</li>
<li><b>Gray release</b>: canary new models/strategies; compare to baseline; ramp up gradually.
</li>
<li><b>Team ops</b>: clear owners for retrieval/KG/training/infra; fast feedback loops.
</li>
</ol>

<hr>

<h2 id="12-next-stops-where-rag-should-evolve">12. Next stops: where RAG should evolve</h2>

<h3 id="121-dynamic-retrieval-and-gating">12.1 Dynamic retrieval and gating</h3>

<p>Scale brings cost; add ExpertRAG‑style gating: only retrieve when internal knowledge is insufficient, and activate sparse “experts” per query.</p>

<h3 id="122-hierarchical-or-hybrid-retrieval">12.2 Hierarchical or hybrid retrieval</h3>

<p>Two‑stage “coarse → fine” pipelines (doc‑level sparse → in‑doc dense → cross‑encoder) help multi‑hop tasks (cf. HiRAG).</p>

<h3 id="123-preserve-structure-in-knowledge-encodings">12.3 Preserve structure in knowledge encodings</h3>

<p>Avoid compressing KGs into a single vector; encode triples or subgraphs; add numeric/date encodings; chain paths with CoT.</p>

<h3 id="124-adaptive-compression-and-knowledge-selection">12.4 Adaptive compression and knowledge selection</h3>

<p>Allocate vector capacity by importance (access frequency, confidence, business value); drop irrelevant tokens—MoE‑style routing.</p>

<h3 id="125-multilingual-and-crosslingual-retrieval">12.5 Multilingual and cross‑lingual retrieval</h3>

<p>Use multilingual embeddings (e.g., gtr/multi‑qa‑mpnet) with language tags/gates; cross‑lingual reasoning is the hard part.</p>

<h3 id="126-external-checks-and-selfconsistency">12.6 External checks and self‑consistency</h3>

<p>Post‑answer verification via graph/SQL; re‑retrieve or abstain on contradictions; check KG path coherence; optional web cross‑checks.</p>

<hr>

<h2 id="13-conclusion-the-map-wont-go-out-of-style">13. Conclusion: the map won’t go out of style</h2>

<p>RAG addresses “finding and citing knowledge,” largely orthogonal to window size. Long context helps, but not with cost, timeliness, audits, or privacy—and not with multi‑step structured tasks.</p>

<p>The 2025 “five‑piece set” emerges: skeleton + page‑flipping + tools + freshness + modest parameter updates. GraphRAG guides complex paths; retrieval‑aware training teaches citation; agents manage plans; freshness prevents staleness; small parameter updates help templates. KBLaM’s unified layer, evidence packs, and audit trails offer a deployment blueprint for regulated settings.</p>

<p>With dynamic gating, hierarchical retrieval, structured encodings, adaptive compression, and multilingual capability, RAG will keep evolving—likely fusing deeper with knowledge‑injection models like KBLaM. One constant remains: <b>under budget and in complex settings, retrieval is the LLM’s most reliable partner</b>. Bring a live map; any backpack gets lighter.</p>

<hr>

<h2 id="references-recommended-reading">References (recommended reading)</h2>

<ol>
<li>Akari Asai et al., <b>Self‑RAG</b>, arXiv, 2024.
</li>
<li>Microsoft Research, <b>GraphRAG</b>, 2024.
</li>
<li>Naman Bansal, <b>Best Open‑Source Embedding Models Benchmarked and Ranked</b>, Supermemory Blog, 2025.
</li>
<li>Haoyu Huang et al., <b>HiRAG: Retrieval‑Augmented Generation with Hierarchical Knowledge</b>, arXiv, 2025.
</li>
<li>Esmail Gumaan, <b>ExpertRAG: Efficient RAG with Mixture of Experts</b>, arXiv, 2025.
</li>
<li>Hang Luo et al., <b>Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph‑Augmented LLMs</b>, arXiv, 2025.
</li>
<li>Wei Liu et al., <b>XRAG: Cross‑lingual Retrieval‑Augmented Generation</b>, arXiv, 2025.
</li>
</ol>

        </article>
  <div class="share-toolbar card" style="margin-top:24px;padding:12px 16px;display:flex;gap:8px;align-items:center;flex-wrap:wrap">
          <strong class="share-title" data-i18n="share_label">Share</strong>
          <div class="spacer" style="flex:0 0 8px"></div>
          <button class="btn outline share-btn" data-share="wechat">
            <svg class="icon" viewBox="0 0 24 24" aria-hidden="true" focusable="false"><path d="M7.5 3C4.46 3 2 5.08 2 7.65c0 1.52.84 2.88 2.15 3.8l-.53 1.93 2.06-1.24c.56.14 1.15.21 1.77.21 3.04 0 5.5-2.08 5.5-4.65S10.54 3 7.5 3zm-1.4 3.6a.9.9 0 110 1.8.9.9 0 010-1.8zm3.8 0a.9.9 0 110 1.8.9.9 0 010-1.8zM16.5 10c-2.86 0-5.17 1.86-5.17 4.15 0 1.27.7 2.4 1.78 3.17l-.44 1.6 1.72-1.03c.47.12.97.18 1.48.18 2.86 0 5.17-1.86 5.17-4.15S19.36 10 16.5 10zm-1.2 2.7a.9.9 0 110 1.8.9.9 0 010-1.8zm3.6 0a.9.9 0 110 1.8.9.9 0 010-1.8z" fill="currentColor" stroke="none"></path></svg>
            <span data-i18n="share_wechat">WeChat</span>
          </button>
          <a class="btn outline share-btn" data-share="whatsapp" target="_blank" rel="noopener"><svg class="icon" viewBox="0 0 24 24" aria-hidden="true"><path d="M20 12a8 8 0 1 1-14.32 4.906L4 21l4.2-1.11A8 8 0 1 1 20 12z" fill="none" stroke="currentColor" stroke-width="1.8" stroke-linecap="round" stroke-linejoin="round"/><path d="M8.5 9.5c.5 2 2.5 3.5 4 4l1.2-.8c.3-.2.7-.1.9.2l.7 1.1c.2.3.1.7-.2.9-1 .7-2.1 1.1-3.3 1.1-2.9 0-5.3-2.4-5.3-5.3 0-1.2.4-2.3 1.1-3.3.2-.3.6-.4.9-.2l1.1.7c.3.2.4.6.2.9l-.8 1.2z"/></svg>
            <span data-i18n="share_whatsapp">WhatsApp</span></a>
          <button class="btn outline share-btn" data-share="copy"><svg class="icon" viewBox="0 0 24 24" aria-hidden="true"><rect x="9" y="9" width="10" height="10" rx="2"/><rect x="5" y="5" width="10" height="10" rx="2"/></svg>
            <span data-i18n="share_copy">Copy link</span></button>
          <button class="btn outline share-btn" data-share="native"><svg class="icon" viewBox="0 0 24 24" aria-hidden="true"><path d="M4 12v7a1 1 0 0 0 1 1h14a1 1 0 0 0 1-1v-7"/><path d="M12 16V3"/><path d="M8 7l4-4 4 4"/></svg>
            <span data-i18n="share_share">Share…</span></button>
        </div>
        <div id="share-modal" class="modal" hidden>
          <div class="modal-content card" role="dialog" aria-modal="true" aria-labelledby="share-title">
            <div style="display:flex;align-items:center;justify-content:space-between;gap:12px">
              <h3 id="share-title" data-i18n="share_wechat">WeChat</h3>
              <button class="btn outline" data-close><span data-i18n="share_close">Close</span></button>
            </div>
            <p class="muted" style="margin:8px 0" data-i18n="share_wechat_qr_tip">Scan in WeChat to share this post</p>
            <div id="qr" style="display:grid;place-items:center;padding:12px"></div>
          </div>
        </div>
        <hr style="margin: 24px 0">
        <nav class="post-nav" aria-label="Post navigation">
          <a class="btn outline" href="../blog.html">← Back to Blog</a>
          <a class="btn outline" href="#" aria-disabled="true" onclick="return false;">Previous</a>
          <a class="btn outline" href="./kblam-project-summary.en.html">Next</a>
        </nav>
      </div>
    </section>
  </main>
  <footer>
    <div class="container"><p>© <span id="year"></span> Fan Wan</p></div>
  </footer>
  <script>
    (function(){
      if (window.hljs) { try { window.hljs.highlightAll(); } catch(e){} }
      function render(){ try { if (window.renderMathInElement) window.renderMathInElement(document.body, { delimiters:[{left:'$$', right:'$$', display:true},{left:'$', right:'$', display:false}] }); } catch(e){} }
      if (document.readyState === 'loading') document.addEventListener('DOMContentLoaded', render); else render();
    })();
  </script>
</body>
</html>